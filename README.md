# Malicious Prompt-Classification
## Overview
This project automates malicious prompt classification and synthetic prompt generation for ParsonsGPT. The pipeline extracts compliance-related words and phrases from company policy documents, generates flagged and non-flagged prompts, and validates them using Legal-BERT against existing labeled prompts.

## Step-by-Step Breakdown

### 1ï¸. Extracting Malicious Terms (`1_scrape_documents.ipynb`)
**Goal:** Extract keywords and phrases from Parsons' policy documents.

**Methods:**
- **TF-IDF + Regex** â†’ Extracts compliance-related terms.
- **spaCy NER** â†’ Detects HR, Legal, and Ethics-related entities.
- **Legal-BERT** â†’ Assigns department labels and flagging status based on extracted words.

**Output:**
- `data/outputs/word_label_bank.csv`

---

### 2ï¸. Generating Synthetic Prompts (`2_generate_prompts.ipynb`)
**Goal:** Generate both malicious and non-malicious prompts based on the extracted word-label pairs.

**Methods:**
- **FLAN-T5** â†’ Zero-shot & fine-tunable prompt generation.
- **User-defined parameters:**
  - Department: (HR, Legal, Security, etc.)
  - Number of prompts to generate
  - Malicious vs. Non-Malicious Ratio

**Output:**
- `data/outputs/generated_prompts.csv`

---

### 3ï¸. Validating Generated Prompts (`3_validate_prompts.ipynb`)
**Goal:** Ensure synthetic prompts align with real flagged queries.

**Methods:**
- **Legal-BERT similarity scoring:**
  - If similarity < 0.75, discard.
  - If similarity > 0.85, confirm as a high-confidence match.
- Adds similarity score column to dataset.

**Output:**
- `data/outputs/final_dataset.csv`

---

## Python Scripts in `models/`

| Script                  | Purpose                                          |
|-------------------------|--------------------------------------------------|
| `bert_similarity.py`    | Computes Legal-BERT similarity between prompts. |
| `flan_t5_prompt_gen.py` | Runs FLAN-T5 to generate synthetic prompts.     |
| `tfidf_extraction.py`   | Extracts compliance terms using TF-IDF + Regex. |

### Running Scripts
Scripts can be executed in the background if needed:
```sh
python models/tfidf_extraction.py
python models/flan_t5_prompt_gen.py --num_prompts 100 --label HR --malicious_ratio 0.5
python models/bert_similarity.py --input data/outputs/generated_prompts.csv
```

---

## Usage

### Step 1: Install Environment
```sh
conda env create -f environment.yml
conda activate malicious_prompt_env
```

### Step 2: Generate the Word/Phrase-Label Bank
```sh
python models/tfidf_extraction.py
```
**Output:** `data/outputs/word_label_bank.csv`

### Step 3: Generate Synthetic Prompts
```sh
python models/flan_t5_prompt_gen.py --num_prompts 100 --label HR --malicious_ratio 0.5
```
**Output:** `data/outputs/generated_prompts.csv`

### Step 4: Validate Prompts with Legal-BERT
```sh
python models/bert_similarity.py --input data/outputs/generated_prompts.csv
```
**Output:** `data/outputs/final_dataset.csv`

---

## Summary
âœ” **Document Scraping:** TF-IDF + Regex, spaCy NER, Legal-BERT  
âœ” **Prompt Generation:** FLAN-T5 (zero-shot, parameter-tunable)  
âœ” **Validation & Labeling:** Legal-BERT (high-confidence scoring)  

This setup ensures a scalable, modular, and intuitive pipeline that allows any user to generate and validate malicious prompt data for ParsonsGPT.

---

## Final Repository Structure
```bash
ğŸ“‚ malicious_prompt_classification
â”‚â”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ policy_documents/   # User-uploaded policy documents (INPUT ONLY)
â”‚   â”œâ”€â”€ outputs/            # Stores all generated CSV files
â”‚   â”‚   â”œâ”€â”€ word_label_bank.csv  # Extracted words & phrases
â”‚   â”‚   â”œâ”€â”€ generated_prompts.csv  # GPT-generated prompts
â”‚   â”‚   â”œâ”€â”€ final_dataset.csv  # Final validated dataset
â”‚
â”‚â”€â”€ ğŸ“‚ models/
â”‚   â”œâ”€â”€ bert_similarity.py  # Legal-BERT similarity checker
â”‚   â”œâ”€â”€ flan_t5_prompt_gen.py   # FLAN-T5-based prompt generation
â”‚   â”œâ”€â”€ tfidf_extraction.py # TF-IDF + Regex-based term extraction
â”‚
â”‚â”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ 1_scrape_documents.ipynb  # Extract word-label bank
â”‚   â”œâ”€â”€ 2_generate_prompts.ipynb  # Generate flagged & non-flagged prompts
â”‚   â”œâ”€â”€ 3_validate_prompts.ipynb  # Compare and validate generated prompts
â”‚
â”‚â”€â”€ environment.yml   # Conda environment file
â”‚â”€â”€ README.md

