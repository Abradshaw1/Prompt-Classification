{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Original dataset size: 76822 rows\n",
      "Dropped 289 rows due to negative similarity.\n",
      "Dropped 60 duplicate prompt rows.\n",
      "Final cleaned dataset size: 76473 rows\n",
      "Saved cleaned dataset to: ../data/outputs/step1_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# READ IN DATASET AND CLEAR THE NEGATIVE SIMALAROITY SCORES\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_FILE = \"../data/outputs/validation_and_cleaning/FINAL_validated_prompts_with_similarity_MPnet.csv\"\n",
    "OUTPUT_FILE = \"../data/outputs/validation_and_cleaning/step1_cleaned_data.csv\"\n",
    "SIMILARITY_COLUMN = \"Similarity Score\"  # Modify if column name differs\n",
    "PROMPT_COLUMN = \"Prompt\"  # Column that contains the actual prompt text\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def filter_negative_similarity(df, column_name):\n",
    "    before = len(df)\n",
    "    df_filtered = df[df[column_name] >= 0].reset_index(drop=True)\n",
    "    dropped = before - len(df_filtered)\n",
    "    print(f\"Dropped {dropped} rows due to negative similarity.\")\n",
    "    return df_filtered\n",
    "\n",
    "def drop_duplicate_prompts(df, column_name):\n",
    "    before = len(df)\n",
    "    df_deduped = df.drop_duplicates(subset=column_name).reset_index(drop=True)\n",
    "    dropped = before - len(df_deduped)\n",
    "    print(f\"Dropped {dropped} duplicate prompt rows.\")\n",
    "    return df_deduped\n",
    "\n",
    "def save_dataset(df, filepath):\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "def main():\n",
    "    print(\"Loading dataset...\")\n",
    "    df = load_dataset(INPUT_FILE)\n",
    "    print(f\"Original dataset size: {len(df)} rows\")\n",
    "\n",
    "    df = filter_negative_similarity(df, SIMILARITY_COLUMN)\n",
    "    df = drop_duplicate_prompts(df, PROMPT_COLUMN)\n",
    "\n",
    "    print(f\"Final cleaned dataset size: {len(df)} rows\")\n",
    "    save_dataset(df, OUTPUT_FILE)\n",
    "    print(f\"Saved cleaned dataset to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input dataset...\n",
      "Initial dataset size: 76473 rows\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Malicious 0/1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/malicious_prompt_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Malicious 0/1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved re-labeled prompts to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRELABELED_PROMPTS_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 82\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(INPUT_FILE)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m df, relabeled_df \u001b[38;5;241m=\u001b[39m \u001b[43mrelabel_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of prompts re-labeled from 0 to 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(relabeled_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(OUTPUT_FILE, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 64\u001b[0m, in \u001b[0;36mrelabel_prompts\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     61\u001b[0m re_labeled_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLABEL_COLUMN\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     65\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m row[PROMPT_COLUMN]\n\u001b[1;32m     66\u001b[0m         matched_category \u001b[38;5;241m=\u001b[39m match_any_category(prompt)\n",
      "File \u001b[0;32m~/anaconda3/envs/malicious_prompt_env/lib/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/envs/malicious_prompt_env/lib/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/envs/malicious_prompt_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Malicious 0/1'"
     ]
    }
   ],
   "source": [
    "# RELABEL DATA BASED ON EXPLANATION-INFORMED CATEGORY MATCHING\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_FILE = \"../data/outputs/validation_and_cleaning/step1_cleaned_data.csv\"\n",
    "OUTPUT_FILE = \"../data/outputs/validation_and_cleaning/step2_cleaned_data.csv\"\n",
    "RELABELED_PROMPTS_FILE = \"../data/outputs/validation_and_cleaning/subset_relabeled_prompts_with_rule.csv\"\n",
    "\n",
    "PROMPT_COLUMN = \"Prompt\"\n",
    "LABEL_COLUMN = \"Malicious (0/1)\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Explanation-Informed Rule Categories from Manual WHYs\n",
    "# -------------------------------------------------------\n",
    "CATEGORY_PATTERNS = {\n",
    "    \"internal_policy_request\": [\n",
    "        r\"\\bparsons\\b.*(standard|policy|procedure|rule|process)\",\n",
    "        r\"\\binternal (compliance|reporting|workflow|guidelines)\",\n",
    "        r\"\\bhow does parsons (handle|deal with|respond to)\"\n",
    "    ],\n",
    "    \"legal_guidance_request\": [\n",
    "        r\"\\blegal (implication|advice|requirement|approval)\",\n",
    "        r\"\\bdo I need to report.*(law|legal)\",\n",
    "        r\"\\bcan parsons (represent|advise|sue|approve)\"\n",
    "    ],\n",
    "    \"security_breach_attempt\": [\n",
    "        r\"\\bbypass\\b.*(security|logs|detection)\",\n",
    "        r\"\\bdelete\\b.*(logs|history|evidence)\",\n",
    "        r\"\\bcover (my )?tracks\\b\",\n",
    "        r\"\\berase\\b.*(audit trail|activity)\",\n",
    "        r\"\\banonymize (my|this) access\"\n",
    "    ],\n",
    "    \"impersonation_or_misuse\": [\n",
    "        r\"\\bimpersonate\\b\",\n",
    "        r\"\\bpretend to be\\b\",\n",
    "        r\"\\bact like\\b\",\n",
    "        r\"\\bforge (identity|credentials)\"\n",
    "    ],\n",
    "    \"ethics_sensitive_request\": [\n",
    "        r\"\\bwhistleblow(er|ing)?\\b\",\n",
    "        r\"\\breport misconduct\\b\",\n",
    "        r\"\\bfile (a )?complaint\\b\",\n",
    "        r\"\\bretaliation\\b\",\n",
    "        r\"\\bunethical behavior\\b\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def match_any_category(text):\n",
    "    \"\"\"Check if the prompt matches any explanation-driven category.\"\"\"\n",
    "    text = text.lower()\n",
    "    for category, patterns in CATEGORY_PATTERNS.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, text):\n",
    "                return category\n",
    "    return None\n",
    "\n",
    "\n",
    "def relabel_prompts(df):\n",
    "    \"\"\"Re-label prompts that match any rule category.\"\"\"\n",
    "    re_labeled_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[LABEL_COLUMN] == 0:\n",
    "            prompt = row[PROMPT_COLUMN]\n",
    "            matched_category = match_any_category(prompt)\n",
    "            if matched_category:\n",
    "                df.at[idx, LABEL_COLUMN] = 1\n",
    "                re_labeled_rows.append({\n",
    "                    PROMPT_COLUMN: prompt,\n",
    "                    \"Rule Matched\": matched_category\n",
    "                })\n",
    "\n",
    "    return df, pd.DataFrame(re_labeled_rows)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Reading input dataset...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    print(f\"Initial dataset size: {len(df)} rows\")\n",
    "\n",
    "    df, relabeled_df = relabel_prompts(df)\n",
    "\n",
    "    print(f\"Number of prompts re-labeled from 0 to 1: {len(relabeled_df)}\")\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    relabeled_df.to_csv(RELABELED_PROMPTS_FILE, index=False)\n",
    "\n",
    "    print(f\"Saved relabeled dataset to: {OUTPUT_FILE}\")\n",
    "    print(f\"Saved re-labeled prompts to: {RELABELED_PROMPTS_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malicious_prompt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
