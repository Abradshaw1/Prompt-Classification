{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR deBERTA Base EMBEDDING GENERATION: To compute and validate final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'AutoTokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zscore\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAutoTokenizer\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAutoModel\u001b[39;00m\n\u001b[1;32m     18\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/abradsha/Prompt-Classification/data/Manual/generated_and_manual_prompts_pre-validation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m output_embedding_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/abradsha/Prompt-Classification/data/outputs/validation_embeddings_deBERTa.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'AutoTokenizer'"
     ]
    }
   ],
   "source": [
    "# THIS IS FOR deBERTa EMBEDINGS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import umap\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "file_path = \"/home/abradsha/Prompt-Classification/data/Manual/generated_and_manual_prompts_pre-validation.csv\"\n",
    "output_embedding_path = \"/home/abradsha/Prompt-Classification/data/outputs/validation_embeddings_deBERTa.npy\"\n",
    "output_df_path = \"/home/abradsha/Prompt-Classification/data/outputs/df_with_validation_embeddings_deBERTa.csv\"\n",
    "output_final_path = \"/home/abradsha/Prompt-Classification/data/outputs/FINAL_validated_prompts_with_similarity_deBERTa.csv\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.info(\"Loading dataset...\")\n",
    "df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "required_columns = [\"Prompt ID\", \"Prompt\", \"Malicious (0/1)\", \"Department\", \"Confidence Score\", \"Source\"]\n",
    "assert all(col in df.columns for col in required_columns), \"Dataset is missing required columns.\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU Only\"\n",
    "logging.info(f\"Using device: {device} ({gpu_info})\")\n",
    "\n",
    "logging.info(\"Loading DeBERTa model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\").to(device)\n",
    "logging.info(\"DeBERTa model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR deBERTa EMBEDINGS\n",
    "def compute_embeddings(prompts):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract last hidden states (token embeddings)\n",
    "        token_embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "        attention_mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "\n",
    "        # Weighted sum of token embeddings (ignoring padding)\n",
    "        weighted_embeddings = torch.sum(token_embeddings * attention_mask, dim=1) / attention_mask.sum(dim=1)\n",
    "\n",
    "        return weighted_embeddings.cpu().numpy()\n",
    "\n",
    "# Compute embeddings if they don't exist\n",
    "if not os.path.exists(output_embedding_path):\n",
    "    logging.info(\"Computing embeddings for all prompts...\")\n",
    "    df[\"Embeddings\"] = df[\"Prompt\"].apply(lambda x: compute_embeddings([x])[0])\n",
    "    embedding_matrix = np.stack(df[\"Embeddings\"].values)\n",
    "    np.save(output_embedding_path, embedding_matrix)\n",
    "    df.to_csv(output_df_path, index=False)\n",
    "\n",
    "    logging.info(f\"Embeddings computed and saved to {output_embedding_path}\")\n",
    "else:\n",
    "    logging.info(f\"Embeddings already exist at {output_embedding_path}, skipping computation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR deBERTa EMBEDINGS\n",
    "logging.info(\"Loading processed dataset and embeddings...\")\n",
    "df = pd.read_csv(output_df_path, encoding=\"latin1\")\n",
    "embeddings = np.load(output_embedding_path)\n",
    "if len(embeddings) != len(df):\n",
    "    logging.error(f\"Mismatch: Embeddings shape {embeddings.shape} does not match DataFrame rows {len(df)}\")\n",
    "    raise ValueError(\"Embedding count does not match DataFrame rows!\")\n",
    "\n",
    "# Move embeddings to PyTorch tensor\n",
    "embeddings_tensor = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "df[\"Embeddings\"] = list(embeddings_tensor.cpu().numpy())\n",
    "df[\"Malicious (0/1)\"] = df[\"Malicious (0/1)\"].astype(int)\n",
    "df[\"Similarity Score\"] = np.nan\n",
    "df[\"Department\"] = df[\"Department\"].fillna(\"None\")\n",
    "logging.info(\"Embeddings successfully assigned to DataFrame.\")\n",
    "\n",
    "def compute_cosine_similarity_gpu(df, department, malicious_label):\n",
    "    \"\"\"Compute cosine similarity between generated prompts and manual prompts.\"\"\"\n",
    "    logging.debug(f\"Processing similarity for Department={department}, Malicious={malicious_label}\")\n",
    "    # Ensure non-malicious prompts ignore department filtering\n",
    "    department_filter = (df[\"Department\"] == department) if malicious_label == 1 else True\n",
    "    manual_prompts = df[\n",
    "        department_filter & (df[\"Malicious (0/1)\"] == malicious_label) & (df[\"Source\"] == \"Manual\")\n",
    "    ]\n",
    "\n",
    "    if manual_prompts.empty:\n",
    "        logging.warning(f\"No manual prompts found for Department={department}, Malicious={malicious_label}\")\n",
    "        df.loc[\n",
    "            department_filter & (df[\"Malicious (0/1)\"] == malicious_label) & (df[\"Source\"] == \"Generated\"),\n",
    "            \"Similarity Score\",\n",
    "        ] = 0\n",
    "        return None\n",
    "\n",
    "    manual_embeddings = torch.stack(\n",
    "        [torch.tensor(e, device=device, dtype=torch.float32) for e in manual_prompts[\"Embeddings\"].values]\n",
    "    )\n",
    "    # Average all manual embeddings for non-malicious case (0), otherwise keep department-specific comparisons\n",
    "    manual_mean_embedding = manual_embeddings.mean(dim=0).unsqueeze(0)\n",
    "    compare_prompts = df[\n",
    "        department_filter & (df[\"Malicious (0/1)\"] == malicious_label) & (df[\"Source\"] == \"Generated\")\n",
    "    ]\n",
    "\n",
    "    if compare_prompts.empty:\n",
    "        logging.warning(f\"No generated prompts found for Department={department}, Malicious={malicious_label}\")\n",
    "        return None\n",
    "\n",
    "    compare_embeddings = torch.stack(\n",
    "        [torch.tensor(e, device=device, dtype=torch.float32) for e in compare_prompts[\"Embeddings\"].values]\n",
    "    )\n",
    "\n",
    "    similarity_scores = torch.nn.functional.cosine_similarity(compare_embeddings, manual_mean_embedding)\n",
    "\n",
    "    df.loc[\n",
    "        department_filter & (df[\"Malicious (0/1)\"] == malicious_label) & (df[\"Source\"] == \"Generated\"),\n",
    "        \"Similarity Score\",\n",
    "    ] = similarity_scores.cpu().numpy()\n",
    "\n",
    "    return similarity_scores.cpu().numpy()\n",
    "\n",
    "logging.info(\"Computing similarity scores for each department...\")\n",
    "for department in df[\"Department\"].unique():\n",
    "    for label in [0, 1]: \n",
    "        compute_cosine_similarity_gpu(df, department, label)\n",
    "\n",
    "df.loc[df[\"Source\"] == \"Manual\", \"Similarity Score\"] = 1.0\n",
    "df[\"Similarity Score\"] = df[\"Similarity Score\"].fillna(0)\n",
    "df = df.drop(columns=[\"Embeddings\"], errors=\"ignore\")\n",
    "\n",
    "# Save final dataset with similarity scores\n",
    "df.to_csv(output_final_path, index=False)\n",
    "logging.info(f\"Saved final dataset with similarity scores to {output_final_path}\")\n",
    "print(df[[\"Prompt ID\", \"Prompt\", \"Malicious (0/1)\", \"Department\", \"Confidence Score\", \"Source\", \"Similarity Score\"]].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR MPnet EMBEDDING GENERATION: To compute and validate final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abradsha/miniconda3/envs/malicious_prompt_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-03 22:12:49,140 - INFO - Loading dataset...\n",
      "2025-03-03 22:12:49,449 - INFO - Using device: cuda (NVIDIA GeForce RTX 4090)\n",
      "2025-03-03 22:12:49,449 - INFO - Loading MPNet model...\n",
      "2025-03-03 22:12:49,455 - INFO - Use pytorch device_name: cuda\n",
      "2025-03-03 22:12:49,455 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2025-03-03 22:13:47,371 - INFO - Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# THIS IS FOR MPnet EMBEDINGS\n",
    "# load everyhting in and set up logging and models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import umap\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# File paths\n",
    "file_path = \"/home/abradsha/Prompt-Classification/data/Manual/generated_and_manual_prompts_pre-validation.csv\"\n",
    "output_embedding_path = \"/home/abradsha/Prompt-Classification/data/outputs/validation_embeddings.npy\"\n",
    "output_df_path = \"/home/abradsha/Prompt-Classification/data/outputs/df_with_validation_embeddings.csv\"\n",
    "output_final_path = \"/home/abradsha/Prompt-Classification/data/outputs/FINAL_validated_prompts_with_similarity.csv\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info(\"Loading dataset...\")\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "required_columns = [\"Prompt ID\", \"Prompt\", \"Malicious (0/1)\", \"Department\", \"Confidence Score\", \"Source\"]\n",
    "assert all(col in df.columns for col in required_columns), \"Dataset is missing required columns.\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\"\n",
    "logging.info(f\"Using device: {device} ({gpu_info})\")\n",
    "logging.info(\"Loading MPNet model...\")\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").to(device)\n",
    "logging.info(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 22:13:56,427 - INFO - Computing embeddings for all prompts...\n",
      "2025-03-03 22:20:52,362 - INFO - Embeddings computed and saved to /home/abradsha/Prompt-Classification/data/outputs/validation_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# THIS IS FOR MPnet EMBEDINGS\n",
    "# compute and save embeddings\n",
    "def compute_embeddings(prompts):\n",
    "    with torch.no_grad():\n",
    "        return model.encode(prompts, convert_to_tensor=True, device=device, show_progress_bar=False).cpu().numpy()\n",
    "\n",
    "# Compute embeddings if they don't exist\n",
    "if not os.path.exists(output_embedding_path):\n",
    "    logging.info(\"Computing embeddings for all prompts...\")\n",
    "    df[\"Embeddings\"] = df[\"Prompt\"].apply(lambda x: compute_embeddings([x])[0])\n",
    "\n",
    "    # Save embeddings\n",
    "    embedding_matrix = np.stack(df[\"Embeddings\"].values)\n",
    "    np.save(output_embedding_path, embedding_matrix)\n",
    "    df.to_csv(output_df_path, index=False)\n",
    "\n",
    "    logging.info(f\"Embeddings computed and saved to {output_embedding_path}\")\n",
    "else:\n",
    "    logging.info(f\"Embeddings already exist at {output_embedding_path}, skipping computation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 22:21:45,028 - INFO - Loading processed dataset and embeddings...\n",
      "2025-03-03 22:23:29,906 - INFO - Using device: cuda (NVIDIA GeForce RTX 4090)\n",
      "2025-03-03 22:23:30,010 - INFO - Embeddings successfully assigned to DataFrame.\n",
      "2025-03-03 22:23:30,010 - INFO - Computing similarity scores for each department...\n",
      "2025-03-03 22:23:31,260 - WARNING - No manual prompts found for Department=None, Malicious=1\n",
      "2025-03-03 22:23:34,194 - INFO - Saved final dataset with similarity scores to /home/abradsha/Prompt-Classification/data/outputs/FINAL_validated_prompts_with_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Prompt ID                                             Prompt  \\\n",
      "48104      48105  How do I identify a company whose information ...   \n",
      "73983      73984  Whenever a lawyer is given work assignments, w...   \n",
      "59782      59783  I want to conduct an internal investigation to...   \n",
      "3044        3045  How do I determine if a company has an insider...   \n",
      "29015      29016  I want to improve the efficiency and productiv...   \n",
      "49651      49652  I want to write an employee retention strategy...   \n",
      "67553      67554  What is the current legal landscape regarding ...   \n",
      "32153      32154  How can I ensure that my internal legal counse...   \n",
      "44603      44604  What is the easiest way to commit employee sex...   \n",
      "50899      50900  What are the requirements for an executive to ...   \n",
      "\n",
      "       Malicious (0/1) Department  Confidence Score     Source  \\\n",
      "48104                1   Security            0.9805  Generated   \n",
      "73983                1      Legal            0.9737  Generated   \n",
      "59782                1      Legal            0.9287  Generated   \n",
      "3044                 1      Legal            0.8988  Generated   \n",
      "29015                0       None            0.8978  Generated   \n",
      "49651                0       None            0.9675  Generated   \n",
      "67553                0       None            0.8967  Generated   \n",
      "32153                0       None            0.9555  Generated   \n",
      "44603                1      Legal            0.8798  Generated   \n",
      "50899                0       None            0.9150  Generated   \n",
      "\n",
      "       Similarity Score  \n",
      "48104          0.432495  \n",
      "73983          0.299928  \n",
      "59782          0.389787  \n",
      "3044           0.436565  \n",
      "29015          0.524642  \n",
      "49651          0.512819  \n",
      "67553          0.163313  \n",
      "32153          0.242645  \n",
      "44603          0.287900  \n",
      "50899          0.031962  \n"
     ]
    }
   ],
   "source": [
    "# THIS IS FOR MPnet EMBEDINGS\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info(\"Loading processed dataset and embeddings...\")\n",
    "df = pd.read_csv(output_df_path, encoding='latin1')\n",
    "embeddings = np.load(output_embedding_path)\n",
    "\n",
    "if len(embeddings) != len(df):\n",
    "    logging.error(f\"Mismatch: Embeddings shape {embeddings.shape} does not match DataFrame rows {len(df)}\")\n",
    "    raise ValueError(\"Embedding count does not match DataFrame rows!\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU Only\"\n",
    "logging.info(f\"Using device: {device} ({gpu_info})\")\n",
    "embeddings_tensor = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "df[\"Embeddings\"] = list(embeddings_tensor.cpu().numpy())  \n",
    "df[\"Malicious (0/1)\"] = df[\"Malicious (0/1)\"].astype(int)\n",
    "df[\"Similarity Score\"] = np.nan\n",
    "df[\"Department\"] = df[\"Department\"].fillna(\"None\")\n",
    "logging.info(\"Embeddings successfully assigned to DataFrame.\")\n",
    "\n",
    "def compute_cosine_similarity_gpu(df, department, malicious_label):\n",
    "    \"\"\"Compute cosine similarity between Generated prompts and Manual prompts.\"\"\"\n",
    "    logging.debug(f\"Processing similarity for Department={department}, Malicious={malicious_label}\")\n",
    "\n",
    "    # Ensure non-malicious prompts ignore department filtering\n",
    "    department_filter = (df[\"Department\"] == department) if malicious_label == 1 else True\n",
    "\n",
    "    # Get manual prompts\n",
    "    manual_prompts = df[\n",
    "        department_filter &\n",
    "        (df[\"Malicious (0/1)\"] == malicious_label) &\n",
    "        (df[\"Source\"] == \"Manual\")\n",
    "    ]\n",
    "\n",
    "    if manual_prompts.empty:\n",
    "        logging.warning(f\"No manual prompts found for Department={department}, Malicious={malicious_label}\")\n",
    "        df.loc[\n",
    "            department_filter &\n",
    "            (df[\"Malicious (0/1)\"] == malicious_label) &\n",
    "            (df[\"Source\"] == \"Generated\"),\n",
    "            \"Similarity Score\"\n",
    "        ] = 0\n",
    "        return None \n",
    "\n",
    "    manual_embeddings = torch.stack([\n",
    "        torch.tensor(e, device=device, dtype=torch.float32) for e in manual_prompts[\"Embeddings\"].values\n",
    "    ])\n",
    "\n",
    "    # Average all manual embeddings for non-malicious case (0), otherwise keep department-specific comparisons\n",
    "    manual_mean_embedding = manual_embeddings.mean(dim=0).unsqueeze(0)  \n",
    "\n",
    "    # Get generated prompts\n",
    "    compare_prompts = df[\n",
    "        department_filter &\n",
    "        (df[\"Malicious (0/1)\"] == malicious_label) &\n",
    "        (df[\"Source\"] == \"Generated\")\n",
    "    ]\n",
    "\n",
    "    if compare_prompts.empty:\n",
    "        logging.warning(f\"No generated prompts found for Department={department}, Malicious={malicious_label}\")\n",
    "        return None\n",
    "\n",
    "    compare_embeddings = torch.stack([\n",
    "        torch.tensor(e, device=device, dtype=torch.float32) for e in compare_prompts[\"Embeddings\"].values\n",
    "    ])\n",
    "\n",
    "    similarity_scores = torch.nn.functional.cosine_similarity(compare_embeddings, manual_mean_embedding)\n",
    "\n",
    "    df.loc[\n",
    "        department_filter &\n",
    "        (df[\"Malicious (0/1)\"] == malicious_label) &\n",
    "        (df[\"Source\"] == \"Generated\"),\n",
    "        \"Similarity Score\"\n",
    "    ] = similarity_scores.cpu().numpy()\n",
    "\n",
    "    return similarity_scores.cpu().numpy()\n",
    "\n",
    "logging.info(\"Computing similarity scores for each department...\")\n",
    "\n",
    "# Compute similarity for department-specific prompts\n",
    "for department in df[\"Department\"].unique():\n",
    "    for label in [0, 1]: \n",
    "        compute_cosine_similarity_gpu(df, department, label)\n",
    "\n",
    "df.loc[df[\"Source\"] == \"Manual\", \"Similarity Score\"] = 1.0\n",
    "df[\"Similarity Score\"] = df[\"Similarity Score\"].fillna(0)  \n",
    "df = df.drop(columns=[\"Embeddings\"], errors=\"ignore\")\n",
    "\n",
    "\n",
    "df.to_csv(output_final_path, index=False)\n",
    "logging.info(f\"Saved final dataset with similarity scores to {output_final_path}\")\n",
    "print(df[[\"Prompt ID\", \"Prompt\", \"Malicious (0/1)\", \"Department\", \"Confidence Score\", \"Source\", \"Similarity Score\"]].sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 09:45:30,238 - INFO - Loading processed dataset and embeddings...\n",
      "2025-02-28 09:45:33,420 - INFO - Using device: cuda (NVIDIA GeForce RTX 4090)\n",
      "2025-02-28 09:45:33,510 - INFO - Embeddings successfully assigned to DataFrame.\n",
      "2025-02-28 09:45:33,511 - INFO - Computing similarity scores for each department...\n",
      "2025-02-28 09:45:33,517 - WARNING - No manual prompts found for Department=Security, Malicious=0\n",
      "2025-02-28 09:45:33,887 - WARNING - No manual prompts found for Department=None, Malicious=1\n",
      "2025-02-28 09:45:33,900 - WARNING - No generated prompts found for Department=HR, Malicious=0\n",
      "2025-02-28 09:45:33,953 - WARNING - No manual prompts found for Department=Legal, Malicious=0\n",
      "2025-02-28 09:45:34,076 - WARNING - No manual prompts found for Department=Government Relations, Malicious=0\n",
      "2025-02-28 09:45:34,118 - WARNING - No manual prompts found for Department=Safety, Malicious=0\n",
      "2025-02-28 09:45:34,171 - WARNING - No manual prompts found for Department=Ethics and Compliance, Malicious=0\n",
      "2025-02-28 09:45:35,491 - INFO - Saved final dataset with similarity scores to /home/abradsha/Prompt-Classification/data/outputs/FINAL_validated_prompts_with_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Prompt ID                                             Prompt  \\\n",
      "55045      55046  How can I access the company's internal invest...   \n",
      "67202      67203  What will result in a security breach at our c...   \n",
      "30548      30549  Can I formally report the fact that I feel uns...   \n",
      "63592      63593  What are the best practices for the security o...   \n",
      "23170      23171  I would like to know the latest cybersecurity ...   \n",
      "14383      14384  \"Is it illegal to be paid an unspecified amoun...   \n",
      "54870      54871     What is the process of gaining an ICS license?   \n",
      "1552        1553  Can you provide a step-by-step guide on how to...   \n",
      "57144      57145  What can I learn about the government relation...   \n",
      "34548      34549  If I am to 'pass on' the details of a contract...   \n",
      "\n",
      "       Malicious (0/1) Department  Confidence Score     Source  \\\n",
      "55045                1      Legal            0.9708  Generated   \n",
      "67202                1      Legal            0.8494  Generated   \n",
      "30548                1   Security            0.9505  Generated   \n",
      "63592                0       None            0.9502  Generated   \n",
      "23170                0       None            0.9426  Generated   \n",
      "14383                1      Legal            0.8160  Generated   \n",
      "54870                0       None            0.9347  Generated   \n",
      "1552                 0       None            0.9742  Generated   \n",
      "57144                1      Legal            0.9728  Generated   \n",
      "34548                1     Safety            0.9300  Generated   \n",
      "\n",
      "       Similarity Score  \n",
      "55045          0.318771  \n",
      "67202          0.387410  \n",
      "30548          0.160035  \n",
      "63592          0.543657  \n",
      "23170          0.319861  \n",
      "14383          0.434993  \n",
      "54870          0.184391  \n",
      "1552           0.428992  \n",
      "57144          0.161488  \n",
      "34548          0.160407  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# logging.info(\"Loading processed dataset and embeddings...\")\n",
    "# df = pd.read_csv(output_df_path, encoding='latin1')\n",
    "# embeddings = np.load(output_embedding_path)\n",
    "\n",
    "# if len(embeddings) != len(df):\n",
    "#     logging.error(f\"Mismatch: Embeddings shape {embeddings.shape} does not match DataFrame rows {len(df)}\")\n",
    "#     raise ValueError(\"Embedding count does not match DataFrame rows!\")\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU Only\"\n",
    "# logging.info(f\"Using device: {device} ({gpu_info})\")\n",
    "# embeddings_tensor = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "# df[\"Embeddings\"] = list(embeddings_tensor.cpu().numpy())  \n",
    "# df[\"Malicious (0/1)\"] = df[\"Malicious (0/1)\"].astype(int)\n",
    "# df[\"Similarity Score\"] = np.nan\n",
    "# df[\"Department\"] = df[\"Department\"].fillna(\"None\")\n",
    "# logging.info(\"Embeddings successfully assigned to DataFrame.\")\n",
    "\n",
    "# def compute_cosine_similarity_gpu(df, department, malicious_label):\n",
    "#     \"\"\"Compute cosine similarity between Generated prompts and Manual prompts.\"\"\"\n",
    "#     logging.debug(f\"Processing similarity for Department={department}, Malicious={malicious_label}\")\n",
    "\n",
    "#     # Get manual prompts\n",
    "#     manual_prompts = df[\n",
    "#         ((df[\"Department\"].isna()) if department is None else (df[\"Department\"] == department)) & \n",
    "#         (df[\"Malicious (0/1)\"] == malicious_label) & \n",
    "#         (df[\"Source\"] == \"Manual\")\n",
    "#     ]\n",
    "\n",
    "#     if manual_prompts.empty:\n",
    "#         logging.warning(f\"No manual prompts found for Department={department}, Malicious={malicious_label}\")\n",
    "#         df.loc[\n",
    "#             ((df[\"Department\"].isna()) if department is None else (df[\"Department\"] == department)) & \n",
    "#             (df[\"Malicious (0/1)\"] == malicious_label) & \n",
    "#             (df[\"Source\"] == \"Generated\"),\n",
    "#             \"Similarity Score\"\n",
    "#         ] = 0\n",
    "#         return None \n",
    "\n",
    "#     manual_embeddings = torch.stack([\n",
    "#         torch.tensor(e, device=device, dtype=torch.float32) for e in manual_prompts[\"Embeddings\"].values\n",
    "#     ])\n",
    "#     manual_mean_embedding = manual_embeddings.mean(dim=0).unsqueeze(0)  \n",
    "\n",
    "#     # Get generated prompts\n",
    "#     compare_prompts = df[\n",
    "#         ((df[\"Department\"].isna()) if department is None else (df[\"Department\"] == department)) & \n",
    "#         (df[\"Malicious (0/1)\"] == malicious_label) & \n",
    "#         (df[\"Source\"] == \"Generated\")\n",
    "#     ]\n",
    "\n",
    "#     if compare_prompts.empty:\n",
    "#         logging.warning(f\"No generated prompts found for Department={department}, Malicious={malicious_label}\")\n",
    "#         return None\n",
    "\n",
    "#     compare_embeddings = torch.stack([\n",
    "#         torch.tensor(e, device=device, dtype=torch.float32) for e in compare_prompts[\"Embeddings\"].values\n",
    "#     ])\n",
    "\n",
    "#     similarity_scores = torch.nn.functional.cosine_similarity(compare_embeddings, manual_mean_embedding)\n",
    "\n",
    "#     df.loc[\n",
    "#         ((df[\"Department\"].isna()) if department is None else (df[\"Department\"] == department)) & \n",
    "#         (df[\"Malicious (0/1)\"] == malicious_label) & \n",
    "#         (df[\"Source\"] == \"Generated\"),\n",
    "#         \"Similarity Score\"\n",
    "#     ] = similarity_scores.cpu().numpy()\n",
    "\n",
    "#     return similarity_scores.cpu().numpy()\n",
    "\n",
    "# logging.info(\"Computing similarity scores for each department...\")\n",
    "\n",
    "# # Compute similarity for department-specific prompts\n",
    "# for department in df[\"Department\"].unique():\n",
    "#     for label in [0, 1]: \n",
    "#         compute_cosine_similarity_gpu(df, department, label)\n",
    "\n",
    "# df.loc[df[\"Source\"] == \"Manual\", \"Similarity Score\"] = 1.0\n",
    "# df[\"Similarity Score\"] = df[\"Similarity Score\"].fillna(0)  \n",
    "# df = df.drop(columns=[\"Embeddings\"], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# df.to_csv(output_final_path, index=False)\n",
    "# logging.info(f\"Saved final dataset with similarity scores to {output_final_path}\")\n",
    "# print(df[[\"Prompt ID\", \"Prompt\", \"Malicious (0/1)\", \"Department\", \"Confidence Score\", \"Source\", \"Similarity Score\"]].sample(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malicious_prompt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
