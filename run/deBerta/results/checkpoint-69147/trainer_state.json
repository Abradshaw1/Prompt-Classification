{
  "best_metric": 0.12236085534095764,
  "best_model_checkpoint": "./results/checkpoint-53781",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 69147,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006507874528179097,
      "grad_norm": 1.3812075853347778,
      "learning_rate": 4.999674606273591e-05,
      "loss": 0.6984,
      "step": 50
    },
    {
      "epoch": 0.013015749056358194,
      "grad_norm": 1.0213795900344849,
      "learning_rate": 4.9993492125471824e-05,
      "loss": 0.6955,
      "step": 100
    },
    {
      "epoch": 0.01952362358453729,
      "grad_norm": 2.302999258041382,
      "learning_rate": 4.999023818820773e-05,
      "loss": 0.6926,
      "step": 150
    },
    {
      "epoch": 0.02603149811271639,
      "grad_norm": 1.9629160165786743,
      "learning_rate": 4.998698425094364e-05,
      "loss": 0.699,
      "step": 200
    },
    {
      "epoch": 0.032539372640895486,
      "grad_norm": 1.189257025718689,
      "learning_rate": 4.998373031367955e-05,
      "loss": 0.6837,
      "step": 250
    },
    {
      "epoch": 0.03904724716907458,
      "grad_norm": 1.0273579359054565,
      "learning_rate": 4.9980476376415466e-05,
      "loss": 0.6854,
      "step": 300
    },
    {
      "epoch": 0.045555121697253675,
      "grad_norm": 1.439684510231018,
      "learning_rate": 4.997722243915138e-05,
      "loss": 0.6445,
      "step": 350
    },
    {
      "epoch": 0.05206299622543278,
      "grad_norm": 5.03896427154541,
      "learning_rate": 4.997396850188729e-05,
      "loss": 0.4774,
      "step": 400
    },
    {
      "epoch": 0.05857087075361187,
      "grad_norm": 5.454194068908691,
      "learning_rate": 4.9970714564623195e-05,
      "loss": 0.3266,
      "step": 450
    },
    {
      "epoch": 0.06507874528179097,
      "grad_norm": 17.620189666748047,
      "learning_rate": 4.996746062735911e-05,
      "loss": 0.3163,
      "step": 500
    },
    {
      "epoch": 0.07158661980997007,
      "grad_norm": 10.781919479370117,
      "learning_rate": 4.9964206690095016e-05,
      "loss": 0.2939,
      "step": 550
    },
    {
      "epoch": 0.07809449433814916,
      "grad_norm": 1.1195977926254272,
      "learning_rate": 4.9960952752830924e-05,
      "loss": 0.28,
      "step": 600
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 5.615295886993408,
      "learning_rate": 4.995769881556684e-05,
      "loss": 0.3755,
      "step": 650
    },
    {
      "epoch": 0.09111024339450735,
      "grad_norm": 7.698751449584961,
      "learning_rate": 4.9954444878302745e-05,
      "loss": 0.3115,
      "step": 700
    },
    {
      "epoch": 0.09761811792268645,
      "grad_norm": 3.511470317840576,
      "learning_rate": 4.995119094103866e-05,
      "loss": 0.334,
      "step": 750
    },
    {
      "epoch": 0.10412599245086555,
      "grad_norm": 0.6305279731750488,
      "learning_rate": 4.994793700377457e-05,
      "loss": 0.2315,
      "step": 800
    },
    {
      "epoch": 0.11063386697904465,
      "grad_norm": 0.37368983030319214,
      "learning_rate": 4.994468306651048e-05,
      "loss": 0.3152,
      "step": 850
    },
    {
      "epoch": 0.11714174150722374,
      "grad_norm": 10.25255012512207,
      "learning_rate": 4.9941429129246394e-05,
      "loss": 0.3235,
      "step": 900
    },
    {
      "epoch": 0.12364961603540284,
      "grad_norm": 2.7966692447662354,
      "learning_rate": 4.99381751919823e-05,
      "loss": 0.2665,
      "step": 950
    },
    {
      "epoch": 0.13015749056358195,
      "grad_norm": 0.40074679255485535,
      "learning_rate": 4.993492125471821e-05,
      "loss": 0.2029,
      "step": 1000
    },
    {
      "epoch": 0.13666536509176103,
      "grad_norm": 0.968333899974823,
      "learning_rate": 4.993166731745412e-05,
      "loss": 0.3149,
      "step": 1050
    },
    {
      "epoch": 0.14317323961994013,
      "grad_norm": 0.6674380898475647,
      "learning_rate": 4.992841338019003e-05,
      "loss": 0.3129,
      "step": 1100
    },
    {
      "epoch": 0.14968111414811922,
      "grad_norm": 9.850410461425781,
      "learning_rate": 4.9925159442925944e-05,
      "loss": 0.2827,
      "step": 1150
    },
    {
      "epoch": 0.15618898867629832,
      "grad_norm": 3.999210834503174,
      "learning_rate": 4.992190550566185e-05,
      "loss": 0.1771,
      "step": 1200
    },
    {
      "epoch": 0.1626968632044774,
      "grad_norm": 0.3470812737941742,
      "learning_rate": 4.991865156839776e-05,
      "loss": 0.2317,
      "step": 1250
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 16.52211570739746,
      "learning_rate": 4.991539763113367e-05,
      "loss": 0.2418,
      "step": 1300
    },
    {
      "epoch": 0.17571261226083562,
      "grad_norm": 2.813606023788452,
      "learning_rate": 4.991214369386959e-05,
      "loss": 0.1931,
      "step": 1350
    },
    {
      "epoch": 0.1822204867890147,
      "grad_norm": 0.3237397372722626,
      "learning_rate": 4.9908889756605494e-05,
      "loss": 0.2204,
      "step": 1400
    },
    {
      "epoch": 0.1887283613171938,
      "grad_norm": 6.13388729095459,
      "learning_rate": 4.990563581934141e-05,
      "loss": 0.2015,
      "step": 1450
    },
    {
      "epoch": 0.1952362358453729,
      "grad_norm": 0.4077408015727997,
      "learning_rate": 4.9902381882077316e-05,
      "loss": 0.1856,
      "step": 1500
    },
    {
      "epoch": 0.201744110373552,
      "grad_norm": 9.11707878112793,
      "learning_rate": 4.989912794481323e-05,
      "loss": 0.2328,
      "step": 1550
    },
    {
      "epoch": 0.2082519849017311,
      "grad_norm": 3.611264944076538,
      "learning_rate": 4.989587400754914e-05,
      "loss": 0.209,
      "step": 1600
    },
    {
      "epoch": 0.2147598594299102,
      "grad_norm": 7.077177047729492,
      "learning_rate": 4.9892620070285044e-05,
      "loss": 0.3059,
      "step": 1650
    },
    {
      "epoch": 0.2212677339580893,
      "grad_norm": 17.37471580505371,
      "learning_rate": 4.988936613302096e-05,
      "loss": 0.2606,
      "step": 1700
    },
    {
      "epoch": 0.22777560848626838,
      "grad_norm": 4.515182018280029,
      "learning_rate": 4.9886112195756866e-05,
      "loss": 0.2237,
      "step": 1750
    },
    {
      "epoch": 0.23428348301444749,
      "grad_norm": 0.5183723568916321,
      "learning_rate": 4.988285825849277e-05,
      "loss": 0.181,
      "step": 1800
    },
    {
      "epoch": 0.24079135754262657,
      "grad_norm": 1.0299774408340454,
      "learning_rate": 4.987960432122869e-05,
      "loss": 0.1864,
      "step": 1850
    },
    {
      "epoch": 0.24729923207080567,
      "grad_norm": 5.589911460876465,
      "learning_rate": 4.98763503839646e-05,
      "loss": 0.1948,
      "step": 1900
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 14.422940254211426,
      "learning_rate": 4.9873096446700515e-05,
      "loss": 0.2184,
      "step": 1950
    },
    {
      "epoch": 0.2603149811271639,
      "grad_norm": 3.560814380645752,
      "learning_rate": 4.986984250943642e-05,
      "loss": 0.2713,
      "step": 2000
    },
    {
      "epoch": 0.26682285565534297,
      "grad_norm": 0.20873567461967468,
      "learning_rate": 4.986658857217233e-05,
      "loss": 0.2382,
      "step": 2050
    },
    {
      "epoch": 0.27333073018352205,
      "grad_norm": 16.047544479370117,
      "learning_rate": 4.9863334634908244e-05,
      "loss": 0.2061,
      "step": 2100
    },
    {
      "epoch": 0.27983860471170113,
      "grad_norm": 11.025662422180176,
      "learning_rate": 4.986008069764415e-05,
      "loss": 0.1562,
      "step": 2150
    },
    {
      "epoch": 0.28634647923988027,
      "grad_norm": 10.899531364440918,
      "learning_rate": 4.985682676038006e-05,
      "loss": 0.2551,
      "step": 2200
    },
    {
      "epoch": 0.29285435376805935,
      "grad_norm": 0.29764482378959656,
      "learning_rate": 4.985357282311597e-05,
      "loss": 0.1514,
      "step": 2250
    },
    {
      "epoch": 0.29936222829623843,
      "grad_norm": 9.616398811340332,
      "learning_rate": 4.985031888585188e-05,
      "loss": 0.2212,
      "step": 2300
    },
    {
      "epoch": 0.30587010282441757,
      "grad_norm": 2.341359853744507,
      "learning_rate": 4.9847064948587794e-05,
      "loss": 0.2437,
      "step": 2350
    },
    {
      "epoch": 0.31237797735259665,
      "grad_norm": 3.3173789978027344,
      "learning_rate": 4.984381101132371e-05,
      "loss": 0.2052,
      "step": 2400
    },
    {
      "epoch": 0.31888585188077573,
      "grad_norm": 1.178920865058899,
      "learning_rate": 4.9840557074059615e-05,
      "loss": 0.2016,
      "step": 2450
    },
    {
      "epoch": 0.3253937264089548,
      "grad_norm": 1.3529285192489624,
      "learning_rate": 4.983730313679553e-05,
      "loss": 0.2234,
      "step": 2500
    },
    {
      "epoch": 0.33190160093713394,
      "grad_norm": 3.7965641021728516,
      "learning_rate": 4.9834049199531436e-05,
      "loss": 0.1863,
      "step": 2550
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 4.015259742736816,
      "learning_rate": 4.9830795262267344e-05,
      "loss": 0.1597,
      "step": 2600
    },
    {
      "epoch": 0.3449173499934921,
      "grad_norm": 0.05903765559196472,
      "learning_rate": 4.982754132500326e-05,
      "loss": 0.194,
      "step": 2650
    },
    {
      "epoch": 0.35142522452167124,
      "grad_norm": 11.975152015686035,
      "learning_rate": 4.9824287387739165e-05,
      "loss": 0.2336,
      "step": 2700
    },
    {
      "epoch": 0.3579330990498503,
      "grad_norm": 6.908271789550781,
      "learning_rate": 4.982103345047508e-05,
      "loss": 0.3086,
      "step": 2750
    },
    {
      "epoch": 0.3644409735780294,
      "grad_norm": 14.688257217407227,
      "learning_rate": 4.9817779513210986e-05,
      "loss": 0.1806,
      "step": 2800
    },
    {
      "epoch": 0.37094884810620854,
      "grad_norm": 0.9832898378372192,
      "learning_rate": 4.9814525575946894e-05,
      "loss": 0.1861,
      "step": 2850
    },
    {
      "epoch": 0.3774567226343876,
      "grad_norm": 8.210029602050781,
      "learning_rate": 4.981127163868281e-05,
      "loss": 0.1686,
      "step": 2900
    },
    {
      "epoch": 0.3839645971625667,
      "grad_norm": 5.571507930755615,
      "learning_rate": 4.980801770141872e-05,
      "loss": 0.201,
      "step": 2950
    },
    {
      "epoch": 0.3904724716907458,
      "grad_norm": 0.7360718846321106,
      "learning_rate": 4.980476376415463e-05,
      "loss": 0.2376,
      "step": 3000
    },
    {
      "epoch": 0.3969803462189249,
      "grad_norm": 0.08593004941940308,
      "learning_rate": 4.980150982689054e-05,
      "loss": 0.187,
      "step": 3050
    },
    {
      "epoch": 0.403488220747104,
      "grad_norm": 3.637843608856201,
      "learning_rate": 4.979825588962645e-05,
      "loss": 0.2748,
      "step": 3100
    },
    {
      "epoch": 0.4099960952752831,
      "grad_norm": 0.09191198647022247,
      "learning_rate": 4.9795001952362365e-05,
      "loss": 0.1911,
      "step": 3150
    },
    {
      "epoch": 0.4165039698034622,
      "grad_norm": 10.6132230758667,
      "learning_rate": 4.979174801509827e-05,
      "loss": 0.1304,
      "step": 3200
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 0.05522184073925018,
      "learning_rate": 4.978849407783418e-05,
      "loss": 0.1666,
      "step": 3250
    },
    {
      "epoch": 0.4295197188598204,
      "grad_norm": 0.09391258656978607,
      "learning_rate": 4.978524014057009e-05,
      "loss": 0.213,
      "step": 3300
    },
    {
      "epoch": 0.43602759338799946,
      "grad_norm": 17.844629287719727,
      "learning_rate": 4.9781986203306e-05,
      "loss": 0.2362,
      "step": 3350
    },
    {
      "epoch": 0.4425354679161786,
      "grad_norm": 11.809107780456543,
      "learning_rate": 4.977873226604191e-05,
      "loss": 0.1884,
      "step": 3400
    },
    {
      "epoch": 0.4490433424443577,
      "grad_norm": 6.290334224700928,
      "learning_rate": 4.977547832877782e-05,
      "loss": 0.1586,
      "step": 3450
    },
    {
      "epoch": 0.45555121697253675,
      "grad_norm": 0.3539143204689026,
      "learning_rate": 4.9772224391513736e-05,
      "loss": 0.2423,
      "step": 3500
    },
    {
      "epoch": 0.4620590915007159,
      "grad_norm": 0.620993435382843,
      "learning_rate": 4.976897045424965e-05,
      "loss": 0.2285,
      "step": 3550
    },
    {
      "epoch": 0.46856696602889497,
      "grad_norm": 7.982565402984619,
      "learning_rate": 4.976571651698556e-05,
      "loss": 0.2036,
      "step": 3600
    },
    {
      "epoch": 0.47507484055707405,
      "grad_norm": 12.66222095489502,
      "learning_rate": 4.9762462579721464e-05,
      "loss": 0.2046,
      "step": 3650
    },
    {
      "epoch": 0.48158271508525313,
      "grad_norm": 15.456794738769531,
      "learning_rate": 4.975920864245738e-05,
      "loss": 0.1561,
      "step": 3700
    },
    {
      "epoch": 0.48809058961343227,
      "grad_norm": 6.977322578430176,
      "learning_rate": 4.9755954705193286e-05,
      "loss": 0.1673,
      "step": 3750
    },
    {
      "epoch": 0.49459846414161135,
      "grad_norm": 0.1294708400964737,
      "learning_rate": 4.975270076792919e-05,
      "loss": 0.1488,
      "step": 3800
    },
    {
      "epoch": 0.5011063386697905,
      "grad_norm": 1.7494699954986572,
      "learning_rate": 4.974944683066511e-05,
      "loss": 0.1906,
      "step": 3850
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 23.7703914642334,
      "learning_rate": 4.9746192893401014e-05,
      "loss": 0.1121,
      "step": 3900
    },
    {
      "epoch": 0.5141220877261486,
      "grad_norm": 0.5931434631347656,
      "learning_rate": 4.974293895613693e-05,
      "loss": 0.182,
      "step": 3950
    },
    {
      "epoch": 0.5206299622543278,
      "grad_norm": 8.635703086853027,
      "learning_rate": 4.973968501887284e-05,
      "loss": 0.291,
      "step": 4000
    },
    {
      "epoch": 0.5271378367825068,
      "grad_norm": 0.08132962882518768,
      "learning_rate": 4.973643108160875e-05,
      "loss": 0.134,
      "step": 4050
    },
    {
      "epoch": 0.5336457113106859,
      "grad_norm": 1.8719886541366577,
      "learning_rate": 4.9733177144344664e-05,
      "loss": 0.2146,
      "step": 4100
    },
    {
      "epoch": 0.5401535858388651,
      "grad_norm": 0.04697994887828827,
      "learning_rate": 4.972992320708057e-05,
      "loss": 0.1533,
      "step": 4150
    },
    {
      "epoch": 0.5466614603670441,
      "grad_norm": 0.0844290629029274,
      "learning_rate": 4.972666926981648e-05,
      "loss": 0.1824,
      "step": 4200
    },
    {
      "epoch": 0.5531693348952232,
      "grad_norm": 9.28817367553711,
      "learning_rate": 4.972341533255239e-05,
      "loss": 0.1609,
      "step": 4250
    },
    {
      "epoch": 0.5596772094234023,
      "grad_norm": 0.7543773651123047,
      "learning_rate": 4.97201613952883e-05,
      "loss": 0.2411,
      "step": 4300
    },
    {
      "epoch": 0.5661850839515814,
      "grad_norm": 0.6711598038673401,
      "learning_rate": 4.971690745802421e-05,
      "loss": 0.1358,
      "step": 4350
    },
    {
      "epoch": 0.5726929584797605,
      "grad_norm": 3.5889551639556885,
      "learning_rate": 4.971365352076012e-05,
      "loss": 0.1866,
      "step": 4400
    },
    {
      "epoch": 0.5792008330079396,
      "grad_norm": 13.170646667480469,
      "learning_rate": 4.971039958349603e-05,
      "loss": 0.1381,
      "step": 4450
    },
    {
      "epoch": 0.5857087075361187,
      "grad_norm": 7.57885217666626,
      "learning_rate": 4.970714564623194e-05,
      "loss": 0.2191,
      "step": 4500
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 0.2737581729888916,
      "learning_rate": 4.9703891708967857e-05,
      "loss": 0.1891,
      "step": 4550
    },
    {
      "epoch": 0.5987244565924769,
      "grad_norm": 0.20991267263889313,
      "learning_rate": 4.9700637771703764e-05,
      "loss": 0.1828,
      "step": 4600
    },
    {
      "epoch": 0.605232331120656,
      "grad_norm": 7.479410171508789,
      "learning_rate": 4.969738383443968e-05,
      "loss": 0.2174,
      "step": 4650
    },
    {
      "epoch": 0.6117402056488351,
      "grad_norm": 0.5552155375480652,
      "learning_rate": 4.9694129897175585e-05,
      "loss": 0.1302,
      "step": 4700
    },
    {
      "epoch": 0.6182480801770142,
      "grad_norm": 4.391262531280518,
      "learning_rate": 4.969087595991149e-05,
      "loss": 0.1824,
      "step": 4750
    },
    {
      "epoch": 0.6247559547051933,
      "grad_norm": 3.2231357097625732,
      "learning_rate": 4.9687622022647406e-05,
      "loss": 0.1791,
      "step": 4800
    },
    {
      "epoch": 0.6312638292333724,
      "grad_norm": 0.45214882493019104,
      "learning_rate": 4.9684368085383314e-05,
      "loss": 0.1672,
      "step": 4850
    },
    {
      "epoch": 0.6377717037615515,
      "grad_norm": 8.402385711669922,
      "learning_rate": 4.968111414811923e-05,
      "loss": 0.2466,
      "step": 4900
    },
    {
      "epoch": 0.6442795782897306,
      "grad_norm": 7.385871887207031,
      "learning_rate": 4.9677860210855135e-05,
      "loss": 0.1809,
      "step": 4950
    },
    {
      "epoch": 0.6507874528179096,
      "grad_norm": 1.173627495765686,
      "learning_rate": 4.967460627359104e-05,
      "loss": 0.1851,
      "step": 5000
    },
    {
      "epoch": 0.6572953273460888,
      "grad_norm": 0.0873325988650322,
      "learning_rate": 4.9671352336326956e-05,
      "loss": 0.1677,
      "step": 5050
    },
    {
      "epoch": 0.6638032018742679,
      "grad_norm": 8.881708145141602,
      "learning_rate": 4.966809839906287e-05,
      "loss": 0.1742,
      "step": 5100
    },
    {
      "epoch": 0.6703110764024469,
      "grad_norm": 7.39114236831665,
      "learning_rate": 4.966484446179878e-05,
      "loss": 0.1228,
      "step": 5150
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 1.9809046983718872,
      "learning_rate": 4.966159052453469e-05,
      "loss": 0.1652,
      "step": 5200
    },
    {
      "epoch": 0.6833268254588052,
      "grad_norm": 10.92947769165039,
      "learning_rate": 4.96583365872706e-05,
      "loss": 0.1964,
      "step": 5250
    },
    {
      "epoch": 0.6898346999869842,
      "grad_norm": 1.9273761510849,
      "learning_rate": 4.965508265000651e-05,
      "loss": 0.1496,
      "step": 5300
    },
    {
      "epoch": 0.6963425745151633,
      "grad_norm": 8.884661674499512,
      "learning_rate": 4.965182871274242e-05,
      "loss": 0.1423,
      "step": 5350
    },
    {
      "epoch": 0.7028504490433425,
      "grad_norm": 0.034394267946481705,
      "learning_rate": 4.964857477547833e-05,
      "loss": 0.1992,
      "step": 5400
    },
    {
      "epoch": 0.7093583235715215,
      "grad_norm": 10.48226261138916,
      "learning_rate": 4.964532083821424e-05,
      "loss": 0.0867,
      "step": 5450
    },
    {
      "epoch": 0.7158661980997006,
      "grad_norm": 0.3553875982761383,
      "learning_rate": 4.964206690095015e-05,
      "loss": 0.1762,
      "step": 5500
    },
    {
      "epoch": 0.7223740726278798,
      "grad_norm": 1.4401041269302368,
      "learning_rate": 4.963881296368606e-05,
      "loss": 0.2293,
      "step": 5550
    },
    {
      "epoch": 0.7288819471560588,
      "grad_norm": 11.187164306640625,
      "learning_rate": 4.963555902642198e-05,
      "loss": 0.2404,
      "step": 5600
    },
    {
      "epoch": 0.7353898216842379,
      "grad_norm": 2.7864484786987305,
      "learning_rate": 4.9632305089157885e-05,
      "loss": 0.1851,
      "step": 5650
    },
    {
      "epoch": 0.7418976962124171,
      "grad_norm": 0.39891573786735535,
      "learning_rate": 4.96290511518938e-05,
      "loss": 0.1644,
      "step": 5700
    },
    {
      "epoch": 0.7484055707405961,
      "grad_norm": 7.03636360168457,
      "learning_rate": 4.9625797214629706e-05,
      "loss": 0.1292,
      "step": 5750
    },
    {
      "epoch": 0.7549134452687752,
      "grad_norm": 3.452263593673706,
      "learning_rate": 4.962254327736561e-05,
      "loss": 0.1806,
      "step": 5800
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 9.22283935546875,
      "learning_rate": 4.961928934010153e-05,
      "loss": 0.1748,
      "step": 5850
    },
    {
      "epoch": 0.7679291943251334,
      "grad_norm": 13.913717269897461,
      "learning_rate": 4.9616035402837434e-05,
      "loss": 0.1204,
      "step": 5900
    },
    {
      "epoch": 0.7744370688533125,
      "grad_norm": 12.360310554504395,
      "learning_rate": 4.961278146557334e-05,
      "loss": 0.2035,
      "step": 5950
    },
    {
      "epoch": 0.7809449433814916,
      "grad_norm": 10.773582458496094,
      "learning_rate": 4.9609527528309256e-05,
      "loss": 0.1037,
      "step": 6000
    },
    {
      "epoch": 0.7874528179096707,
      "grad_norm": 5.228166103363037,
      "learning_rate": 4.960627359104516e-05,
      "loss": 0.1478,
      "step": 6050
    },
    {
      "epoch": 0.7939606924378498,
      "grad_norm": 7.488658428192139,
      "learning_rate": 4.960301965378108e-05,
      "loss": 0.1593,
      "step": 6100
    },
    {
      "epoch": 0.8004685669660289,
      "grad_norm": 2.0164616107940674,
      "learning_rate": 4.959976571651699e-05,
      "loss": 0.1985,
      "step": 6150
    },
    {
      "epoch": 0.806976441494208,
      "grad_norm": 8.881577491760254,
      "learning_rate": 4.95965117792529e-05,
      "loss": 0.2581,
      "step": 6200
    },
    {
      "epoch": 0.8134843160223871,
      "grad_norm": 1.860408067703247,
      "learning_rate": 4.959325784198881e-05,
      "loss": 0.1498,
      "step": 6250
    },
    {
      "epoch": 0.8199921905505662,
      "grad_norm": 0.7701991200447083,
      "learning_rate": 4.959000390472472e-05,
      "loss": 0.197,
      "step": 6300
    },
    {
      "epoch": 0.8265000650787453,
      "grad_norm": 1.3026341199874878,
      "learning_rate": 4.958674996746063e-05,
      "loss": 0.1824,
      "step": 6350
    },
    {
      "epoch": 0.8330079396069244,
      "grad_norm": 0.7205959558486938,
      "learning_rate": 4.958349603019654e-05,
      "loss": 0.1625,
      "step": 6400
    },
    {
      "epoch": 0.8395158141351035,
      "grad_norm": 0.059468500316143036,
      "learning_rate": 4.958024209293245e-05,
      "loss": 0.0996,
      "step": 6450
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 10.839303016662598,
      "learning_rate": 4.957698815566836e-05,
      "loss": 0.1758,
      "step": 6500
    },
    {
      "epoch": 0.8525315631914616,
      "grad_norm": 0.09830722212791443,
      "learning_rate": 4.957373421840427e-05,
      "loss": 0.1657,
      "step": 6550
    },
    {
      "epoch": 0.8590394377196408,
      "grad_norm": 0.029897155240178108,
      "learning_rate": 4.957048028114018e-05,
      "loss": 0.1014,
      "step": 6600
    },
    {
      "epoch": 0.8655473122478199,
      "grad_norm": 18.572071075439453,
      "learning_rate": 4.956722634387609e-05,
      "loss": 0.1389,
      "step": 6650
    },
    {
      "epoch": 0.8720551867759989,
      "grad_norm": 8.600873947143555,
      "learning_rate": 4.9563972406612005e-05,
      "loss": 0.218,
      "step": 6700
    },
    {
      "epoch": 0.878563061304178,
      "grad_norm": 7.2731709480285645,
      "learning_rate": 4.956071846934791e-05,
      "loss": 0.1705,
      "step": 6750
    },
    {
      "epoch": 0.8850709358323572,
      "grad_norm": 0.35045215487480164,
      "learning_rate": 4.9557464532083827e-05,
      "loss": 0.1549,
      "step": 6800
    },
    {
      "epoch": 0.8915788103605362,
      "grad_norm": 5.829655170440674,
      "learning_rate": 4.9554210594819734e-05,
      "loss": 0.1531,
      "step": 6850
    },
    {
      "epoch": 0.8980866848887153,
      "grad_norm": 0.2595415711402893,
      "learning_rate": 4.955095665755565e-05,
      "loss": 0.1623,
      "step": 6900
    },
    {
      "epoch": 0.9045945594168945,
      "grad_norm": 0.02873554639518261,
      "learning_rate": 4.9547702720291555e-05,
      "loss": 0.1674,
      "step": 6950
    },
    {
      "epoch": 0.9111024339450735,
      "grad_norm": 0.0413910448551178,
      "learning_rate": 4.954444878302746e-05,
      "loss": 0.2264,
      "step": 7000
    },
    {
      "epoch": 0.9176103084732526,
      "grad_norm": 0.41213762760162354,
      "learning_rate": 4.9541194845763377e-05,
      "loss": 0.1629,
      "step": 7050
    },
    {
      "epoch": 0.9241181830014318,
      "grad_norm": 2.2815732955932617,
      "learning_rate": 4.9537940908499284e-05,
      "loss": 0.1523,
      "step": 7100
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 16.927732467651367,
      "learning_rate": 4.95346869712352e-05,
      "loss": 0.1842,
      "step": 7150
    },
    {
      "epoch": 0.9371339320577899,
      "grad_norm": 1.9145939350128174,
      "learning_rate": 4.953143303397111e-05,
      "loss": 0.1591,
      "step": 7200
    },
    {
      "epoch": 0.943641806585969,
      "grad_norm": 3.12231707572937,
      "learning_rate": 4.952817909670702e-05,
      "loss": 0.1838,
      "step": 7250
    },
    {
      "epoch": 0.9501496811141481,
      "grad_norm": 0.09171919524669647,
      "learning_rate": 4.952492515944293e-05,
      "loss": 0.2104,
      "step": 7300
    },
    {
      "epoch": 0.9566575556423272,
      "grad_norm": 8.566399574279785,
      "learning_rate": 4.952167122217884e-05,
      "loss": 0.1619,
      "step": 7350
    },
    {
      "epoch": 0.9631654301705063,
      "grad_norm": 0.517205536365509,
      "learning_rate": 4.951841728491475e-05,
      "loss": 0.1883,
      "step": 7400
    },
    {
      "epoch": 0.9696733046986854,
      "grad_norm": 6.410024642944336,
      "learning_rate": 4.951516334765066e-05,
      "loss": 0.1446,
      "step": 7450
    },
    {
      "epoch": 0.9761811792268645,
      "grad_norm": 8.773873329162598,
      "learning_rate": 4.951190941038657e-05,
      "loss": 0.115,
      "step": 7500
    },
    {
      "epoch": 0.9826890537550436,
      "grad_norm": 0.7090122103691101,
      "learning_rate": 4.9508655473122476e-05,
      "loss": 0.1719,
      "step": 7550
    },
    {
      "epoch": 0.9891969282832227,
      "grad_norm": 16.3675537109375,
      "learning_rate": 4.950540153585839e-05,
      "loss": 0.2099,
      "step": 7600
    },
    {
      "epoch": 0.9957048028114018,
      "grad_norm": 7.653703689575195,
      "learning_rate": 4.95021475985943e-05,
      "loss": 0.172,
      "step": 7650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9520989261308168,
      "eval_f1": 0.9515151515151515,
      "eval_loss": 0.1641651839017868,
      "eval_precision": 0.9628049593387549,
      "eval_recall": 0.9404870425836698,
      "eval_runtime": 23.5634,
      "eval_samples_per_second": 652.07,
      "eval_steps_per_second": 81.525,
      "step": 7683
    },
    {
      "epoch": 1.002212677339581,
      "grad_norm": 2.665804386138916,
      "learning_rate": 4.949889366133021e-05,
      "loss": 0.1564,
      "step": 7700
    },
    {
      "epoch": 1.00872055186776,
      "grad_norm": 0.3456185460090637,
      "learning_rate": 4.9495639724066126e-05,
      "loss": 0.1906,
      "step": 7750
    },
    {
      "epoch": 1.015228426395939,
      "grad_norm": 5.831532001495361,
      "learning_rate": 4.949238578680203e-05,
      "loss": 0.1808,
      "step": 7800
    },
    {
      "epoch": 1.0217363009241183,
      "grad_norm": 6.379550457000732,
      "learning_rate": 4.948913184953795e-05,
      "loss": 0.2219,
      "step": 7850
    },
    {
      "epoch": 1.0282441754522973,
      "grad_norm": 8.324572563171387,
      "learning_rate": 4.9485877912273855e-05,
      "loss": 0.1098,
      "step": 7900
    },
    {
      "epoch": 1.0347520499804763,
      "grad_norm": 14.488425254821777,
      "learning_rate": 4.948262397500976e-05,
      "loss": 0.1601,
      "step": 7950
    },
    {
      "epoch": 1.0412599245086556,
      "grad_norm": 0.06518727540969849,
      "learning_rate": 4.9479370037745676e-05,
      "loss": 0.16,
      "step": 8000
    },
    {
      "epoch": 1.0477677990368346,
      "grad_norm": 9.779130935668945,
      "learning_rate": 4.947611610048158e-05,
      "loss": 0.1202,
      "step": 8050
    },
    {
      "epoch": 1.0542756735650136,
      "grad_norm": 24.39558982849121,
      "learning_rate": 4.94728621632175e-05,
      "loss": 0.2028,
      "step": 8100
    },
    {
      "epoch": 1.0607835480931929,
      "grad_norm": 6.418975353240967,
      "learning_rate": 4.9469608225953405e-05,
      "loss": 0.1603,
      "step": 8150
    },
    {
      "epoch": 1.0672914226213719,
      "grad_norm": 0.19937436282634735,
      "learning_rate": 4.946635428868931e-05,
      "loss": 0.1445,
      "step": 8200
    },
    {
      "epoch": 1.073799297149551,
      "grad_norm": 0.15283173322677612,
      "learning_rate": 4.9463100351425226e-05,
      "loss": 0.1936,
      "step": 8250
    },
    {
      "epoch": 1.0803071716777302,
      "grad_norm": 0.4603518545627594,
      "learning_rate": 4.945984641416114e-05,
      "loss": 0.1129,
      "step": 8300
    },
    {
      "epoch": 1.0868150462059092,
      "grad_norm": 0.034379102289676666,
      "learning_rate": 4.945659247689705e-05,
      "loss": 0.1783,
      "step": 8350
    },
    {
      "epoch": 1.0933229207340882,
      "grad_norm": 6.005712509155273,
      "learning_rate": 4.945333853963296e-05,
      "loss": 0.1603,
      "step": 8400
    },
    {
      "epoch": 1.0998307952622675,
      "grad_norm": 0.16106382012367249,
      "learning_rate": 4.945008460236887e-05,
      "loss": 0.1474,
      "step": 8450
    },
    {
      "epoch": 1.1063386697904465,
      "grad_norm": 8.338719367980957,
      "learning_rate": 4.944683066510478e-05,
      "loss": 0.1291,
      "step": 8500
    },
    {
      "epoch": 1.1128465443186255,
      "grad_norm": 0.18638606369495392,
      "learning_rate": 4.944357672784069e-05,
      "loss": 0.2283,
      "step": 8550
    },
    {
      "epoch": 1.1193544188468045,
      "grad_norm": 0.8677372336387634,
      "learning_rate": 4.94403227905766e-05,
      "loss": 0.0948,
      "step": 8600
    },
    {
      "epoch": 1.1258622933749838,
      "grad_norm": 0.86557936668396,
      "learning_rate": 4.943706885331251e-05,
      "loss": 0.2145,
      "step": 8650
    },
    {
      "epoch": 1.1323701679031628,
      "grad_norm": 0.06939643621444702,
      "learning_rate": 4.943381491604842e-05,
      "loss": 0.1673,
      "step": 8700
    },
    {
      "epoch": 1.1388780424313418,
      "grad_norm": 11.4772310256958,
      "learning_rate": 4.943056097878433e-05,
      "loss": 0.1084,
      "step": 8750
    },
    {
      "epoch": 1.145385916959521,
      "grad_norm": 3.61833119392395,
      "learning_rate": 4.942730704152025e-05,
      "loss": 0.1912,
      "step": 8800
    },
    {
      "epoch": 1.1518937914877,
      "grad_norm": 0.06671342253684998,
      "learning_rate": 4.9424053104256154e-05,
      "loss": 0.1297,
      "step": 8850
    },
    {
      "epoch": 1.1584016660158791,
      "grad_norm": 4.4636759757995605,
      "learning_rate": 4.942079916699206e-05,
      "loss": 0.1582,
      "step": 8900
    },
    {
      "epoch": 1.1649095405440584,
      "grad_norm": 0.04796713590621948,
      "learning_rate": 4.9417545229727975e-05,
      "loss": 0.1637,
      "step": 8950
    },
    {
      "epoch": 1.1714174150722374,
      "grad_norm": 15.378447532653809,
      "learning_rate": 4.941429129246388e-05,
      "loss": 0.1605,
      "step": 9000
    },
    {
      "epoch": 1.1779252896004164,
      "grad_norm": 0.28710687160491943,
      "learning_rate": 4.9411037355199797e-05,
      "loss": 0.1179,
      "step": 9050
    },
    {
      "epoch": 1.1844331641285957,
      "grad_norm": 0.37187033891677856,
      "learning_rate": 4.9407783417935704e-05,
      "loss": 0.1579,
      "step": 9100
    },
    {
      "epoch": 1.1909410386567747,
      "grad_norm": 0.37981265783309937,
      "learning_rate": 4.940452948067161e-05,
      "loss": 0.1778,
      "step": 9150
    },
    {
      "epoch": 1.1974489131849537,
      "grad_norm": 0.7232957482337952,
      "learning_rate": 4.9401275543407525e-05,
      "loss": 0.1133,
      "step": 9200
    },
    {
      "epoch": 1.203956787713133,
      "grad_norm": 0.12360726296901703,
      "learning_rate": 4.939802160614343e-05,
      "loss": 0.1003,
      "step": 9250
    },
    {
      "epoch": 1.210464662241312,
      "grad_norm": 17.341041564941406,
      "learning_rate": 4.9394767668879347e-05,
      "loss": 0.1659,
      "step": 9300
    },
    {
      "epoch": 1.216972536769491,
      "grad_norm": 0.11876513808965683,
      "learning_rate": 4.939151373161526e-05,
      "loss": 0.2076,
      "step": 9350
    },
    {
      "epoch": 1.2234804112976703,
      "grad_norm": 10.828323364257812,
      "learning_rate": 4.938825979435117e-05,
      "loss": 0.2003,
      "step": 9400
    },
    {
      "epoch": 1.2299882858258493,
      "grad_norm": 14.638250350952148,
      "learning_rate": 4.938500585708708e-05,
      "loss": 0.1208,
      "step": 9450
    },
    {
      "epoch": 1.2364961603540283,
      "grad_norm": 8.069096565246582,
      "learning_rate": 4.938175191982299e-05,
      "loss": 0.11,
      "step": 9500
    },
    {
      "epoch": 1.2430040348822076,
      "grad_norm": 10.241419792175293,
      "learning_rate": 4.9378497982558897e-05,
      "loss": 0.1485,
      "step": 9550
    },
    {
      "epoch": 1.2495119094103866,
      "grad_norm": 31.841840744018555,
      "learning_rate": 4.937524404529481e-05,
      "loss": 0.1564,
      "step": 9600
    },
    {
      "epoch": 1.2560197839385656,
      "grad_norm": 0.2555406391620636,
      "learning_rate": 4.937199010803072e-05,
      "loss": 0.1684,
      "step": 9650
    },
    {
      "epoch": 1.2625276584667446,
      "grad_norm": 0.019578825682401657,
      "learning_rate": 4.9368736170766625e-05,
      "loss": 0.0868,
      "step": 9700
    },
    {
      "epoch": 1.2690355329949239,
      "grad_norm": 8.85439682006836,
      "learning_rate": 4.936548223350254e-05,
      "loss": 0.2649,
      "step": 9750
    },
    {
      "epoch": 1.275543407523103,
      "grad_norm": 7.486957550048828,
      "learning_rate": 4.9362228296238446e-05,
      "loss": 0.1133,
      "step": 9800
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.77162104845047,
      "learning_rate": 4.935897435897436e-05,
      "loss": 0.1585,
      "step": 9850
    },
    {
      "epoch": 1.2885591565794612,
      "grad_norm": 1.9446656703948975,
      "learning_rate": 4.9355720421710275e-05,
      "loss": 0.1758,
      "step": 9900
    },
    {
      "epoch": 1.2950670311076402,
      "grad_norm": 11.427372932434082,
      "learning_rate": 4.935246648444618e-05,
      "loss": 0.1435,
      "step": 9950
    },
    {
      "epoch": 1.3015749056358192,
      "grad_norm": 14.206907272338867,
      "learning_rate": 4.9349212547182096e-05,
      "loss": 0.1745,
      "step": 10000
    },
    {
      "epoch": 1.3080827801639985,
      "grad_norm": 16.819406509399414,
      "learning_rate": 4.9345958609918e-05,
      "loss": 0.1497,
      "step": 10050
    },
    {
      "epoch": 1.3145906546921775,
      "grad_norm": 0.38162460923194885,
      "learning_rate": 4.934270467265391e-05,
      "loss": 0.1729,
      "step": 10100
    },
    {
      "epoch": 1.3210985292203565,
      "grad_norm": 0.13392484188079834,
      "learning_rate": 4.9339450735389825e-05,
      "loss": 0.085,
      "step": 10150
    },
    {
      "epoch": 1.3276064037485358,
      "grad_norm": 0.03813571482896805,
      "learning_rate": 4.933619679812573e-05,
      "loss": 0.2107,
      "step": 10200
    },
    {
      "epoch": 1.3341142782767148,
      "grad_norm": 12.586904525756836,
      "learning_rate": 4.9332942860861646e-05,
      "loss": 0.1446,
      "step": 10250
    },
    {
      "epoch": 1.3406221528048938,
      "grad_norm": 3.2765724658966064,
      "learning_rate": 4.932968892359755e-05,
      "loss": 0.1578,
      "step": 10300
    },
    {
      "epoch": 1.347130027333073,
      "grad_norm": 12.959855079650879,
      "learning_rate": 4.932643498633347e-05,
      "loss": 0.126,
      "step": 10350
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 0.1834837943315506,
      "learning_rate": 4.932318104906938e-05,
      "loss": 0.1713,
      "step": 10400
    },
    {
      "epoch": 1.3601457763894311,
      "grad_norm": 0.1363143026828766,
      "learning_rate": 4.931992711180529e-05,
      "loss": 0.199,
      "step": 10450
    },
    {
      "epoch": 1.3666536509176104,
      "grad_norm": 0.13322801887989044,
      "learning_rate": 4.9316673174541196e-05,
      "loss": 0.1523,
      "step": 10500
    },
    {
      "epoch": 1.3731615254457894,
      "grad_norm": 0.025128530338406563,
      "learning_rate": 4.931341923727711e-05,
      "loss": 0.0851,
      "step": 10550
    },
    {
      "epoch": 1.3796693999739684,
      "grad_norm": 4.338446140289307,
      "learning_rate": 4.931016530001302e-05,
      "loss": 0.1625,
      "step": 10600
    },
    {
      "epoch": 1.3861772745021477,
      "grad_norm": 0.4221166670322418,
      "learning_rate": 4.930691136274893e-05,
      "loss": 0.126,
      "step": 10650
    },
    {
      "epoch": 1.3926851490303267,
      "grad_norm": 0.6329705715179443,
      "learning_rate": 4.930365742548484e-05,
      "loss": 0.1433,
      "step": 10700
    },
    {
      "epoch": 1.3991930235585057,
      "grad_norm": 0.04149295762181282,
      "learning_rate": 4.9300403488220746e-05,
      "loss": 0.1112,
      "step": 10750
    },
    {
      "epoch": 1.405700898086685,
      "grad_norm": 0.030794663354754448,
      "learning_rate": 4.929714955095666e-05,
      "loss": 0.2097,
      "step": 10800
    },
    {
      "epoch": 1.412208772614864,
      "grad_norm": 0.06947751343250275,
      "learning_rate": 4.929389561369257e-05,
      "loss": 0.1265,
      "step": 10850
    },
    {
      "epoch": 1.418716647143043,
      "grad_norm": 1.4416431188583374,
      "learning_rate": 4.929064167642848e-05,
      "loss": 0.1135,
      "step": 10900
    },
    {
      "epoch": 1.4252245216712223,
      "grad_norm": 26.12932586669922,
      "learning_rate": 4.9287387739164395e-05,
      "loss": 0.1699,
      "step": 10950
    },
    {
      "epoch": 1.4317323961994013,
      "grad_norm": 0.6048192381858826,
      "learning_rate": 4.92841338019003e-05,
      "loss": 0.09,
      "step": 11000
    },
    {
      "epoch": 1.4382402707275803,
      "grad_norm": 0.026666762307286263,
      "learning_rate": 4.928087986463622e-05,
      "loss": 0.1431,
      "step": 11050
    },
    {
      "epoch": 1.4447481452557596,
      "grad_norm": 2.771547555923462,
      "learning_rate": 4.9277625927372124e-05,
      "loss": 0.1531,
      "step": 11100
    },
    {
      "epoch": 1.4512560197839386,
      "grad_norm": 11.961490631103516,
      "learning_rate": 4.927437199010803e-05,
      "loss": 0.1664,
      "step": 11150
    },
    {
      "epoch": 1.4577638943121176,
      "grad_norm": 0.017150476574897766,
      "learning_rate": 4.9271118052843945e-05,
      "loss": 0.113,
      "step": 11200
    },
    {
      "epoch": 1.4642717688402969,
      "grad_norm": 12.131622314453125,
      "learning_rate": 4.926786411557985e-05,
      "loss": 0.1426,
      "step": 11250
    },
    {
      "epoch": 1.4707796433684759,
      "grad_norm": 0.03393922746181488,
      "learning_rate": 4.926461017831576e-05,
      "loss": 0.092,
      "step": 11300
    },
    {
      "epoch": 1.477287517896655,
      "grad_norm": 0.16875140368938446,
      "learning_rate": 4.9261356241051674e-05,
      "loss": 0.1636,
      "step": 11350
    },
    {
      "epoch": 1.4837953924248342,
      "grad_norm": 0.031809259206056595,
      "learning_rate": 4.925810230378758e-05,
      "loss": 0.1822,
      "step": 11400
    },
    {
      "epoch": 1.4903032669530132,
      "grad_norm": 0.04174767807126045,
      "learning_rate": 4.9254848366523495e-05,
      "loss": 0.1397,
      "step": 11450
    },
    {
      "epoch": 1.4968111414811922,
      "grad_norm": 0.2778308689594269,
      "learning_rate": 4.925159442925941e-05,
      "loss": 0.1419,
      "step": 11500
    },
    {
      "epoch": 1.5033190160093715,
      "grad_norm": 0.0800660029053688,
      "learning_rate": 4.9248340491995317e-05,
      "loss": 0.1257,
      "step": 11550
    },
    {
      "epoch": 1.5098268905375505,
      "grad_norm": 0.7403349280357361,
      "learning_rate": 4.924508655473123e-05,
      "loss": 0.0856,
      "step": 11600
    },
    {
      "epoch": 1.5163347650657295,
      "grad_norm": 11.967114448547363,
      "learning_rate": 4.924183261746714e-05,
      "loss": 0.1391,
      "step": 11650
    },
    {
      "epoch": 1.5228426395939088,
      "grad_norm": 0.9223673939704895,
      "learning_rate": 4.9238578680203045e-05,
      "loss": 0.1363,
      "step": 11700
    },
    {
      "epoch": 1.5293505141220878,
      "grad_norm": 0.03691522777080536,
      "learning_rate": 4.923532474293896e-05,
      "loss": 0.1667,
      "step": 11750
    },
    {
      "epoch": 1.5358583886502668,
      "grad_norm": 0.058523260056972504,
      "learning_rate": 4.9232070805674867e-05,
      "loss": 0.2171,
      "step": 11800
    },
    {
      "epoch": 1.542366263178446,
      "grad_norm": 0.6529152989387512,
      "learning_rate": 4.922881686841078e-05,
      "loss": 0.1833,
      "step": 11850
    },
    {
      "epoch": 1.5488741377066249,
      "grad_norm": 0.13119326531887054,
      "learning_rate": 4.922556293114669e-05,
      "loss": 0.1163,
      "step": 11900
    },
    {
      "epoch": 1.555382012234804,
      "grad_norm": 14.467597007751465,
      "learning_rate": 4.92223089938826e-05,
      "loss": 0.1072,
      "step": 11950
    },
    {
      "epoch": 1.5618898867629833,
      "grad_norm": 0.02712908387184143,
      "learning_rate": 4.9219055056618516e-05,
      "loss": 0.1189,
      "step": 12000
    },
    {
      "epoch": 1.5683977612911622,
      "grad_norm": 0.2419629991054535,
      "learning_rate": 4.921580111935442e-05,
      "loss": 0.1435,
      "step": 12050
    },
    {
      "epoch": 1.5749056358193414,
      "grad_norm": 0.12091991305351257,
      "learning_rate": 4.921254718209033e-05,
      "loss": 0.0864,
      "step": 12100
    },
    {
      "epoch": 1.5814135103475206,
      "grad_norm": 11.679594039916992,
      "learning_rate": 4.9209293244826245e-05,
      "loss": 0.148,
      "step": 12150
    },
    {
      "epoch": 1.5879213848756994,
      "grad_norm": 0.07737796008586884,
      "learning_rate": 4.920603930756215e-05,
      "loss": 0.1569,
      "step": 12200
    },
    {
      "epoch": 1.5944292594038787,
      "grad_norm": 13.243753433227539,
      "learning_rate": 4.9202785370298066e-05,
      "loss": 0.1035,
      "step": 12250
    },
    {
      "epoch": 1.600937133932058,
      "grad_norm": 0.02416854351758957,
      "learning_rate": 4.919953143303397e-05,
      "loss": 0.1439,
      "step": 12300
    },
    {
      "epoch": 1.6074450084602367,
      "grad_norm": 5.927316188812256,
      "learning_rate": 4.919627749576988e-05,
      "loss": 0.1813,
      "step": 12350
    },
    {
      "epoch": 1.613952882988416,
      "grad_norm": 0.8304111957550049,
      "learning_rate": 4.9193023558505795e-05,
      "loss": 0.1752,
      "step": 12400
    },
    {
      "epoch": 1.6204607575165952,
      "grad_norm": 3.242077112197876,
      "learning_rate": 4.91897696212417e-05,
      "loss": 0.1199,
      "step": 12450
    },
    {
      "epoch": 1.626968632044774,
      "grad_norm": 0.08660236746072769,
      "learning_rate": 4.9186515683977616e-05,
      "loss": 0.1677,
      "step": 12500
    },
    {
      "epoch": 1.6334765065729533,
      "grad_norm": 0.15082260966300964,
      "learning_rate": 4.918326174671353e-05,
      "loss": 0.1521,
      "step": 12550
    },
    {
      "epoch": 1.6399843811011323,
      "grad_norm": 5.644507884979248,
      "learning_rate": 4.918000780944944e-05,
      "loss": 0.1509,
      "step": 12600
    },
    {
      "epoch": 1.6464922556293113,
      "grad_norm": 2.157442808151245,
      "learning_rate": 4.917675387218535e-05,
      "loss": 0.1238,
      "step": 12650
    },
    {
      "epoch": 1.6530001301574906,
      "grad_norm": 0.090110644698143,
      "learning_rate": 4.917349993492126e-05,
      "loss": 0.1004,
      "step": 12700
    },
    {
      "epoch": 1.6595080046856696,
      "grad_norm": 0.19340449571609497,
      "learning_rate": 4.9170245997657166e-05,
      "loss": 0.2002,
      "step": 12750
    },
    {
      "epoch": 1.6660158792138486,
      "grad_norm": 0.3538038432598114,
      "learning_rate": 4.916699206039308e-05,
      "loss": 0.0857,
      "step": 12800
    },
    {
      "epoch": 1.6725237537420279,
      "grad_norm": 0.7474675178527832,
      "learning_rate": 4.916373812312899e-05,
      "loss": 0.1564,
      "step": 12850
    },
    {
      "epoch": 1.679031628270207,
      "grad_norm": 4.8825554847717285,
      "learning_rate": 4.9160484185864895e-05,
      "loss": 0.2371,
      "step": 12900
    },
    {
      "epoch": 1.685539502798386,
      "grad_norm": 0.15645837783813477,
      "learning_rate": 4.915723024860081e-05,
      "loss": 0.1502,
      "step": 12950
    },
    {
      "epoch": 1.6920473773265652,
      "grad_norm": 0.21007506549358368,
      "learning_rate": 4.9153976311336716e-05,
      "loss": 0.1365,
      "step": 13000
    },
    {
      "epoch": 1.6985552518547442,
      "grad_norm": 1.0072402954101562,
      "learning_rate": 4.915072237407263e-05,
      "loss": 0.122,
      "step": 13050
    },
    {
      "epoch": 1.7050631263829232,
      "grad_norm": 20.391664505004883,
      "learning_rate": 4.9147468436808544e-05,
      "loss": 0.1678,
      "step": 13100
    },
    {
      "epoch": 1.7115710009111025,
      "grad_norm": 0.05528023838996887,
      "learning_rate": 4.914421449954445e-05,
      "loss": 0.1071,
      "step": 13150
    },
    {
      "epoch": 1.7180788754392815,
      "grad_norm": 0.019536742940545082,
      "learning_rate": 4.9140960562280365e-05,
      "loss": 0.0959,
      "step": 13200
    },
    {
      "epoch": 1.7245867499674605,
      "grad_norm": 0.04767356440424919,
      "learning_rate": 4.913770662501627e-05,
      "loss": 0.1441,
      "step": 13250
    },
    {
      "epoch": 1.7310946244956398,
      "grad_norm": 10.206432342529297,
      "learning_rate": 4.913445268775218e-05,
      "loss": 0.2135,
      "step": 13300
    },
    {
      "epoch": 1.7376024990238188,
      "grad_norm": 6.385863304138184,
      "learning_rate": 4.9131198750488094e-05,
      "loss": 0.1842,
      "step": 13350
    },
    {
      "epoch": 1.7441103735519978,
      "grad_norm": 0.03581838682293892,
      "learning_rate": 4.9127944813224e-05,
      "loss": 0.1645,
      "step": 13400
    },
    {
      "epoch": 1.750618248080177,
      "grad_norm": 5.491337776184082,
      "learning_rate": 4.912469087595991e-05,
      "loss": 0.1509,
      "step": 13450
    },
    {
      "epoch": 1.757126122608356,
      "grad_norm": 0.13854818046092987,
      "learning_rate": 4.912143693869582e-05,
      "loss": 0.1485,
      "step": 13500
    },
    {
      "epoch": 1.7636339971365351,
      "grad_norm": 7.22587251663208,
      "learning_rate": 4.911818300143174e-05,
      "loss": 0.1278,
      "step": 13550
    },
    {
      "epoch": 1.7701418716647144,
      "grad_norm": 0.058161839842796326,
      "learning_rate": 4.911492906416765e-05,
      "loss": 0.1493,
      "step": 13600
    },
    {
      "epoch": 1.7766497461928934,
      "grad_norm": 0.2587072253227234,
      "learning_rate": 4.911167512690356e-05,
      "loss": 0.1169,
      "step": 13650
    },
    {
      "epoch": 1.7831576207210724,
      "grad_norm": 4.668724060058594,
      "learning_rate": 4.9108421189639465e-05,
      "loss": 0.1821,
      "step": 13700
    },
    {
      "epoch": 1.7896654952492517,
      "grad_norm": 0.2494363635778427,
      "learning_rate": 4.910516725237538e-05,
      "loss": 0.1532,
      "step": 13750
    },
    {
      "epoch": 1.7961733697774307,
      "grad_norm": 0.07167938351631165,
      "learning_rate": 4.910191331511129e-05,
      "loss": 0.0673,
      "step": 13800
    },
    {
      "epoch": 1.8026812443056097,
      "grad_norm": 0.2139759212732315,
      "learning_rate": 4.9098659377847194e-05,
      "loss": 0.1911,
      "step": 13850
    },
    {
      "epoch": 1.809189118833789,
      "grad_norm": 6.645130157470703,
      "learning_rate": 4.909540544058311e-05,
      "loss": 0.1666,
      "step": 13900
    },
    {
      "epoch": 1.815696993361968,
      "grad_norm": 7.8851542472839355,
      "learning_rate": 4.9092151503319015e-05,
      "loss": 0.1389,
      "step": 13950
    },
    {
      "epoch": 1.822204867890147,
      "grad_norm": 0.03661886230111122,
      "learning_rate": 4.908889756605493e-05,
      "loss": 0.1408,
      "step": 14000
    },
    {
      "epoch": 1.8287127424183263,
      "grad_norm": 0.10194265097379684,
      "learning_rate": 4.9085643628790837e-05,
      "loss": 0.1121,
      "step": 14050
    },
    {
      "epoch": 1.8352206169465053,
      "grad_norm": 13.26901626586914,
      "learning_rate": 4.908238969152675e-05,
      "loss": 0.1183,
      "step": 14100
    },
    {
      "epoch": 1.8417284914746843,
      "grad_norm": 0.07233265042304993,
      "learning_rate": 4.9079135754262665e-05,
      "loss": 0.1018,
      "step": 14150
    },
    {
      "epoch": 1.8482363660028636,
      "grad_norm": 6.116343021392822,
      "learning_rate": 4.907588181699857e-05,
      "loss": 0.2039,
      "step": 14200
    },
    {
      "epoch": 1.8547442405310426,
      "grad_norm": 0.029885699972510338,
      "learning_rate": 4.907262787973448e-05,
      "loss": 0.1333,
      "step": 14250
    },
    {
      "epoch": 1.8612521150592216,
      "grad_norm": 0.06612466275691986,
      "learning_rate": 4.906937394247039e-05,
      "loss": 0.1746,
      "step": 14300
    },
    {
      "epoch": 1.8677599895874009,
      "grad_norm": 0.049233775585889816,
      "learning_rate": 4.90661200052063e-05,
      "loss": 0.1463,
      "step": 14350
    },
    {
      "epoch": 1.8742678641155799,
      "grad_norm": 0.05762655287981033,
      "learning_rate": 4.9062866067942215e-05,
      "loss": 0.1932,
      "step": 14400
    },
    {
      "epoch": 1.880775738643759,
      "grad_norm": 0.9342510104179382,
      "learning_rate": 4.905961213067812e-05,
      "loss": 0.1704,
      "step": 14450
    },
    {
      "epoch": 1.8872836131719382,
      "grad_norm": 1.985012412071228,
      "learning_rate": 4.905635819341403e-05,
      "loss": 0.1373,
      "step": 14500
    },
    {
      "epoch": 1.8937914877001172,
      "grad_norm": 0.07113059610128403,
      "learning_rate": 4.905310425614994e-05,
      "loss": 0.1514,
      "step": 14550
    },
    {
      "epoch": 1.9002993622282962,
      "grad_norm": 0.24279630184173584,
      "learning_rate": 4.904985031888585e-05,
      "loss": 0.1389,
      "step": 14600
    },
    {
      "epoch": 1.9068072367564755,
      "grad_norm": 1.5568612813949585,
      "learning_rate": 4.9046596381621765e-05,
      "loss": 0.2173,
      "step": 14650
    },
    {
      "epoch": 1.9133151112846545,
      "grad_norm": 6.497393608093262,
      "learning_rate": 4.904334244435768e-05,
      "loss": 0.1171,
      "step": 14700
    },
    {
      "epoch": 1.9198229858128335,
      "grad_norm": 0.10093584656715393,
      "learning_rate": 4.9040088507093586e-05,
      "loss": 0.1198,
      "step": 14750
    },
    {
      "epoch": 1.9263308603410128,
      "grad_norm": 0.04076114296913147,
      "learning_rate": 4.90368345698295e-05,
      "loss": 0.2034,
      "step": 14800
    },
    {
      "epoch": 1.9328387348691918,
      "grad_norm": 0.047204747796058655,
      "learning_rate": 4.903358063256541e-05,
      "loss": 0.1684,
      "step": 14850
    },
    {
      "epoch": 1.9393466093973708,
      "grad_norm": 0.13177898526191711,
      "learning_rate": 4.9030326695301315e-05,
      "loss": 0.133,
      "step": 14900
    },
    {
      "epoch": 1.94585448392555,
      "grad_norm": 0.052263177931308746,
      "learning_rate": 4.902707275803723e-05,
      "loss": 0.1666,
      "step": 14950
    },
    {
      "epoch": 1.9523623584537289,
      "grad_norm": 0.14488516747951508,
      "learning_rate": 4.9023818820773136e-05,
      "loss": 0.1691,
      "step": 15000
    },
    {
      "epoch": 1.958870232981908,
      "grad_norm": 0.0820934846997261,
      "learning_rate": 4.902056488350904e-05,
      "loss": 0.1535,
      "step": 15050
    },
    {
      "epoch": 1.9653781075100873,
      "grad_norm": 0.02219446934759617,
      "learning_rate": 4.901731094624496e-05,
      "loss": 0.1532,
      "step": 15100
    },
    {
      "epoch": 1.9718859820382661,
      "grad_norm": 1.121666431427002,
      "learning_rate": 4.901405700898087e-05,
      "loss": 0.1551,
      "step": 15150
    },
    {
      "epoch": 1.9783938565664454,
      "grad_norm": 3.1951489448547363,
      "learning_rate": 4.9010803071716785e-05,
      "loss": 0.0991,
      "step": 15200
    },
    {
      "epoch": 1.9849017310946246,
      "grad_norm": 9.022994041442871,
      "learning_rate": 4.900754913445269e-05,
      "loss": 0.2445,
      "step": 15250
    },
    {
      "epoch": 1.9914096056228034,
      "grad_norm": 2.134265899658203,
      "learning_rate": 4.90042951971886e-05,
      "loss": 0.1518,
      "step": 15300
    },
    {
      "epoch": 1.9979174801509827,
      "grad_norm": 0.03204072639346123,
      "learning_rate": 4.9001041259924514e-05,
      "loss": 0.1552,
      "step": 15350
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.957630979498861,
      "eval_f1": 0.9584741978694903,
      "eval_loss": 0.15767742693424225,
      "eval_precision": 0.93935983995999,
      "eval_recall": 0.9783826019012892,
      "eval_runtime": 23.5314,
      "eval_samples_per_second": 652.957,
      "eval_steps_per_second": 81.636,
      "step": 15366
    },
    {
      "epoch": 2.004425354679162,
      "grad_norm": 7.797076225280762,
      "learning_rate": 4.899778732266042e-05,
      "loss": 0.1141,
      "step": 15400
    },
    {
      "epoch": 2.0109332292073407,
      "grad_norm": 11.346613883972168,
      "learning_rate": 4.899453338539633e-05,
      "loss": 0.1109,
      "step": 15450
    },
    {
      "epoch": 2.01744110373552,
      "grad_norm": 1.0078827142715454,
      "learning_rate": 4.899127944813224e-05,
      "loss": 0.1189,
      "step": 15500
    },
    {
      "epoch": 2.0239489782636992,
      "grad_norm": 0.0685650110244751,
      "learning_rate": 4.898802551086815e-05,
      "loss": 0.1302,
      "step": 15550
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 7.899686336517334,
      "learning_rate": 4.8984771573604064e-05,
      "loss": 0.1856,
      "step": 15600
    },
    {
      "epoch": 2.0369647273200573,
      "grad_norm": 0.04603924974799156,
      "learning_rate": 4.898151763633997e-05,
      "loss": 0.096,
      "step": 15650
    },
    {
      "epoch": 2.0434726018482365,
      "grad_norm": 21.939945220947266,
      "learning_rate": 4.8978263699075885e-05,
      "loss": 0.1598,
      "step": 15700
    },
    {
      "epoch": 2.0499804763764153,
      "grad_norm": 12.191812515258789,
      "learning_rate": 4.89750097618118e-05,
      "loss": 0.1432,
      "step": 15750
    },
    {
      "epoch": 2.0564883509045946,
      "grad_norm": 0.16421853005886078,
      "learning_rate": 4.897175582454771e-05,
      "loss": 0.1262,
      "step": 15800
    },
    {
      "epoch": 2.062996225432774,
      "grad_norm": 0.48563218116760254,
      "learning_rate": 4.8968501887283614e-05,
      "loss": 0.1767,
      "step": 15850
    },
    {
      "epoch": 2.0695040999609526,
      "grad_norm": 0.2543254494667053,
      "learning_rate": 4.896524795001953e-05,
      "loss": 0.1269,
      "step": 15900
    },
    {
      "epoch": 2.076011974489132,
      "grad_norm": 0.22104069590568542,
      "learning_rate": 4.8961994012755435e-05,
      "loss": 0.1306,
      "step": 15950
    },
    {
      "epoch": 2.082519849017311,
      "grad_norm": 0.028700875118374825,
      "learning_rate": 4.895874007549135e-05,
      "loss": 0.1341,
      "step": 16000
    },
    {
      "epoch": 2.08902772354549,
      "grad_norm": 0.10041572153568268,
      "learning_rate": 4.895548613822726e-05,
      "loss": 0.123,
      "step": 16050
    },
    {
      "epoch": 2.095535598073669,
      "grad_norm": 0.04513291269540787,
      "learning_rate": 4.8952232200963164e-05,
      "loss": 0.1746,
      "step": 16100
    },
    {
      "epoch": 2.1020434726018484,
      "grad_norm": 23.85489273071289,
      "learning_rate": 4.894897826369908e-05,
      "loss": 0.1347,
      "step": 16150
    },
    {
      "epoch": 2.1085513471300272,
      "grad_norm": 2.281782865524292,
      "learning_rate": 4.8945724326434985e-05,
      "loss": 0.1243,
      "step": 16200
    },
    {
      "epoch": 2.1150592216582065,
      "grad_norm": 4.3162078857421875,
      "learning_rate": 4.89424703891709e-05,
      "loss": 0.0908,
      "step": 16250
    },
    {
      "epoch": 2.1215670961863857,
      "grad_norm": 10.04615592956543,
      "learning_rate": 4.8939216451906813e-05,
      "loss": 0.1379,
      "step": 16300
    },
    {
      "epoch": 2.1280749707145645,
      "grad_norm": 1.536232352256775,
      "learning_rate": 4.893596251464272e-05,
      "loss": 0.1465,
      "step": 16350
    },
    {
      "epoch": 2.1345828452427438,
      "grad_norm": 0.21692000329494476,
      "learning_rate": 4.8932708577378635e-05,
      "loss": 0.1383,
      "step": 16400
    },
    {
      "epoch": 2.141090719770923,
      "grad_norm": 16.96668815612793,
      "learning_rate": 4.892945464011454e-05,
      "loss": 0.1488,
      "step": 16450
    },
    {
      "epoch": 2.147598594299102,
      "grad_norm": 2.7147974967956543,
      "learning_rate": 4.892620070285045e-05,
      "loss": 0.1198,
      "step": 16500
    },
    {
      "epoch": 2.154106468827281,
      "grad_norm": 0.4049952030181885,
      "learning_rate": 4.892294676558636e-05,
      "loss": 0.1579,
      "step": 16550
    },
    {
      "epoch": 2.1606143433554603,
      "grad_norm": 0.21015870571136475,
      "learning_rate": 4.891969282832227e-05,
      "loss": 0.1449,
      "step": 16600
    },
    {
      "epoch": 2.167122217883639,
      "grad_norm": 0.2752813696861267,
      "learning_rate": 4.891643889105818e-05,
      "loss": 0.1046,
      "step": 16650
    },
    {
      "epoch": 2.1736300924118184,
      "grad_norm": 0.024910980835556984,
      "learning_rate": 4.891318495379409e-05,
      "loss": 0.0939,
      "step": 16700
    },
    {
      "epoch": 2.1801379669399976,
      "grad_norm": 23.137601852416992,
      "learning_rate": 4.8909931016530006e-05,
      "loss": 0.1378,
      "step": 16750
    },
    {
      "epoch": 2.1866458414681764,
      "grad_norm": 0.019716138020157814,
      "learning_rate": 4.890667707926592e-05,
      "loss": 0.1853,
      "step": 16800
    },
    {
      "epoch": 2.1931537159963557,
      "grad_norm": 0.11892297118902206,
      "learning_rate": 4.890342314200183e-05,
      "loss": 0.1467,
      "step": 16850
    },
    {
      "epoch": 2.199661590524535,
      "grad_norm": 0.042628828436136246,
      "learning_rate": 4.8900169204737735e-05,
      "loss": 0.1343,
      "step": 16900
    },
    {
      "epoch": 2.2061694650527137,
      "grad_norm": 0.17061102390289307,
      "learning_rate": 4.889691526747365e-05,
      "loss": 0.145,
      "step": 16950
    },
    {
      "epoch": 2.212677339580893,
      "grad_norm": 0.8359262943267822,
      "learning_rate": 4.8893661330209556e-05,
      "loss": 0.0879,
      "step": 17000
    },
    {
      "epoch": 2.219185214109072,
      "grad_norm": 13.92702865600586,
      "learning_rate": 4.889040739294546e-05,
      "loss": 0.1264,
      "step": 17050
    },
    {
      "epoch": 2.225693088637251,
      "grad_norm": 3.7105181217193604,
      "learning_rate": 4.888715345568138e-05,
      "loss": 0.1298,
      "step": 17100
    },
    {
      "epoch": 2.2322009631654303,
      "grad_norm": 1.963477611541748,
      "learning_rate": 4.8883899518417285e-05,
      "loss": 0.1118,
      "step": 17150
    },
    {
      "epoch": 2.238708837693609,
      "grad_norm": 15.741917610168457,
      "learning_rate": 4.88806455811532e-05,
      "loss": 0.1408,
      "step": 17200
    },
    {
      "epoch": 2.2452167122217883,
      "grad_norm": 4.839621543884277,
      "learning_rate": 4.8877391643889106e-05,
      "loss": 0.1596,
      "step": 17250
    },
    {
      "epoch": 2.2517245867499676,
      "grad_norm": 0.17438547313213348,
      "learning_rate": 4.887413770662502e-05,
      "loss": 0.1349,
      "step": 17300
    },
    {
      "epoch": 2.2582324612781464,
      "grad_norm": 0.1263711154460907,
      "learning_rate": 4.8870883769360934e-05,
      "loss": 0.2115,
      "step": 17350
    },
    {
      "epoch": 2.2647403358063256,
      "grad_norm": 5.637409210205078,
      "learning_rate": 4.886762983209684e-05,
      "loss": 0.1212,
      "step": 17400
    },
    {
      "epoch": 2.271248210334505,
      "grad_norm": 9.137714385986328,
      "learning_rate": 4.886437589483275e-05,
      "loss": 0.1143,
      "step": 17450
    },
    {
      "epoch": 2.2777560848626837,
      "grad_norm": 0.2410699874162674,
      "learning_rate": 4.886112195756866e-05,
      "loss": 0.146,
      "step": 17500
    },
    {
      "epoch": 2.284263959390863,
      "grad_norm": 1.494920253753662,
      "learning_rate": 4.885786802030457e-05,
      "loss": 0.1168,
      "step": 17550
    },
    {
      "epoch": 2.290771833919042,
      "grad_norm": 13.794830322265625,
      "learning_rate": 4.885461408304048e-05,
      "loss": 0.1114,
      "step": 17600
    },
    {
      "epoch": 2.297279708447221,
      "grad_norm": 0.027646159753203392,
      "learning_rate": 4.885136014577639e-05,
      "loss": 0.1622,
      "step": 17650
    },
    {
      "epoch": 2.3037875829754,
      "grad_norm": 0.050578076392412186,
      "learning_rate": 4.88481062085123e-05,
      "loss": 0.1458,
      "step": 17700
    },
    {
      "epoch": 2.3102954575035795,
      "grad_norm": 2.0325229167938232,
      "learning_rate": 4.884485227124821e-05,
      "loss": 0.1378,
      "step": 17750
    },
    {
      "epoch": 2.3168033320317583,
      "grad_norm": 0.033298831433057785,
      "learning_rate": 4.884159833398412e-05,
      "loss": 0.1806,
      "step": 17800
    },
    {
      "epoch": 2.3233112065599375,
      "grad_norm": 0.11425977945327759,
      "learning_rate": 4.8838344396720034e-05,
      "loss": 0.1577,
      "step": 17850
    },
    {
      "epoch": 2.3298190810881168,
      "grad_norm": 0.043812066316604614,
      "learning_rate": 4.883509045945595e-05,
      "loss": 0.1455,
      "step": 17900
    },
    {
      "epoch": 2.3363269556162956,
      "grad_norm": 14.725293159484863,
      "learning_rate": 4.8831836522191855e-05,
      "loss": 0.1595,
      "step": 17950
    },
    {
      "epoch": 2.342834830144475,
      "grad_norm": 0.026033367961645126,
      "learning_rate": 4.882858258492776e-05,
      "loss": 0.1178,
      "step": 18000
    },
    {
      "epoch": 2.349342704672654,
      "grad_norm": 13.511418342590332,
      "learning_rate": 4.882532864766368e-05,
      "loss": 0.0997,
      "step": 18050
    },
    {
      "epoch": 2.355850579200833,
      "grad_norm": 1.3838070631027222,
      "learning_rate": 4.8822074710399584e-05,
      "loss": 0.1723,
      "step": 18100
    },
    {
      "epoch": 2.362358453729012,
      "grad_norm": 8.137016296386719,
      "learning_rate": 4.88188207731355e-05,
      "loss": 0.1129,
      "step": 18150
    },
    {
      "epoch": 2.3688663282571913,
      "grad_norm": 0.03568211570382118,
      "learning_rate": 4.8815566835871405e-05,
      "loss": 0.1252,
      "step": 18200
    },
    {
      "epoch": 2.37537420278537,
      "grad_norm": 0.4262472689151764,
      "learning_rate": 4.881231289860731e-05,
      "loss": 0.1787,
      "step": 18250
    },
    {
      "epoch": 2.3818820773135494,
      "grad_norm": 0.10068541020154953,
      "learning_rate": 4.880905896134323e-05,
      "loss": 0.1546,
      "step": 18300
    },
    {
      "epoch": 2.3883899518417286,
      "grad_norm": 2.91074800491333,
      "learning_rate": 4.880580502407914e-05,
      "loss": 0.0384,
      "step": 18350
    },
    {
      "epoch": 2.3948978263699074,
      "grad_norm": 0.14017127454280853,
      "learning_rate": 4.880255108681505e-05,
      "loss": 0.0889,
      "step": 18400
    },
    {
      "epoch": 2.4014057008980867,
      "grad_norm": 0.011899822391569614,
      "learning_rate": 4.879929714955096e-05,
      "loss": 0.063,
      "step": 18450
    },
    {
      "epoch": 2.407913575426266,
      "grad_norm": 0.035371117293834686,
      "learning_rate": 4.879604321228687e-05,
      "loss": 0.2144,
      "step": 18500
    },
    {
      "epoch": 2.4144214499544447,
      "grad_norm": 0.017105113714933395,
      "learning_rate": 4.8792789275022783e-05,
      "loss": 0.1306,
      "step": 18550
    },
    {
      "epoch": 2.420929324482624,
      "grad_norm": 5.068283557891846,
      "learning_rate": 4.878953533775869e-05,
      "loss": 0.1678,
      "step": 18600
    },
    {
      "epoch": 2.4274371990108032,
      "grad_norm": 0.031552426517009735,
      "learning_rate": 4.87862814004946e-05,
      "loss": 0.1411,
      "step": 18650
    },
    {
      "epoch": 2.433945073538982,
      "grad_norm": 0.023961974307894707,
      "learning_rate": 4.878302746323051e-05,
      "loss": 0.1429,
      "step": 18700
    },
    {
      "epoch": 2.4404529480671613,
      "grad_norm": 7.052323341369629,
      "learning_rate": 4.877977352596642e-05,
      "loss": 0.1339,
      "step": 18750
    },
    {
      "epoch": 2.4469608225953405,
      "grad_norm": 0.1224079355597496,
      "learning_rate": 4.877651958870233e-05,
      "loss": 0.1172,
      "step": 18800
    },
    {
      "epoch": 2.4534686971235193,
      "grad_norm": 0.030196910724043846,
      "learning_rate": 4.877326565143824e-05,
      "loss": 0.1052,
      "step": 18850
    },
    {
      "epoch": 2.4599765716516986,
      "grad_norm": 23.72169303894043,
      "learning_rate": 4.8770011714174155e-05,
      "loss": 0.1035,
      "step": 18900
    },
    {
      "epoch": 2.466484446179878,
      "grad_norm": 0.15595221519470215,
      "learning_rate": 4.876675777691007e-05,
      "loss": 0.1766,
      "step": 18950
    },
    {
      "epoch": 2.4729923207080566,
      "grad_norm": 0.10904870927333832,
      "learning_rate": 4.8763503839645976e-05,
      "loss": 0.1223,
      "step": 19000
    },
    {
      "epoch": 2.479500195236236,
      "grad_norm": 0.04518578574061394,
      "learning_rate": 4.876024990238188e-05,
      "loss": 0.1622,
      "step": 19050
    },
    {
      "epoch": 2.486008069764415,
      "grad_norm": 1.1210267543792725,
      "learning_rate": 4.87569959651178e-05,
      "loss": 0.1191,
      "step": 19100
    },
    {
      "epoch": 2.492515944292594,
      "grad_norm": 0.04031261429190636,
      "learning_rate": 4.8753742027853705e-05,
      "loss": 0.1418,
      "step": 19150
    },
    {
      "epoch": 2.499023818820773,
      "grad_norm": 0.027552153915166855,
      "learning_rate": 4.875048809058961e-05,
      "loss": 0.134,
      "step": 19200
    },
    {
      "epoch": 2.505531693348952,
      "grad_norm": 0.14764264225959778,
      "learning_rate": 4.8747234153325526e-05,
      "loss": 0.1107,
      "step": 19250
    },
    {
      "epoch": 2.5120395678771312,
      "grad_norm": 13.316261291503906,
      "learning_rate": 4.874398021606143e-05,
      "loss": 0.1238,
      "step": 19300
    },
    {
      "epoch": 2.5185474424053105,
      "grad_norm": 0.07016028463840485,
      "learning_rate": 4.874072627879735e-05,
      "loss": 0.1336,
      "step": 19350
    },
    {
      "epoch": 2.5250553169334893,
      "grad_norm": 12.935718536376953,
      "learning_rate": 4.8737472341533255e-05,
      "loss": 0.1218,
      "step": 19400
    },
    {
      "epoch": 2.5315631914616685,
      "grad_norm": 0.013753043487668037,
      "learning_rate": 4.873421840426917e-05,
      "loss": 0.0878,
      "step": 19450
    },
    {
      "epoch": 2.5380710659898478,
      "grad_norm": 6.214257717132568,
      "learning_rate": 4.873096446700508e-05,
      "loss": 0.121,
      "step": 19500
    },
    {
      "epoch": 2.5445789405180266,
      "grad_norm": 8.685687065124512,
      "learning_rate": 4.872771052974099e-05,
      "loss": 0.1677,
      "step": 19550
    },
    {
      "epoch": 2.551086815046206,
      "grad_norm": 0.10380689799785614,
      "learning_rate": 4.87244565924769e-05,
      "loss": 0.0926,
      "step": 19600
    },
    {
      "epoch": 2.557594689574385,
      "grad_norm": 0.5467530488967896,
      "learning_rate": 4.872120265521281e-05,
      "loss": 0.1321,
      "step": 19650
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 13.203764915466309,
      "learning_rate": 4.871794871794872e-05,
      "loss": 0.1004,
      "step": 19700
    },
    {
      "epoch": 2.570610438630743,
      "grad_norm": 0.19385361671447754,
      "learning_rate": 4.871469478068463e-05,
      "loss": 0.1426,
      "step": 19750
    },
    {
      "epoch": 2.5771183131589224,
      "grad_norm": 7.010174751281738,
      "learning_rate": 4.871144084342054e-05,
      "loss": 0.1406,
      "step": 19800
    },
    {
      "epoch": 2.583626187687101,
      "grad_norm": 5.716273784637451,
      "learning_rate": 4.870818690615645e-05,
      "loss": 0.1401,
      "step": 19850
    },
    {
      "epoch": 2.5901340622152804,
      "grad_norm": 1.1403930187225342,
      "learning_rate": 4.870493296889236e-05,
      "loss": 0.1299,
      "step": 19900
    },
    {
      "epoch": 2.5966419367434597,
      "grad_norm": 17.863107681274414,
      "learning_rate": 4.8701679031628275e-05,
      "loss": 0.1786,
      "step": 19950
    },
    {
      "epoch": 2.6031498112716385,
      "grad_norm": 0.44097164273262024,
      "learning_rate": 4.869842509436418e-05,
      "loss": 0.1334,
      "step": 20000
    },
    {
      "epoch": 2.6096576857998177,
      "grad_norm": 3.0073280334472656,
      "learning_rate": 4.86951711571001e-05,
      "loss": 0.1231,
      "step": 20050
    },
    {
      "epoch": 2.616165560327997,
      "grad_norm": 0.03746332973241806,
      "learning_rate": 4.8691917219836004e-05,
      "loss": 0.1346,
      "step": 20100
    },
    {
      "epoch": 2.6226734348561758,
      "grad_norm": 0.2895454466342926,
      "learning_rate": 4.868866328257192e-05,
      "loss": 0.1358,
      "step": 20150
    },
    {
      "epoch": 2.629181309384355,
      "grad_norm": 0.40780267119407654,
      "learning_rate": 4.8685409345307825e-05,
      "loss": 0.1671,
      "step": 20200
    },
    {
      "epoch": 2.6356891839125343,
      "grad_norm": 0.056738656014204025,
      "learning_rate": 4.868215540804373e-05,
      "loss": 0.188,
      "step": 20250
    },
    {
      "epoch": 2.642197058440713,
      "grad_norm": 0.4718140661716461,
      "learning_rate": 4.867890147077965e-05,
      "loss": 0.1632,
      "step": 20300
    },
    {
      "epoch": 2.6487049329688923,
      "grad_norm": 9.483783721923828,
      "learning_rate": 4.8675647533515554e-05,
      "loss": 0.0943,
      "step": 20350
    },
    {
      "epoch": 2.6552128074970716,
      "grad_norm": 11.253108024597168,
      "learning_rate": 4.867239359625146e-05,
      "loss": 0.1422,
      "step": 20400
    },
    {
      "epoch": 2.6617206820252504,
      "grad_norm": 0.018036244437098503,
      "learning_rate": 4.8669139658987375e-05,
      "loss": 0.1146,
      "step": 20450
    },
    {
      "epoch": 2.6682285565534296,
      "grad_norm": 0.0861050933599472,
      "learning_rate": 4.866588572172329e-05,
      "loss": 0.1529,
      "step": 20500
    },
    {
      "epoch": 2.674736431081609,
      "grad_norm": 0.39398279786109924,
      "learning_rate": 4.8662631784459204e-05,
      "loss": 0.1047,
      "step": 20550
    },
    {
      "epoch": 2.6812443056097877,
      "grad_norm": 9.00473690032959,
      "learning_rate": 4.865937784719511e-05,
      "loss": 0.1111,
      "step": 20600
    },
    {
      "epoch": 2.687752180137967,
      "grad_norm": 12.554722785949707,
      "learning_rate": 4.865612390993102e-05,
      "loss": 0.1507,
      "step": 20650
    },
    {
      "epoch": 2.694260054666146,
      "grad_norm": 15.931230545043945,
      "learning_rate": 4.865286997266693e-05,
      "loss": 0.1357,
      "step": 20700
    },
    {
      "epoch": 2.700767929194325,
      "grad_norm": 0.06763004511594772,
      "learning_rate": 4.864961603540284e-05,
      "loss": 0.0884,
      "step": 20750
    },
    {
      "epoch": 2.707275803722504,
      "grad_norm": 4.345361709594727,
      "learning_rate": 4.864636209813875e-05,
      "loss": 0.1198,
      "step": 20800
    },
    {
      "epoch": 2.7137836782506835,
      "grad_norm": 0.021687960252165794,
      "learning_rate": 4.864310816087466e-05,
      "loss": 0.0568,
      "step": 20850
    },
    {
      "epoch": 2.7202915527788623,
      "grad_norm": 0.026941196992993355,
      "learning_rate": 4.863985422361057e-05,
      "loss": 0.1323,
      "step": 20900
    },
    {
      "epoch": 2.7267994273070415,
      "grad_norm": 0.0141479866579175,
      "learning_rate": 4.863660028634648e-05,
      "loss": 0.1032,
      "step": 20950
    },
    {
      "epoch": 2.7333073018352207,
      "grad_norm": 4.967340469360352,
      "learning_rate": 4.863334634908239e-05,
      "loss": 0.1157,
      "step": 21000
    },
    {
      "epoch": 2.7398151763633996,
      "grad_norm": 0.09730853140354156,
      "learning_rate": 4.8630092411818303e-05,
      "loss": 0.2053,
      "step": 21050
    },
    {
      "epoch": 2.746323050891579,
      "grad_norm": 5.7590250968933105,
      "learning_rate": 4.862683847455422e-05,
      "loss": 0.1484,
      "step": 21100
    },
    {
      "epoch": 2.752830925419758,
      "grad_norm": 0.5050641298294067,
      "learning_rate": 4.8623584537290125e-05,
      "loss": 0.1624,
      "step": 21150
    },
    {
      "epoch": 2.759338799947937,
      "grad_norm": 7.524742126464844,
      "learning_rate": 4.862033060002603e-05,
      "loss": 0.1432,
      "step": 21200
    },
    {
      "epoch": 2.765846674476116,
      "grad_norm": 1.9896836280822754,
      "learning_rate": 4.8617076662761946e-05,
      "loss": 0.1103,
      "step": 21250
    },
    {
      "epoch": 2.7723545490042953,
      "grad_norm": 11.995037078857422,
      "learning_rate": 4.8613822725497853e-05,
      "loss": 0.1152,
      "step": 21300
    },
    {
      "epoch": 2.778862423532474,
      "grad_norm": 0.5257721543312073,
      "learning_rate": 4.861056878823377e-05,
      "loss": 0.1653,
      "step": 21350
    },
    {
      "epoch": 2.7853702980606534,
      "grad_norm": 0.06854847818613052,
      "learning_rate": 4.8607314850969675e-05,
      "loss": 0.1627,
      "step": 21400
    },
    {
      "epoch": 2.7918781725888326,
      "grad_norm": 6.819100856781006,
      "learning_rate": 4.860406091370558e-05,
      "loss": 0.1692,
      "step": 21450
    },
    {
      "epoch": 2.7983860471170114,
      "grad_norm": 9.00434684753418,
      "learning_rate": 4.8600806976441496e-05,
      "loss": 0.1439,
      "step": 21500
    },
    {
      "epoch": 2.8048939216451907,
      "grad_norm": 2.615994691848755,
      "learning_rate": 4.859755303917741e-05,
      "loss": 0.0788,
      "step": 21550
    },
    {
      "epoch": 2.81140179617337,
      "grad_norm": 9.736556053161621,
      "learning_rate": 4.859429910191332e-05,
      "loss": 0.0863,
      "step": 21600
    },
    {
      "epoch": 2.8179096707015487,
      "grad_norm": 0.05818544328212738,
      "learning_rate": 4.859104516464923e-05,
      "loss": 0.1,
      "step": 21650
    },
    {
      "epoch": 2.824417545229728,
      "grad_norm": 0.12648481130599976,
      "learning_rate": 4.858779122738514e-05,
      "loss": 0.0809,
      "step": 21700
    },
    {
      "epoch": 2.8309254197579072,
      "grad_norm": 0.019126208499073982,
      "learning_rate": 4.8584537290121046e-05,
      "loss": 0.1063,
      "step": 21750
    },
    {
      "epoch": 2.837433294286086,
      "grad_norm": 19.46422004699707,
      "learning_rate": 4.858128335285696e-05,
      "loss": 0.2404,
      "step": 21800
    },
    {
      "epoch": 2.8439411688142653,
      "grad_norm": 0.11361008137464523,
      "learning_rate": 4.857802941559287e-05,
      "loss": 0.1426,
      "step": 21850
    },
    {
      "epoch": 2.8504490433424445,
      "grad_norm": 22.921669006347656,
      "learning_rate": 4.857477547832878e-05,
      "loss": 0.0937,
      "step": 21900
    },
    {
      "epoch": 2.8569569178706233,
      "grad_norm": 12.37033462524414,
      "learning_rate": 4.857152154106469e-05,
      "loss": 0.218,
      "step": 21950
    },
    {
      "epoch": 2.8634647923988026,
      "grad_norm": 0.8251739144325256,
      "learning_rate": 4.8568267603800596e-05,
      "loss": 0.1286,
      "step": 22000
    },
    {
      "epoch": 2.869972666926982,
      "grad_norm": 5.399989604949951,
      "learning_rate": 4.856501366653651e-05,
      "loss": 0.1397,
      "step": 22050
    },
    {
      "epoch": 2.8764805414551606,
      "grad_norm": 0.012404902838170528,
      "learning_rate": 4.8561759729272424e-05,
      "loss": 0.1129,
      "step": 22100
    },
    {
      "epoch": 2.88298841598334,
      "grad_norm": 0.12743036448955536,
      "learning_rate": 4.855850579200833e-05,
      "loss": 0.1119,
      "step": 22150
    },
    {
      "epoch": 2.889496290511519,
      "grad_norm": 0.07312975078821182,
      "learning_rate": 4.8555251854744245e-05,
      "loss": 0.0839,
      "step": 22200
    },
    {
      "epoch": 2.896004165039698,
      "grad_norm": 0.2517096996307373,
      "learning_rate": 4.855199791748015e-05,
      "loss": 0.1014,
      "step": 22250
    },
    {
      "epoch": 2.902512039567877,
      "grad_norm": 0.03584212064743042,
      "learning_rate": 4.854874398021607e-05,
      "loss": 0.1424,
      "step": 22300
    },
    {
      "epoch": 2.9090199140960564,
      "grad_norm": 11.233590126037598,
      "learning_rate": 4.8545490042951974e-05,
      "loss": 0.1969,
      "step": 22350
    },
    {
      "epoch": 2.9155277886242352,
      "grad_norm": 8.48696517944336,
      "learning_rate": 4.854223610568788e-05,
      "loss": 0.1713,
      "step": 22400
    },
    {
      "epoch": 2.9220356631524145,
      "grad_norm": 0.10478278249502182,
      "learning_rate": 4.8538982168423795e-05,
      "loss": 0.1206,
      "step": 22450
    },
    {
      "epoch": 2.9285435376805937,
      "grad_norm": 9.108345985412598,
      "learning_rate": 4.85357282311597e-05,
      "loss": 0.099,
      "step": 22500
    },
    {
      "epoch": 2.9350514122087725,
      "grad_norm": 0.02820737101137638,
      "learning_rate": 4.853247429389561e-05,
      "loss": 0.1064,
      "step": 22550
    },
    {
      "epoch": 2.9415592867369518,
      "grad_norm": 11.466516494750977,
      "learning_rate": 4.8529220356631524e-05,
      "loss": 0.1449,
      "step": 22600
    },
    {
      "epoch": 2.948067161265131,
      "grad_norm": 2.4706602096557617,
      "learning_rate": 4.852596641936744e-05,
      "loss": 0.194,
      "step": 22650
    },
    {
      "epoch": 2.95457503579331,
      "grad_norm": 0.12021327763795853,
      "learning_rate": 4.852271248210335e-05,
      "loss": 0.0852,
      "step": 22700
    },
    {
      "epoch": 2.961082910321489,
      "grad_norm": 0.05535348504781723,
      "learning_rate": 4.851945854483926e-05,
      "loss": 0.0955,
      "step": 22750
    },
    {
      "epoch": 2.9675907848496683,
      "grad_norm": 13.209935188293457,
      "learning_rate": 4.851620460757517e-05,
      "loss": 0.1399,
      "step": 22800
    },
    {
      "epoch": 2.974098659377847,
      "grad_norm": 0.014339552260935307,
      "learning_rate": 4.851295067031108e-05,
      "loss": 0.1224,
      "step": 22850
    },
    {
      "epoch": 2.9806065339060264,
      "grad_norm": 7.235111236572266,
      "learning_rate": 4.850969673304699e-05,
      "loss": 0.1389,
      "step": 22900
    },
    {
      "epoch": 2.9871144084342056,
      "grad_norm": 11.54689884185791,
      "learning_rate": 4.8506442795782895e-05,
      "loss": 0.1205,
      "step": 22950
    },
    {
      "epoch": 2.9936222829623844,
      "grad_norm": 0.39972370862960815,
      "learning_rate": 4.850318885851881e-05,
      "loss": 0.162,
      "step": 23000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9609502115196876,
      "eval_f1": 0.9607945635128071,
      "eval_loss": 0.13890495896339417,
      "eval_precision": 0.9641967213114754,
      "eval_recall": 0.9574163302513348,
      "eval_runtime": 23.5444,
      "eval_samples_per_second": 652.597,
      "eval_steps_per_second": 81.591,
      "step": 23049
    },
    {
      "epoch": 3.0001301574905637,
      "grad_norm": 0.593690812587738,
      "learning_rate": 4.849993492125472e-05,
      "loss": 0.0991,
      "step": 23050
    },
    {
      "epoch": 3.0066380320187425,
      "grad_norm": 1.1539154052734375,
      "learning_rate": 4.849668098399063e-05,
      "loss": 0.1507,
      "step": 23100
    },
    {
      "epoch": 3.0131459065469217,
      "grad_norm": 8.46802806854248,
      "learning_rate": 4.8493427046726545e-05,
      "loss": 0.0993,
      "step": 23150
    },
    {
      "epoch": 3.019653781075101,
      "grad_norm": 0.023874778300523758,
      "learning_rate": 4.849017310946245e-05,
      "loss": 0.0972,
      "step": 23200
    },
    {
      "epoch": 3.0261616556032798,
      "grad_norm": 0.012888340279459953,
      "learning_rate": 4.8486919172198366e-05,
      "loss": 0.1025,
      "step": 23250
    },
    {
      "epoch": 3.032669530131459,
      "grad_norm": 0.06822624802589417,
      "learning_rate": 4.8483665234934273e-05,
      "loss": 0.1,
      "step": 23300
    },
    {
      "epoch": 3.0391774046596383,
      "grad_norm": 6.364134788513184,
      "learning_rate": 4.848041129767018e-05,
      "loss": 0.1196,
      "step": 23350
    },
    {
      "epoch": 3.045685279187817,
      "grad_norm": 0.05296402424573898,
      "learning_rate": 4.8477157360406095e-05,
      "loss": 0.1991,
      "step": 23400
    },
    {
      "epoch": 3.0521931537159963,
      "grad_norm": 1.0721279382705688,
      "learning_rate": 4.8473903423142e-05,
      "loss": 0.1571,
      "step": 23450
    },
    {
      "epoch": 3.0587010282441756,
      "grad_norm": 2.3439857959747314,
      "learning_rate": 4.8470649485877916e-05,
      "loss": 0.1511,
      "step": 23500
    },
    {
      "epoch": 3.0652089027723544,
      "grad_norm": 14.816227912902832,
      "learning_rate": 4.8467395548613823e-05,
      "loss": 0.0851,
      "step": 23550
    },
    {
      "epoch": 3.0717167773005336,
      "grad_norm": 4.755258560180664,
      "learning_rate": 4.846414161134973e-05,
      "loss": 0.1531,
      "step": 23600
    },
    {
      "epoch": 3.078224651828713,
      "grad_norm": 0.15966565907001495,
      "learning_rate": 4.8460887674085645e-05,
      "loss": 0.1565,
      "step": 23650
    },
    {
      "epoch": 3.0847325263568917,
      "grad_norm": 12.640557289123535,
      "learning_rate": 4.845763373682156e-05,
      "loss": 0.1798,
      "step": 23700
    },
    {
      "epoch": 3.091240400885071,
      "grad_norm": 4.895206928253174,
      "learning_rate": 4.8454379799557466e-05,
      "loss": 0.1573,
      "step": 23750
    },
    {
      "epoch": 3.09774827541325,
      "grad_norm": 1.1120179891586304,
      "learning_rate": 4.845112586229338e-05,
      "loss": 0.1004,
      "step": 23800
    },
    {
      "epoch": 3.104256149941429,
      "grad_norm": 11.142414093017578,
      "learning_rate": 4.844787192502929e-05,
      "loss": 0.1524,
      "step": 23850
    },
    {
      "epoch": 3.110764024469608,
      "grad_norm": 0.027851084247231483,
      "learning_rate": 4.84446179877652e-05,
      "loss": 0.2043,
      "step": 23900
    },
    {
      "epoch": 3.1172718989977874,
      "grad_norm": 3.647763729095459,
      "learning_rate": 4.844136405050111e-05,
      "loss": 0.115,
      "step": 23950
    },
    {
      "epoch": 3.1237797735259663,
      "grad_norm": 0.02096526511013508,
      "learning_rate": 4.8438110113237016e-05,
      "loss": 0.1032,
      "step": 24000
    },
    {
      "epoch": 3.1302876480541455,
      "grad_norm": 10.403385162353516,
      "learning_rate": 4.843485617597293e-05,
      "loss": 0.1099,
      "step": 24050
    },
    {
      "epoch": 3.1367955225823247,
      "grad_norm": 8.59312629699707,
      "learning_rate": 4.843160223870884e-05,
      "loss": 0.1186,
      "step": 24100
    },
    {
      "epoch": 3.1433033971105035,
      "grad_norm": 0.10443432629108429,
      "learning_rate": 4.8428348301444745e-05,
      "loss": 0.1294,
      "step": 24150
    },
    {
      "epoch": 3.149811271638683,
      "grad_norm": 0.1461266577243805,
      "learning_rate": 4.842509436418066e-05,
      "loss": 0.0959,
      "step": 24200
    },
    {
      "epoch": 3.156319146166862,
      "grad_norm": 1.5345853567123413,
      "learning_rate": 4.842184042691657e-05,
      "loss": 0.1348,
      "step": 24250
    },
    {
      "epoch": 3.162827020695041,
      "grad_norm": 13.384522438049316,
      "learning_rate": 4.841858648965249e-05,
      "loss": 0.208,
      "step": 24300
    },
    {
      "epoch": 3.16933489522322,
      "grad_norm": 0.069160096347332,
      "learning_rate": 4.8415332552388394e-05,
      "loss": 0.1073,
      "step": 24350
    },
    {
      "epoch": 3.1758427697513993,
      "grad_norm": 0.01788705214858055,
      "learning_rate": 4.84120786151243e-05,
      "loss": 0.1051,
      "step": 24400
    },
    {
      "epoch": 3.182350644279578,
      "grad_norm": 19.03590202331543,
      "learning_rate": 4.8408824677860216e-05,
      "loss": 0.1509,
      "step": 24450
    },
    {
      "epoch": 3.1888585188077574,
      "grad_norm": 0.13838917016983032,
      "learning_rate": 4.840557074059612e-05,
      "loss": 0.1419,
      "step": 24500
    },
    {
      "epoch": 3.1953663933359366,
      "grad_norm": 0.05565016344189644,
      "learning_rate": 4.840231680333203e-05,
      "loss": 0.139,
      "step": 24550
    },
    {
      "epoch": 3.2018742678641154,
      "grad_norm": 0.7248947024345398,
      "learning_rate": 4.8399062866067944e-05,
      "loss": 0.1095,
      "step": 24600
    },
    {
      "epoch": 3.2083821423922947,
      "grad_norm": 0.016650782898068428,
      "learning_rate": 4.839580892880385e-05,
      "loss": 0.0844,
      "step": 24650
    },
    {
      "epoch": 3.214890016920474,
      "grad_norm": 0.2689093053340912,
      "learning_rate": 4.8392554991539766e-05,
      "loss": 0.0982,
      "step": 24700
    },
    {
      "epoch": 3.2213978914486527,
      "grad_norm": 5.320571422576904,
      "learning_rate": 4.838930105427568e-05,
      "loss": 0.1234,
      "step": 24750
    },
    {
      "epoch": 3.227905765976832,
      "grad_norm": 7.132057189941406,
      "learning_rate": 4.838604711701159e-05,
      "loss": 0.1311,
      "step": 24800
    },
    {
      "epoch": 3.2344136405050112,
      "grad_norm": 7.497856140136719,
      "learning_rate": 4.83827931797475e-05,
      "loss": 0.0549,
      "step": 24850
    },
    {
      "epoch": 3.24092151503319,
      "grad_norm": 1.3908735513687134,
      "learning_rate": 4.837953924248341e-05,
      "loss": 0.0853,
      "step": 24900
    },
    {
      "epoch": 3.2474293895613693,
      "grad_norm": 0.04720386117696762,
      "learning_rate": 4.8376285305219315e-05,
      "loss": 0.137,
      "step": 24950
    },
    {
      "epoch": 3.2539372640895485,
      "grad_norm": 24.998842239379883,
      "learning_rate": 4.837303136795523e-05,
      "loss": 0.1707,
      "step": 25000
    },
    {
      "epoch": 3.2604451386177273,
      "grad_norm": 0.010240110568702221,
      "learning_rate": 4.836977743069114e-05,
      "loss": 0.0935,
      "step": 25050
    },
    {
      "epoch": 3.2669530131459066,
      "grad_norm": 7.791457176208496,
      "learning_rate": 4.836652349342705e-05,
      "loss": 0.1026,
      "step": 25100
    },
    {
      "epoch": 3.273460887674086,
      "grad_norm": 0.43443119525909424,
      "learning_rate": 4.836326955616296e-05,
      "loss": 0.1177,
      "step": 25150
    },
    {
      "epoch": 3.2799687622022646,
      "grad_norm": 0.032524388283491135,
      "learning_rate": 4.8360015618898865e-05,
      "loss": 0.0953,
      "step": 25200
    },
    {
      "epoch": 3.286476636730444,
      "grad_norm": 0.16995804011821747,
      "learning_rate": 4.835676168163478e-05,
      "loss": 0.1404,
      "step": 25250
    },
    {
      "epoch": 3.292984511258623,
      "grad_norm": 0.025494005531072617,
      "learning_rate": 4.8353507744370694e-05,
      "loss": 0.1121,
      "step": 25300
    },
    {
      "epoch": 3.299492385786802,
      "grad_norm": 0.01400645449757576,
      "learning_rate": 4.83502538071066e-05,
      "loss": 0.1331,
      "step": 25350
    },
    {
      "epoch": 3.306000260314981,
      "grad_norm": 0.8961796164512634,
      "learning_rate": 4.8346999869842515e-05,
      "loss": 0.0654,
      "step": 25400
    },
    {
      "epoch": 3.31250813484316,
      "grad_norm": 5.173026084899902,
      "learning_rate": 4.834374593257842e-05,
      "loss": 0.1586,
      "step": 25450
    },
    {
      "epoch": 3.3190160093713392,
      "grad_norm": 0.022728532552719116,
      "learning_rate": 4.8340491995314336e-05,
      "loss": 0.0744,
      "step": 25500
    },
    {
      "epoch": 3.3255238838995185,
      "grad_norm": 0.09552105516195297,
      "learning_rate": 4.8337238058050244e-05,
      "loss": 0.1027,
      "step": 25550
    },
    {
      "epoch": 3.3320317584276973,
      "grad_norm": 0.026435669511556625,
      "learning_rate": 4.833398412078615e-05,
      "loss": 0.1859,
      "step": 25600
    },
    {
      "epoch": 3.3385396329558765,
      "grad_norm": 0.05190568044781685,
      "learning_rate": 4.8330730183522065e-05,
      "loss": 0.1231,
      "step": 25650
    },
    {
      "epoch": 3.3450475074840558,
      "grad_norm": 0.09149689227342606,
      "learning_rate": 4.832747624625797e-05,
      "loss": 0.1266,
      "step": 25700
    },
    {
      "epoch": 3.3515553820122346,
      "grad_norm": 0.9085971713066101,
      "learning_rate": 4.832422230899388e-05,
      "loss": 0.1502,
      "step": 25750
    },
    {
      "epoch": 3.358063256540414,
      "grad_norm": 0.06865201145410538,
      "learning_rate": 4.8320968371729793e-05,
      "loss": 0.0819,
      "step": 25800
    },
    {
      "epoch": 3.364571131068593,
      "grad_norm": 1.0909669399261475,
      "learning_rate": 4.831771443446571e-05,
      "loss": 0.1465,
      "step": 25850
    },
    {
      "epoch": 3.371079005596772,
      "grad_norm": 0.02297832816839218,
      "learning_rate": 4.8314460497201615e-05,
      "loss": 0.1263,
      "step": 25900
    },
    {
      "epoch": 3.377586880124951,
      "grad_norm": 0.04301103204488754,
      "learning_rate": 4.831120655993753e-05,
      "loss": 0.143,
      "step": 25950
    },
    {
      "epoch": 3.3840947546531304,
      "grad_norm": 1.0184508562088013,
      "learning_rate": 4.8307952622673436e-05,
      "loss": 0.0517,
      "step": 26000
    },
    {
      "epoch": 3.390602629181309,
      "grad_norm": 7.765904426574707,
      "learning_rate": 4.830469868540935e-05,
      "loss": 0.1105,
      "step": 26050
    },
    {
      "epoch": 3.3971105037094884,
      "grad_norm": 0.024311618879437447,
      "learning_rate": 4.830144474814526e-05,
      "loss": 0.1413,
      "step": 26100
    },
    {
      "epoch": 3.4036183782376677,
      "grad_norm": 12.756978034973145,
      "learning_rate": 4.8298190810881165e-05,
      "loss": 0.1367,
      "step": 26150
    },
    {
      "epoch": 3.4101262527658465,
      "grad_norm": 0.021361708641052246,
      "learning_rate": 4.829493687361708e-05,
      "loss": 0.1578,
      "step": 26200
    },
    {
      "epoch": 3.4166341272940257,
      "grad_norm": 16.47197914123535,
      "learning_rate": 4.8291682936352986e-05,
      "loss": 0.0891,
      "step": 26250
    },
    {
      "epoch": 3.423142001822205,
      "grad_norm": 4.585603713989258,
      "learning_rate": 4.82884289990889e-05,
      "loss": 0.145,
      "step": 26300
    },
    {
      "epoch": 3.4296498763503838,
      "grad_norm": 9.83541202545166,
      "learning_rate": 4.8285175061824814e-05,
      "loss": 0.1609,
      "step": 26350
    },
    {
      "epoch": 3.436157750878563,
      "grad_norm": 0.3199840784072876,
      "learning_rate": 4.828192112456072e-05,
      "loss": 0.1343,
      "step": 26400
    },
    {
      "epoch": 3.4426656254067423,
      "grad_norm": 9.753118515014648,
      "learning_rate": 4.8278667187296636e-05,
      "loss": 0.1149,
      "step": 26450
    },
    {
      "epoch": 3.449173499934921,
      "grad_norm": 11.59484577178955,
      "learning_rate": 4.827541325003254e-05,
      "loss": 0.1898,
      "step": 26500
    },
    {
      "epoch": 3.4556813744631003,
      "grad_norm": 11.511968612670898,
      "learning_rate": 4.827215931276845e-05,
      "loss": 0.1138,
      "step": 26550
    },
    {
      "epoch": 3.4621892489912796,
      "grad_norm": 0.12357602268457413,
      "learning_rate": 4.8268905375504364e-05,
      "loss": 0.1736,
      "step": 26600
    },
    {
      "epoch": 3.4686971235194584,
      "grad_norm": 0.2600524425506592,
      "learning_rate": 4.826565143824027e-05,
      "loss": 0.1029,
      "step": 26650
    },
    {
      "epoch": 3.4752049980476376,
      "grad_norm": 0.019355185329914093,
      "learning_rate": 4.826239750097618e-05,
      "loss": 0.1241,
      "step": 26700
    },
    {
      "epoch": 3.481712872575817,
      "grad_norm": 0.009524446912109852,
      "learning_rate": 4.825914356371209e-05,
      "loss": 0.0872,
      "step": 26750
    },
    {
      "epoch": 3.4882207471039957,
      "grad_norm": 4.917799472808838,
      "learning_rate": 4.8255889626448e-05,
      "loss": 0.1327,
      "step": 26800
    },
    {
      "epoch": 3.494728621632175,
      "grad_norm": 7.260196685791016,
      "learning_rate": 4.8252635689183914e-05,
      "loss": 0.152,
      "step": 26850
    },
    {
      "epoch": 3.501236496160354,
      "grad_norm": 0.09387341886758804,
      "learning_rate": 4.824938175191983e-05,
      "loss": 0.2166,
      "step": 26900
    },
    {
      "epoch": 3.507744370688533,
      "grad_norm": 4.421066761016846,
      "learning_rate": 4.8246127814655736e-05,
      "loss": 0.1226,
      "step": 26950
    },
    {
      "epoch": 3.514252245216712,
      "grad_norm": 0.26358291506767273,
      "learning_rate": 4.824287387739165e-05,
      "loss": 0.09,
      "step": 27000
    },
    {
      "epoch": 3.5207601197448914,
      "grad_norm": 0.06469367444515228,
      "learning_rate": 4.823961994012756e-05,
      "loss": 0.1642,
      "step": 27050
    },
    {
      "epoch": 3.5272679942730703,
      "grad_norm": 0.13954214751720428,
      "learning_rate": 4.8236366002863464e-05,
      "loss": 0.1094,
      "step": 27100
    },
    {
      "epoch": 3.5337758688012495,
      "grad_norm": 12.151707649230957,
      "learning_rate": 4.823311206559938e-05,
      "loss": 0.0951,
      "step": 27150
    },
    {
      "epoch": 3.5402837433294287,
      "grad_norm": 0.04431736469268799,
      "learning_rate": 4.8229858128335286e-05,
      "loss": 0.1119,
      "step": 27200
    },
    {
      "epoch": 3.5467916178576075,
      "grad_norm": 10.654582977294922,
      "learning_rate": 4.82266041910712e-05,
      "loss": 0.1029,
      "step": 27250
    },
    {
      "epoch": 3.553299492385787,
      "grad_norm": 2.551827907562256,
      "learning_rate": 4.822335025380711e-05,
      "loss": 0.1563,
      "step": 27300
    },
    {
      "epoch": 3.559807366913966,
      "grad_norm": 6.168320655822754,
      "learning_rate": 4.8220096316543014e-05,
      "loss": 0.16,
      "step": 27350
    },
    {
      "epoch": 3.566315241442145,
      "grad_norm": 6.168201446533203,
      "learning_rate": 4.821684237927893e-05,
      "loss": 0.147,
      "step": 27400
    },
    {
      "epoch": 3.572823115970324,
      "grad_norm": 12.975556373596191,
      "learning_rate": 4.821358844201484e-05,
      "loss": 0.1155,
      "step": 27450
    },
    {
      "epoch": 3.5793309904985033,
      "grad_norm": 0.09461301565170288,
      "learning_rate": 4.821033450475075e-05,
      "loss": 0.1106,
      "step": 27500
    },
    {
      "epoch": 3.585838865026682,
      "grad_norm": 0.07923684269189835,
      "learning_rate": 4.8207080567486664e-05,
      "loss": 0.1309,
      "step": 27550
    },
    {
      "epoch": 3.5923467395548614,
      "grad_norm": 0.1652088761329651,
      "learning_rate": 4.820382663022257e-05,
      "loss": 0.1055,
      "step": 27600
    },
    {
      "epoch": 3.5988546140830406,
      "grad_norm": 3.986253261566162,
      "learning_rate": 4.8200572692958485e-05,
      "loss": 0.1115,
      "step": 27650
    },
    {
      "epoch": 3.6053624886112194,
      "grad_norm": 0.013426532968878746,
      "learning_rate": 4.819731875569439e-05,
      "loss": 0.1006,
      "step": 27700
    },
    {
      "epoch": 3.6118703631393987,
      "grad_norm": 0.017120303586125374,
      "learning_rate": 4.81940648184303e-05,
      "loss": 0.0542,
      "step": 27750
    },
    {
      "epoch": 3.618378237667578,
      "grad_norm": 1.1902416944503784,
      "learning_rate": 4.8190810881166214e-05,
      "loss": 0.1521,
      "step": 27800
    },
    {
      "epoch": 3.6248861121957567,
      "grad_norm": 0.045882754027843475,
      "learning_rate": 4.818755694390212e-05,
      "loss": 0.1629,
      "step": 27850
    },
    {
      "epoch": 3.631393986723936,
      "grad_norm": 1.8383581638336182,
      "learning_rate": 4.8184303006638035e-05,
      "loss": 0.0949,
      "step": 27900
    },
    {
      "epoch": 3.6379018612521152,
      "grad_norm": 0.0460929200053215,
      "learning_rate": 4.818104906937395e-05,
      "loss": 0.1192,
      "step": 27950
    },
    {
      "epoch": 3.644409735780294,
      "grad_norm": 8.345949172973633,
      "learning_rate": 4.8177795132109856e-05,
      "loss": 0.1246,
      "step": 28000
    },
    {
      "epoch": 3.6509176103084733,
      "grad_norm": 7.545253276824951,
      "learning_rate": 4.817454119484577e-05,
      "loss": 0.1507,
      "step": 28050
    },
    {
      "epoch": 3.6574254848366525,
      "grad_norm": 0.08793774992227554,
      "learning_rate": 4.817128725758168e-05,
      "loss": 0.1039,
      "step": 28100
    },
    {
      "epoch": 3.6639333593648313,
      "grad_norm": 0.03177754953503609,
      "learning_rate": 4.8168033320317585e-05,
      "loss": 0.0776,
      "step": 28150
    },
    {
      "epoch": 3.6704412338930106,
      "grad_norm": 13.164463996887207,
      "learning_rate": 4.81647793830535e-05,
      "loss": 0.0862,
      "step": 28200
    },
    {
      "epoch": 3.67694910842119,
      "grad_norm": 0.034586694091558456,
      "learning_rate": 4.8161525445789406e-05,
      "loss": 0.1289,
      "step": 28250
    },
    {
      "epoch": 3.6834569829493686,
      "grad_norm": 0.052980780601501465,
      "learning_rate": 4.8158271508525313e-05,
      "loss": 0.1811,
      "step": 28300
    },
    {
      "epoch": 3.689964857477548,
      "grad_norm": 0.11999000608921051,
      "learning_rate": 4.815501757126123e-05,
      "loss": 0.1154,
      "step": 28350
    },
    {
      "epoch": 3.696472732005727,
      "grad_norm": 7.1758928298950195,
      "learning_rate": 4.8151763633997135e-05,
      "loss": 0.1278,
      "step": 28400
    },
    {
      "epoch": 3.702980606533906,
      "grad_norm": 0.04276454821228981,
      "learning_rate": 4.814850969673305e-05,
      "loss": 0.12,
      "step": 28450
    },
    {
      "epoch": 3.709488481062085,
      "grad_norm": 0.021867021918296814,
      "learning_rate": 4.814525575946896e-05,
      "loss": 0.098,
      "step": 28500
    },
    {
      "epoch": 3.7159963555902644,
      "grad_norm": 0.11862970888614655,
      "learning_rate": 4.814200182220487e-05,
      "loss": 0.1308,
      "step": 28550
    },
    {
      "epoch": 3.7225042301184432,
      "grad_norm": 1.9435093402862549,
      "learning_rate": 4.8138747884940784e-05,
      "loss": 0.1058,
      "step": 28600
    },
    {
      "epoch": 3.7290121046466225,
      "grad_norm": 0.07674436271190643,
      "learning_rate": 4.813549394767669e-05,
      "loss": 0.133,
      "step": 28650
    },
    {
      "epoch": 3.7355199791748017,
      "grad_norm": 1.1110738515853882,
      "learning_rate": 4.81322400104126e-05,
      "loss": 0.0532,
      "step": 28700
    },
    {
      "epoch": 3.7420278537029805,
      "grad_norm": 0.6043984293937683,
      "learning_rate": 4.812898607314851e-05,
      "loss": 0.1421,
      "step": 28750
    },
    {
      "epoch": 3.7485357282311598,
      "grad_norm": 9.609564781188965,
      "learning_rate": 4.812573213588442e-05,
      "loss": 0.1601,
      "step": 28800
    },
    {
      "epoch": 3.755043602759339,
      "grad_norm": 0.18504323065280914,
      "learning_rate": 4.8122478198620334e-05,
      "loss": 0.1282,
      "step": 28850
    },
    {
      "epoch": 3.761551477287518,
      "grad_norm": 0.015745533630251884,
      "learning_rate": 4.811922426135624e-05,
      "loss": 0.175,
      "step": 28900
    },
    {
      "epoch": 3.768059351815697,
      "grad_norm": 0.011609986424446106,
      "learning_rate": 4.8115970324092156e-05,
      "loss": 0.1025,
      "step": 28950
    },
    {
      "epoch": 3.7745672263438763,
      "grad_norm": 0.06652611494064331,
      "learning_rate": 4.811271638682806e-05,
      "loss": 0.1192,
      "step": 29000
    },
    {
      "epoch": 3.781075100872055,
      "grad_norm": 0.15063545107841492,
      "learning_rate": 4.810946244956398e-05,
      "loss": 0.0954,
      "step": 29050
    },
    {
      "epoch": 3.7875829754002344,
      "grad_norm": 0.5470114350318909,
      "learning_rate": 4.8106208512299884e-05,
      "loss": 0.1683,
      "step": 29100
    },
    {
      "epoch": 3.7940908499284136,
      "grad_norm": 0.036013927310705185,
      "learning_rate": 4.81029545750358e-05,
      "loss": 0.1495,
      "step": 29150
    },
    {
      "epoch": 3.8005987244565924,
      "grad_norm": 2.4706883430480957,
      "learning_rate": 4.8099700637771706e-05,
      "loss": 0.1272,
      "step": 29200
    },
    {
      "epoch": 3.8071065989847717,
      "grad_norm": 0.042761050164699554,
      "learning_rate": 4.809644670050762e-05,
      "loss": 0.1142,
      "step": 29250
    },
    {
      "epoch": 3.813614473512951,
      "grad_norm": 0.20342324674129486,
      "learning_rate": 4.809319276324353e-05,
      "loss": 0.085,
      "step": 29300
    },
    {
      "epoch": 3.8201223480411297,
      "grad_norm": 0.3016709089279175,
      "learning_rate": 4.8089938825979434e-05,
      "loss": 0.1117,
      "step": 29350
    },
    {
      "epoch": 3.826630222569309,
      "grad_norm": 0.13143500685691833,
      "learning_rate": 4.808668488871535e-05,
      "loss": 0.0872,
      "step": 29400
    },
    {
      "epoch": 3.833138097097488,
      "grad_norm": 0.2804153561592102,
      "learning_rate": 4.8083430951451256e-05,
      "loss": 0.0881,
      "step": 29450
    },
    {
      "epoch": 3.839645971625667,
      "grad_norm": 10.32705307006836,
      "learning_rate": 4.808017701418717e-05,
      "loss": 0.1684,
      "step": 29500
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.1516399383544922,
      "learning_rate": 4.8076923076923084e-05,
      "loss": 0.1652,
      "step": 29550
    },
    {
      "epoch": 3.8526617206820255,
      "grad_norm": 0.09403467923402786,
      "learning_rate": 4.807366913965899e-05,
      "loss": 0.0966,
      "step": 29600
    },
    {
      "epoch": 3.8591695952102043,
      "grad_norm": 7.497125148773193,
      "learning_rate": 4.8070415202394905e-05,
      "loss": 0.1719,
      "step": 29650
    },
    {
      "epoch": 3.8656774697383836,
      "grad_norm": 0.017170019447803497,
      "learning_rate": 4.806716126513081e-05,
      "loss": 0.0958,
      "step": 29700
    },
    {
      "epoch": 3.872185344266563,
      "grad_norm": 0.2976313531398773,
      "learning_rate": 4.806390732786672e-05,
      "loss": 0.1341,
      "step": 29750
    },
    {
      "epoch": 3.8786932187947416,
      "grad_norm": 0.20034223794937134,
      "learning_rate": 4.8060653390602634e-05,
      "loss": 0.0523,
      "step": 29800
    },
    {
      "epoch": 3.885201093322921,
      "grad_norm": 0.09692662209272385,
      "learning_rate": 4.805739945333854e-05,
      "loss": 0.1543,
      "step": 29850
    },
    {
      "epoch": 3.8917089678511,
      "grad_norm": 0.8685670495033264,
      "learning_rate": 4.805414551607445e-05,
      "loss": 0.1336,
      "step": 29900
    },
    {
      "epoch": 3.898216842379279,
      "grad_norm": 0.02388300932943821,
      "learning_rate": 4.805089157881036e-05,
      "loss": 0.0612,
      "step": 29950
    },
    {
      "epoch": 3.904724716907458,
      "grad_norm": 17.060260772705078,
      "learning_rate": 4.804763764154627e-05,
      "loss": 0.1217,
      "step": 30000
    },
    {
      "epoch": 3.9112325914356374,
      "grad_norm": 0.12773896753787994,
      "learning_rate": 4.8044383704282184e-05,
      "loss": 0.1545,
      "step": 30050
    },
    {
      "epoch": 3.917740465963816,
      "grad_norm": 6.569093227386475,
      "learning_rate": 4.80411297670181e-05,
      "loss": 0.095,
      "step": 30100
    },
    {
      "epoch": 3.9242483404919954,
      "grad_norm": 2.897594928741455,
      "learning_rate": 4.8037875829754005e-05,
      "loss": 0.1705,
      "step": 30150
    },
    {
      "epoch": 3.9307562150201742,
      "grad_norm": 0.21907499432563782,
      "learning_rate": 4.803462189248992e-05,
      "loss": 0.1713,
      "step": 30200
    },
    {
      "epoch": 3.9372640895483535,
      "grad_norm": 13.114214897155762,
      "learning_rate": 4.8031367955225826e-05,
      "loss": 0.1625,
      "step": 30250
    },
    {
      "epoch": 3.9437719640765327,
      "grad_norm": 0.4753205478191376,
      "learning_rate": 4.8028114017961734e-05,
      "loss": 0.0829,
      "step": 30300
    },
    {
      "epoch": 3.9502798386047115,
      "grad_norm": 1.558364987373352,
      "learning_rate": 4.802486008069765e-05,
      "loss": 0.081,
      "step": 30350
    },
    {
      "epoch": 3.956787713132891,
      "grad_norm": 10.234240531921387,
      "learning_rate": 4.8021606143433555e-05,
      "loss": 0.117,
      "step": 30400
    },
    {
      "epoch": 3.96329558766107,
      "grad_norm": 5.202437877655029,
      "learning_rate": 4.801835220616946e-05,
      "loss": 0.1628,
      "step": 30450
    },
    {
      "epoch": 3.969803462189249,
      "grad_norm": 0.09766307473182678,
      "learning_rate": 4.8015098268905376e-05,
      "loss": 0.0856,
      "step": 30500
    },
    {
      "epoch": 3.976311336717428,
      "grad_norm": 0.09063670039176941,
      "learning_rate": 4.801184433164129e-05,
      "loss": 0.0944,
      "step": 30550
    },
    {
      "epoch": 3.9828192112456073,
      "grad_norm": 0.01452259998768568,
      "learning_rate": 4.80085903943772e-05,
      "loss": 0.0884,
      "step": 30600
    },
    {
      "epoch": 3.989327085773786,
      "grad_norm": 0.06476549059152603,
      "learning_rate": 4.800533645711311e-05,
      "loss": 0.1358,
      "step": 30650
    },
    {
      "epoch": 3.9958349603019654,
      "grad_norm": 11.166574478149414,
      "learning_rate": 4.800208251984902e-05,
      "loss": 0.1383,
      "step": 30700
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9636186137325089,
      "eval_f1": 0.9635284139100933,
      "eval_loss": 0.13552522659301758,
      "eval_precision": 0.9654811715481172,
      "eval_recall": 0.9615835395233754,
      "eval_runtime": 23.5894,
      "eval_samples_per_second": 651.352,
      "eval_steps_per_second": 81.435,
      "step": 30732
    },
    {
      "epoch": 4.002342834830144,
      "grad_norm": 0.04808750003576279,
      "learning_rate": 4.799882858258493e-05,
      "loss": 0.0921,
      "step": 30750
    },
    {
      "epoch": 4.008850709358324,
      "grad_norm": 0.07292388379573822,
      "learning_rate": 4.799557464532084e-05,
      "loss": 0.1596,
      "step": 30800
    },
    {
      "epoch": 4.015358583886503,
      "grad_norm": 9.5848970413208,
      "learning_rate": 4.799232070805675e-05,
      "loss": 0.0955,
      "step": 30850
    },
    {
      "epoch": 4.0218664584146815,
      "grad_norm": 5.78266716003418,
      "learning_rate": 4.798906677079266e-05,
      "loss": 0.1346,
      "step": 30900
    },
    {
      "epoch": 4.028374332942861,
      "grad_norm": 0.012185969389975071,
      "learning_rate": 4.798581283352857e-05,
      "loss": 0.0899,
      "step": 30950
    },
    {
      "epoch": 4.03488220747104,
      "grad_norm": 20.734699249267578,
      "learning_rate": 4.798255889626448e-05,
      "loss": 0.1215,
      "step": 31000
    },
    {
      "epoch": 4.041390081999219,
      "grad_norm": 0.07087311893701553,
      "learning_rate": 4.797930495900039e-05,
      "loss": 0.1147,
      "step": 31050
    },
    {
      "epoch": 4.0478979565273985,
      "grad_norm": 0.1732914298772812,
      "learning_rate": 4.7976051021736304e-05,
      "loss": 0.1044,
      "step": 31100
    },
    {
      "epoch": 4.054405831055577,
      "grad_norm": 16.661100387573242,
      "learning_rate": 4.797279708447222e-05,
      "loss": 0.0961,
      "step": 31150
    },
    {
      "epoch": 4.060913705583756,
      "grad_norm": 0.005055371671915054,
      "learning_rate": 4.7969543147208126e-05,
      "loss": 0.1245,
      "step": 31200
    },
    {
      "epoch": 4.067421580111936,
      "grad_norm": 11.405861854553223,
      "learning_rate": 4.796628920994403e-05,
      "loss": 0.1313,
      "step": 31250
    },
    {
      "epoch": 4.073929454640115,
      "grad_norm": 0.09940151870250702,
      "learning_rate": 4.796303527267995e-05,
      "loss": 0.1171,
      "step": 31300
    },
    {
      "epoch": 4.080437329168293,
      "grad_norm": 8.058341026306152,
      "learning_rate": 4.7959781335415854e-05,
      "loss": 0.0916,
      "step": 31350
    },
    {
      "epoch": 4.086945203696473,
      "grad_norm": 0.4212748408317566,
      "learning_rate": 4.795652739815177e-05,
      "loss": 0.1293,
      "step": 31400
    },
    {
      "epoch": 4.093453078224652,
      "grad_norm": 3.4170737266540527,
      "learning_rate": 4.7953273460887676e-05,
      "loss": 0.1321,
      "step": 31450
    },
    {
      "epoch": 4.099960952752831,
      "grad_norm": 0.0650378167629242,
      "learning_rate": 4.795001952362358e-05,
      "loss": 0.0984,
      "step": 31500
    },
    {
      "epoch": 4.10646882728101,
      "grad_norm": 0.10481797158718109,
      "learning_rate": 4.79467655863595e-05,
      "loss": 0.0847,
      "step": 31550
    },
    {
      "epoch": 4.112976701809189,
      "grad_norm": 0.047323718667030334,
      "learning_rate": 4.7943511649095404e-05,
      "loss": 0.1093,
      "step": 31600
    },
    {
      "epoch": 4.119484576337368,
      "grad_norm": 0.0942487046122551,
      "learning_rate": 4.794025771183132e-05,
      "loss": 0.1387,
      "step": 31650
    },
    {
      "epoch": 4.125992450865548,
      "grad_norm": 0.9053531289100647,
      "learning_rate": 4.793700377456723e-05,
      "loss": 0.1421,
      "step": 31700
    },
    {
      "epoch": 4.1325003253937265,
      "grad_norm": 0.023364733904600143,
      "learning_rate": 4.793374983730314e-05,
      "loss": 0.0908,
      "step": 31750
    },
    {
      "epoch": 4.139008199921905,
      "grad_norm": 11.06521987915039,
      "learning_rate": 4.7930495900039054e-05,
      "loss": 0.1675,
      "step": 31800
    },
    {
      "epoch": 4.145516074450085,
      "grad_norm": 0.04708541929721832,
      "learning_rate": 4.792724196277496e-05,
      "loss": 0.0967,
      "step": 31850
    },
    {
      "epoch": 4.152023948978264,
      "grad_norm": 0.2982139587402344,
      "learning_rate": 4.792398802551087e-05,
      "loss": 0.1744,
      "step": 31900
    },
    {
      "epoch": 4.158531823506443,
      "grad_norm": 0.13684259355068207,
      "learning_rate": 4.792073408824678e-05,
      "loss": 0.1261,
      "step": 31950
    },
    {
      "epoch": 4.165039698034622,
      "grad_norm": 0.15041135251522064,
      "learning_rate": 4.791748015098269e-05,
      "loss": 0.1472,
      "step": 32000
    },
    {
      "epoch": 4.171547572562801,
      "grad_norm": 0.7472792267799377,
      "learning_rate": 4.79142262137186e-05,
      "loss": 0.1563,
      "step": 32050
    },
    {
      "epoch": 4.17805544709098,
      "grad_norm": 5.327669620513916,
      "learning_rate": 4.791097227645451e-05,
      "loss": 0.1463,
      "step": 32100
    },
    {
      "epoch": 4.18456332161916,
      "grad_norm": 4.509275913238525,
      "learning_rate": 4.7907718339190425e-05,
      "loss": 0.0829,
      "step": 32150
    },
    {
      "epoch": 4.191071196147338,
      "grad_norm": 0.02534261904656887,
      "learning_rate": 4.790446440192633e-05,
      "loss": 0.1002,
      "step": 32200
    },
    {
      "epoch": 4.197579070675517,
      "grad_norm": 0.043055783957242966,
      "learning_rate": 4.7901210464662246e-05,
      "loss": 0.1181,
      "step": 32250
    },
    {
      "epoch": 4.204086945203697,
      "grad_norm": 0.085917167365551,
      "learning_rate": 4.7897956527398154e-05,
      "loss": 0.0938,
      "step": 32300
    },
    {
      "epoch": 4.210594819731876,
      "grad_norm": 0.23952707648277283,
      "learning_rate": 4.789470259013407e-05,
      "loss": 0.1163,
      "step": 32350
    },
    {
      "epoch": 4.2171026942600545,
      "grad_norm": 0.0963529571890831,
      "learning_rate": 4.7891448652869975e-05,
      "loss": 0.1359,
      "step": 32400
    },
    {
      "epoch": 4.223610568788234,
      "grad_norm": 0.6283540725708008,
      "learning_rate": 4.788819471560588e-05,
      "loss": 0.1293,
      "step": 32450
    },
    {
      "epoch": 4.230118443316413,
      "grad_norm": 0.01508916076272726,
      "learning_rate": 4.7884940778341796e-05,
      "loss": 0.1118,
      "step": 32500
    },
    {
      "epoch": 4.236626317844592,
      "grad_norm": 0.09685593098402023,
      "learning_rate": 4.7881686841077704e-05,
      "loss": 0.117,
      "step": 32550
    },
    {
      "epoch": 4.2431341923727715,
      "grad_norm": 0.10518625378608704,
      "learning_rate": 4.787843290381362e-05,
      "loss": 0.1556,
      "step": 32600
    },
    {
      "epoch": 4.24964206690095,
      "grad_norm": 0.008976245298981667,
      "learning_rate": 4.7875178966549525e-05,
      "loss": 0.1217,
      "step": 32650
    },
    {
      "epoch": 4.256149941429129,
      "grad_norm": 0.02485673315823078,
      "learning_rate": 4.787192502928544e-05,
      "loss": 0.11,
      "step": 32700
    },
    {
      "epoch": 4.262657815957309,
      "grad_norm": 7.676645755767822,
      "learning_rate": 4.786867109202135e-05,
      "loss": 0.0909,
      "step": 32750
    },
    {
      "epoch": 4.2691656904854876,
      "grad_norm": 0.005754523444920778,
      "learning_rate": 4.786541715475726e-05,
      "loss": 0.1192,
      "step": 32800
    },
    {
      "epoch": 4.275673565013666,
      "grad_norm": 6.518667697906494,
      "learning_rate": 4.786216321749317e-05,
      "loss": 0.167,
      "step": 32850
    },
    {
      "epoch": 4.282181439541846,
      "grad_norm": 0.7148614525794983,
      "learning_rate": 4.785890928022908e-05,
      "loss": 0.1725,
      "step": 32900
    },
    {
      "epoch": 4.288689314070025,
      "grad_norm": 12.756180763244629,
      "learning_rate": 4.785565534296499e-05,
      "loss": 0.0851,
      "step": 32950
    },
    {
      "epoch": 4.295197188598204,
      "grad_norm": 0.2528008818626404,
      "learning_rate": 4.78524014057009e-05,
      "loss": 0.0776,
      "step": 33000
    },
    {
      "epoch": 4.3017050631263825,
      "grad_norm": 0.041986893862485886,
      "learning_rate": 4.784914746843681e-05,
      "loss": 0.1061,
      "step": 33050
    },
    {
      "epoch": 4.308212937654562,
      "grad_norm": 17.334917068481445,
      "learning_rate": 4.784589353117272e-05,
      "loss": 0.1459,
      "step": 33100
    },
    {
      "epoch": 4.314720812182741,
      "grad_norm": 4.675488471984863,
      "learning_rate": 4.784263959390863e-05,
      "loss": 0.0884,
      "step": 33150
    },
    {
      "epoch": 4.321228686710921,
      "grad_norm": 11.535873413085938,
      "learning_rate": 4.783938565664454e-05,
      "loss": 0.1555,
      "step": 33200
    },
    {
      "epoch": 4.3277365612390994,
      "grad_norm": 9.278748512268066,
      "learning_rate": 4.783613171938045e-05,
      "loss": 0.1101,
      "step": 33250
    },
    {
      "epoch": 4.334244435767278,
      "grad_norm": 0.010826748795807362,
      "learning_rate": 4.783287778211637e-05,
      "loss": 0.1038,
      "step": 33300
    },
    {
      "epoch": 4.340752310295457,
      "grad_norm": 0.3340807557106018,
      "learning_rate": 4.7829623844852274e-05,
      "loss": 0.0723,
      "step": 33350
    },
    {
      "epoch": 4.347260184823637,
      "grad_norm": 0.11600542068481445,
      "learning_rate": 4.782636990758819e-05,
      "loss": 0.1059,
      "step": 33400
    },
    {
      "epoch": 4.3537680593518155,
      "grad_norm": 7.149758815765381,
      "learning_rate": 4.7823115970324096e-05,
      "loss": 0.1521,
      "step": 33450
    },
    {
      "epoch": 4.360275933879995,
      "grad_norm": 0.10370807349681854,
      "learning_rate": 4.781986203306e-05,
      "loss": 0.0851,
      "step": 33500
    },
    {
      "epoch": 4.366783808408174,
      "grad_norm": 0.10905394703149796,
      "learning_rate": 4.781660809579592e-05,
      "loss": 0.105,
      "step": 33550
    },
    {
      "epoch": 4.373291682936353,
      "grad_norm": 2.1073427200317383,
      "learning_rate": 4.7813354158531824e-05,
      "loss": 0.0827,
      "step": 33600
    },
    {
      "epoch": 4.379799557464532,
      "grad_norm": 0.3275434970855713,
      "learning_rate": 4.781010022126773e-05,
      "loss": 0.0929,
      "step": 33650
    },
    {
      "epoch": 4.386307431992711,
      "grad_norm": 12.489266395568848,
      "learning_rate": 4.7806846284003646e-05,
      "loss": 0.0698,
      "step": 33700
    },
    {
      "epoch": 4.39281530652089,
      "grad_norm": 0.38257646560668945,
      "learning_rate": 4.780359234673956e-05,
      "loss": 0.1721,
      "step": 33750
    },
    {
      "epoch": 4.39932318104907,
      "grad_norm": 0.07510001212358475,
      "learning_rate": 4.780033840947547e-05,
      "loss": 0.1316,
      "step": 33800
    },
    {
      "epoch": 4.405831055577249,
      "grad_norm": 8.82239818572998,
      "learning_rate": 4.779708447221138e-05,
      "loss": 0.0802,
      "step": 33850
    },
    {
      "epoch": 4.412338930105427,
      "grad_norm": 0.658831000328064,
      "learning_rate": 4.779383053494729e-05,
      "loss": 0.0815,
      "step": 33900
    },
    {
      "epoch": 4.418846804633606,
      "grad_norm": 17.077533721923828,
      "learning_rate": 4.77905765976832e-05,
      "loss": 0.1415,
      "step": 33950
    },
    {
      "epoch": 4.425354679161786,
      "grad_norm": 0.009327827021479607,
      "learning_rate": 4.778732266041911e-05,
      "loss": 0.0818,
      "step": 34000
    },
    {
      "epoch": 4.431862553689965,
      "grad_norm": 0.9675971269607544,
      "learning_rate": 4.778406872315502e-05,
      "loss": 0.1593,
      "step": 34050
    },
    {
      "epoch": 4.438370428218144,
      "grad_norm": 0.0546816885471344,
      "learning_rate": 4.778081478589093e-05,
      "loss": 0.1429,
      "step": 34100
    },
    {
      "epoch": 4.444878302746323,
      "grad_norm": 5.766690254211426,
      "learning_rate": 4.777756084862684e-05,
      "loss": 0.0869,
      "step": 34150
    },
    {
      "epoch": 4.451386177274502,
      "grad_norm": 8.281933784484863,
      "learning_rate": 4.777430691136275e-05,
      "loss": 0.0567,
      "step": 34200
    },
    {
      "epoch": 4.457894051802681,
      "grad_norm": 12.335867881774902,
      "learning_rate": 4.777105297409866e-05,
      "loss": 0.155,
      "step": 34250
    },
    {
      "epoch": 4.4644019263308605,
      "grad_norm": 0.02411557361483574,
      "learning_rate": 4.7767799036834574e-05,
      "loss": 0.1331,
      "step": 34300
    },
    {
      "epoch": 4.470909800859039,
      "grad_norm": 0.02798321843147278,
      "learning_rate": 4.776454509957049e-05,
      "loss": 0.1468,
      "step": 34350
    },
    {
      "epoch": 4.477417675387218,
      "grad_norm": 6.776033401489258,
      "learning_rate": 4.7761291162306395e-05,
      "loss": 0.1393,
      "step": 34400
    },
    {
      "epoch": 4.483925549915398,
      "grad_norm": 0.1583881825208664,
      "learning_rate": 4.77580372250423e-05,
      "loss": 0.154,
      "step": 34450
    },
    {
      "epoch": 4.490433424443577,
      "grad_norm": 0.27480581402778625,
      "learning_rate": 4.7754783287778216e-05,
      "loss": 0.1552,
      "step": 34500
    },
    {
      "epoch": 4.496941298971755,
      "grad_norm": 0.10397283732891083,
      "learning_rate": 4.7751529350514124e-05,
      "loss": 0.1032,
      "step": 34550
    },
    {
      "epoch": 4.503449173499935,
      "grad_norm": 4.193070888519287,
      "learning_rate": 4.774827541325003e-05,
      "loss": 0.1456,
      "step": 34600
    },
    {
      "epoch": 4.509957048028114,
      "grad_norm": 0.1893397867679596,
      "learning_rate": 4.7745021475985945e-05,
      "loss": 0.0555,
      "step": 34650
    },
    {
      "epoch": 4.516464922556293,
      "grad_norm": 12.35066032409668,
      "learning_rate": 4.774176753872185e-05,
      "loss": 0.1513,
      "step": 34700
    },
    {
      "epoch": 4.522972797084472,
      "grad_norm": 1.3352863788604736,
      "learning_rate": 4.7738513601457766e-05,
      "loss": 0.0996,
      "step": 34750
    },
    {
      "epoch": 4.529480671612651,
      "grad_norm": 13.399827003479004,
      "learning_rate": 4.7735259664193674e-05,
      "loss": 0.131,
      "step": 34800
    },
    {
      "epoch": 4.53598854614083,
      "grad_norm": 17.828773498535156,
      "learning_rate": 4.773200572692959e-05,
      "loss": 0.1331,
      "step": 34850
    },
    {
      "epoch": 4.54249642066901,
      "grad_norm": 0.12731392681598663,
      "learning_rate": 4.77287517896655e-05,
      "loss": 0.0997,
      "step": 34900
    },
    {
      "epoch": 4.5490042951971885,
      "grad_norm": 0.034856341779232025,
      "learning_rate": 4.772549785240141e-05,
      "loss": 0.0738,
      "step": 34950
    },
    {
      "epoch": 4.555512169725367,
      "grad_norm": 0.3850443959236145,
      "learning_rate": 4.7722243915137316e-05,
      "loss": 0.0745,
      "step": 35000
    },
    {
      "epoch": 4.562020044253547,
      "grad_norm": 0.39919835329055786,
      "learning_rate": 4.771898997787323e-05,
      "loss": 0.1343,
      "step": 35050
    },
    {
      "epoch": 4.568527918781726,
      "grad_norm": 0.3387187719345093,
      "learning_rate": 4.771573604060914e-05,
      "loss": 0.1506,
      "step": 35100
    },
    {
      "epoch": 4.575035793309905,
      "grad_norm": 0.08103227615356445,
      "learning_rate": 4.771248210334505e-05,
      "loss": 0.0964,
      "step": 35150
    },
    {
      "epoch": 4.581543667838084,
      "grad_norm": 8.4722900390625,
      "learning_rate": 4.770922816608096e-05,
      "loss": 0.1213,
      "step": 35200
    },
    {
      "epoch": 4.588051542366263,
      "grad_norm": 4.97926664352417,
      "learning_rate": 4.7705974228816866e-05,
      "loss": 0.131,
      "step": 35250
    },
    {
      "epoch": 4.594559416894442,
      "grad_norm": 0.3290615677833557,
      "learning_rate": 4.770272029155278e-05,
      "loss": 0.1077,
      "step": 35300
    },
    {
      "epoch": 4.601067291422622,
      "grad_norm": 0.197829470038414,
      "learning_rate": 4.7699466354288694e-05,
      "loss": 0.1313,
      "step": 35350
    },
    {
      "epoch": 4.6075751659508,
      "grad_norm": 13.070985794067383,
      "learning_rate": 4.76962124170246e-05,
      "loss": 0.1257,
      "step": 35400
    },
    {
      "epoch": 4.614083040478979,
      "grad_norm": 7.095822811126709,
      "learning_rate": 4.7692958479760516e-05,
      "loss": 0.0938,
      "step": 35450
    },
    {
      "epoch": 4.620590915007159,
      "grad_norm": 0.6309435963630676,
      "learning_rate": 4.768970454249642e-05,
      "loss": 0.1183,
      "step": 35500
    },
    {
      "epoch": 4.627098789535338,
      "grad_norm": 0.06027841940522194,
      "learning_rate": 4.768645060523234e-05,
      "loss": 0.0728,
      "step": 35550
    },
    {
      "epoch": 4.6336066640635165,
      "grad_norm": 0.18697002530097961,
      "learning_rate": 4.7683196667968244e-05,
      "loss": 0.0945,
      "step": 35600
    },
    {
      "epoch": 4.640114538591696,
      "grad_norm": 19.895633697509766,
      "learning_rate": 4.767994273070415e-05,
      "loss": 0.0581,
      "step": 35650
    },
    {
      "epoch": 4.646622413119875,
      "grad_norm": 0.09673341363668442,
      "learning_rate": 4.7676688793440066e-05,
      "loss": 0.2054,
      "step": 35700
    },
    {
      "epoch": 4.653130287648054,
      "grad_norm": 0.2599237859249115,
      "learning_rate": 4.767343485617597e-05,
      "loss": 0.1285,
      "step": 35750
    },
    {
      "epoch": 4.6596381621762335,
      "grad_norm": 0.043022092431783676,
      "learning_rate": 4.767018091891188e-05,
      "loss": 0.0813,
      "step": 35800
    },
    {
      "epoch": 4.666146036704412,
      "grad_norm": 0.044507600367069244,
      "learning_rate": 4.7666926981647794e-05,
      "loss": 0.1018,
      "step": 35850
    },
    {
      "epoch": 4.672653911232591,
      "grad_norm": 8.157931327819824,
      "learning_rate": 4.766367304438371e-05,
      "loss": 0.1319,
      "step": 35900
    },
    {
      "epoch": 4.679161785760771,
      "grad_norm": 0.19392403960227966,
      "learning_rate": 4.766041910711962e-05,
      "loss": 0.1124,
      "step": 35950
    },
    {
      "epoch": 4.68566966028895,
      "grad_norm": 0.07786825299263,
      "learning_rate": 4.765716516985553e-05,
      "loss": 0.088,
      "step": 36000
    },
    {
      "epoch": 4.692177534817128,
      "grad_norm": 0.035050954669713974,
      "learning_rate": 4.765391123259144e-05,
      "loss": 0.104,
      "step": 36050
    },
    {
      "epoch": 4.698685409345308,
      "grad_norm": 0.032824281603097916,
      "learning_rate": 4.765065729532735e-05,
      "loss": 0.0967,
      "step": 36100
    },
    {
      "epoch": 4.705193283873487,
      "grad_norm": 0.02685678005218506,
      "learning_rate": 4.764740335806326e-05,
      "loss": 0.1284,
      "step": 36150
    },
    {
      "epoch": 4.711701158401666,
      "grad_norm": 6.734501838684082,
      "learning_rate": 4.7644149420799166e-05,
      "loss": 0.084,
      "step": 36200
    },
    {
      "epoch": 4.718209032929845,
      "grad_norm": 0.016846537590026855,
      "learning_rate": 4.764089548353508e-05,
      "loss": 0.1449,
      "step": 36250
    },
    {
      "epoch": 4.724716907458024,
      "grad_norm": 7.588740348815918,
      "learning_rate": 4.763764154627099e-05,
      "loss": 0.1241,
      "step": 36300
    },
    {
      "epoch": 4.731224781986203,
      "grad_norm": 0.15916606783866882,
      "learning_rate": 4.76343876090069e-05,
      "loss": 0.1128,
      "step": 36350
    },
    {
      "epoch": 4.737732656514383,
      "grad_norm": 0.09583109617233276,
      "learning_rate": 4.763113367174281e-05,
      "loss": 0.1001,
      "step": 36400
    },
    {
      "epoch": 4.7442405310425615,
      "grad_norm": 0.1023254543542862,
      "learning_rate": 4.762787973447872e-05,
      "loss": 0.1043,
      "step": 36450
    },
    {
      "epoch": 4.75074840557074,
      "grad_norm": 0.0902104601264,
      "learning_rate": 4.7624625797214636e-05,
      "loss": 0.1833,
      "step": 36500
    },
    {
      "epoch": 4.75725628009892,
      "grad_norm": 0.026519358158111572,
      "learning_rate": 4.7621371859950544e-05,
      "loss": 0.0894,
      "step": 36550
    },
    {
      "epoch": 4.763764154627099,
      "grad_norm": 8.453144073486328,
      "learning_rate": 4.761811792268645e-05,
      "loss": 0.111,
      "step": 36600
    },
    {
      "epoch": 4.770272029155278,
      "grad_norm": 0.019437629729509354,
      "learning_rate": 4.7614863985422365e-05,
      "loss": 0.1476,
      "step": 36650
    },
    {
      "epoch": 4.776779903683457,
      "grad_norm": 0.04951268807053566,
      "learning_rate": 4.761161004815827e-05,
      "loss": 0.0997,
      "step": 36700
    },
    {
      "epoch": 4.783287778211636,
      "grad_norm": 0.1878994256258011,
      "learning_rate": 4.7608356110894186e-05,
      "loss": 0.1418,
      "step": 36750
    },
    {
      "epoch": 4.789795652739815,
      "grad_norm": 1.0662727355957031,
      "learning_rate": 4.7605102173630094e-05,
      "loss": 0.0822,
      "step": 36800
    },
    {
      "epoch": 4.796303527267995,
      "grad_norm": 0.015404441393911839,
      "learning_rate": 4.7601848236366e-05,
      "loss": 0.1337,
      "step": 36850
    },
    {
      "epoch": 4.802811401796173,
      "grad_norm": 0.014353620819747448,
      "learning_rate": 4.7598594299101915e-05,
      "loss": 0.1317,
      "step": 36900
    },
    {
      "epoch": 4.809319276324352,
      "grad_norm": 0.013021402060985565,
      "learning_rate": 4.759534036183783e-05,
      "loss": 0.0989,
      "step": 36950
    },
    {
      "epoch": 4.815827150852532,
      "grad_norm": 0.07882973551750183,
      "learning_rate": 4.7592086424573736e-05,
      "loss": 0.0905,
      "step": 37000
    },
    {
      "epoch": 4.822335025380711,
      "grad_norm": 5.36370849609375,
      "learning_rate": 4.758883248730965e-05,
      "loss": 0.1365,
      "step": 37050
    },
    {
      "epoch": 4.8288428999088895,
      "grad_norm": 0.05192997306585312,
      "learning_rate": 4.758557855004556e-05,
      "loss": 0.1241,
      "step": 37100
    },
    {
      "epoch": 4.835350774437069,
      "grad_norm": 0.11353575438261032,
      "learning_rate": 4.758232461278147e-05,
      "loss": 0.1447,
      "step": 37150
    },
    {
      "epoch": 4.841858648965248,
      "grad_norm": 0.2728486657142639,
      "learning_rate": 4.757907067551738e-05,
      "loss": 0.1358,
      "step": 37200
    },
    {
      "epoch": 4.848366523493427,
      "grad_norm": 0.18169005215168,
      "learning_rate": 4.7575816738253286e-05,
      "loss": 0.0924,
      "step": 37250
    },
    {
      "epoch": 4.8548743980216065,
      "grad_norm": 5.140697956085205,
      "learning_rate": 4.75725628009892e-05,
      "loss": 0.1156,
      "step": 37300
    },
    {
      "epoch": 4.861382272549785,
      "grad_norm": 0.16479448974132538,
      "learning_rate": 4.756930886372511e-05,
      "loss": 0.0988,
      "step": 37350
    },
    {
      "epoch": 4.867890147077964,
      "grad_norm": 0.10435832291841507,
      "learning_rate": 4.7566054926461015e-05,
      "loss": 0.1718,
      "step": 37400
    },
    {
      "epoch": 4.874398021606144,
      "grad_norm": 0.13404910266399384,
      "learning_rate": 4.756280098919693e-05,
      "loss": 0.084,
      "step": 37450
    },
    {
      "epoch": 4.880905896134323,
      "grad_norm": 17.22030258178711,
      "learning_rate": 4.755954705193284e-05,
      "loss": 0.1033,
      "step": 37500
    },
    {
      "epoch": 4.887413770662501,
      "grad_norm": 0.12347663938999176,
      "learning_rate": 4.755629311466876e-05,
      "loss": 0.103,
      "step": 37550
    },
    {
      "epoch": 4.893921645190681,
      "grad_norm": 0.020123623311519623,
      "learning_rate": 4.7553039177404664e-05,
      "loss": 0.132,
      "step": 37600
    },
    {
      "epoch": 4.90042951971886,
      "grad_norm": 0.03617994859814644,
      "learning_rate": 4.754978524014057e-05,
      "loss": 0.0712,
      "step": 37650
    },
    {
      "epoch": 4.906937394247039,
      "grad_norm": 14.79484748840332,
      "learning_rate": 4.7546531302876486e-05,
      "loss": 0.1034,
      "step": 37700
    },
    {
      "epoch": 4.913445268775218,
      "grad_norm": 0.018221670761704445,
      "learning_rate": 4.754327736561239e-05,
      "loss": 0.1225,
      "step": 37750
    },
    {
      "epoch": 4.919953143303397,
      "grad_norm": 0.24674156308174133,
      "learning_rate": 4.75400234283483e-05,
      "loss": 0.0959,
      "step": 37800
    },
    {
      "epoch": 4.926461017831576,
      "grad_norm": 0.033534884452819824,
      "learning_rate": 4.7536769491084214e-05,
      "loss": 0.1736,
      "step": 37850
    },
    {
      "epoch": 4.932968892359756,
      "grad_norm": 0.03820642828941345,
      "learning_rate": 4.753351555382012e-05,
      "loss": 0.0607,
      "step": 37900
    },
    {
      "epoch": 4.9394767668879345,
      "grad_norm": 11.634419441223145,
      "learning_rate": 4.7530261616556036e-05,
      "loss": 0.0854,
      "step": 37950
    },
    {
      "epoch": 4.945984641416113,
      "grad_norm": 3.401583671569824,
      "learning_rate": 4.752700767929194e-05,
      "loss": 0.1065,
      "step": 38000
    },
    {
      "epoch": 4.952492515944293,
      "grad_norm": 19.664798736572266,
      "learning_rate": 4.752375374202786e-05,
      "loss": 0.1023,
      "step": 38050
    },
    {
      "epoch": 4.959000390472472,
      "grad_norm": 7.18058967590332,
      "learning_rate": 4.752049980476377e-05,
      "loss": 0.1253,
      "step": 38100
    },
    {
      "epoch": 4.965508265000651,
      "grad_norm": 0.05000029876828194,
      "learning_rate": 4.751724586749968e-05,
      "loss": 0.1187,
      "step": 38150
    },
    {
      "epoch": 4.97201613952883,
      "grad_norm": 0.07362222671508789,
      "learning_rate": 4.7513991930235586e-05,
      "loss": 0.1946,
      "step": 38200
    },
    {
      "epoch": 4.978524014057009,
      "grad_norm": 10.553442001342773,
      "learning_rate": 4.75107379929715e-05,
      "loss": 0.1142,
      "step": 38250
    },
    {
      "epoch": 4.985031888585188,
      "grad_norm": 0.45905622839927673,
      "learning_rate": 4.750748405570741e-05,
      "loss": 0.0854,
      "step": 38300
    },
    {
      "epoch": 4.991539763113368,
      "grad_norm": 0.5545270442962646,
      "learning_rate": 4.750423011844332e-05,
      "loss": 0.1152,
      "step": 38350
    },
    {
      "epoch": 4.998047637641546,
      "grad_norm": 20.48005485534668,
      "learning_rate": 4.750097618117923e-05,
      "loss": 0.1148,
      "step": 38400
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9643345265213147,
      "eval_f1": 0.9645031739862676,
      "eval_loss": 0.15092921257019043,
      "eval_precision": 0.959530867379817,
      "eval_recall": 0.9695272821982029,
      "eval_runtime": 23.5135,
      "eval_samples_per_second": 653.454,
      "eval_steps_per_second": 81.698,
      "step": 38415
    },
    {
      "epoch": 5.004555512169725,
      "grad_norm": 0.05098502337932587,
      "learning_rate": 4.7497722243915136e-05,
      "loss": 0.1602,
      "step": 38450
    },
    {
      "epoch": 5.011063386697905,
      "grad_norm": 0.2088303416967392,
      "learning_rate": 4.749446830665105e-05,
      "loss": 0.1142,
      "step": 38500
    },
    {
      "epoch": 5.017571261226084,
      "grad_norm": 0.06887992471456528,
      "learning_rate": 4.7491214369386964e-05,
      "loss": 0.0536,
      "step": 38550
    },
    {
      "epoch": 5.0240791357542625,
      "grad_norm": 26.716312408447266,
      "learning_rate": 4.748796043212287e-05,
      "loss": 0.1084,
      "step": 38600
    },
    {
      "epoch": 5.030587010282442,
      "grad_norm": 0.23283573985099792,
      "learning_rate": 4.7484706494858785e-05,
      "loss": 0.0827,
      "step": 38650
    },
    {
      "epoch": 5.037094884810621,
      "grad_norm": 0.38181817531585693,
      "learning_rate": 4.748145255759469e-05,
      "loss": 0.0467,
      "step": 38700
    },
    {
      "epoch": 5.0436027593388,
      "grad_norm": 0.18938779830932617,
      "learning_rate": 4.7478198620330606e-05,
      "loss": 0.1549,
      "step": 38750
    },
    {
      "epoch": 5.0501106338669794,
      "grad_norm": 28.02243423461914,
      "learning_rate": 4.7474944683066514e-05,
      "loss": 0.1695,
      "step": 38800
    },
    {
      "epoch": 5.056618508395158,
      "grad_norm": 0.0646129846572876,
      "learning_rate": 4.747169074580242e-05,
      "loss": 0.1376,
      "step": 38850
    },
    {
      "epoch": 5.063126382923337,
      "grad_norm": 15.258172988891602,
      "learning_rate": 4.7468436808538335e-05,
      "loss": 0.0836,
      "step": 38900
    },
    {
      "epoch": 5.069634257451517,
      "grad_norm": 0.052599187940359116,
      "learning_rate": 4.746518287127424e-05,
      "loss": 0.1353,
      "step": 38950
    },
    {
      "epoch": 5.0761421319796955,
      "grad_norm": 1.8465120792388916,
      "learning_rate": 4.746192893401015e-05,
      "loss": 0.1344,
      "step": 39000
    },
    {
      "epoch": 5.082650006507874,
      "grad_norm": 0.09135900437831879,
      "learning_rate": 4.7458674996746064e-05,
      "loss": 0.0819,
      "step": 39050
    },
    {
      "epoch": 5.089157881036054,
      "grad_norm": 20.582386016845703,
      "learning_rate": 4.745542105948198e-05,
      "loss": 0.1151,
      "step": 39100
    },
    {
      "epoch": 5.095665755564233,
      "grad_norm": 0.6094596982002258,
      "learning_rate": 4.7452167122217885e-05,
      "loss": 0.097,
      "step": 39150
    },
    {
      "epoch": 5.102173630092412,
      "grad_norm": 22.88372039794922,
      "learning_rate": 4.74489131849538e-05,
      "loss": 0.1407,
      "step": 39200
    },
    {
      "epoch": 5.108681504620591,
      "grad_norm": 0.4507399797439575,
      "learning_rate": 4.7445659247689706e-05,
      "loss": 0.073,
      "step": 39250
    },
    {
      "epoch": 5.11518937914877,
      "grad_norm": 0.1783471256494522,
      "learning_rate": 4.744240531042562e-05,
      "loss": 0.1485,
      "step": 39300
    },
    {
      "epoch": 5.121697253676949,
      "grad_norm": 0.13978904485702515,
      "learning_rate": 4.743915137316153e-05,
      "loss": 0.1239,
      "step": 39350
    },
    {
      "epoch": 5.128205128205128,
      "grad_norm": 3.959714412689209,
      "learning_rate": 4.7435897435897435e-05,
      "loss": 0.0504,
      "step": 39400
    },
    {
      "epoch": 5.134713002733307,
      "grad_norm": 0.25943392515182495,
      "learning_rate": 4.743264349863335e-05,
      "loss": 0.1382,
      "step": 39450
    },
    {
      "epoch": 5.141220877261486,
      "grad_norm": 7.46777868270874,
      "learning_rate": 4.7429389561369256e-05,
      "loss": 0.2055,
      "step": 39500
    },
    {
      "epoch": 5.147728751789666,
      "grad_norm": 1.0095746517181396,
      "learning_rate": 4.7426135624105164e-05,
      "loss": 0.1242,
      "step": 39550
    },
    {
      "epoch": 5.154236626317845,
      "grad_norm": 0.26575469970703125,
      "learning_rate": 4.742288168684108e-05,
      "loss": 0.0912,
      "step": 39600
    },
    {
      "epoch": 5.1607445008460235,
      "grad_norm": 12.45095443725586,
      "learning_rate": 4.741962774957699e-05,
      "loss": 0.1247,
      "step": 39650
    },
    {
      "epoch": 5.167252375374202,
      "grad_norm": 0.0478869192302227,
      "learning_rate": 4.7416373812312906e-05,
      "loss": 0.092,
      "step": 39700
    },
    {
      "epoch": 5.173760249902382,
      "grad_norm": 0.0547240749001503,
      "learning_rate": 4.741311987504881e-05,
      "loss": 0.0986,
      "step": 39750
    },
    {
      "epoch": 5.180268124430561,
      "grad_norm": 16.371173858642578,
      "learning_rate": 4.740986593778472e-05,
      "loss": 0.084,
      "step": 39800
    },
    {
      "epoch": 5.1867759989587405,
      "grad_norm": 11.286635398864746,
      "learning_rate": 4.7406612000520634e-05,
      "loss": 0.1591,
      "step": 39850
    },
    {
      "epoch": 5.193283873486919,
      "grad_norm": 0.0393306128680706,
      "learning_rate": 4.740335806325654e-05,
      "loss": 0.1302,
      "step": 39900
    },
    {
      "epoch": 5.199791748015098,
      "grad_norm": 0.3451157808303833,
      "learning_rate": 4.740010412599245e-05,
      "loss": 0.0897,
      "step": 39950
    },
    {
      "epoch": 5.206299622543277,
      "grad_norm": 0.3033612072467804,
      "learning_rate": 4.739685018872836e-05,
      "loss": 0.1406,
      "step": 40000
    },
    {
      "epoch": 5.212807497071457,
      "grad_norm": 5.0192437171936035,
      "learning_rate": 4.739359625146427e-05,
      "loss": 0.095,
      "step": 40050
    },
    {
      "epoch": 5.219315371599635,
      "grad_norm": 0.1337251514196396,
      "learning_rate": 4.7390342314200184e-05,
      "loss": 0.1171,
      "step": 40100
    },
    {
      "epoch": 5.225823246127814,
      "grad_norm": 23.29744529724121,
      "learning_rate": 4.73870883769361e-05,
      "loss": 0.1585,
      "step": 40150
    },
    {
      "epoch": 5.232331120655994,
      "grad_norm": 0.465340256690979,
      "learning_rate": 4.7383834439672006e-05,
      "loss": 0.1202,
      "step": 40200
    },
    {
      "epoch": 5.238838995184173,
      "grad_norm": 12.258404731750488,
      "learning_rate": 4.738058050240792e-05,
      "loss": 0.147,
      "step": 40250
    },
    {
      "epoch": 5.2453468697123515,
      "grad_norm": 0.17693811655044556,
      "learning_rate": 4.737732656514383e-05,
      "loss": 0.1708,
      "step": 40300
    },
    {
      "epoch": 5.251854744240531,
      "grad_norm": 0.0981985479593277,
      "learning_rate": 4.7374072627879734e-05,
      "loss": 0.0792,
      "step": 40350
    },
    {
      "epoch": 5.25836261876871,
      "grad_norm": 19.06075096130371,
      "learning_rate": 4.737081869061565e-05,
      "loss": 0.1248,
      "step": 40400
    },
    {
      "epoch": 5.264870493296889,
      "grad_norm": 4.975017070770264,
      "learning_rate": 4.7367564753351556e-05,
      "loss": 0.1205,
      "step": 40450
    },
    {
      "epoch": 5.2713783678250685,
      "grad_norm": 8.756160736083984,
      "learning_rate": 4.736431081608747e-05,
      "loss": 0.0891,
      "step": 40500
    },
    {
      "epoch": 5.277886242353247,
      "grad_norm": 21.582717895507812,
      "learning_rate": 4.736105687882338e-05,
      "loss": 0.1136,
      "step": 40550
    },
    {
      "epoch": 5.284394116881426,
      "grad_norm": 0.19344790279865265,
      "learning_rate": 4.7357802941559284e-05,
      "loss": 0.1048,
      "step": 40600
    },
    {
      "epoch": 5.290901991409606,
      "grad_norm": 20.22994041442871,
      "learning_rate": 4.73545490042952e-05,
      "loss": 0.088,
      "step": 40650
    },
    {
      "epoch": 5.297409865937785,
      "grad_norm": 0.18782442808151245,
      "learning_rate": 4.735129506703111e-05,
      "loss": 0.1009,
      "step": 40700
    },
    {
      "epoch": 5.303917740465963,
      "grad_norm": 0.045440103858709335,
      "learning_rate": 4.734804112976702e-05,
      "loss": 0.1588,
      "step": 40750
    },
    {
      "epoch": 5.310425614994143,
      "grad_norm": 0.25057604908943176,
      "learning_rate": 4.7344787192502934e-05,
      "loss": 0.0654,
      "step": 40800
    },
    {
      "epoch": 5.316933489522322,
      "grad_norm": 0.24805520474910736,
      "learning_rate": 4.734153325523884e-05,
      "loss": 0.077,
      "step": 40850
    },
    {
      "epoch": 5.323441364050501,
      "grad_norm": 0.03899127244949341,
      "learning_rate": 4.7338279317974755e-05,
      "loss": 0.0914,
      "step": 40900
    },
    {
      "epoch": 5.32994923857868,
      "grad_norm": 0.008142022415995598,
      "learning_rate": 4.733502538071066e-05,
      "loss": 0.1016,
      "step": 40950
    },
    {
      "epoch": 5.336457113106859,
      "grad_norm": 1.1322726011276245,
      "learning_rate": 4.733177144344657e-05,
      "loss": 0.1394,
      "step": 41000
    },
    {
      "epoch": 5.342964987635038,
      "grad_norm": 0.13335351645946503,
      "learning_rate": 4.7328517506182484e-05,
      "loss": 0.1143,
      "step": 41050
    },
    {
      "epoch": 5.349472862163218,
      "grad_norm": 18.00783348083496,
      "learning_rate": 4.732526356891839e-05,
      "loss": 0.1377,
      "step": 41100
    },
    {
      "epoch": 5.3559807366913965,
      "grad_norm": 0.010630978271365166,
      "learning_rate": 4.73220096316543e-05,
      "loss": 0.1099,
      "step": 41150
    },
    {
      "epoch": 5.362488611219575,
      "grad_norm": 0.1114712730050087,
      "learning_rate": 4.731875569439021e-05,
      "loss": 0.1173,
      "step": 41200
    },
    {
      "epoch": 5.368996485747755,
      "grad_norm": 0.012413271702826023,
      "learning_rate": 4.7315501757126126e-05,
      "loss": 0.0904,
      "step": 41250
    },
    {
      "epoch": 5.375504360275934,
      "grad_norm": 4.393368244171143,
      "learning_rate": 4.731224781986204e-05,
      "loss": 0.14,
      "step": 41300
    },
    {
      "epoch": 5.382012234804113,
      "grad_norm": 10.443100929260254,
      "learning_rate": 4.730899388259795e-05,
      "loss": 0.0622,
      "step": 41350
    },
    {
      "epoch": 5.388520109332292,
      "grad_norm": 0.02399357408285141,
      "learning_rate": 4.7305739945333855e-05,
      "loss": 0.0979,
      "step": 41400
    },
    {
      "epoch": 5.395027983860471,
      "grad_norm": 0.6370252966880798,
      "learning_rate": 4.730248600806977e-05,
      "loss": 0.1222,
      "step": 41450
    },
    {
      "epoch": 5.40153585838865,
      "grad_norm": 3.108058452606201,
      "learning_rate": 4.7299232070805676e-05,
      "loss": 0.1338,
      "step": 41500
    },
    {
      "epoch": 5.40804373291683,
      "grad_norm": 6.510237216949463,
      "learning_rate": 4.7295978133541584e-05,
      "loss": 0.0732,
      "step": 41550
    },
    {
      "epoch": 5.414551607445008,
      "grad_norm": 7.865297317504883,
      "learning_rate": 4.72927241962775e-05,
      "loss": 0.1114,
      "step": 41600
    },
    {
      "epoch": 5.421059481973187,
      "grad_norm": 0.12580439448356628,
      "learning_rate": 4.7289470259013405e-05,
      "loss": 0.116,
      "step": 41650
    },
    {
      "epoch": 5.427567356501367,
      "grad_norm": 5.832249164581299,
      "learning_rate": 4.728621632174932e-05,
      "loss": 0.1137,
      "step": 41700
    },
    {
      "epoch": 5.434075231029546,
      "grad_norm": 0.4184287190437317,
      "learning_rate": 4.728296238448523e-05,
      "loss": 0.0601,
      "step": 41750
    },
    {
      "epoch": 5.4405831055577245,
      "grad_norm": 10.559016227722168,
      "learning_rate": 4.727970844722114e-05,
      "loss": 0.1278,
      "step": 41800
    },
    {
      "epoch": 5.447090980085904,
      "grad_norm": 0.01721499301493168,
      "learning_rate": 4.7276454509957055e-05,
      "loss": 0.0879,
      "step": 41850
    },
    {
      "epoch": 5.453598854614083,
      "grad_norm": 7.42620849609375,
      "learning_rate": 4.727320057269296e-05,
      "loss": 0.0797,
      "step": 41900
    },
    {
      "epoch": 5.460106729142262,
      "grad_norm": 0.09561257809400558,
      "learning_rate": 4.726994663542887e-05,
      "loss": 0.1064,
      "step": 41950
    },
    {
      "epoch": 5.4666146036704415,
      "grad_norm": 1.9346284866333008,
      "learning_rate": 4.726669269816478e-05,
      "loss": 0.1383,
      "step": 42000
    },
    {
      "epoch": 5.47312247819862,
      "grad_norm": 0.012170529924333096,
      "learning_rate": 4.726343876090069e-05,
      "loss": 0.1259,
      "step": 42050
    },
    {
      "epoch": 5.479630352726799,
      "grad_norm": 10.804291725158691,
      "learning_rate": 4.7260184823636605e-05,
      "loss": 0.0733,
      "step": 42100
    },
    {
      "epoch": 5.486138227254979,
      "grad_norm": 0.05115495249629021,
      "learning_rate": 4.725693088637251e-05,
      "loss": 0.09,
      "step": 42150
    },
    {
      "epoch": 5.492646101783158,
      "grad_norm": 0.6351144909858704,
      "learning_rate": 4.725367694910842e-05,
      "loss": 0.12,
      "step": 42200
    },
    {
      "epoch": 5.499153976311336,
      "grad_norm": 0.02394799329340458,
      "learning_rate": 4.725042301184433e-05,
      "loss": 0.1269,
      "step": 42250
    },
    {
      "epoch": 5.505661850839516,
      "grad_norm": 0.1389334499835968,
      "learning_rate": 4.724716907458025e-05,
      "loss": 0.1156,
      "step": 42300
    },
    {
      "epoch": 5.512169725367695,
      "grad_norm": 0.16044674813747406,
      "learning_rate": 4.7243915137316154e-05,
      "loss": 0.1518,
      "step": 42350
    },
    {
      "epoch": 5.518677599895874,
      "grad_norm": 5.543507099151611,
      "learning_rate": 4.724066120005207e-05,
      "loss": 0.1824,
      "step": 42400
    },
    {
      "epoch": 5.525185474424053,
      "grad_norm": 0.1318318098783493,
      "learning_rate": 4.7237407262787976e-05,
      "loss": 0.0947,
      "step": 42450
    },
    {
      "epoch": 5.531693348952232,
      "grad_norm": 7.998441696166992,
      "learning_rate": 4.723415332552389e-05,
      "loss": 0.0777,
      "step": 42500
    },
    {
      "epoch": 5.538201223480411,
      "grad_norm": 0.04452318325638771,
      "learning_rate": 4.72308993882598e-05,
      "loss": 0.123,
      "step": 42550
    },
    {
      "epoch": 5.544709098008591,
      "grad_norm": 17.54635238647461,
      "learning_rate": 4.7227645450995704e-05,
      "loss": 0.0985,
      "step": 42600
    },
    {
      "epoch": 5.5512169725367695,
      "grad_norm": 0.24358674883842468,
      "learning_rate": 4.722439151373162e-05,
      "loss": 0.0621,
      "step": 42650
    },
    {
      "epoch": 5.557724847064948,
      "grad_norm": 0.09890758246183395,
      "learning_rate": 4.7221137576467526e-05,
      "loss": 0.1732,
      "step": 42700
    },
    {
      "epoch": 5.564232721593128,
      "grad_norm": 0.06397568434476852,
      "learning_rate": 4.721788363920343e-05,
      "loss": 0.0989,
      "step": 42750
    },
    {
      "epoch": 5.570740596121307,
      "grad_norm": 0.11834972351789474,
      "learning_rate": 4.721462970193935e-05,
      "loss": 0.1014,
      "step": 42800
    },
    {
      "epoch": 5.577248470649486,
      "grad_norm": 0.012370150536298752,
      "learning_rate": 4.721137576467526e-05,
      "loss": 0.1055,
      "step": 42850
    },
    {
      "epoch": 5.583756345177665,
      "grad_norm": 7.3487935066223145,
      "learning_rate": 4.7208121827411175e-05,
      "loss": 0.1451,
      "step": 42900
    },
    {
      "epoch": 5.590264219705844,
      "grad_norm": 1.3500639200210571,
      "learning_rate": 4.720486789014708e-05,
      "loss": 0.1335,
      "step": 42950
    },
    {
      "epoch": 5.596772094234023,
      "grad_norm": 0.04807107895612717,
      "learning_rate": 4.720161395288299e-05,
      "loss": 0.0882,
      "step": 43000
    },
    {
      "epoch": 5.603279968762203,
      "grad_norm": 0.0917557030916214,
      "learning_rate": 4.7198360015618904e-05,
      "loss": 0.0408,
      "step": 43050
    },
    {
      "epoch": 5.609787843290381,
      "grad_norm": 4.184579849243164,
      "learning_rate": 4.719510607835481e-05,
      "loss": 0.1666,
      "step": 43100
    },
    {
      "epoch": 5.61629571781856,
      "grad_norm": 0.07345908880233765,
      "learning_rate": 4.719185214109072e-05,
      "loss": 0.1297,
      "step": 43150
    },
    {
      "epoch": 5.62280359234674,
      "grad_norm": 0.009086037054657936,
      "learning_rate": 4.718859820382663e-05,
      "loss": 0.1408,
      "step": 43200
    },
    {
      "epoch": 5.629311466874919,
      "grad_norm": 11.181177139282227,
      "learning_rate": 4.718534426656254e-05,
      "loss": 0.1385,
      "step": 43250
    },
    {
      "epoch": 5.6358193414030975,
      "grad_norm": 11.882023811340332,
      "learning_rate": 4.7182090329298454e-05,
      "loss": 0.0759,
      "step": 43300
    },
    {
      "epoch": 5.642327215931277,
      "grad_norm": 0.9445912837982178,
      "learning_rate": 4.717883639203437e-05,
      "loss": 0.1372,
      "step": 43350
    },
    {
      "epoch": 5.648835090459456,
      "grad_norm": 0.4817371070384979,
      "learning_rate": 4.7175582454770275e-05,
      "loss": 0.0871,
      "step": 43400
    },
    {
      "epoch": 5.655342964987635,
      "grad_norm": 0.08793661743402481,
      "learning_rate": 4.717232851750619e-05,
      "loss": 0.141,
      "step": 43450
    },
    {
      "epoch": 5.6618508395158145,
      "grad_norm": 30.365232467651367,
      "learning_rate": 4.7169074580242097e-05,
      "loss": 0.1041,
      "step": 43500
    },
    {
      "epoch": 5.668358714043993,
      "grad_norm": 0.03125370293855667,
      "learning_rate": 4.7165820642978004e-05,
      "loss": 0.101,
      "step": 43550
    },
    {
      "epoch": 5.674866588572172,
      "grad_norm": 1.7909839153289795,
      "learning_rate": 4.716256670571392e-05,
      "loss": 0.0675,
      "step": 43600
    },
    {
      "epoch": 5.681374463100352,
      "grad_norm": 1.9890179634094238,
      "learning_rate": 4.7159312768449825e-05,
      "loss": 0.0456,
      "step": 43650
    },
    {
      "epoch": 5.687882337628531,
      "grad_norm": 0.007941160351037979,
      "learning_rate": 4.715605883118573e-05,
      "loss": 0.0795,
      "step": 43700
    },
    {
      "epoch": 5.694390212156709,
      "grad_norm": 9.483181953430176,
      "learning_rate": 4.7152804893921646e-05,
      "loss": 0.1308,
      "step": 43750
    },
    {
      "epoch": 5.700898086684889,
      "grad_norm": 13.507389068603516,
      "learning_rate": 4.7149550956657554e-05,
      "loss": 0.0981,
      "step": 43800
    },
    {
      "epoch": 5.707405961213068,
      "grad_norm": 14.182109832763672,
      "learning_rate": 4.714629701939347e-05,
      "loss": 0.1344,
      "step": 43850
    },
    {
      "epoch": 5.713913835741247,
      "grad_norm": 9.753474235534668,
      "learning_rate": 4.714304308212938e-05,
      "loss": 0.0993,
      "step": 43900
    },
    {
      "epoch": 5.720421710269426,
      "grad_norm": 8.693709373474121,
      "learning_rate": 4.713978914486529e-05,
      "loss": 0.1023,
      "step": 43950
    },
    {
      "epoch": 5.726929584797605,
      "grad_norm": 0.048267435282468796,
      "learning_rate": 4.71365352076012e-05,
      "loss": 0.1651,
      "step": 44000
    },
    {
      "epoch": 5.733437459325784,
      "grad_norm": 9.028213500976562,
      "learning_rate": 4.713328127033711e-05,
      "loss": 0.1261,
      "step": 44050
    },
    {
      "epoch": 5.739945333853964,
      "grad_norm": 0.08531603217124939,
      "learning_rate": 4.713002733307302e-05,
      "loss": 0.07,
      "step": 44100
    },
    {
      "epoch": 5.7464532083821425,
      "grad_norm": 0.04398053511977196,
      "learning_rate": 4.712677339580893e-05,
      "loss": 0.0737,
      "step": 44150
    },
    {
      "epoch": 5.752961082910321,
      "grad_norm": 0.07323351502418518,
      "learning_rate": 4.712351945854484e-05,
      "loss": 0.1276,
      "step": 44200
    },
    {
      "epoch": 5.759468957438501,
      "grad_norm": 0.08052748441696167,
      "learning_rate": 4.712026552128075e-05,
      "loss": 0.1295,
      "step": 44250
    },
    {
      "epoch": 5.76597683196668,
      "grad_norm": 0.048936981707811356,
      "learning_rate": 4.711701158401666e-05,
      "loss": 0.0866,
      "step": 44300
    },
    {
      "epoch": 5.772484706494859,
      "grad_norm": 0.05670309066772461,
      "learning_rate": 4.711375764675257e-05,
      "loss": 0.1091,
      "step": 44350
    },
    {
      "epoch": 5.778992581023038,
      "grad_norm": 1.3028227090835571,
      "learning_rate": 4.711050370948848e-05,
      "loss": 0.0694,
      "step": 44400
    },
    {
      "epoch": 5.785500455551217,
      "grad_norm": 6.358609676361084,
      "learning_rate": 4.7107249772224396e-05,
      "loss": 0.1699,
      "step": 44450
    },
    {
      "epoch": 5.792008330079396,
      "grad_norm": 0.3260107636451721,
      "learning_rate": 4.71039958349603e-05,
      "loss": 0.1189,
      "step": 44500
    },
    {
      "epoch": 5.7985162046075756,
      "grad_norm": 0.029426030814647675,
      "learning_rate": 4.710074189769622e-05,
      "loss": 0.1382,
      "step": 44550
    },
    {
      "epoch": 5.805024079135754,
      "grad_norm": 0.06646154075860977,
      "learning_rate": 4.7097487960432125e-05,
      "loss": 0.1387,
      "step": 44600
    },
    {
      "epoch": 5.811531953663933,
      "grad_norm": 0.04491604492068291,
      "learning_rate": 4.709423402316804e-05,
      "loss": 0.0801,
      "step": 44650
    },
    {
      "epoch": 5.818039828192113,
      "grad_norm": 12.054174423217773,
      "learning_rate": 4.7090980085903946e-05,
      "loss": 0.1048,
      "step": 44700
    },
    {
      "epoch": 5.824547702720292,
      "grad_norm": 13.14252758026123,
      "learning_rate": 4.708772614863985e-05,
      "loss": 0.0978,
      "step": 44750
    },
    {
      "epoch": 5.8310555772484705,
      "grad_norm": 0.034866757690906525,
      "learning_rate": 4.708447221137577e-05,
      "loss": 0.1088,
      "step": 44800
    },
    {
      "epoch": 5.837563451776649,
      "grad_norm": 0.0945722833275795,
      "learning_rate": 4.7081218274111674e-05,
      "loss": 0.157,
      "step": 44850
    },
    {
      "epoch": 5.844071326304829,
      "grad_norm": 0.23293963074684143,
      "learning_rate": 4.707796433684759e-05,
      "loss": 0.088,
      "step": 44900
    },
    {
      "epoch": 5.850579200833008,
      "grad_norm": 0.01878690905869007,
      "learning_rate": 4.70747103995835e-05,
      "loss": 0.0748,
      "step": 44950
    },
    {
      "epoch": 5.8570870753611874,
      "grad_norm": 0.850462019443512,
      "learning_rate": 4.707145646231941e-05,
      "loss": 0.1761,
      "step": 45000
    },
    {
      "epoch": 5.863594949889366,
      "grad_norm": 0.038214921951293945,
      "learning_rate": 4.7068202525055324e-05,
      "loss": 0.075,
      "step": 45050
    },
    {
      "epoch": 5.870102824417545,
      "grad_norm": 22.37759017944336,
      "learning_rate": 4.706494858779123e-05,
      "loss": 0.1083,
      "step": 45100
    },
    {
      "epoch": 5.876610698945724,
      "grad_norm": 0.6168487071990967,
      "learning_rate": 4.706169465052714e-05,
      "loss": 0.1023,
      "step": 45150
    },
    {
      "epoch": 5.8831185734739035,
      "grad_norm": 8.103338241577148,
      "learning_rate": 4.705844071326305e-05,
      "loss": 0.0924,
      "step": 45200
    },
    {
      "epoch": 5.889626448002082,
      "grad_norm": 0.06500744074583054,
      "learning_rate": 4.705518677599896e-05,
      "loss": 0.0967,
      "step": 45250
    },
    {
      "epoch": 5.896134322530262,
      "grad_norm": 22.216976165771484,
      "learning_rate": 4.705193283873487e-05,
      "loss": 0.1044,
      "step": 45300
    },
    {
      "epoch": 5.902642197058441,
      "grad_norm": 0.01689772494137287,
      "learning_rate": 4.704867890147078e-05,
      "loss": 0.0561,
      "step": 45350
    },
    {
      "epoch": 5.90915007158662,
      "grad_norm": 0.006627243012189865,
      "learning_rate": 4.704542496420669e-05,
      "loss": 0.0744,
      "step": 45400
    },
    {
      "epoch": 5.9156579461147984,
      "grad_norm": 0.3506588339805603,
      "learning_rate": 4.70421710269426e-05,
      "loss": 0.0895,
      "step": 45450
    },
    {
      "epoch": 5.922165820642978,
      "grad_norm": 1.0786361694335938,
      "learning_rate": 4.7038917089678517e-05,
      "loss": 0.1279,
      "step": 45500
    },
    {
      "epoch": 5.928673695171157,
      "grad_norm": 0.01484224759042263,
      "learning_rate": 4.7035663152414424e-05,
      "loss": 0.0807,
      "step": 45550
    },
    {
      "epoch": 5.935181569699337,
      "grad_norm": 0.34607163071632385,
      "learning_rate": 4.703240921515034e-05,
      "loss": 0.1009,
      "step": 45600
    },
    {
      "epoch": 5.941689444227515,
      "grad_norm": 0.28052347898483276,
      "learning_rate": 4.7029155277886245e-05,
      "loss": 0.166,
      "step": 45650
    },
    {
      "epoch": 5.948197318755694,
      "grad_norm": 0.02282494679093361,
      "learning_rate": 4.702590134062215e-05,
      "loss": 0.1178,
      "step": 45700
    },
    {
      "epoch": 5.954705193283873,
      "grad_norm": 18.736705780029297,
      "learning_rate": 4.7022647403358067e-05,
      "loss": 0.107,
      "step": 45750
    },
    {
      "epoch": 5.961213067812053,
      "grad_norm": 0.16159239411354065,
      "learning_rate": 4.7019393466093974e-05,
      "loss": 0.1672,
      "step": 45800
    },
    {
      "epoch": 5.9677209423402315,
      "grad_norm": 0.011865762062370777,
      "learning_rate": 4.701613952882989e-05,
      "loss": 0.0852,
      "step": 45850
    },
    {
      "epoch": 5.974228816868411,
      "grad_norm": 0.16428329050540924,
      "learning_rate": 4.7012885591565795e-05,
      "loss": 0.1081,
      "step": 45900
    },
    {
      "epoch": 5.98073669139659,
      "grad_norm": 0.23075811564922333,
      "learning_rate": 4.70096316543017e-05,
      "loss": 0.0929,
      "step": 45950
    },
    {
      "epoch": 5.987244565924769,
      "grad_norm": 0.0422898530960083,
      "learning_rate": 4.7006377717037617e-05,
      "loss": 0.0991,
      "step": 46000
    },
    {
      "epoch": 5.993752440452948,
      "grad_norm": 1.4933385848999023,
      "learning_rate": 4.700312377977353e-05,
      "loss": 0.1557,
      "step": 46050
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9641392775789132,
      "eval_f1": 0.9638095238095238,
      "eval_loss": 0.13799650967121124,
      "eval_precision": 0.9723032069970845,
      "eval_recall": 0.9554629509050657,
      "eval_runtime": 23.554,
      "eval_samples_per_second": 652.332,
      "eval_steps_per_second": 81.557,
      "step": 46098
    },
    {
      "epoch": 6.000260314981127,
      "grad_norm": 0.02672301046550274,
      "learning_rate": 4.699986984250944e-05,
      "loss": 0.0883,
      "step": 46100
    },
    {
      "epoch": 6.006768189509306,
      "grad_norm": 10.833595275878906,
      "learning_rate": 4.699661590524535e-05,
      "loss": 0.1226,
      "step": 46150
    },
    {
      "epoch": 6.013276064037485,
      "grad_norm": 6.217144012451172,
      "learning_rate": 4.699336196798126e-05,
      "loss": 0.0533,
      "step": 46200
    },
    {
      "epoch": 6.019783938565665,
      "grad_norm": 0.013793316669762135,
      "learning_rate": 4.699010803071717e-05,
      "loss": 0.0967,
      "step": 46250
    },
    {
      "epoch": 6.026291813093843,
      "grad_norm": 0.11856336891651154,
      "learning_rate": 4.698685409345308e-05,
      "loss": 0.0926,
      "step": 46300
    },
    {
      "epoch": 6.032799687622022,
      "grad_norm": 8.150486946105957,
      "learning_rate": 4.698360015618899e-05,
      "loss": 0.1296,
      "step": 46350
    },
    {
      "epoch": 6.039307562150202,
      "grad_norm": 9.66641616821289,
      "learning_rate": 4.69803462189249e-05,
      "loss": 0.1325,
      "step": 46400
    },
    {
      "epoch": 6.045815436678381,
      "grad_norm": 9.465841293334961,
      "learning_rate": 4.697709228166081e-05,
      "loss": 0.0734,
      "step": 46450
    },
    {
      "epoch": 6.0523233112065595,
      "grad_norm": 0.025216232985258102,
      "learning_rate": 4.697383834439672e-05,
      "loss": 0.1045,
      "step": 46500
    },
    {
      "epoch": 6.058831185734739,
      "grad_norm": 0.06364042311906815,
      "learning_rate": 4.697058440713264e-05,
      "loss": 0.1315,
      "step": 46550
    },
    {
      "epoch": 6.065339060262918,
      "grad_norm": 0.25542140007019043,
      "learning_rate": 4.6967330469868545e-05,
      "loss": 0.1334,
      "step": 46600
    },
    {
      "epoch": 6.071846934791097,
      "grad_norm": 0.13014668226242065,
      "learning_rate": 4.696407653260446e-05,
      "loss": 0.1198,
      "step": 46650
    },
    {
      "epoch": 6.0783548093192765,
      "grad_norm": 4.27101993560791,
      "learning_rate": 4.6960822595340366e-05,
      "loss": 0.1047,
      "step": 46700
    },
    {
      "epoch": 6.084862683847455,
      "grad_norm": 3.2344534397125244,
      "learning_rate": 4.695756865807627e-05,
      "loss": 0.1265,
      "step": 46750
    },
    {
      "epoch": 6.091370558375634,
      "grad_norm": 0.10623227059841156,
      "learning_rate": 4.695431472081219e-05,
      "loss": 0.0523,
      "step": 46800
    },
    {
      "epoch": 6.097878432903814,
      "grad_norm": 0.07492183148860931,
      "learning_rate": 4.6951060783548095e-05,
      "loss": 0.0799,
      "step": 46850
    },
    {
      "epoch": 6.104386307431993,
      "grad_norm": 14.21641731262207,
      "learning_rate": 4.6947806846284e-05,
      "loss": 0.1009,
      "step": 46900
    },
    {
      "epoch": 6.110894181960171,
      "grad_norm": 0.03400483354926109,
      "learning_rate": 4.6944552909019916e-05,
      "loss": 0.105,
      "step": 46950
    },
    {
      "epoch": 6.117402056488351,
      "grad_norm": 0.18399058282375336,
      "learning_rate": 4.694129897175582e-05,
      "loss": 0.136,
      "step": 47000
    },
    {
      "epoch": 6.12390993101653,
      "grad_norm": 0.37030360102653503,
      "learning_rate": 4.693804503449174e-05,
      "loss": 0.0983,
      "step": 47050
    },
    {
      "epoch": 6.130417805544709,
      "grad_norm": 0.03267286717891693,
      "learning_rate": 4.693479109722765e-05,
      "loss": 0.128,
      "step": 47100
    },
    {
      "epoch": 6.136925680072888,
      "grad_norm": 0.04622482880949974,
      "learning_rate": 4.693153715996356e-05,
      "loss": 0.1217,
      "step": 47150
    },
    {
      "epoch": 6.143433554601067,
      "grad_norm": 0.004836237523704767,
      "learning_rate": 4.692828322269947e-05,
      "loss": 0.071,
      "step": 47200
    },
    {
      "epoch": 6.149941429129246,
      "grad_norm": 0.10416994243860245,
      "learning_rate": 4.692502928543538e-05,
      "loss": 0.0866,
      "step": 47250
    },
    {
      "epoch": 6.156449303657426,
      "grad_norm": 3.450105667114258,
      "learning_rate": 4.692177534817129e-05,
      "loss": 0.1418,
      "step": 47300
    },
    {
      "epoch": 6.1629571781856045,
      "grad_norm": 6.554843425750732,
      "learning_rate": 4.69185214109072e-05,
      "loss": 0.1152,
      "step": 47350
    },
    {
      "epoch": 6.169465052713783,
      "grad_norm": 0.196024551987648,
      "learning_rate": 4.691526747364311e-05,
      "loss": 0.1229,
      "step": 47400
    },
    {
      "epoch": 6.175972927241963,
      "grad_norm": 0.2991877496242523,
      "learning_rate": 4.691201353637902e-05,
      "loss": 0.0874,
      "step": 47450
    },
    {
      "epoch": 6.182480801770142,
      "grad_norm": 0.1295289397239685,
      "learning_rate": 4.690875959911493e-05,
      "loss": 0.1305,
      "step": 47500
    },
    {
      "epoch": 6.188988676298321,
      "grad_norm": 0.5614163875579834,
      "learning_rate": 4.690550566185084e-05,
      "loss": 0.1335,
      "step": 47550
    },
    {
      "epoch": 6.1954965508265,
      "grad_norm": 0.045796263962984085,
      "learning_rate": 4.690225172458675e-05,
      "loss": 0.083,
      "step": 47600
    },
    {
      "epoch": 6.202004425354679,
      "grad_norm": 1.7891645431518555,
      "learning_rate": 4.6898997787322665e-05,
      "loss": 0.1311,
      "step": 47650
    },
    {
      "epoch": 6.208512299882858,
      "grad_norm": 0.0963984951376915,
      "learning_rate": 4.689574385005857e-05,
      "loss": 0.1197,
      "step": 47700
    },
    {
      "epoch": 6.215020174411038,
      "grad_norm": 0.06369046866893768,
      "learning_rate": 4.689248991279449e-05,
      "loss": 0.129,
      "step": 47750
    },
    {
      "epoch": 6.221528048939216,
      "grad_norm": 5.996749401092529,
      "learning_rate": 4.6889235975530394e-05,
      "loss": 0.1048,
      "step": 47800
    },
    {
      "epoch": 6.228035923467395,
      "grad_norm": 0.019727645441889763,
      "learning_rate": 4.68859820382663e-05,
      "loss": 0.0852,
      "step": 47850
    },
    {
      "epoch": 6.234543797995575,
      "grad_norm": 5.620448589324951,
      "learning_rate": 4.6882728101002215e-05,
      "loss": 0.0804,
      "step": 47900
    },
    {
      "epoch": 6.241051672523754,
      "grad_norm": 0.36532261967658997,
      "learning_rate": 4.687947416373812e-05,
      "loss": 0.0686,
      "step": 47950
    },
    {
      "epoch": 6.2475595470519325,
      "grad_norm": 6.0548996925354,
      "learning_rate": 4.6876220226474037e-05,
      "loss": 0.1321,
      "step": 48000
    },
    {
      "epoch": 6.254067421580112,
      "grad_norm": 0.6884934902191162,
      "learning_rate": 4.6872966289209944e-05,
      "loss": 0.0752,
      "step": 48050
    },
    {
      "epoch": 6.260575296108291,
      "grad_norm": 0.5733731389045715,
      "learning_rate": 4.686971235194586e-05,
      "loss": 0.1308,
      "step": 48100
    },
    {
      "epoch": 6.26708317063647,
      "grad_norm": 0.06990465521812439,
      "learning_rate": 4.686645841468177e-05,
      "loss": 0.1643,
      "step": 48150
    },
    {
      "epoch": 6.2735910451646495,
      "grad_norm": 0.13966993987560272,
      "learning_rate": 4.686320447741768e-05,
      "loss": 0.1381,
      "step": 48200
    },
    {
      "epoch": 6.280098919692828,
      "grad_norm": 0.05162621662020683,
      "learning_rate": 4.6859950540153587e-05,
      "loss": 0.0751,
      "step": 48250
    },
    {
      "epoch": 6.286606794221007,
      "grad_norm": 0.7020197510719299,
      "learning_rate": 4.68566966028895e-05,
      "loss": 0.1338,
      "step": 48300
    },
    {
      "epoch": 6.293114668749187,
      "grad_norm": 0.0701514333486557,
      "learning_rate": 4.685344266562541e-05,
      "loss": 0.0876,
      "step": 48350
    },
    {
      "epoch": 6.299622543277366,
      "grad_norm": 1.8540689945220947,
      "learning_rate": 4.685018872836132e-05,
      "loss": 0.1173,
      "step": 48400
    },
    {
      "epoch": 6.306130417805544,
      "grad_norm": 0.10704325884580612,
      "learning_rate": 4.684693479109723e-05,
      "loss": 0.0771,
      "step": 48450
    },
    {
      "epoch": 6.312638292333724,
      "grad_norm": 0.38642618060112,
      "learning_rate": 4.6843680853833137e-05,
      "loss": 0.1153,
      "step": 48500
    },
    {
      "epoch": 6.319146166861903,
      "grad_norm": 4.754282474517822,
      "learning_rate": 4.684042691656905e-05,
      "loss": 0.1322,
      "step": 48550
    },
    {
      "epoch": 6.325654041390082,
      "grad_norm": 13.622568130493164,
      "learning_rate": 4.683717297930496e-05,
      "loss": 0.0773,
      "step": 48600
    },
    {
      "epoch": 6.332161915918261,
      "grad_norm": 0.11482946574687958,
      "learning_rate": 4.683391904204087e-05,
      "loss": 0.1009,
      "step": 48650
    },
    {
      "epoch": 6.33866979044644,
      "grad_norm": 14.582661628723145,
      "learning_rate": 4.6830665104776786e-05,
      "loss": 0.1207,
      "step": 48700
    },
    {
      "epoch": 6.345177664974619,
      "grad_norm": 0.052717290818691254,
      "learning_rate": 4.682741116751269e-05,
      "loss": 0.1071,
      "step": 48750
    },
    {
      "epoch": 6.351685539502799,
      "grad_norm": 0.014303990639746189,
      "learning_rate": 4.682415723024861e-05,
      "loss": 0.0798,
      "step": 48800
    },
    {
      "epoch": 6.3581934140309775,
      "grad_norm": 0.03241059184074402,
      "learning_rate": 4.6820903292984515e-05,
      "loss": 0.0942,
      "step": 48850
    },
    {
      "epoch": 6.364701288559156,
      "grad_norm": 0.013613729737699032,
      "learning_rate": 4.681764935572042e-05,
      "loss": 0.114,
      "step": 48900
    },
    {
      "epoch": 6.371209163087336,
      "grad_norm": 7.284686088562012,
      "learning_rate": 4.6814395418456336e-05,
      "loss": 0.0836,
      "step": 48950
    },
    {
      "epoch": 6.377717037615515,
      "grad_norm": 21.273700714111328,
      "learning_rate": 4.681114148119224e-05,
      "loss": 0.0951,
      "step": 49000
    },
    {
      "epoch": 6.384224912143694,
      "grad_norm": 8.5714693069458,
      "learning_rate": 4.680788754392815e-05,
      "loss": 0.1229,
      "step": 49050
    },
    {
      "epoch": 6.390732786671873,
      "grad_norm": 0.046952225267887115,
      "learning_rate": 4.6804633606664065e-05,
      "loss": 0.1243,
      "step": 49100
    },
    {
      "epoch": 6.397240661200052,
      "grad_norm": 0.022341400384902954,
      "learning_rate": 4.680137966939997e-05,
      "loss": 0.1041,
      "step": 49150
    },
    {
      "epoch": 6.403748535728231,
      "grad_norm": 0.17576105892658234,
      "learning_rate": 4.6798125732135886e-05,
      "loss": 0.1032,
      "step": 49200
    },
    {
      "epoch": 6.410256410256411,
      "grad_norm": 0.13432860374450684,
      "learning_rate": 4.67948717948718e-05,
      "loss": 0.1004,
      "step": 49250
    },
    {
      "epoch": 6.416764284784589,
      "grad_norm": 0.010020872578024864,
      "learning_rate": 4.679161785760771e-05,
      "loss": 0.1039,
      "step": 49300
    },
    {
      "epoch": 6.423272159312768,
      "grad_norm": 0.24130213260650635,
      "learning_rate": 4.678836392034362e-05,
      "loss": 0.0928,
      "step": 49350
    },
    {
      "epoch": 6.429780033840948,
      "grad_norm": 0.02260778844356537,
      "learning_rate": 4.678510998307953e-05,
      "loss": 0.0688,
      "step": 49400
    },
    {
      "epoch": 6.436287908369127,
      "grad_norm": 0.18361718952655792,
      "learning_rate": 4.6781856045815436e-05,
      "loss": 0.1645,
      "step": 49450
    },
    {
      "epoch": 6.4427957828973055,
      "grad_norm": 0.07699946314096451,
      "learning_rate": 4.677860210855135e-05,
      "loss": 0.104,
      "step": 49500
    },
    {
      "epoch": 6.449303657425485,
      "grad_norm": 8.517796516418457,
      "learning_rate": 4.677534817128726e-05,
      "loss": 0.0696,
      "step": 49550
    },
    {
      "epoch": 6.455811531953664,
      "grad_norm": 0.10062975436449051,
      "learning_rate": 4.677209423402317e-05,
      "loss": 0.1628,
      "step": 49600
    },
    {
      "epoch": 6.462319406481843,
      "grad_norm": 12.739669799804688,
      "learning_rate": 4.676884029675908e-05,
      "loss": 0.0625,
      "step": 49650
    },
    {
      "epoch": 6.4688272810100225,
      "grad_norm": 0.9028900265693665,
      "learning_rate": 4.676558635949499e-05,
      "loss": 0.077,
      "step": 49700
    },
    {
      "epoch": 6.475335155538201,
      "grad_norm": 0.06683333963155746,
      "learning_rate": 4.676233242223091e-05,
      "loss": 0.1244,
      "step": 49750
    },
    {
      "epoch": 6.48184303006638,
      "grad_norm": 9.593056678771973,
      "learning_rate": 4.6759078484966814e-05,
      "loss": 0.1085,
      "step": 49800
    },
    {
      "epoch": 6.48835090459456,
      "grad_norm": 0.047079384326934814,
      "learning_rate": 4.675582454770272e-05,
      "loss": 0.0693,
      "step": 49850
    },
    {
      "epoch": 6.494858779122739,
      "grad_norm": 0.07375488430261612,
      "learning_rate": 4.6752570610438635e-05,
      "loss": 0.1698,
      "step": 49900
    },
    {
      "epoch": 6.501366653650917,
      "grad_norm": 11.812874794006348,
      "learning_rate": 4.674931667317454e-05,
      "loss": 0.1032,
      "step": 49950
    },
    {
      "epoch": 6.507874528179097,
      "grad_norm": 5.730124473571777,
      "learning_rate": 4.674606273591046e-05,
      "loss": 0.1116,
      "step": 50000
    },
    {
      "epoch": 6.514382402707276,
      "grad_norm": 11.477102279663086,
      "learning_rate": 4.6742808798646364e-05,
      "loss": 0.1378,
      "step": 50050
    },
    {
      "epoch": 6.520890277235455,
      "grad_norm": 25.943279266357422,
      "learning_rate": 4.673955486138227e-05,
      "loss": 0.0775,
      "step": 50100
    },
    {
      "epoch": 6.527398151763634,
      "grad_norm": 0.5042170882225037,
      "learning_rate": 4.6736300924118185e-05,
      "loss": 0.0629,
      "step": 50150
    },
    {
      "epoch": 6.533906026291813,
      "grad_norm": 0.03077385388314724,
      "learning_rate": 4.673304698685409e-05,
      "loss": 0.1057,
      "step": 50200
    },
    {
      "epoch": 6.540413900819992,
      "grad_norm": 5.003028869628906,
      "learning_rate": 4.672979304959001e-05,
      "loss": 0.1249,
      "step": 50250
    },
    {
      "epoch": 6.546921775348172,
      "grad_norm": 0.02438134327530861,
      "learning_rate": 4.672653911232592e-05,
      "loss": 0.109,
      "step": 50300
    },
    {
      "epoch": 6.5534296498763505,
      "grad_norm": 0.49575087428092957,
      "learning_rate": 4.672328517506183e-05,
      "loss": 0.0455,
      "step": 50350
    },
    {
      "epoch": 6.559937524404529,
      "grad_norm": 0.08015512675046921,
      "learning_rate": 4.672003123779774e-05,
      "loss": 0.0918,
      "step": 50400
    },
    {
      "epoch": 6.566445398932709,
      "grad_norm": 19.565095901489258,
      "learning_rate": 4.671677730053365e-05,
      "loss": 0.095,
      "step": 50450
    },
    {
      "epoch": 6.572953273460888,
      "grad_norm": 0.07102310657501221,
      "learning_rate": 4.6713523363269557e-05,
      "loss": 0.1613,
      "step": 50500
    },
    {
      "epoch": 6.579461147989067,
      "grad_norm": 6.673734188079834,
      "learning_rate": 4.671026942600547e-05,
      "loss": 0.0913,
      "step": 50550
    },
    {
      "epoch": 6.585969022517246,
      "grad_norm": 0.3325503170490265,
      "learning_rate": 4.670701548874138e-05,
      "loss": 0.1097,
      "step": 50600
    },
    {
      "epoch": 6.592476897045425,
      "grad_norm": 0.022712377831339836,
      "learning_rate": 4.6703761551477285e-05,
      "loss": 0.0504,
      "step": 50650
    },
    {
      "epoch": 6.598984771573604,
      "grad_norm": 0.07638213038444519,
      "learning_rate": 4.67005076142132e-05,
      "loss": 0.0762,
      "step": 50700
    },
    {
      "epoch": 6.6054926461017835,
      "grad_norm": 0.037318699061870575,
      "learning_rate": 4.6697253676949107e-05,
      "loss": 0.1106,
      "step": 50750
    },
    {
      "epoch": 6.612000520629962,
      "grad_norm": 0.037074942141771317,
      "learning_rate": 4.669399973968502e-05,
      "loss": 0.1349,
      "step": 50800
    },
    {
      "epoch": 6.618508395158141,
      "grad_norm": 0.012179096229374409,
      "learning_rate": 4.6690745802420935e-05,
      "loss": 0.1064,
      "step": 50850
    },
    {
      "epoch": 6.62501626968632,
      "grad_norm": 22.22751235961914,
      "learning_rate": 4.668749186515684e-05,
      "loss": 0.142,
      "step": 50900
    },
    {
      "epoch": 6.6315241442145,
      "grad_norm": 31.278202056884766,
      "learning_rate": 4.6684237927892756e-05,
      "loss": 0.0426,
      "step": 50950
    },
    {
      "epoch": 6.6380320187426785,
      "grad_norm": 6.901481628417969,
      "learning_rate": 4.668098399062866e-05,
      "loss": 0.1691,
      "step": 51000
    },
    {
      "epoch": 6.644539893270858,
      "grad_norm": 5.457571506500244,
      "learning_rate": 4.667773005336457e-05,
      "loss": 0.1457,
      "step": 51050
    },
    {
      "epoch": 6.651047767799037,
      "grad_norm": 7.514976978302002,
      "learning_rate": 4.6674476116100485e-05,
      "loss": 0.097,
      "step": 51100
    },
    {
      "epoch": 6.657555642327216,
      "grad_norm": 0.06297892332077026,
      "learning_rate": 4.667122217883639e-05,
      "loss": 0.0929,
      "step": 51150
    },
    {
      "epoch": 6.6640635168553946,
      "grad_norm": 5.22580099105835,
      "learning_rate": 4.6667968241572306e-05,
      "loss": 0.1669,
      "step": 51200
    },
    {
      "epoch": 6.670571391383574,
      "grad_norm": 0.06403838843107224,
      "learning_rate": 4.666471430430821e-05,
      "loss": 0.0375,
      "step": 51250
    },
    {
      "epoch": 6.677079265911753,
      "grad_norm": 0.06685353815555573,
      "learning_rate": 4.666146036704413e-05,
      "loss": 0.1152,
      "step": 51300
    },
    {
      "epoch": 6.683587140439933,
      "grad_norm": 0.025717560201883316,
      "learning_rate": 4.665820642978004e-05,
      "loss": 0.111,
      "step": 51350
    },
    {
      "epoch": 6.6900950149681115,
      "grad_norm": 23.37735939025879,
      "learning_rate": 4.665495249251595e-05,
      "loss": 0.1146,
      "step": 51400
    },
    {
      "epoch": 6.69660288949629,
      "grad_norm": 16.53260612487793,
      "learning_rate": 4.6651698555251856e-05,
      "loss": 0.1321,
      "step": 51450
    },
    {
      "epoch": 6.703110764024469,
      "grad_norm": 16.00699234008789,
      "learning_rate": 4.664844461798777e-05,
      "loss": 0.0856,
      "step": 51500
    },
    {
      "epoch": 6.709618638552649,
      "grad_norm": 1.8346771001815796,
      "learning_rate": 4.664519068072368e-05,
      "loss": 0.0936,
      "step": 51550
    },
    {
      "epoch": 6.716126513080828,
      "grad_norm": 0.13243037462234497,
      "learning_rate": 4.664193674345959e-05,
      "loss": 0.0576,
      "step": 51600
    },
    {
      "epoch": 6.722634387609007,
      "grad_norm": 0.03831636160612106,
      "learning_rate": 4.66386828061955e-05,
      "loss": 0.0764,
      "step": 51650
    },
    {
      "epoch": 6.729142262137186,
      "grad_norm": 0.056776147335767746,
      "learning_rate": 4.6635428868931406e-05,
      "loss": 0.1473,
      "step": 51700
    },
    {
      "epoch": 6.735650136665365,
      "grad_norm": 1.2072237730026245,
      "learning_rate": 4.663217493166732e-05,
      "loss": 0.0816,
      "step": 51750
    },
    {
      "epoch": 6.742158011193544,
      "grad_norm": 0.04853144660592079,
      "learning_rate": 4.662892099440323e-05,
      "loss": 0.1611,
      "step": 51800
    },
    {
      "epoch": 6.748665885721723,
      "grad_norm": 5.232934474945068,
      "learning_rate": 4.662566705713914e-05,
      "loss": 0.1411,
      "step": 51850
    },
    {
      "epoch": 6.755173760249902,
      "grad_norm": 8.873469352722168,
      "learning_rate": 4.6622413119875055e-05,
      "loss": 0.1053,
      "step": 51900
    },
    {
      "epoch": 6.761681634778082,
      "grad_norm": 0.11189228296279907,
      "learning_rate": 4.661915918261096e-05,
      "loss": 0.1125,
      "step": 51950
    },
    {
      "epoch": 6.768189509306261,
      "grad_norm": 0.30587780475616455,
      "learning_rate": 4.661590524534687e-05,
      "loss": 0.104,
      "step": 52000
    },
    {
      "epoch": 6.7746973838344395,
      "grad_norm": 0.04089173674583435,
      "learning_rate": 4.6612651308082784e-05,
      "loss": 0.1391,
      "step": 52050
    },
    {
      "epoch": 6.781205258362618,
      "grad_norm": 9.14382266998291,
      "learning_rate": 4.660939737081869e-05,
      "loss": 0.1026,
      "step": 52100
    },
    {
      "epoch": 6.787713132890798,
      "grad_norm": 12.754510879516602,
      "learning_rate": 4.6606143433554605e-05,
      "loss": 0.1083,
      "step": 52150
    },
    {
      "epoch": 6.794221007418977,
      "grad_norm": 0.005654435604810715,
      "learning_rate": 4.660288949629051e-05,
      "loss": 0.1168,
      "step": 52200
    },
    {
      "epoch": 6.8007288819471565,
      "grad_norm": 6.8553009033203125,
      "learning_rate": 4.659963555902642e-05,
      "loss": 0.0922,
      "step": 52250
    },
    {
      "epoch": 6.807236756475335,
      "grad_norm": 0.007401667535305023,
      "learning_rate": 4.6596381621762334e-05,
      "loss": 0.1061,
      "step": 52300
    },
    {
      "epoch": 6.813744631003514,
      "grad_norm": 0.009704595431685448,
      "learning_rate": 4.659312768449824e-05,
      "loss": 0.0663,
      "step": 52350
    },
    {
      "epoch": 6.820252505531693,
      "grad_norm": 0.18267829716205597,
      "learning_rate": 4.6589873747234155e-05,
      "loss": 0.1219,
      "step": 52400
    },
    {
      "epoch": 6.826760380059873,
      "grad_norm": 5.814814567565918,
      "learning_rate": 4.658661980997007e-05,
      "loss": 0.1324,
      "step": 52450
    },
    {
      "epoch": 6.833268254588051,
      "grad_norm": 0.15662778913974762,
      "learning_rate": 4.658336587270598e-05,
      "loss": 0.1677,
      "step": 52500
    },
    {
      "epoch": 6.839776129116231,
      "grad_norm": 0.14522644877433777,
      "learning_rate": 4.658011193544189e-05,
      "loss": 0.1161,
      "step": 52550
    },
    {
      "epoch": 6.84628400364441,
      "grad_norm": 0.39410024881362915,
      "learning_rate": 4.65768579981778e-05,
      "loss": 0.0649,
      "step": 52600
    },
    {
      "epoch": 6.852791878172589,
      "grad_norm": 6.177700042724609,
      "learning_rate": 4.6573604060913705e-05,
      "loss": 0.1189,
      "step": 52650
    },
    {
      "epoch": 6.8592997527007675,
      "grad_norm": 0.13785648345947266,
      "learning_rate": 4.657035012364962e-05,
      "loss": 0.1049,
      "step": 52700
    },
    {
      "epoch": 6.865807627228947,
      "grad_norm": 6.537515640258789,
      "learning_rate": 4.656709618638553e-05,
      "loss": 0.1631,
      "step": 52750
    },
    {
      "epoch": 6.872315501757126,
      "grad_norm": 0.0795510858297348,
      "learning_rate": 4.6563842249121434e-05,
      "loss": 0.1068,
      "step": 52800
    },
    {
      "epoch": 6.878823376285306,
      "grad_norm": 0.08927733451128006,
      "learning_rate": 4.656058831185735e-05,
      "loss": 0.141,
      "step": 52850
    },
    {
      "epoch": 6.8853312508134845,
      "grad_norm": 5.478874683380127,
      "learning_rate": 4.655733437459326e-05,
      "loss": 0.1025,
      "step": 52900
    },
    {
      "epoch": 6.891839125341663,
      "grad_norm": 1.0110704898834229,
      "learning_rate": 4.6554080437329176e-05,
      "loss": 0.0695,
      "step": 52950
    },
    {
      "epoch": 6.898346999869842,
      "grad_norm": 2.12753963470459,
      "learning_rate": 4.655082650006508e-05,
      "loss": 0.0843,
      "step": 53000
    },
    {
      "epoch": 6.904854874398022,
      "grad_norm": 0.03563740476965904,
      "learning_rate": 4.654757256280099e-05,
      "loss": 0.0933,
      "step": 53050
    },
    {
      "epoch": 6.911362748926201,
      "grad_norm": 6.657129764556885,
      "learning_rate": 4.6544318625536905e-05,
      "loss": 0.1273,
      "step": 53100
    },
    {
      "epoch": 6.917870623454379,
      "grad_norm": 4.777927875518799,
      "learning_rate": 4.654106468827281e-05,
      "loss": 0.1718,
      "step": 53150
    },
    {
      "epoch": 6.924378497982559,
      "grad_norm": 0.10306981205940247,
      "learning_rate": 4.653781075100872e-05,
      "loss": 0.0922,
      "step": 53200
    },
    {
      "epoch": 6.930886372510738,
      "grad_norm": 0.7911050319671631,
      "learning_rate": 4.653455681374463e-05,
      "loss": 0.1097,
      "step": 53250
    },
    {
      "epoch": 6.937394247038917,
      "grad_norm": 0.023072881624102592,
      "learning_rate": 4.653130287648054e-05,
      "loss": 0.1277,
      "step": 53300
    },
    {
      "epoch": 6.943902121567096,
      "grad_norm": 0.033312492072582245,
      "learning_rate": 4.6528048939216455e-05,
      "loss": 0.0708,
      "step": 53350
    },
    {
      "epoch": 6.950409996095275,
      "grad_norm": 1.3149250745773315,
      "learning_rate": 4.652479500195236e-05,
      "loss": 0.0703,
      "step": 53400
    },
    {
      "epoch": 6.956917870623454,
      "grad_norm": 0.24651390314102173,
      "learning_rate": 4.6521541064688276e-05,
      "loss": 0.1227,
      "step": 53450
    },
    {
      "epoch": 6.963425745151634,
      "grad_norm": 7.03366231918335,
      "learning_rate": 4.651828712742419e-05,
      "loss": 0.1473,
      "step": 53500
    },
    {
      "epoch": 6.9699336196798125,
      "grad_norm": 0.0426943376660347,
      "learning_rate": 4.65150331901601e-05,
      "loss": 0.1434,
      "step": 53550
    },
    {
      "epoch": 6.976441494207991,
      "grad_norm": 0.2250586599111557,
      "learning_rate": 4.6511779252896005e-05,
      "loss": 0.0838,
      "step": 53600
    },
    {
      "epoch": 6.982949368736171,
      "grad_norm": 1.3015825748443604,
      "learning_rate": 4.650852531563192e-05,
      "loss": 0.1056,
      "step": 53650
    },
    {
      "epoch": 6.98945724326435,
      "grad_norm": 0.035016611218452454,
      "learning_rate": 4.6505271378367826e-05,
      "loss": 0.1231,
      "step": 53700
    },
    {
      "epoch": 6.995965117792529,
      "grad_norm": 12.649009704589844,
      "learning_rate": 4.650201744110374e-05,
      "loss": 0.1556,
      "step": 53750
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9666124308493329,
      "eval_f1": 0.9668068586218053,
      "eval_loss": 0.12236085534095764,
      "eval_precision": 0.9607767489711934,
      "eval_recall": 0.9729131397317359,
      "eval_runtime": 23.5335,
      "eval_samples_per_second": 652.899,
      "eval_steps_per_second": 81.628,
      "step": 53781
    },
    {
      "epoch": 7.002472992320708,
      "grad_norm": 0.2960924208164215,
      "learning_rate": 4.649876350383965e-05,
      "loss": 0.0572,
      "step": 53800
    },
    {
      "epoch": 7.008980866848887,
      "grad_norm": 0.2706206738948822,
      "learning_rate": 4.6495509566575555e-05,
      "loss": 0.0892,
      "step": 53850
    },
    {
      "epoch": 7.015488741377066,
      "grad_norm": 0.15011107921600342,
      "learning_rate": 4.649225562931147e-05,
      "loss": 0.0874,
      "step": 53900
    },
    {
      "epoch": 7.021996615905246,
      "grad_norm": 0.1389632672071457,
      "learning_rate": 4.6489001692047376e-05,
      "loss": 0.1023,
      "step": 53950
    },
    {
      "epoch": 7.028504490433424,
      "grad_norm": 0.11626702547073364,
      "learning_rate": 4.648574775478329e-05,
      "loss": 0.0737,
      "step": 54000
    },
    {
      "epoch": 7.035012364961603,
      "grad_norm": 0.42142146825790405,
      "learning_rate": 4.6482493817519204e-05,
      "loss": 0.1466,
      "step": 54050
    },
    {
      "epoch": 7.041520239489783,
      "grad_norm": 9.01461124420166,
      "learning_rate": 4.647923988025511e-05,
      "loss": 0.0707,
      "step": 54100
    },
    {
      "epoch": 7.048028114017962,
      "grad_norm": 2.1949007511138916,
      "learning_rate": 4.6475985942991025e-05,
      "loss": 0.1261,
      "step": 54150
    },
    {
      "epoch": 7.0545359885461405,
      "grad_norm": 0.05323860049247742,
      "learning_rate": 4.647273200572693e-05,
      "loss": 0.1028,
      "step": 54200
    },
    {
      "epoch": 7.06104386307432,
      "grad_norm": 10.605215072631836,
      "learning_rate": 4.646947806846284e-05,
      "loss": 0.0934,
      "step": 54250
    },
    {
      "epoch": 7.067551737602499,
      "grad_norm": 0.008124316111207008,
      "learning_rate": 4.6466224131198754e-05,
      "loss": 0.1179,
      "step": 54300
    },
    {
      "epoch": 7.074059612130678,
      "grad_norm": 0.1460106521844864,
      "learning_rate": 4.646297019393466e-05,
      "loss": 0.0304,
      "step": 54350
    },
    {
      "epoch": 7.0805674866588575,
      "grad_norm": 0.12265226989984512,
      "learning_rate": 4.645971625667057e-05,
      "loss": 0.1208,
      "step": 54400
    },
    {
      "epoch": 7.087075361187036,
      "grad_norm": 0.029432082548737526,
      "learning_rate": 4.645646231940648e-05,
      "loss": 0.067,
      "step": 54450
    },
    {
      "epoch": 7.093583235715215,
      "grad_norm": 0.01967552676796913,
      "learning_rate": 4.64532083821424e-05,
      "loss": 0.1075,
      "step": 54500
    },
    {
      "epoch": 7.100091110243395,
      "grad_norm": 0.1564904898405075,
      "learning_rate": 4.644995444487831e-05,
      "loss": 0.1207,
      "step": 54550
    },
    {
      "epoch": 7.106598984771574,
      "grad_norm": 6.721632957458496,
      "learning_rate": 4.644670050761422e-05,
      "loss": 0.0826,
      "step": 54600
    },
    {
      "epoch": 7.113106859299752,
      "grad_norm": 0.16024644672870636,
      "learning_rate": 4.6443446570350125e-05,
      "loss": 0.1096,
      "step": 54650
    },
    {
      "epoch": 7.119614733827932,
      "grad_norm": 23.43764877319336,
      "learning_rate": 4.644019263308604e-05,
      "loss": 0.1036,
      "step": 54700
    },
    {
      "epoch": 7.126122608356111,
      "grad_norm": 0.012532930821180344,
      "learning_rate": 4.643693869582195e-05,
      "loss": 0.1214,
      "step": 54750
    },
    {
      "epoch": 7.13263048288429,
      "grad_norm": 0.07637910544872284,
      "learning_rate": 4.6433684758557854e-05,
      "loss": 0.089,
      "step": 54800
    },
    {
      "epoch": 7.139138357412469,
      "grad_norm": 0.038267042487859726,
      "learning_rate": 4.643043082129377e-05,
      "loss": 0.0942,
      "step": 54850
    },
    {
      "epoch": 7.145646231940648,
      "grad_norm": 0.08634847402572632,
      "learning_rate": 4.6427176884029675e-05,
      "loss": 0.0683,
      "step": 54900
    },
    {
      "epoch": 7.152154106468827,
      "grad_norm": 0.33897385001182556,
      "learning_rate": 4.642392294676559e-05,
      "loss": 0.1465,
      "step": 54950
    },
    {
      "epoch": 7.158661980997007,
      "grad_norm": 0.22944335639476776,
      "learning_rate": 4.64206690095015e-05,
      "loss": 0.1036,
      "step": 55000
    },
    {
      "epoch": 7.1651698555251855,
      "grad_norm": 0.030284281820058823,
      "learning_rate": 4.641741507223741e-05,
      "loss": 0.0727,
      "step": 55050
    },
    {
      "epoch": 7.171677730053364,
      "grad_norm": 0.5694271326065063,
      "learning_rate": 4.6414161134973325e-05,
      "loss": 0.1214,
      "step": 55100
    },
    {
      "epoch": 7.178185604581544,
      "grad_norm": 0.13642510771751404,
      "learning_rate": 4.641090719770923e-05,
      "loss": 0.1439,
      "step": 55150
    },
    {
      "epoch": 7.184693479109723,
      "grad_norm": 9.234628677368164,
      "learning_rate": 4.640765326044514e-05,
      "loss": 0.0922,
      "step": 55200
    },
    {
      "epoch": 7.191201353637902,
      "grad_norm": 19.754287719726562,
      "learning_rate": 4.6404399323181053e-05,
      "loss": 0.1157,
      "step": 55250
    },
    {
      "epoch": 7.197709228166081,
      "grad_norm": 0.10601980239152908,
      "learning_rate": 4.640114538591696e-05,
      "loss": 0.1518,
      "step": 55300
    },
    {
      "epoch": 7.20421710269426,
      "grad_norm": 0.008301543071866035,
      "learning_rate": 4.6397891448652875e-05,
      "loss": 0.1206,
      "step": 55350
    },
    {
      "epoch": 7.210724977222439,
      "grad_norm": 1.4750893115997314,
      "learning_rate": 4.639463751138878e-05,
      "loss": 0.12,
      "step": 55400
    },
    {
      "epoch": 7.217232851750619,
      "grad_norm": 0.03693045303225517,
      "learning_rate": 4.639138357412469e-05,
      "loss": 0.0508,
      "step": 55450
    },
    {
      "epoch": 7.223740726278797,
      "grad_norm": 0.060154132544994354,
      "learning_rate": 4.63881296368606e-05,
      "loss": 0.1337,
      "step": 55500
    },
    {
      "epoch": 7.230248600806976,
      "grad_norm": 0.13458222150802612,
      "learning_rate": 4.638487569959651e-05,
      "loss": 0.0866,
      "step": 55550
    },
    {
      "epoch": 7.236756475335156,
      "grad_norm": 0.006350661162286997,
      "learning_rate": 4.6381621762332425e-05,
      "loss": 0.0949,
      "step": 55600
    },
    {
      "epoch": 7.243264349863335,
      "grad_norm": 4.772884368896484,
      "learning_rate": 4.637836782506834e-05,
      "loss": 0.1665,
      "step": 55650
    },
    {
      "epoch": 7.2497722243915135,
      "grad_norm": 0.15754181146621704,
      "learning_rate": 4.6375113887804246e-05,
      "loss": 0.1333,
      "step": 55700
    },
    {
      "epoch": 7.256280098919693,
      "grad_norm": 0.08303970098495483,
      "learning_rate": 4.637185995054016e-05,
      "loss": 0.087,
      "step": 55750
    },
    {
      "epoch": 7.262787973447872,
      "grad_norm": 14.859306335449219,
      "learning_rate": 4.636860601327607e-05,
      "loss": 0.1875,
      "step": 55800
    },
    {
      "epoch": 7.269295847976051,
      "grad_norm": 0.08909738808870316,
      "learning_rate": 4.6365352076011975e-05,
      "loss": 0.1265,
      "step": 55850
    },
    {
      "epoch": 7.2758037225042305,
      "grad_norm": 8.1288423538208,
      "learning_rate": 4.636209813874789e-05,
      "loss": 0.0889,
      "step": 55900
    },
    {
      "epoch": 7.282311597032409,
      "grad_norm": 0.043958473950624466,
      "learning_rate": 4.6358844201483796e-05,
      "loss": 0.1081,
      "step": 55950
    },
    {
      "epoch": 7.288819471560588,
      "grad_norm": 2.7091987133026123,
      "learning_rate": 4.63555902642197e-05,
      "loss": 0.0756,
      "step": 56000
    },
    {
      "epoch": 7.295327346088768,
      "grad_norm": 0.20270715653896332,
      "learning_rate": 4.635233632695562e-05,
      "loss": 0.0685,
      "step": 56050
    },
    {
      "epoch": 7.301835220616947,
      "grad_norm": 13.164774894714355,
      "learning_rate": 4.634908238969153e-05,
      "loss": 0.1292,
      "step": 56100
    },
    {
      "epoch": 7.308343095145125,
      "grad_norm": 0.32654792070388794,
      "learning_rate": 4.634582845242744e-05,
      "loss": 0.0553,
      "step": 56150
    },
    {
      "epoch": 7.314850969673305,
      "grad_norm": 0.5630722045898438,
      "learning_rate": 4.634257451516335e-05,
      "loss": 0.1476,
      "step": 56200
    },
    {
      "epoch": 7.321358844201484,
      "grad_norm": 0.06423570960760117,
      "learning_rate": 4.633932057789926e-05,
      "loss": 0.0598,
      "step": 56250
    },
    {
      "epoch": 7.327866718729663,
      "grad_norm": 0.7111344933509827,
      "learning_rate": 4.6336066640635174e-05,
      "loss": 0.1124,
      "step": 56300
    },
    {
      "epoch": 7.334374593257842,
      "grad_norm": 5.440489768981934,
      "learning_rate": 4.633281270337108e-05,
      "loss": 0.1104,
      "step": 56350
    },
    {
      "epoch": 7.340882467786021,
      "grad_norm": 0.25865504145622253,
      "learning_rate": 4.632955876610699e-05,
      "loss": 0.0704,
      "step": 56400
    },
    {
      "epoch": 7.3473903423142,
      "grad_norm": 2.950423002243042,
      "learning_rate": 4.63263048288429e-05,
      "loss": 0.1036,
      "step": 56450
    },
    {
      "epoch": 7.35389821684238,
      "grad_norm": 0.03741677477955818,
      "learning_rate": 4.632305089157881e-05,
      "loss": 0.1172,
      "step": 56500
    },
    {
      "epoch": 7.3604060913705585,
      "grad_norm": 0.09288295358419418,
      "learning_rate": 4.631979695431472e-05,
      "loss": 0.0999,
      "step": 56550
    },
    {
      "epoch": 7.366913965898737,
      "grad_norm": 0.018643856048583984,
      "learning_rate": 4.631654301705063e-05,
      "loss": 0.1191,
      "step": 56600
    },
    {
      "epoch": 7.373421840426917,
      "grad_norm": 0.10119472444057465,
      "learning_rate": 4.6313289079786545e-05,
      "loss": 0.1141,
      "step": 56650
    },
    {
      "epoch": 7.379929714955096,
      "grad_norm": 19.409597396850586,
      "learning_rate": 4.631003514252246e-05,
      "loss": 0.1036,
      "step": 56700
    },
    {
      "epoch": 7.386437589483275,
      "grad_norm": 0.19680850207805634,
      "learning_rate": 4.630678120525837e-05,
      "loss": 0.1519,
      "step": 56750
    },
    {
      "epoch": 7.392945464011454,
      "grad_norm": 0.13570435345172882,
      "learning_rate": 4.6303527267994274e-05,
      "loss": 0.1159,
      "step": 56800
    },
    {
      "epoch": 7.399453338539633,
      "grad_norm": 0.10740786790847778,
      "learning_rate": 4.630027333073019e-05,
      "loss": 0.139,
      "step": 56850
    },
    {
      "epoch": 7.405961213067812,
      "grad_norm": 0.3195251524448395,
      "learning_rate": 4.6297019393466095e-05,
      "loss": 0.05,
      "step": 56900
    },
    {
      "epoch": 7.4124690875959915,
      "grad_norm": 6.406149387359619,
      "learning_rate": 4.6293765456202e-05,
      "loss": 0.1271,
      "step": 56950
    },
    {
      "epoch": 7.41897696212417,
      "grad_norm": 0.0077603161334991455,
      "learning_rate": 4.629051151893792e-05,
      "loss": 0.0899,
      "step": 57000
    },
    {
      "epoch": 7.425484836652349,
      "grad_norm": 2.778089761734009,
      "learning_rate": 4.6287257581673824e-05,
      "loss": 0.0882,
      "step": 57050
    },
    {
      "epoch": 7.431992711180529,
      "grad_norm": 0.07284760475158691,
      "learning_rate": 4.628400364440974e-05,
      "loss": 0.1152,
      "step": 57100
    },
    {
      "epoch": 7.438500585708708,
      "grad_norm": 31.593725204467773,
      "learning_rate": 4.6280749707145645e-05,
      "loss": 0.0957,
      "step": 57150
    },
    {
      "epoch": 7.4450084602368864,
      "grad_norm": 7.999079704284668,
      "learning_rate": 4.627749576988156e-05,
      "loss": 0.1041,
      "step": 57200
    },
    {
      "epoch": 7.451516334765066,
      "grad_norm": 0.025008343160152435,
      "learning_rate": 4.6274241832617473e-05,
      "loss": 0.1353,
      "step": 57250
    },
    {
      "epoch": 7.458024209293245,
      "grad_norm": 6.888242244720459,
      "learning_rate": 4.627098789535338e-05,
      "loss": 0.067,
      "step": 57300
    },
    {
      "epoch": 7.464532083821424,
      "grad_norm": 0.1883278489112854,
      "learning_rate": 4.626773395808929e-05,
      "loss": 0.0699,
      "step": 57350
    },
    {
      "epoch": 7.471039958349603,
      "grad_norm": 0.10555592179298401,
      "learning_rate": 4.62644800208252e-05,
      "loss": 0.0385,
      "step": 57400
    },
    {
      "epoch": 7.477547832877782,
      "grad_norm": 0.1001422107219696,
      "learning_rate": 4.626122608356111e-05,
      "loss": 0.1415,
      "step": 57450
    },
    {
      "epoch": 7.484055707405961,
      "grad_norm": 1.4150314331054688,
      "learning_rate": 4.6257972146297023e-05,
      "loss": 0.0768,
      "step": 57500
    },
    {
      "epoch": 7.49056358193414,
      "grad_norm": 0.0543849840760231,
      "learning_rate": 4.625471820903293e-05,
      "loss": 0.1169,
      "step": 57550
    },
    {
      "epoch": 7.4970714564623195,
      "grad_norm": 7.119150161743164,
      "learning_rate": 4.625146427176884e-05,
      "loss": 0.1269,
      "step": 57600
    },
    {
      "epoch": 7.503579330990498,
      "grad_norm": 6.271478652954102,
      "learning_rate": 4.624821033450475e-05,
      "loss": 0.0976,
      "step": 57650
    },
    {
      "epoch": 7.510087205518678,
      "grad_norm": 0.20458441972732544,
      "learning_rate": 4.6244956397240666e-05,
      "loss": 0.1136,
      "step": 57700
    },
    {
      "epoch": 7.516595080046857,
      "grad_norm": 0.09879376739263535,
      "learning_rate": 4.6241702459976573e-05,
      "loss": 0.1385,
      "step": 57750
    },
    {
      "epoch": 7.523102954575036,
      "grad_norm": 1.0329761505126953,
      "learning_rate": 4.623844852271249e-05,
      "loss": 0.1186,
      "step": 57800
    },
    {
      "epoch": 7.529610829103214,
      "grad_norm": 0.5318529605865479,
      "learning_rate": 4.6235194585448395e-05,
      "loss": 0.0763,
      "step": 57850
    },
    {
      "epoch": 7.536118703631394,
      "grad_norm": 1.0244444608688354,
      "learning_rate": 4.623194064818431e-05,
      "loss": 0.0907,
      "step": 57900
    },
    {
      "epoch": 7.542626578159573,
      "grad_norm": 2.5892393589019775,
      "learning_rate": 4.6228686710920216e-05,
      "loss": 0.0769,
      "step": 57950
    },
    {
      "epoch": 7.549134452687753,
      "grad_norm": 0.635297417640686,
      "learning_rate": 4.622543277365612e-05,
      "loss": 0.1195,
      "step": 58000
    },
    {
      "epoch": 7.555642327215931,
      "grad_norm": 0.008854866027832031,
      "learning_rate": 4.622217883639204e-05,
      "loss": 0.051,
      "step": 58050
    },
    {
      "epoch": 7.56215020174411,
      "grad_norm": 0.08198963850736618,
      "learning_rate": 4.6218924899127945e-05,
      "loss": 0.0828,
      "step": 58100
    },
    {
      "epoch": 7.568658076272289,
      "grad_norm": 0.04027508199214935,
      "learning_rate": 4.621567096186385e-05,
      "loss": 0.1126,
      "step": 58150
    },
    {
      "epoch": 7.575165950800469,
      "grad_norm": 13.817575454711914,
      "learning_rate": 4.6212417024599766e-05,
      "loss": 0.088,
      "step": 58200
    },
    {
      "epoch": 7.5816738253286475,
      "grad_norm": 8.136337280273438,
      "learning_rate": 4.620916308733568e-05,
      "loss": 0.0967,
      "step": 58250
    },
    {
      "epoch": 7.588181699856827,
      "grad_norm": 0.011671442538499832,
      "learning_rate": 4.6205909150071594e-05,
      "loss": 0.1104,
      "step": 58300
    },
    {
      "epoch": 7.594689574385006,
      "grad_norm": 1.6188879013061523,
      "learning_rate": 4.62026552128075e-05,
      "loss": 0.0861,
      "step": 58350
    },
    {
      "epoch": 7.601197448913185,
      "grad_norm": 0.6271781921386719,
      "learning_rate": 4.619940127554341e-05,
      "loss": 0.0591,
      "step": 58400
    },
    {
      "epoch": 7.607705323441364,
      "grad_norm": 0.13522480428218842,
      "learning_rate": 4.619614733827932e-05,
      "loss": 0.0911,
      "step": 58450
    },
    {
      "epoch": 7.614213197969543,
      "grad_norm": 9.802876472473145,
      "learning_rate": 4.619289340101523e-05,
      "loss": 0.0948,
      "step": 58500
    },
    {
      "epoch": 7.620721072497722,
      "grad_norm": 11.042145729064941,
      "learning_rate": 4.618963946375114e-05,
      "loss": 0.0941,
      "step": 58550
    },
    {
      "epoch": 7.627228947025902,
      "grad_norm": 0.00434805266559124,
      "learning_rate": 4.618638552648705e-05,
      "loss": 0.1359,
      "step": 58600
    },
    {
      "epoch": 7.633736821554081,
      "grad_norm": 0.10641384869813919,
      "learning_rate": 4.618313158922296e-05,
      "loss": 0.1207,
      "step": 58650
    },
    {
      "epoch": 7.640244696082259,
      "grad_norm": 0.003632205305621028,
      "learning_rate": 4.617987765195887e-05,
      "loss": 0.1064,
      "step": 58700
    },
    {
      "epoch": 7.646752570610438,
      "grad_norm": 8.205659866333008,
      "learning_rate": 4.617662371469478e-05,
      "loss": 0.0856,
      "step": 58750
    },
    {
      "epoch": 7.653260445138618,
      "grad_norm": 0.15681719779968262,
      "learning_rate": 4.6173369777430694e-05,
      "loss": 0.0762,
      "step": 58800
    },
    {
      "epoch": 7.659768319666797,
      "grad_norm": 0.0254663173109293,
      "learning_rate": 4.617011584016661e-05,
      "loss": 0.0685,
      "step": 58850
    },
    {
      "epoch": 7.666276194194976,
      "grad_norm": 0.0058285631239414215,
      "learning_rate": 4.6166861902902515e-05,
      "loss": 0.1518,
      "step": 58900
    },
    {
      "epoch": 7.672784068723155,
      "grad_norm": 0.008990922942757607,
      "learning_rate": 4.616360796563842e-05,
      "loss": 0.0799,
      "step": 58950
    },
    {
      "epoch": 7.679291943251334,
      "grad_norm": 0.39930951595306396,
      "learning_rate": 4.616035402837434e-05,
      "loss": 0.1105,
      "step": 59000
    },
    {
      "epoch": 7.685799817779513,
      "grad_norm": 14.547587394714355,
      "learning_rate": 4.6157100091110244e-05,
      "loss": 0.1139,
      "step": 59050
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 14.524616241455078,
      "learning_rate": 4.615384615384616e-05,
      "loss": 0.0471,
      "step": 59100
    },
    {
      "epoch": 7.698815566835871,
      "grad_norm": 0.3281528055667877,
      "learning_rate": 4.6150592216582065e-05,
      "loss": 0.0546,
      "step": 59150
    },
    {
      "epoch": 7.70532344136405,
      "grad_norm": 11.00086784362793,
      "learning_rate": 4.614733827931797e-05,
      "loss": 0.1111,
      "step": 59200
    },
    {
      "epoch": 7.71183131589223,
      "grad_norm": 0.12548691034317017,
      "learning_rate": 4.614408434205389e-05,
      "loss": 0.1267,
      "step": 59250
    },
    {
      "epoch": 7.718339190420409,
      "grad_norm": 1.003847599029541,
      "learning_rate": 4.61408304047898e-05,
      "loss": 0.0963,
      "step": 59300
    },
    {
      "epoch": 7.724847064948587,
      "grad_norm": 0.660495400428772,
      "learning_rate": 4.613757646752571e-05,
      "loss": 0.0974,
      "step": 59350
    },
    {
      "epoch": 7.731354939476767,
      "grad_norm": 0.040345244109630585,
      "learning_rate": 4.613432253026162e-05,
      "loss": 0.0813,
      "step": 59400
    },
    {
      "epoch": 7.737862814004946,
      "grad_norm": 6.1200785636901855,
      "learning_rate": 4.613106859299753e-05,
      "loss": 0.0922,
      "step": 59450
    },
    {
      "epoch": 7.744370688533125,
      "grad_norm": 0.022168247029185295,
      "learning_rate": 4.6127814655733444e-05,
      "loss": 0.1525,
      "step": 59500
    },
    {
      "epoch": 7.750878563061304,
      "grad_norm": 0.05819486826658249,
      "learning_rate": 4.612456071846935e-05,
      "loss": 0.0723,
      "step": 59550
    },
    {
      "epoch": 7.757386437589483,
      "grad_norm": 0.00843758974224329,
      "learning_rate": 4.612130678120526e-05,
      "loss": 0.1413,
      "step": 59600
    },
    {
      "epoch": 7.763894312117662,
      "grad_norm": 6.937167167663574,
      "learning_rate": 4.611805284394117e-05,
      "loss": 0.0956,
      "step": 59650
    },
    {
      "epoch": 7.770402186645842,
      "grad_norm": 6.653156280517578,
      "learning_rate": 4.611479890667708e-05,
      "loss": 0.122,
      "step": 59700
    },
    {
      "epoch": 7.7769100611740205,
      "grad_norm": 0.1349441409111023,
      "learning_rate": 4.611154496941299e-05,
      "loss": 0.103,
      "step": 59750
    },
    {
      "epoch": 7.783417935702199,
      "grad_norm": 0.05474196374416351,
      "learning_rate": 4.61082910321489e-05,
      "loss": 0.0848,
      "step": 59800
    },
    {
      "epoch": 7.789925810230379,
      "grad_norm": 0.08241788297891617,
      "learning_rate": 4.6105037094884815e-05,
      "loss": 0.1119,
      "step": 59850
    },
    {
      "epoch": 7.796433684758558,
      "grad_norm": 0.02620924822986126,
      "learning_rate": 4.610178315762073e-05,
      "loss": 0.1056,
      "step": 59900
    },
    {
      "epoch": 7.802941559286737,
      "grad_norm": 0.1234869733452797,
      "learning_rate": 4.6098529220356636e-05,
      "loss": 0.0882,
      "step": 59950
    },
    {
      "epoch": 7.809449433814916,
      "grad_norm": 0.05871981009840965,
      "learning_rate": 4.6095275283092543e-05,
      "loss": 0.0302,
      "step": 60000
    },
    {
      "epoch": 7.815957308343095,
      "grad_norm": 0.4550274610519409,
      "learning_rate": 4.609202134582846e-05,
      "loss": 0.1277,
      "step": 60050
    },
    {
      "epoch": 7.822465182871274,
      "grad_norm": 0.11689551174640656,
      "learning_rate": 4.6088767408564365e-05,
      "loss": 0.1195,
      "step": 60100
    },
    {
      "epoch": 7.828973057399454,
      "grad_norm": 0.06840874999761581,
      "learning_rate": 4.608551347130027e-05,
      "loss": 0.0977,
      "step": 60150
    },
    {
      "epoch": 7.835480931927632,
      "grad_norm": 0.09384371340274811,
      "learning_rate": 4.6082259534036186e-05,
      "loss": 0.123,
      "step": 60200
    },
    {
      "epoch": 7.841988806455811,
      "grad_norm": 20.27618408203125,
      "learning_rate": 4.6079005596772093e-05,
      "loss": 0.0939,
      "step": 60250
    },
    {
      "epoch": 7.848496680983991,
      "grad_norm": 0.09452597796916962,
      "learning_rate": 4.607575165950801e-05,
      "loss": 0.1455,
      "step": 60300
    },
    {
      "epoch": 7.85500455551217,
      "grad_norm": 0.43857383728027344,
      "learning_rate": 4.6072497722243915e-05,
      "loss": 0.1176,
      "step": 60350
    },
    {
      "epoch": 7.8615124300403485,
      "grad_norm": 6.713953018188477,
      "learning_rate": 4.606924378497983e-05,
      "loss": 0.1103,
      "step": 60400
    },
    {
      "epoch": 7.868020304568528,
      "grad_norm": 1.7363171577453613,
      "learning_rate": 4.606598984771574e-05,
      "loss": 0.0897,
      "step": 60450
    },
    {
      "epoch": 7.874528179096707,
      "grad_norm": 0.13873843848705292,
      "learning_rate": 4.606273591045165e-05,
      "loss": 0.1178,
      "step": 60500
    },
    {
      "epoch": 7.881036053624886,
      "grad_norm": 0.033205337822437286,
      "learning_rate": 4.605948197318756e-05,
      "loss": 0.0903,
      "step": 60550
    },
    {
      "epoch": 7.8875439281530655,
      "grad_norm": 11.195982933044434,
      "learning_rate": 4.605622803592347e-05,
      "loss": 0.1009,
      "step": 60600
    },
    {
      "epoch": 7.894051802681244,
      "grad_norm": 6.095778942108154,
      "learning_rate": 4.605297409865938e-05,
      "loss": 0.0991,
      "step": 60650
    },
    {
      "epoch": 7.900559677209423,
      "grad_norm": 0.1730063259601593,
      "learning_rate": 4.6049720161395286e-05,
      "loss": 0.0863,
      "step": 60700
    },
    {
      "epoch": 7.907067551737603,
      "grad_norm": 0.07542411983013153,
      "learning_rate": 4.60464662241312e-05,
      "loss": 0.1117,
      "step": 60750
    },
    {
      "epoch": 7.913575426265782,
      "grad_norm": 0.37745392322540283,
      "learning_rate": 4.604321228686711e-05,
      "loss": 0.1003,
      "step": 60800
    },
    {
      "epoch": 7.92008330079396,
      "grad_norm": 0.020483091473579407,
      "learning_rate": 4.603995834960302e-05,
      "loss": 0.062,
      "step": 60850
    },
    {
      "epoch": 7.92659117532214,
      "grad_norm": 0.13007739186286926,
      "learning_rate": 4.6036704412338936e-05,
      "loss": 0.085,
      "step": 60900
    },
    {
      "epoch": 7.933099049850319,
      "grad_norm": 0.3013082444667816,
      "learning_rate": 4.603345047507484e-05,
      "loss": 0.0726,
      "step": 60950
    },
    {
      "epoch": 7.939606924378498,
      "grad_norm": 0.08398237824440002,
      "learning_rate": 4.603019653781076e-05,
      "loss": 0.1526,
      "step": 61000
    },
    {
      "epoch": 7.946114798906677,
      "grad_norm": 1.3657199144363403,
      "learning_rate": 4.6026942600546664e-05,
      "loss": 0.1277,
      "step": 61050
    },
    {
      "epoch": 7.952622673434856,
      "grad_norm": 0.45563599467277527,
      "learning_rate": 4.602368866328257e-05,
      "loss": 0.153,
      "step": 61100
    },
    {
      "epoch": 7.959130547963035,
      "grad_norm": 0.1889508217573166,
      "learning_rate": 4.6020434726018485e-05,
      "loss": 0.089,
      "step": 61150
    },
    {
      "epoch": 7.965638422491215,
      "grad_norm": 0.03037785179913044,
      "learning_rate": 4.601718078875439e-05,
      "loss": 0.0819,
      "step": 61200
    },
    {
      "epoch": 7.9721462970193935,
      "grad_norm": 0.14098358154296875,
      "learning_rate": 4.601392685149031e-05,
      "loss": 0.1365,
      "step": 61250
    },
    {
      "epoch": 7.978654171547572,
      "grad_norm": 0.15934883058071136,
      "learning_rate": 4.6010672914226214e-05,
      "loss": 0.0728,
      "step": 61300
    },
    {
      "epoch": 7.985162046075752,
      "grad_norm": 26.049448013305664,
      "learning_rate": 4.600741897696212e-05,
      "loss": 0.0717,
      "step": 61350
    },
    {
      "epoch": 7.991669920603931,
      "grad_norm": 0.21304483711719513,
      "learning_rate": 4.6004165039698035e-05,
      "loss": 0.1261,
      "step": 61400
    },
    {
      "epoch": 7.99817779513211,
      "grad_norm": 8.13391399383545,
      "learning_rate": 4.600091110243395e-05,
      "loss": 0.1275,
      "step": 61450
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9674585095997397,
      "eval_f1": 0.9675282504221328,
      "eval_loss": 0.12393482029438019,
      "eval_precision": 0.9650213758258842,
      "eval_recall": 0.970048183357208,
      "eval_runtime": 23.544,
      "eval_samples_per_second": 652.609,
      "eval_steps_per_second": 81.592,
      "step": 61464
    },
    {
      "epoch": 8.004685669660288,
      "grad_norm": 0.03237111493945122,
      "learning_rate": 4.599765716516986e-05,
      "loss": 0.0696,
      "step": 61500
    },
    {
      "epoch": 8.011193544188467,
      "grad_norm": 0.10752871632575989,
      "learning_rate": 4.599440322790577e-05,
      "loss": 0.0652,
      "step": 61550
    },
    {
      "epoch": 8.017701418716648,
      "grad_norm": 0.15593183040618896,
      "learning_rate": 4.599114929064168e-05,
      "loss": 0.1368,
      "step": 61600
    },
    {
      "epoch": 8.024209293244827,
      "grad_norm": 0.19287730753421783,
      "learning_rate": 4.598789535337759e-05,
      "loss": 0.0772,
      "step": 61650
    },
    {
      "epoch": 8.030717167773005,
      "grad_norm": 0.03733065724372864,
      "learning_rate": 4.59846414161135e-05,
      "loss": 0.1509,
      "step": 61700
    },
    {
      "epoch": 8.037225042301184,
      "grad_norm": 18.69493293762207,
      "learning_rate": 4.598138747884941e-05,
      "loss": 0.0492,
      "step": 61750
    },
    {
      "epoch": 8.043732916829363,
      "grad_norm": 0.9589694142341614,
      "learning_rate": 4.597813354158532e-05,
      "loss": 0.0722,
      "step": 61800
    },
    {
      "epoch": 8.050240791357542,
      "grad_norm": 8.039973258972168,
      "learning_rate": 4.597487960432123e-05,
      "loss": 0.0869,
      "step": 61850
    },
    {
      "epoch": 8.056748665885722,
      "grad_norm": 0.03742147237062454,
      "learning_rate": 4.597162566705714e-05,
      "loss": 0.0828,
      "step": 61900
    },
    {
      "epoch": 8.063256540413901,
      "grad_norm": 0.10387953370809555,
      "learning_rate": 4.596837172979305e-05,
      "loss": 0.1088,
      "step": 61950
    },
    {
      "epoch": 8.06976441494208,
      "grad_norm": 13.158124923706055,
      "learning_rate": 4.5965117792528964e-05,
      "loss": 0.1306,
      "step": 62000
    },
    {
      "epoch": 8.076272289470259,
      "grad_norm": 12.09029769897461,
      "learning_rate": 4.596186385526488e-05,
      "loss": 0.0782,
      "step": 62050
    },
    {
      "epoch": 8.082780163998438,
      "grad_norm": 0.019028445705771446,
      "learning_rate": 4.5958609918000785e-05,
      "loss": 0.0693,
      "step": 62100
    },
    {
      "epoch": 8.089288038526616,
      "grad_norm": 0.024460647255182266,
      "learning_rate": 4.595535598073669e-05,
      "loss": 0.0821,
      "step": 62150
    },
    {
      "epoch": 8.095795913054797,
      "grad_norm": 7.360158920288086,
      "learning_rate": 4.5952102043472606e-05,
      "loss": 0.0907,
      "step": 62200
    },
    {
      "epoch": 8.102303787582976,
      "grad_norm": 0.030266985297203064,
      "learning_rate": 4.5948848106208513e-05,
      "loss": 0.1248,
      "step": 62250
    },
    {
      "epoch": 8.108811662111155,
      "grad_norm": 9.883973121643066,
      "learning_rate": 4.594559416894442e-05,
      "loss": 0.0951,
      "step": 62300
    },
    {
      "epoch": 8.115319536639333,
      "grad_norm": 0.010256554000079632,
      "learning_rate": 4.5942340231680335e-05,
      "loss": 0.0954,
      "step": 62350
    },
    {
      "epoch": 8.121827411167512,
      "grad_norm": 18.210174560546875,
      "learning_rate": 4.593908629441624e-05,
      "loss": 0.1955,
      "step": 62400
    },
    {
      "epoch": 8.128335285695691,
      "grad_norm": 0.9676604270935059,
      "learning_rate": 4.5935832357152156e-05,
      "loss": 0.1317,
      "step": 62450
    },
    {
      "epoch": 8.134843160223872,
      "grad_norm": 8.24020767211914,
      "learning_rate": 4.593257841988807e-05,
      "loss": 0.1313,
      "step": 62500
    },
    {
      "epoch": 8.14135103475205,
      "grad_norm": 0.30796682834625244,
      "learning_rate": 4.592932448262398e-05,
      "loss": 0.0942,
      "step": 62550
    },
    {
      "epoch": 8.14785890928023,
      "grad_norm": 0.027858370915055275,
      "learning_rate": 4.592607054535989e-05,
      "loss": 0.1402,
      "step": 62600
    },
    {
      "epoch": 8.154366783808408,
      "grad_norm": 0.0354849249124527,
      "learning_rate": 4.59228166080958e-05,
      "loss": 0.0914,
      "step": 62650
    },
    {
      "epoch": 8.160874658336587,
      "grad_norm": 0.08975034207105637,
      "learning_rate": 4.5919562670831706e-05,
      "loss": 0.0986,
      "step": 62700
    },
    {
      "epoch": 8.167382532864766,
      "grad_norm": 0.09518449008464813,
      "learning_rate": 4.591630873356762e-05,
      "loss": 0.0714,
      "step": 62750
    },
    {
      "epoch": 8.173890407392946,
      "grad_norm": 0.19066773355007172,
      "learning_rate": 4.591305479630353e-05,
      "loss": 0.0962,
      "step": 62800
    },
    {
      "epoch": 8.180398281921125,
      "grad_norm": 0.11301972717046738,
      "learning_rate": 4.590980085903944e-05,
      "loss": 0.102,
      "step": 62850
    },
    {
      "epoch": 8.186906156449304,
      "grad_norm": 7.248947620391846,
      "learning_rate": 4.590654692177535e-05,
      "loss": 0.1266,
      "step": 62900
    },
    {
      "epoch": 8.193414030977483,
      "grad_norm": 0.028583312407135963,
      "learning_rate": 4.5903292984511256e-05,
      "loss": 0.0953,
      "step": 62950
    },
    {
      "epoch": 8.199921905505661,
      "grad_norm": 0.3504084050655365,
      "learning_rate": 4.590003904724717e-05,
      "loss": 0.1385,
      "step": 63000
    },
    {
      "epoch": 8.20642978003384,
      "grad_norm": 0.7076664566993713,
      "learning_rate": 4.5896785109983084e-05,
      "loss": 0.0682,
      "step": 63050
    },
    {
      "epoch": 8.21293765456202,
      "grad_norm": 9.585009574890137,
      "learning_rate": 4.589353117271899e-05,
      "loss": 0.1008,
      "step": 63100
    },
    {
      "epoch": 8.2194455290902,
      "grad_norm": 0.18185147643089294,
      "learning_rate": 4.5890277235454906e-05,
      "loss": 0.0727,
      "step": 63150
    },
    {
      "epoch": 8.225953403618378,
      "grad_norm": 12.999373435974121,
      "learning_rate": 4.588702329819081e-05,
      "loss": 0.1575,
      "step": 63200
    },
    {
      "epoch": 8.232461278146557,
      "grad_norm": 6.607362747192383,
      "learning_rate": 4.588376936092673e-05,
      "loss": 0.1127,
      "step": 63250
    },
    {
      "epoch": 8.238969152674736,
      "grad_norm": 0.6652407646179199,
      "learning_rate": 4.5880515423662634e-05,
      "loss": 0.065,
      "step": 63300
    },
    {
      "epoch": 8.245477027202915,
      "grad_norm": 0.5690920352935791,
      "learning_rate": 4.587726148639854e-05,
      "loss": 0.0912,
      "step": 63350
    },
    {
      "epoch": 8.251984901731095,
      "grad_norm": 0.7063316106796265,
      "learning_rate": 4.5874007549134456e-05,
      "loss": 0.0915,
      "step": 63400
    },
    {
      "epoch": 8.258492776259274,
      "grad_norm": 12.689108848571777,
      "learning_rate": 4.587075361187036e-05,
      "loss": 0.1142,
      "step": 63450
    },
    {
      "epoch": 8.265000650787453,
      "grad_norm": 0.23845022916793823,
      "learning_rate": 4.586749967460628e-05,
      "loss": 0.0208,
      "step": 63500
    },
    {
      "epoch": 8.271508525315632,
      "grad_norm": 0.02035244181752205,
      "learning_rate": 4.5864245737342184e-05,
      "loss": 0.0985,
      "step": 63550
    },
    {
      "epoch": 8.27801639984381,
      "grad_norm": 0.16609546542167664,
      "learning_rate": 4.58609918000781e-05,
      "loss": 0.1528,
      "step": 63600
    },
    {
      "epoch": 8.28452427437199,
      "grad_norm": 0.008250705897808075,
      "learning_rate": 4.585773786281401e-05,
      "loss": 0.0431,
      "step": 63650
    },
    {
      "epoch": 8.29103214890017,
      "grad_norm": 0.5148966908454895,
      "learning_rate": 4.585448392554992e-05,
      "loss": 0.0924,
      "step": 63700
    },
    {
      "epoch": 8.297540023428349,
      "grad_norm": 0.19416162371635437,
      "learning_rate": 4.585122998828583e-05,
      "loss": 0.0818,
      "step": 63750
    },
    {
      "epoch": 8.304047897956528,
      "grad_norm": 0.027880962938070297,
      "learning_rate": 4.584797605102174e-05,
      "loss": 0.0631,
      "step": 63800
    },
    {
      "epoch": 8.310555772484706,
      "grad_norm": 0.019899077713489532,
      "learning_rate": 4.584472211375765e-05,
      "loss": 0.0755,
      "step": 63850
    },
    {
      "epoch": 8.317063647012885,
      "grad_norm": 0.010317116044461727,
      "learning_rate": 4.5841468176493555e-05,
      "loss": 0.0529,
      "step": 63900
    },
    {
      "epoch": 8.323571521541064,
      "grad_norm": 16.935937881469727,
      "learning_rate": 4.583821423922947e-05,
      "loss": 0.1328,
      "step": 63950
    },
    {
      "epoch": 8.330079396069245,
      "grad_norm": 0.04482509568333626,
      "learning_rate": 4.583496030196538e-05,
      "loss": 0.1175,
      "step": 64000
    },
    {
      "epoch": 8.336587270597423,
      "grad_norm": 10.061062812805176,
      "learning_rate": 4.583170636470129e-05,
      "loss": 0.0929,
      "step": 64050
    },
    {
      "epoch": 8.343095145125602,
      "grad_norm": 0.030927760526537895,
      "learning_rate": 4.5828452427437205e-05,
      "loss": 0.0762,
      "step": 64100
    },
    {
      "epoch": 8.349603019653781,
      "grad_norm": 9.880209922790527,
      "learning_rate": 4.582519849017311e-05,
      "loss": 0.079,
      "step": 64150
    },
    {
      "epoch": 8.35611089418196,
      "grad_norm": 0.13858433067798615,
      "learning_rate": 4.5821944552909026e-05,
      "loss": 0.0703,
      "step": 64200
    },
    {
      "epoch": 8.362618768710139,
      "grad_norm": 0.04841019958257675,
      "learning_rate": 4.5818690615644934e-05,
      "loss": 0.0877,
      "step": 64250
    },
    {
      "epoch": 8.36912664323832,
      "grad_norm": 0.19858480989933014,
      "learning_rate": 4.581543667838084e-05,
      "loss": 0.0705,
      "step": 64300
    },
    {
      "epoch": 8.375634517766498,
      "grad_norm": 15.086227416992188,
      "learning_rate": 4.5812182741116755e-05,
      "loss": 0.12,
      "step": 64350
    },
    {
      "epoch": 8.382142392294677,
      "grad_norm": 0.0828886479139328,
      "learning_rate": 4.580892880385266e-05,
      "loss": 0.0892,
      "step": 64400
    },
    {
      "epoch": 8.388650266822856,
      "grad_norm": 3.8406453132629395,
      "learning_rate": 4.5805674866588576e-05,
      "loss": 0.1162,
      "step": 64450
    },
    {
      "epoch": 8.395158141351034,
      "grad_norm": 0.022798679769039154,
      "learning_rate": 4.5802420929324484e-05,
      "loss": 0.0713,
      "step": 64500
    },
    {
      "epoch": 8.401666015879213,
      "grad_norm": 18.38629722595215,
      "learning_rate": 4.579916699206039e-05,
      "loss": 0.1653,
      "step": 64550
    },
    {
      "epoch": 8.408173890407394,
      "grad_norm": 0.05286137014627457,
      "learning_rate": 4.5795913054796305e-05,
      "loss": 0.0727,
      "step": 64600
    },
    {
      "epoch": 8.414681764935573,
      "grad_norm": 1.0380258560180664,
      "learning_rate": 4.579265911753222e-05,
      "loss": 0.0625,
      "step": 64650
    },
    {
      "epoch": 8.421189639463751,
      "grad_norm": 0.1629108339548111,
      "learning_rate": 4.5789405180268126e-05,
      "loss": 0.0856,
      "step": 64700
    },
    {
      "epoch": 8.42769751399193,
      "grad_norm": 0.17573267221450806,
      "learning_rate": 4.578615124300404e-05,
      "loss": 0.1547,
      "step": 64750
    },
    {
      "epoch": 8.434205388520109,
      "grad_norm": 18.745073318481445,
      "learning_rate": 4.578289730573995e-05,
      "loss": 0.1387,
      "step": 64800
    },
    {
      "epoch": 8.440713263048288,
      "grad_norm": 9.276288986206055,
      "learning_rate": 4.5779643368475855e-05,
      "loss": 0.1406,
      "step": 64850
    },
    {
      "epoch": 8.447221137576468,
      "grad_norm": 0.49967852234840393,
      "learning_rate": 4.577638943121177e-05,
      "loss": 0.1211,
      "step": 64900
    },
    {
      "epoch": 8.453729012104647,
      "grad_norm": 14.941291809082031,
      "learning_rate": 4.5773135493947676e-05,
      "loss": 0.1074,
      "step": 64950
    },
    {
      "epoch": 8.460236886632826,
      "grad_norm": 0.05281072482466698,
      "learning_rate": 4.576988155668359e-05,
      "loss": 0.1233,
      "step": 65000
    },
    {
      "epoch": 8.466744761161005,
      "grad_norm": 0.03565215691924095,
      "learning_rate": 4.57666276194195e-05,
      "loss": 0.1104,
      "step": 65050
    },
    {
      "epoch": 8.473252635689184,
      "grad_norm": 0.3160656988620758,
      "learning_rate": 4.576337368215541e-05,
      "loss": 0.1177,
      "step": 65100
    },
    {
      "epoch": 8.479760510217362,
      "grad_norm": 0.048721812665462494,
      "learning_rate": 4.576011974489132e-05,
      "loss": 0.1016,
      "step": 65150
    },
    {
      "epoch": 8.486268384745543,
      "grad_norm": 9.241469383239746,
      "learning_rate": 4.575686580762723e-05,
      "loss": 0.1158,
      "step": 65200
    },
    {
      "epoch": 8.492776259273722,
      "grad_norm": 18.649965286254883,
      "learning_rate": 4.575361187036314e-05,
      "loss": 0.0838,
      "step": 65250
    },
    {
      "epoch": 8.4992841338019,
      "grad_norm": 0.11738502979278564,
      "learning_rate": 4.5750357933099054e-05,
      "loss": 0.0975,
      "step": 65300
    },
    {
      "epoch": 8.50579200833008,
      "grad_norm": 3.8045742511749268,
      "learning_rate": 4.574710399583496e-05,
      "loss": 0.0508,
      "step": 65350
    },
    {
      "epoch": 8.512299882858258,
      "grad_norm": 10.029122352600098,
      "learning_rate": 4.5743850058570876e-05,
      "loss": 0.0854,
      "step": 65400
    },
    {
      "epoch": 8.518807757386437,
      "grad_norm": 1.7454981803894043,
      "learning_rate": 4.574059612130678e-05,
      "loss": 0.0986,
      "step": 65450
    },
    {
      "epoch": 8.525315631914617,
      "grad_norm": 0.050983455032110214,
      "learning_rate": 4.573734218404269e-05,
      "loss": 0.1466,
      "step": 65500
    },
    {
      "epoch": 8.531823506442796,
      "grad_norm": 0.03256111219525337,
      "learning_rate": 4.5734088246778604e-05,
      "loss": 0.1182,
      "step": 65550
    },
    {
      "epoch": 8.538331380970975,
      "grad_norm": 0.02058955654501915,
      "learning_rate": 4.573083430951451e-05,
      "loss": 0.0867,
      "step": 65600
    },
    {
      "epoch": 8.544839255499154,
      "grad_norm": 12.65115737915039,
      "learning_rate": 4.5727580372250426e-05,
      "loss": 0.0928,
      "step": 65650
    },
    {
      "epoch": 8.551347130027333,
      "grad_norm": 0.17649327218532562,
      "learning_rate": 4.572432643498634e-05,
      "loss": 0.0914,
      "step": 65700
    },
    {
      "epoch": 8.557855004555512,
      "grad_norm": 0.008829749189317226,
      "learning_rate": 4.572107249772225e-05,
      "loss": 0.076,
      "step": 65750
    },
    {
      "epoch": 8.564362879083692,
      "grad_norm": 3.6824378967285156,
      "learning_rate": 4.571781856045816e-05,
      "loss": 0.088,
      "step": 65800
    },
    {
      "epoch": 8.570870753611871,
      "grad_norm": 0.04830633103847504,
      "learning_rate": 4.571456462319407e-05,
      "loss": 0.0937,
      "step": 65850
    },
    {
      "epoch": 8.57737862814005,
      "grad_norm": 0.15100087225437164,
      "learning_rate": 4.5711310685929976e-05,
      "loss": 0.1319,
      "step": 65900
    },
    {
      "epoch": 8.583886502668229,
      "grad_norm": 0.051024939864873886,
      "learning_rate": 4.570805674866589e-05,
      "loss": 0.0626,
      "step": 65950
    },
    {
      "epoch": 8.590394377196407,
      "grad_norm": 0.014758329838514328,
      "learning_rate": 4.57048028114018e-05,
      "loss": 0.0847,
      "step": 66000
    },
    {
      "epoch": 8.596902251724586,
      "grad_norm": 0.014437825419008732,
      "learning_rate": 4.5701548874137704e-05,
      "loss": 0.0671,
      "step": 66050
    },
    {
      "epoch": 8.603410126252765,
      "grad_norm": 0.9591159224510193,
      "learning_rate": 4.569829493687362e-05,
      "loss": 0.117,
      "step": 66100
    },
    {
      "epoch": 8.609918000780945,
      "grad_norm": 10.954989433288574,
      "learning_rate": 4.5695040999609525e-05,
      "loss": 0.0828,
      "step": 66150
    },
    {
      "epoch": 8.616425875309124,
      "grad_norm": 0.039978861808776855,
      "learning_rate": 4.569178706234544e-05,
      "loss": 0.1664,
      "step": 66200
    },
    {
      "epoch": 8.622933749837303,
      "grad_norm": 0.07845916599035263,
      "learning_rate": 4.5688533125081354e-05,
      "loss": 0.0993,
      "step": 66250
    },
    {
      "epoch": 8.629441624365482,
      "grad_norm": 0.182289257645607,
      "learning_rate": 4.568527918781726e-05,
      "loss": 0.1254,
      "step": 66300
    },
    {
      "epoch": 8.63594949889366,
      "grad_norm": 0.02946692518889904,
      "learning_rate": 4.5682025250553175e-05,
      "loss": 0.1088,
      "step": 66350
    },
    {
      "epoch": 8.642457373421841,
      "grad_norm": 12.017537117004395,
      "learning_rate": 4.567877131328908e-05,
      "loss": 0.0893,
      "step": 66400
    },
    {
      "epoch": 8.64896524795002,
      "grad_norm": 9.723504066467285,
      "learning_rate": 4.567551737602499e-05,
      "loss": 0.1428,
      "step": 66450
    },
    {
      "epoch": 8.655473122478199,
      "grad_norm": 0.03303869813680649,
      "learning_rate": 4.5672263438760904e-05,
      "loss": 0.0445,
      "step": 66500
    },
    {
      "epoch": 8.661980997006378,
      "grad_norm": 0.6115871071815491,
      "learning_rate": 4.566900950149681e-05,
      "loss": 0.0921,
      "step": 66550
    },
    {
      "epoch": 8.668488871534556,
      "grad_norm": 0.12165257334709167,
      "learning_rate": 4.5665755564232725e-05,
      "loss": 0.0726,
      "step": 66600
    },
    {
      "epoch": 8.674996746062735,
      "grad_norm": 0.8846213221549988,
      "learning_rate": 4.566250162696863e-05,
      "loss": 0.1029,
      "step": 66650
    },
    {
      "epoch": 8.681504620590914,
      "grad_norm": 0.07810361683368683,
      "learning_rate": 4.5659247689704546e-05,
      "loss": 0.075,
      "step": 66700
    },
    {
      "epoch": 8.688012495119095,
      "grad_norm": 29.591936111450195,
      "learning_rate": 4.5655993752440454e-05,
      "loss": 0.0911,
      "step": 66750
    },
    {
      "epoch": 8.694520369647273,
      "grad_norm": 0.007661164738237858,
      "learning_rate": 4.565273981517637e-05,
      "loss": 0.116,
      "step": 66800
    },
    {
      "epoch": 8.701028244175452,
      "grad_norm": 15.863471031188965,
      "learning_rate": 4.5649485877912275e-05,
      "loss": 0.1308,
      "step": 66850
    },
    {
      "epoch": 8.707536118703631,
      "grad_norm": 0.013580933213233948,
      "learning_rate": 4.564623194064819e-05,
      "loss": 0.0789,
      "step": 66900
    },
    {
      "epoch": 8.71404399323181,
      "grad_norm": 0.16131317615509033,
      "learning_rate": 4.5642978003384096e-05,
      "loss": 0.1121,
      "step": 66950
    },
    {
      "epoch": 8.72055186775999,
      "grad_norm": 0.6451982855796814,
      "learning_rate": 4.563972406612001e-05,
      "loss": 0.1105,
      "step": 67000
    },
    {
      "epoch": 8.72705974228817,
      "grad_norm": 0.11766866594552994,
      "learning_rate": 4.563647012885592e-05,
      "loss": 0.1173,
      "step": 67050
    },
    {
      "epoch": 8.733567616816348,
      "grad_norm": 1.4328314065933228,
      "learning_rate": 4.5633216191591825e-05,
      "loss": 0.1013,
      "step": 67100
    },
    {
      "epoch": 8.740075491344527,
      "grad_norm": 12.493461608886719,
      "learning_rate": 4.562996225432774e-05,
      "loss": 0.0816,
      "step": 67150
    },
    {
      "epoch": 8.746583365872706,
      "grad_norm": 13.7855863571167,
      "learning_rate": 4.5626708317063646e-05,
      "loss": 0.104,
      "step": 67200
    },
    {
      "epoch": 8.753091240400884,
      "grad_norm": 0.12796781957149506,
      "learning_rate": 4.562345437979956e-05,
      "loss": 0.0748,
      "step": 67250
    },
    {
      "epoch": 8.759599114929063,
      "grad_norm": 28.24512481689453,
      "learning_rate": 4.5620200442535474e-05,
      "loss": 0.0763,
      "step": 67300
    },
    {
      "epoch": 8.766106989457244,
      "grad_norm": 10.47807788848877,
      "learning_rate": 4.561694650527138e-05,
      "loss": 0.1555,
      "step": 67350
    },
    {
      "epoch": 8.772614863985423,
      "grad_norm": 27.135868072509766,
      "learning_rate": 4.5613692568007296e-05,
      "loss": 0.0763,
      "step": 67400
    },
    {
      "epoch": 8.779122738513601,
      "grad_norm": 2.410619020462036,
      "learning_rate": 4.56104386307432e-05,
      "loss": 0.0949,
      "step": 67450
    },
    {
      "epoch": 8.78563061304178,
      "grad_norm": 0.277682900428772,
      "learning_rate": 4.560718469347911e-05,
      "loss": 0.14,
      "step": 67500
    },
    {
      "epoch": 8.792138487569959,
      "grad_norm": 0.011783430352807045,
      "learning_rate": 4.5603930756215024e-05,
      "loss": 0.1124,
      "step": 67550
    },
    {
      "epoch": 8.79864636209814,
      "grad_norm": 0.158872589468956,
      "learning_rate": 4.560067681895093e-05,
      "loss": 0.0902,
      "step": 67600
    },
    {
      "epoch": 8.805154236626318,
      "grad_norm": 19.487468719482422,
      "learning_rate": 4.559742288168684e-05,
      "loss": 0.1734,
      "step": 67650
    },
    {
      "epoch": 8.811662111154497,
      "grad_norm": 0.4923519194126129,
      "learning_rate": 4.559416894442275e-05,
      "loss": 0.1124,
      "step": 67700
    },
    {
      "epoch": 8.818169985682676,
      "grad_norm": 7.3589630126953125,
      "learning_rate": 4.559091500715866e-05,
      "loss": 0.1038,
      "step": 67750
    },
    {
      "epoch": 8.824677860210855,
      "grad_norm": 0.4586612582206726,
      "learning_rate": 4.5587661069894574e-05,
      "loss": 0.1402,
      "step": 67800
    },
    {
      "epoch": 8.831185734739034,
      "grad_norm": 0.20941096544265747,
      "learning_rate": 4.558440713263049e-05,
      "loss": 0.1482,
      "step": 67850
    },
    {
      "epoch": 8.837693609267212,
      "grad_norm": 0.3509953022003174,
      "learning_rate": 4.5581153195366396e-05,
      "loss": 0.1156,
      "step": 67900
    },
    {
      "epoch": 8.844201483795393,
      "grad_norm": 0.36348819732666016,
      "learning_rate": 4.557789925810231e-05,
      "loss": 0.1154,
      "step": 67950
    },
    {
      "epoch": 8.850709358323572,
      "grad_norm": 0.08073640614748001,
      "learning_rate": 4.557464532083822e-05,
      "loss": 0.1067,
      "step": 68000
    },
    {
      "epoch": 8.85721723285175,
      "grad_norm": 0.2505750060081482,
      "learning_rate": 4.5571391383574124e-05,
      "loss": 0.1059,
      "step": 68050
    },
    {
      "epoch": 8.86372510737993,
      "grad_norm": 5.581012725830078,
      "learning_rate": 4.556813744631004e-05,
      "loss": 0.0663,
      "step": 68100
    },
    {
      "epoch": 8.870232981908108,
      "grad_norm": 0.28265291452407837,
      "learning_rate": 4.5564883509045946e-05,
      "loss": 0.1265,
      "step": 68150
    },
    {
      "epoch": 8.876740856436289,
      "grad_norm": 0.5560598969459534,
      "learning_rate": 4.556162957178186e-05,
      "loss": 0.0898,
      "step": 68200
    },
    {
      "epoch": 8.883248730964468,
      "grad_norm": 7.214788913726807,
      "learning_rate": 4.555837563451777e-05,
      "loss": 0.1099,
      "step": 68250
    },
    {
      "epoch": 8.889756605492646,
      "grad_norm": 20.02078628540039,
      "learning_rate": 4.555512169725368e-05,
      "loss": 0.1101,
      "step": 68300
    },
    {
      "epoch": 8.896264480020825,
      "grad_norm": 0.0692673772573471,
      "learning_rate": 4.555186775998959e-05,
      "loss": 0.1269,
      "step": 68350
    },
    {
      "epoch": 8.902772354549004,
      "grad_norm": 0.06074311211705208,
      "learning_rate": 4.55486138227255e-05,
      "loss": 0.0891,
      "step": 68400
    },
    {
      "epoch": 8.909280229077183,
      "grad_norm": 7.242265224456787,
      "learning_rate": 4.554535988546141e-05,
      "loss": 0.1163,
      "step": 68450
    },
    {
      "epoch": 8.915788103605362,
      "grad_norm": 3.3626835346221924,
      "learning_rate": 4.5542105948197324e-05,
      "loss": 0.1488,
      "step": 68500
    },
    {
      "epoch": 8.922295978133542,
      "grad_norm": 0.17975111305713654,
      "learning_rate": 4.553885201093323e-05,
      "loss": 0.0958,
      "step": 68550
    },
    {
      "epoch": 8.928803852661721,
      "grad_norm": 1.112724781036377,
      "learning_rate": 4.5535598073669145e-05,
      "loss": 0.1259,
      "step": 68600
    },
    {
      "epoch": 8.9353117271899,
      "grad_norm": 0.06933901458978653,
      "learning_rate": 4.553234413640505e-05,
      "loss": 0.1015,
      "step": 68650
    },
    {
      "epoch": 8.941819601718079,
      "grad_norm": 28.943782806396484,
      "learning_rate": 4.552909019914096e-05,
      "loss": 0.1376,
      "step": 68700
    },
    {
      "epoch": 8.948327476246257,
      "grad_norm": 0.029728759080171585,
      "learning_rate": 4.5525836261876874e-05,
      "loss": 0.0718,
      "step": 68750
    },
    {
      "epoch": 8.954835350774436,
      "grad_norm": 1.579422116279602,
      "learning_rate": 4.552258232461278e-05,
      "loss": 0.094,
      "step": 68800
    },
    {
      "epoch": 8.961343225302617,
      "grad_norm": 0.1517307609319687,
      "learning_rate": 4.5519328387348695e-05,
      "loss": 0.0978,
      "step": 68850
    },
    {
      "epoch": 8.967851099830796,
      "grad_norm": 0.3561038672924042,
      "learning_rate": 4.551607445008461e-05,
      "loss": 0.0841,
      "step": 68900
    },
    {
      "epoch": 8.974358974358974,
      "grad_norm": 18.968685150146484,
      "learning_rate": 4.5512820512820516e-05,
      "loss": 0.1338,
      "step": 68950
    },
    {
      "epoch": 8.980866848887153,
      "grad_norm": 0.12366276234388351,
      "learning_rate": 4.550956657555643e-05,
      "loss": 0.0823,
      "step": 69000
    },
    {
      "epoch": 8.987374723415332,
      "grad_norm": 0.25688645243644714,
      "learning_rate": 4.550631263829234e-05,
      "loss": 0.113,
      "step": 69050
    },
    {
      "epoch": 8.99388259794351,
      "grad_norm": 0.14396575093269348,
      "learning_rate": 4.5503058701028245e-05,
      "loss": 0.099,
      "step": 69100
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9662870159453303,
      "eval_f1": 0.9660149586668416,
      "eval_loss": 0.13454413414001465,
      "eval_precision": 0.9734232447441491,
      "eval_recall": 0.9587185831488475,
      "eval_runtime": 23.5478,
      "eval_samples_per_second": 652.502,
      "eval_steps_per_second": 81.579,
      "step": 69147
    }
  ],
  "logging_steps": 50,
  "max_steps": 768300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.67626076498391e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
