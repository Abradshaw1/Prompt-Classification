{
  "best_metric": 0.19822363555431366,
  "best_model_checkpoint": "./results/checkpoint-7683",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7683,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006507874528179097,
      "grad_norm": 1.2684589624404907,
      "learning_rate": 4.967460627359104e-05,
      "loss": 0.6916,
      "step": 50
    },
    {
      "epoch": 0.013015749056358194,
      "grad_norm": 1.1612277030944824,
      "learning_rate": 4.9349212547182096e-05,
      "loss": 0.702,
      "step": 100
    },
    {
      "epoch": 0.01952362358453729,
      "grad_norm": 2.376819372177124,
      "learning_rate": 4.9023818820773136e-05,
      "loss": 0.698,
      "step": 150
    },
    {
      "epoch": 0.02603149811271639,
      "grad_norm": 2.075603723526001,
      "learning_rate": 4.869842509436418e-05,
      "loss": 0.6916,
      "step": 200
    },
    {
      "epoch": 0.032539372640895486,
      "grad_norm": 1.3460583686828613,
      "learning_rate": 4.837303136795523e-05,
      "loss": 0.6877,
      "step": 250
    },
    {
      "epoch": 0.03904724716907458,
      "grad_norm": 0.9814984798431396,
      "learning_rate": 4.804763764154627e-05,
      "loss": 0.6793,
      "step": 300
    },
    {
      "epoch": 0.045555121697253675,
      "grad_norm": 1.4165775775909424,
      "learning_rate": 4.7722243915137316e-05,
      "loss": 0.6482,
      "step": 350
    },
    {
      "epoch": 0.05206299622543278,
      "grad_norm": 2.540619373321533,
      "learning_rate": 4.739685018872836e-05,
      "loss": 0.5414,
      "step": 400
    },
    {
      "epoch": 0.05857087075361187,
      "grad_norm": 2.839792251586914,
      "learning_rate": 4.707145646231941e-05,
      "loss": 0.3836,
      "step": 450
    },
    {
      "epoch": 0.06507874528179097,
      "grad_norm": 7.135203838348389,
      "learning_rate": 4.674606273591046e-05,
      "loss": 0.3835,
      "step": 500
    },
    {
      "epoch": 0.07158661980997007,
      "grad_norm": 5.219701766967773,
      "learning_rate": 4.64206690095015e-05,
      "loss": 0.3234,
      "step": 550
    },
    {
      "epoch": 0.07809449433814916,
      "grad_norm": 3.8894548416137695,
      "learning_rate": 4.6095275283092543e-05,
      "loss": 0.2812,
      "step": 600
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 4.271664619445801,
      "learning_rate": 4.576988155668359e-05,
      "loss": 0.2952,
      "step": 650
    },
    {
      "epoch": 0.09111024339450735,
      "grad_norm": 6.491387367248535,
      "learning_rate": 4.544448783027464e-05,
      "loss": 0.3088,
      "step": 700
    },
    {
      "epoch": 0.09761811792268645,
      "grad_norm": 0.8196221590042114,
      "learning_rate": 4.511909410386568e-05,
      "loss": 0.3314,
      "step": 750
    },
    {
      "epoch": 0.10412599245086555,
      "grad_norm": 1.9954445362091064,
      "learning_rate": 4.4793700377456724e-05,
      "loss": 0.2472,
      "step": 800
    },
    {
      "epoch": 0.11063386697904465,
      "grad_norm": 1.0224580764770508,
      "learning_rate": 4.446830665104777e-05,
      "loss": 0.2816,
      "step": 850
    },
    {
      "epoch": 0.11714174150722374,
      "grad_norm": 7.092493534088135,
      "learning_rate": 4.414291292463881e-05,
      "loss": 0.305,
      "step": 900
    },
    {
      "epoch": 0.12364961603540284,
      "grad_norm": 7.175285816192627,
      "learning_rate": 4.3817519198229864e-05,
      "loss": 0.2641,
      "step": 950
    },
    {
      "epoch": 0.13015749056358195,
      "grad_norm": 0.3958054482936859,
      "learning_rate": 4.3492125471820904e-05,
      "loss": 0.2347,
      "step": 1000
    },
    {
      "epoch": 0.13666536509176103,
      "grad_norm": 3.3034884929656982,
      "learning_rate": 4.316673174541195e-05,
      "loss": 0.3138,
      "step": 1050
    },
    {
      "epoch": 0.14317323961994013,
      "grad_norm": 0.7401832938194275,
      "learning_rate": 4.2841338019003e-05,
      "loss": 0.3183,
      "step": 1100
    },
    {
      "epoch": 0.14968111414811922,
      "grad_norm": 7.6586174964904785,
      "learning_rate": 4.251594429259404e-05,
      "loss": 0.2662,
      "step": 1150
    },
    {
      "epoch": 0.15618898867629832,
      "grad_norm": 5.216855525970459,
      "learning_rate": 4.219055056618509e-05,
      "loss": 0.1919,
      "step": 1200
    },
    {
      "epoch": 0.1626968632044774,
      "grad_norm": 1.3744266033172607,
      "learning_rate": 4.186515683977613e-05,
      "loss": 0.2386,
      "step": 1250
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 7.306083679199219,
      "learning_rate": 4.153976311336718e-05,
      "loss": 0.2345,
      "step": 1300
    },
    {
      "epoch": 0.17571261226083562,
      "grad_norm": 2.8114919662475586,
      "learning_rate": 4.1214369386958225e-05,
      "loss": 0.223,
      "step": 1350
    },
    {
      "epoch": 0.1822204867890147,
      "grad_norm": 0.1668170690536499,
      "learning_rate": 4.0888975660549265e-05,
      "loss": 0.2208,
      "step": 1400
    },
    {
      "epoch": 0.1887283613171938,
      "grad_norm": 8.532694816589355,
      "learning_rate": 4.056358193414031e-05,
      "loss": 0.242,
      "step": 1450
    },
    {
      "epoch": 0.1952362358453729,
      "grad_norm": 0.2279667854309082,
      "learning_rate": 4.023818820773136e-05,
      "loss": 0.2133,
      "step": 1500
    },
    {
      "epoch": 0.201744110373552,
      "grad_norm": 6.291457653045654,
      "learning_rate": 3.9912794481322405e-05,
      "loss": 0.2292,
      "step": 1550
    },
    {
      "epoch": 0.2082519849017311,
      "grad_norm": 0.9668239951133728,
      "learning_rate": 3.9587400754913445e-05,
      "loss": 0.2106,
      "step": 1600
    },
    {
      "epoch": 0.2147598594299102,
      "grad_norm": 15.25806713104248,
      "learning_rate": 3.926200702850449e-05,
      "loss": 0.3179,
      "step": 1650
    },
    {
      "epoch": 0.2212677339580893,
      "grad_norm": 11.599584579467773,
      "learning_rate": 3.893661330209554e-05,
      "loss": 0.2317,
      "step": 1700
    },
    {
      "epoch": 0.22777560848626838,
      "grad_norm": 6.760477066040039,
      "learning_rate": 3.861121957568658e-05,
      "loss": 0.243,
      "step": 1750
    },
    {
      "epoch": 0.23428348301444749,
      "grad_norm": 2.8660264015197754,
      "learning_rate": 3.828582584927763e-05,
      "loss": 0.2011,
      "step": 1800
    },
    {
      "epoch": 0.24079135754262657,
      "grad_norm": 5.631855487823486,
      "learning_rate": 3.796043212286867e-05,
      "loss": 0.2252,
      "step": 1850
    },
    {
      "epoch": 0.24729923207080567,
      "grad_norm": 2.299304723739624,
      "learning_rate": 3.763503839645971e-05,
      "loss": 0.2056,
      "step": 1900
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 4.861282825469971,
      "learning_rate": 3.7309644670050766e-05,
      "loss": 0.2415,
      "step": 1950
    },
    {
      "epoch": 0.2603149811271639,
      "grad_norm": 1.7582038640975952,
      "learning_rate": 3.6984250943641806e-05,
      "loss": 0.2657,
      "step": 2000
    },
    {
      "epoch": 0.26682285565534297,
      "grad_norm": 2.815084457397461,
      "learning_rate": 3.665885721723285e-05,
      "loss": 0.2244,
      "step": 2050
    },
    {
      "epoch": 0.27333073018352205,
      "grad_norm": 21.244171142578125,
      "learning_rate": 3.63334634908239e-05,
      "loss": 0.2523,
      "step": 2100
    },
    {
      "epoch": 0.27983860471170113,
      "grad_norm": 8.76937484741211,
      "learning_rate": 3.600806976441494e-05,
      "loss": 0.2013,
      "step": 2150
    },
    {
      "epoch": 0.28634647923988027,
      "grad_norm": 8.137629508972168,
      "learning_rate": 3.568267603800599e-05,
      "loss": 0.2241,
      "step": 2200
    },
    {
      "epoch": 0.29285435376805935,
      "grad_norm": 0.1181236058473587,
      "learning_rate": 3.535728231159703e-05,
      "loss": 0.1426,
      "step": 2250
    },
    {
      "epoch": 0.29936222829623843,
      "grad_norm": 0.841587245464325,
      "learning_rate": 3.503188858518808e-05,
      "loss": 0.1977,
      "step": 2300
    },
    {
      "epoch": 0.30587010282441757,
      "grad_norm": 13.27499771118164,
      "learning_rate": 3.4706494858779127e-05,
      "loss": 0.2237,
      "step": 2350
    },
    {
      "epoch": 0.31237797735259665,
      "grad_norm": 8.672415733337402,
      "learning_rate": 3.4381101132370167e-05,
      "loss": 0.2366,
      "step": 2400
    },
    {
      "epoch": 0.31888585188077573,
      "grad_norm": 1.3171216249465942,
      "learning_rate": 3.405570740596121e-05,
      "loss": 0.1903,
      "step": 2450
    },
    {
      "epoch": 0.3253937264089548,
      "grad_norm": 5.226428985595703,
      "learning_rate": 3.373031367955226e-05,
      "loss": 0.193,
      "step": 2500
    },
    {
      "epoch": 0.33190160093713394,
      "grad_norm": 13.160584449768066,
      "learning_rate": 3.340491995314331e-05,
      "loss": 0.2069,
      "step": 2550
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 9.798527717590332,
      "learning_rate": 3.307952622673435e-05,
      "loss": 0.2005,
      "step": 2600
    },
    {
      "epoch": 0.3449173499934921,
      "grad_norm": 6.036993026733398,
      "learning_rate": 3.2754132500325394e-05,
      "loss": 0.2011,
      "step": 2650
    },
    {
      "epoch": 0.35142522452167124,
      "grad_norm": 8.165510177612305,
      "learning_rate": 3.242873877391644e-05,
      "loss": 0.2123,
      "step": 2700
    },
    {
      "epoch": 0.3579330990498503,
      "grad_norm": 9.747062683105469,
      "learning_rate": 3.210334504750749e-05,
      "loss": 0.3186,
      "step": 2750
    },
    {
      "epoch": 0.3644409735780294,
      "grad_norm": 5.805779457092285,
      "learning_rate": 3.1777951321098534e-05,
      "loss": 0.2176,
      "step": 2800
    },
    {
      "epoch": 0.37094884810620854,
      "grad_norm": 0.8634887933731079,
      "learning_rate": 3.1452557594689574e-05,
      "loss": 0.2122,
      "step": 2850
    },
    {
      "epoch": 0.3774567226343876,
      "grad_norm": 9.641561508178711,
      "learning_rate": 3.112716386828062e-05,
      "loss": 0.1941,
      "step": 2900
    },
    {
      "epoch": 0.3839645971625667,
      "grad_norm": 3.9663782119750977,
      "learning_rate": 3.080177014187167e-05,
      "loss": 0.2405,
      "step": 2950
    },
    {
      "epoch": 0.3904724716907458,
      "grad_norm": 3.8272523880004883,
      "learning_rate": 3.047637641546271e-05,
      "loss": 0.2391,
      "step": 3000
    },
    {
      "epoch": 0.3969803462189249,
      "grad_norm": 0.16381047666072845,
      "learning_rate": 3.0150982689053758e-05,
      "loss": 0.2085,
      "step": 3050
    },
    {
      "epoch": 0.403488220747104,
      "grad_norm": 3.7008659839630127,
      "learning_rate": 2.98255889626448e-05,
      "loss": 0.2575,
      "step": 3100
    },
    {
      "epoch": 0.4099960952752831,
      "grad_norm": 2.28151273727417,
      "learning_rate": 2.9500195236235845e-05,
      "loss": 0.1945,
      "step": 3150
    },
    {
      "epoch": 0.4165039698034622,
      "grad_norm": 9.806269645690918,
      "learning_rate": 2.9174801509826895e-05,
      "loss": 0.1622,
      "step": 3200
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 1.7682013511657715,
      "learning_rate": 2.8849407783417938e-05,
      "loss": 0.1767,
      "step": 3250
    },
    {
      "epoch": 0.4295197188598204,
      "grad_norm": 1.4582798480987549,
      "learning_rate": 2.8524014057008978e-05,
      "loss": 0.209,
      "step": 3300
    },
    {
      "epoch": 0.43602759338799946,
      "grad_norm": 11.138895988464355,
      "learning_rate": 2.819862033060003e-05,
      "loss": 0.2448,
      "step": 3350
    },
    {
      "epoch": 0.4425354679161786,
      "grad_norm": 13.566849708557129,
      "learning_rate": 2.7873226604191072e-05,
      "loss": 0.167,
      "step": 3400
    },
    {
      "epoch": 0.4490433424443577,
      "grad_norm": 12.229472160339355,
      "learning_rate": 2.7547832877782122e-05,
      "loss": 0.1746,
      "step": 3450
    },
    {
      "epoch": 0.45555121697253675,
      "grad_norm": 0.42682787775993347,
      "learning_rate": 2.7222439151373162e-05,
      "loss": 0.2336,
      "step": 3500
    },
    {
      "epoch": 0.4620590915007159,
      "grad_norm": 24.975730895996094,
      "learning_rate": 2.6897045424964205e-05,
      "loss": 0.1811,
      "step": 3550
    },
    {
      "epoch": 0.46856696602889497,
      "grad_norm": 11.140725135803223,
      "learning_rate": 2.6571651698555255e-05,
      "loss": 0.2051,
      "step": 3600
    },
    {
      "epoch": 0.47507484055707405,
      "grad_norm": 11.561005592346191,
      "learning_rate": 2.62462579721463e-05,
      "loss": 0.1825,
      "step": 3650
    },
    {
      "epoch": 0.48158271508525313,
      "grad_norm": 18.703628540039062,
      "learning_rate": 2.5920864245737342e-05,
      "loss": 0.1822,
      "step": 3700
    },
    {
      "epoch": 0.48809058961343227,
      "grad_norm": 6.874792575836182,
      "learning_rate": 2.559547051932839e-05,
      "loss": 0.1565,
      "step": 3750
    },
    {
      "epoch": 0.49459846414161135,
      "grad_norm": 0.10271501541137695,
      "learning_rate": 2.5270076792919432e-05,
      "loss": 0.1804,
      "step": 3800
    },
    {
      "epoch": 0.5011063386697905,
      "grad_norm": 2.289295196533203,
      "learning_rate": 2.494468306651048e-05,
      "loss": 0.1953,
      "step": 3850
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 46.582027435302734,
      "learning_rate": 2.4619289340101523e-05,
      "loss": 0.1485,
      "step": 3900
    },
    {
      "epoch": 0.5141220877261486,
      "grad_norm": 9.74600887298584,
      "learning_rate": 2.429389561369257e-05,
      "loss": 0.2232,
      "step": 3950
    },
    {
      "epoch": 0.5206299622543278,
      "grad_norm": 5.460799217224121,
      "learning_rate": 2.3968501887283616e-05,
      "loss": 0.3239,
      "step": 4000
    },
    {
      "epoch": 0.5271378367825068,
      "grad_norm": 0.16177645325660706,
      "learning_rate": 2.364310816087466e-05,
      "loss": 0.1718,
      "step": 4050
    },
    {
      "epoch": 0.5336457113106859,
      "grad_norm": 1.6035107374191284,
      "learning_rate": 2.3317714434465703e-05,
      "loss": 0.2318,
      "step": 4100
    },
    {
      "epoch": 0.5401535858388651,
      "grad_norm": 0.1390526294708252,
      "learning_rate": 2.299232070805675e-05,
      "loss": 0.1541,
      "step": 4150
    },
    {
      "epoch": 0.5466614603670441,
      "grad_norm": 0.10035098344087601,
      "learning_rate": 2.2666926981647797e-05,
      "loss": 0.1943,
      "step": 4200
    },
    {
      "epoch": 0.5531693348952232,
      "grad_norm": 5.124448299407959,
      "learning_rate": 2.234153325523884e-05,
      "loss": 0.1669,
      "step": 4250
    },
    {
      "epoch": 0.5596772094234023,
      "grad_norm": 0.8499168753623962,
      "learning_rate": 2.2016139528829883e-05,
      "loss": 0.1955,
      "step": 4300
    },
    {
      "epoch": 0.5661850839515814,
      "grad_norm": 0.808977484703064,
      "learning_rate": 2.169074580242093e-05,
      "loss": 0.1813,
      "step": 4350
    },
    {
      "epoch": 0.5726929584797605,
      "grad_norm": 2.002851963043213,
      "learning_rate": 2.1365352076011977e-05,
      "loss": 0.1516,
      "step": 4400
    },
    {
      "epoch": 0.5792008330079396,
      "grad_norm": 11.570463180541992,
      "learning_rate": 2.103995834960302e-05,
      "loss": 0.1461,
      "step": 4450
    },
    {
      "epoch": 0.5857087075361187,
      "grad_norm": 6.0466814041137695,
      "learning_rate": 2.0714564623194067e-05,
      "loss": 0.2312,
      "step": 4500
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 0.6588004231452942,
      "learning_rate": 2.038917089678511e-05,
      "loss": 0.2385,
      "step": 4550
    },
    {
      "epoch": 0.5987244565924769,
      "grad_norm": 0.1444033533334732,
      "learning_rate": 2.0063777170376154e-05,
      "loss": 0.1807,
      "step": 4600
    },
    {
      "epoch": 0.605232331120656,
      "grad_norm": 8.668052673339844,
      "learning_rate": 1.97383834439672e-05,
      "loss": 0.2081,
      "step": 4650
    },
    {
      "epoch": 0.6117402056488351,
      "grad_norm": 2.61330509185791,
      "learning_rate": 1.9412989717558247e-05,
      "loss": 0.138,
      "step": 4700
    },
    {
      "epoch": 0.6182480801770142,
      "grad_norm": 3.3223886489868164,
      "learning_rate": 1.908759599114929e-05,
      "loss": 0.1624,
      "step": 4750
    },
    {
      "epoch": 0.6247559547051933,
      "grad_norm": 2.870144844055176,
      "learning_rate": 1.8762202264740338e-05,
      "loss": 0.2439,
      "step": 4800
    },
    {
      "epoch": 0.6312638292333724,
      "grad_norm": 0.37544506788253784,
      "learning_rate": 1.843680853833138e-05,
      "loss": 0.1575,
      "step": 4850
    },
    {
      "epoch": 0.6377717037615515,
      "grad_norm": 8.745977401733398,
      "learning_rate": 1.8111414811922428e-05,
      "loss": 0.2453,
      "step": 4900
    },
    {
      "epoch": 0.6442795782897306,
      "grad_norm": 0.28699901700019836,
      "learning_rate": 1.778602108551347e-05,
      "loss": 0.2481,
      "step": 4950
    },
    {
      "epoch": 0.6507874528179096,
      "grad_norm": 1.4311108589172363,
      "learning_rate": 1.7460627359104518e-05,
      "loss": 0.2054,
      "step": 5000
    },
    {
      "epoch": 0.6572953273460888,
      "grad_norm": 0.16909795999526978,
      "learning_rate": 1.7135233632695565e-05,
      "loss": 0.2031,
      "step": 5050
    },
    {
      "epoch": 0.6638032018742679,
      "grad_norm": 16.831226348876953,
      "learning_rate": 1.6809839906286605e-05,
      "loss": 0.1604,
      "step": 5100
    },
    {
      "epoch": 0.6703110764024469,
      "grad_norm": 0.24388010799884796,
      "learning_rate": 1.648444617987765e-05,
      "loss": 0.1247,
      "step": 5150
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.16304700076580048,
      "learning_rate": 1.6159052453468698e-05,
      "loss": 0.202,
      "step": 5200
    },
    {
      "epoch": 0.6833268254588052,
      "grad_norm": 13.163601875305176,
      "learning_rate": 1.5833658727059745e-05,
      "loss": 0.2715,
      "step": 5250
    },
    {
      "epoch": 0.6898346999869842,
      "grad_norm": 14.063652992248535,
      "learning_rate": 1.550826500065079e-05,
      "loss": 0.1537,
      "step": 5300
    },
    {
      "epoch": 0.6963425745151633,
      "grad_norm": 2.4564976692199707,
      "learning_rate": 1.5182871274241834e-05,
      "loss": 0.1606,
      "step": 5350
    },
    {
      "epoch": 0.7028504490433425,
      "grad_norm": 0.04924251511693001,
      "learning_rate": 1.4857477547832879e-05,
      "loss": 0.1993,
      "step": 5400
    },
    {
      "epoch": 0.7093583235715215,
      "grad_norm": 7.312571048736572,
      "learning_rate": 1.4532083821423922e-05,
      "loss": 0.1281,
      "step": 5450
    },
    {
      "epoch": 0.7158661980997006,
      "grad_norm": 0.07101664692163467,
      "learning_rate": 1.4206690095014969e-05,
      "loss": 0.2083,
      "step": 5500
    },
    {
      "epoch": 0.7223740726278798,
      "grad_norm": 0.9467424750328064,
      "learning_rate": 1.3881296368606014e-05,
      "loss": 0.1962,
      "step": 5550
    },
    {
      "epoch": 0.7288819471560588,
      "grad_norm": 4.482257843017578,
      "learning_rate": 1.355590264219706e-05,
      "loss": 0.1952,
      "step": 5600
    },
    {
      "epoch": 0.7353898216842379,
      "grad_norm": 10.481292724609375,
      "learning_rate": 1.3230508915788104e-05,
      "loss": 0.1556,
      "step": 5650
    },
    {
      "epoch": 0.7418976962124171,
      "grad_norm": 1.1305725574493408,
      "learning_rate": 1.2905115189379149e-05,
      "loss": 0.2036,
      "step": 5700
    },
    {
      "epoch": 0.7484055707405961,
      "grad_norm": 4.875345230102539,
      "learning_rate": 1.2579721462970196e-05,
      "loss": 0.1498,
      "step": 5750
    },
    {
      "epoch": 0.7549134452687752,
      "grad_norm": 7.794529438018799,
      "learning_rate": 1.225432773656124e-05,
      "loss": 0.2286,
      "step": 5800
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 7.174578666687012,
      "learning_rate": 1.1928934010152284e-05,
      "loss": 0.2203,
      "step": 5850
    },
    {
      "epoch": 0.7679291943251334,
      "grad_norm": 14.43912410736084,
      "learning_rate": 1.1603540283743331e-05,
      "loss": 0.1522,
      "step": 5900
    },
    {
      "epoch": 0.7744370688533125,
      "grad_norm": 9.669170379638672,
      "learning_rate": 1.1278146557334375e-05,
      "loss": 0.2211,
      "step": 5950
    },
    {
      "epoch": 0.7809449433814916,
      "grad_norm": 10.17822265625,
      "learning_rate": 1.095275283092542e-05,
      "loss": 0.1197,
      "step": 6000
    },
    {
      "epoch": 0.7874528179096707,
      "grad_norm": 3.6023576259613037,
      "learning_rate": 1.0627359104516465e-05,
      "loss": 0.1808,
      "step": 6050
    },
    {
      "epoch": 0.7939606924378498,
      "grad_norm": 0.36894041299819946,
      "learning_rate": 1.030196537810751e-05,
      "loss": 0.1664,
      "step": 6100
    },
    {
      "epoch": 0.8004685669660289,
      "grad_norm": 2.016923189163208,
      "learning_rate": 9.976571651698557e-06,
      "loss": 0.2113,
      "step": 6150
    },
    {
      "epoch": 0.806976441494208,
      "grad_norm": 8.840688705444336,
      "learning_rate": 9.6511779252896e-06,
      "loss": 0.255,
      "step": 6200
    },
    {
      "epoch": 0.8134843160223871,
      "grad_norm": 10.54377269744873,
      "learning_rate": 9.325784198880647e-06,
      "loss": 0.1684,
      "step": 6250
    },
    {
      "epoch": 0.8199921905505662,
      "grad_norm": 0.2175673246383667,
      "learning_rate": 9.000390472471692e-06,
      "loss": 0.2247,
      "step": 6300
    },
    {
      "epoch": 0.8265000650787453,
      "grad_norm": 6.017751216888428,
      "learning_rate": 8.674996746062735e-06,
      "loss": 0.1793,
      "step": 6350
    },
    {
      "epoch": 0.8330079396069244,
      "grad_norm": 0.4484698176383972,
      "learning_rate": 8.349603019653782e-06,
      "loss": 0.1766,
      "step": 6400
    },
    {
      "epoch": 0.8395158141351035,
      "grad_norm": 0.08648896217346191,
      "learning_rate": 8.024209293244825e-06,
      "loss": 0.1175,
      "step": 6450
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 5.721574306488037,
      "learning_rate": 7.698815566835872e-06,
      "loss": 0.2146,
      "step": 6500
    },
    {
      "epoch": 0.8525315631914616,
      "grad_norm": 0.2679693102836609,
      "learning_rate": 7.3734218404269165e-06,
      "loss": 0.1791,
      "step": 6550
    },
    {
      "epoch": 0.8590394377196408,
      "grad_norm": 0.057116732001304626,
      "learning_rate": 7.048028114017962e-06,
      "loss": 0.1687,
      "step": 6600
    },
    {
      "epoch": 0.8655473122478199,
      "grad_norm": 13.749441146850586,
      "learning_rate": 6.7226343876090075e-06,
      "loss": 0.1585,
      "step": 6650
    },
    {
      "epoch": 0.8720551867759989,
      "grad_norm": 8.659581184387207,
      "learning_rate": 6.397240661200052e-06,
      "loss": 0.1933,
      "step": 6700
    },
    {
      "epoch": 0.878563061304178,
      "grad_norm": 0.08135733753442764,
      "learning_rate": 6.071846934791098e-06,
      "loss": 0.1775,
      "step": 6750
    },
    {
      "epoch": 0.8850709358323572,
      "grad_norm": 15.883150100708008,
      "learning_rate": 5.746453208382143e-06,
      "loss": 0.1786,
      "step": 6800
    },
    {
      "epoch": 0.8915788103605362,
      "grad_norm": 18.12819480895996,
      "learning_rate": 5.421059481973188e-06,
      "loss": 0.1874,
      "step": 6850
    },
    {
      "epoch": 0.8980866848887153,
      "grad_norm": 0.213799849152565,
      "learning_rate": 5.095665755564233e-06,
      "loss": 0.1601,
      "step": 6900
    },
    {
      "epoch": 0.9045945594168945,
      "grad_norm": 0.19317854940891266,
      "learning_rate": 4.770272029155278e-06,
      "loss": 0.2073,
      "step": 6950
    },
    {
      "epoch": 0.9111024339450735,
      "grad_norm": 0.10259438306093216,
      "learning_rate": 4.444878302746323e-06,
      "loss": 0.2822,
      "step": 7000
    },
    {
      "epoch": 0.9176103084732526,
      "grad_norm": 3.2400476932525635,
      "learning_rate": 4.119484576337369e-06,
      "loss": 0.1805,
      "step": 7050
    },
    {
      "epoch": 0.9241181830014318,
      "grad_norm": 1.1277974843978882,
      "learning_rate": 3.7940908499284137e-06,
      "loss": 0.1472,
      "step": 7100
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 9.255287170410156,
      "learning_rate": 3.4686971235194584e-06,
      "loss": 0.207,
      "step": 7150
    },
    {
      "epoch": 0.9371339320577899,
      "grad_norm": 0.20328368246555328,
      "learning_rate": 3.143303397110504e-06,
      "loss": 0.1696,
      "step": 7200
    },
    {
      "epoch": 0.943641806585969,
      "grad_norm": 0.09563539177179337,
      "learning_rate": 2.817909670701549e-06,
      "loss": 0.1696,
      "step": 7250
    },
    {
      "epoch": 0.9501496811141481,
      "grad_norm": 0.07055521011352539,
      "learning_rate": 2.492515944292594e-06,
      "loss": 0.2298,
      "step": 7300
    },
    {
      "epoch": 0.9566575556423272,
      "grad_norm": 13.9857759475708,
      "learning_rate": 2.167122217883639e-06,
      "loss": 0.1802,
      "step": 7350
    },
    {
      "epoch": 0.9631654301705063,
      "grad_norm": 1.1242938041687012,
      "learning_rate": 1.8417284914746845e-06,
      "loss": 0.1913,
      "step": 7400
    },
    {
      "epoch": 0.9696733046986854,
      "grad_norm": 9.146126747131348,
      "learning_rate": 1.5163347650657298e-06,
      "loss": 0.1404,
      "step": 7450
    },
    {
      "epoch": 0.9761811792268645,
      "grad_norm": 3.766692876815796,
      "learning_rate": 1.1909410386567748e-06,
      "loss": 0.1587,
      "step": 7500
    },
    {
      "epoch": 0.9826890537550436,
      "grad_norm": 1.496512532234192,
      "learning_rate": 8.655473122478198e-07,
      "loss": 0.1859,
      "step": 7550
    },
    {
      "epoch": 0.9891969282832227,
      "grad_norm": 3.519092082977295,
      "learning_rate": 5.40153585838865e-07,
      "loss": 0.2191,
      "step": 7600
    },
    {
      "epoch": 0.9957048028114018,
      "grad_norm": 5.541266918182373,
      "learning_rate": 2.1475985942991019e-07,
      "loss": 0.1394,
      "step": 7650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9459811259355678,
      "eval_f1": 0.9460618663893944,
      "eval_loss": 0.19822363555431366,
      "eval_precision": 0.9442210403424569,
      "eval_recall": 0.9479098840994922,
      "eval_runtime": 552.3939,
      "eval_samples_per_second": 27.815,
      "eval_steps_per_second": 3.478,
      "step": 7683
    }
  ],
  "logging_steps": 50,
  "max_steps": 7683,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4084734183315456.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
