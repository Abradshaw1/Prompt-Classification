{
  "best_metric": 0.030531423166394234,
  "best_model_checkpoint": "./results/checkpoint-6480",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6480,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07716049382716049,
      "grad_norm": 2.3680837154388428,
      "learning_rate": 4.996141975308643e-05,
      "loss": 0.6986,
      "step": 50
    },
    {
      "epoch": 0.15432098765432098,
      "grad_norm": 1.7608397006988525,
      "learning_rate": 4.9922839506172845e-05,
      "loss": 0.6965,
      "step": 100
    },
    {
      "epoch": 0.23148148148148148,
      "grad_norm": 3.4151387214660645,
      "learning_rate": 4.988425925925926e-05,
      "loss": 0.6892,
      "step": 150
    },
    {
      "epoch": 0.30864197530864196,
      "grad_norm": 1.1648515462875366,
      "learning_rate": 4.984567901234568e-05,
      "loss": 0.6908,
      "step": 200
    },
    {
      "epoch": 0.38580246913580246,
      "grad_norm": 1.9584126472473145,
      "learning_rate": 4.9807098765432105e-05,
      "loss": 0.6549,
      "step": 250
    },
    {
      "epoch": 0.46296296296296297,
      "grad_norm": 3.0563251972198486,
      "learning_rate": 4.976851851851852e-05,
      "loss": 0.449,
      "step": 300
    },
    {
      "epoch": 0.5401234567901234,
      "grad_norm": 1.8670148849487305,
      "learning_rate": 4.972993827160494e-05,
      "loss": 0.2173,
      "step": 350
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 1.3660722970962524,
      "learning_rate": 4.969135802469136e-05,
      "loss": 0.1257,
      "step": 400
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.28340935707092285,
      "learning_rate": 4.965277777777778e-05,
      "loss": 0.0994,
      "step": 450
    },
    {
      "epoch": 0.7716049382716049,
      "grad_norm": 0.21632809937000275,
      "learning_rate": 4.96141975308642e-05,
      "loss": 0.0569,
      "step": 500
    },
    {
      "epoch": 0.8487654320987654,
      "grad_norm": 0.1708008199930191,
      "learning_rate": 4.957561728395062e-05,
      "loss": 0.09,
      "step": 550
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.14783619344234467,
      "learning_rate": 4.9537037037037035e-05,
      "loss": 0.03,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9884169884169884,
      "eval_f1": 0.9888971132494448,
      "eval_loss": 0.060326263308525085,
      "eval_precision": 0.9823529411764705,
      "eval_recall": 0.9955290611028316,
      "eval_runtime": 1.9671,
      "eval_samples_per_second": 658.328,
      "eval_steps_per_second": 82.355,
      "step": 648
    },
    {
      "epoch": 1.0030864197530864,
      "grad_norm": 0.11762536317110062,
      "learning_rate": 4.949845679012346e-05,
      "loss": 0.1244,
      "step": 650
    },
    {
      "epoch": 1.0802469135802468,
      "grad_norm": 4.41304349899292,
      "learning_rate": 4.945987654320988e-05,
      "loss": 0.1006,
      "step": 700
    },
    {
      "epoch": 1.1574074074074074,
      "grad_norm": 0.5356112122535706,
      "learning_rate": 4.94212962962963e-05,
      "loss": 0.09,
      "step": 750
    },
    {
      "epoch": 1.2345679012345678,
      "grad_norm": 0.07643423229455948,
      "learning_rate": 4.938271604938271e-05,
      "loss": 0.0617,
      "step": 800
    },
    {
      "epoch": 1.3117283950617284,
      "grad_norm": 0.5226731300354004,
      "learning_rate": 4.934413580246914e-05,
      "loss": 0.0777,
      "step": 850
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.057917520403862,
      "learning_rate": 4.930555555555556e-05,
      "loss": 0.0363,
      "step": 900
    },
    {
      "epoch": 1.4660493827160495,
      "grad_norm": 0.0761527568101883,
      "learning_rate": 4.926697530864198e-05,
      "loss": 0.0334,
      "step": 950
    },
    {
      "epoch": 1.5432098765432098,
      "grad_norm": 2.9573960304260254,
      "learning_rate": 4.92283950617284e-05,
      "loss": 0.0936,
      "step": 1000
    },
    {
      "epoch": 1.6203703703703702,
      "grad_norm": 0.040395818650722504,
      "learning_rate": 4.9189814814814815e-05,
      "loss": 0.0395,
      "step": 1050
    },
    {
      "epoch": 1.6975308641975309,
      "grad_norm": 4.437081813812256,
      "learning_rate": 4.915123456790124e-05,
      "loss": 0.14,
      "step": 1100
    },
    {
      "epoch": 1.7746913580246915,
      "grad_norm": 0.08689115941524506,
      "learning_rate": 4.911265432098766e-05,
      "loss": 0.0849,
      "step": 1150
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.06682652980089188,
      "learning_rate": 4.9074074074074075e-05,
      "loss": 0.0927,
      "step": 1200
    },
    {
      "epoch": 1.9290123456790123,
      "grad_norm": 0.22743117809295654,
      "learning_rate": 4.903549382716049e-05,
      "loss": 0.0711,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9884169884169884,
      "eval_f1": 0.9888971132494448,
      "eval_loss": 0.0600418858230114,
      "eval_precision": 0.9823529411764705,
      "eval_recall": 0.9955290611028316,
      "eval_runtime": 1.9648,
      "eval_samples_per_second": 659.092,
      "eval_steps_per_second": 82.45,
      "step": 1296
    },
    {
      "epoch": 2.006172839506173,
      "grad_norm": 0.06749416887760162,
      "learning_rate": 4.899691358024692e-05,
      "loss": 0.0282,
      "step": 1300
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.1069137305021286,
      "learning_rate": 4.8958333333333335e-05,
      "loss": 0.0837,
      "step": 1350
    },
    {
      "epoch": 2.1604938271604937,
      "grad_norm": 0.09930428117513657,
      "learning_rate": 4.891975308641975e-05,
      "loss": 0.0341,
      "step": 1400
    },
    {
      "epoch": 2.2376543209876543,
      "grad_norm": 0.07384706288576126,
      "learning_rate": 4.888117283950617e-05,
      "loss": 0.0977,
      "step": 1450
    },
    {
      "epoch": 2.314814814814815,
      "grad_norm": 0.05152643844485283,
      "learning_rate": 4.8842592592592595e-05,
      "loss": 0.0762,
      "step": 1500
    },
    {
      "epoch": 2.3919753086419755,
      "grad_norm": 0.04058675095438957,
      "learning_rate": 4.880401234567901e-05,
      "loss": 0.0429,
      "step": 1550
    },
    {
      "epoch": 2.4691358024691357,
      "grad_norm": 0.03550375998020172,
      "learning_rate": 4.876543209876544e-05,
      "loss": 0.0979,
      "step": 1600
    },
    {
      "epoch": 2.5462962962962963,
      "grad_norm": 0.04726794734597206,
      "learning_rate": 4.8726851851851855e-05,
      "loss": 0.0336,
      "step": 1650
    },
    {
      "epoch": 2.623456790123457,
      "grad_norm": 0.04590208828449249,
      "learning_rate": 4.868827160493827e-05,
      "loss": 0.089,
      "step": 1700
    },
    {
      "epoch": 2.700617283950617,
      "grad_norm": 0.019069386646151543,
      "learning_rate": 4.86496913580247e-05,
      "loss": 0.0525,
      "step": 1750
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.048235468566417694,
      "learning_rate": 4.8611111111111115e-05,
      "loss": 0.059,
      "step": 1800
    },
    {
      "epoch": 2.8549382716049383,
      "grad_norm": 0.08601514250040054,
      "learning_rate": 4.857253086419753e-05,
      "loss": 0.0678,
      "step": 1850
    },
    {
      "epoch": 2.932098765432099,
      "grad_norm": 0.04617128148674965,
      "learning_rate": 4.853395061728395e-05,
      "loss": 0.0804,
      "step": 1900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9907335907335907,
      "eval_f1": 0.9911111111111112,
      "eval_loss": 0.048592377454042435,
      "eval_precision": 0.9852724594992637,
      "eval_recall": 0.9970193740685543,
      "eval_runtime": 1.973,
      "eval_samples_per_second": 656.361,
      "eval_steps_per_second": 82.108,
      "step": 1944
    },
    {
      "epoch": 3.009259259259259,
      "grad_norm": 0.06480825692415237,
      "learning_rate": 4.8495370370370375e-05,
      "loss": 0.0784,
      "step": 1950
    },
    {
      "epoch": 3.0864197530864197,
      "grad_norm": 0.09510764479637146,
      "learning_rate": 4.845679012345679e-05,
      "loss": 0.0517,
      "step": 2000
    },
    {
      "epoch": 3.1635802469135803,
      "grad_norm": 0.2575649321079254,
      "learning_rate": 4.841820987654321e-05,
      "loss": 0.1027,
      "step": 2050
    },
    {
      "epoch": 3.240740740740741,
      "grad_norm": 0.036512888967990875,
      "learning_rate": 4.837962962962963e-05,
      "loss": 0.0317,
      "step": 2100
    },
    {
      "epoch": 3.317901234567901,
      "grad_norm": 0.07966411113739014,
      "learning_rate": 4.834104938271605e-05,
      "loss": 0.0683,
      "step": 2150
    },
    {
      "epoch": 3.3950617283950617,
      "grad_norm": 0.026571618393063545,
      "learning_rate": 4.830246913580247e-05,
      "loss": 0.0383,
      "step": 2200
    },
    {
      "epoch": 3.4722222222222223,
      "grad_norm": 0.4968945384025574,
      "learning_rate": 4.8263888888888895e-05,
      "loss": 0.0518,
      "step": 2250
    },
    {
      "epoch": 3.549382716049383,
      "grad_norm": 0.018863489851355553,
      "learning_rate": 4.8225308641975306e-05,
      "loss": 0.1071,
      "step": 2300
    },
    {
      "epoch": 3.626543209876543,
      "grad_norm": 0.028493214398622513,
      "learning_rate": 4.818672839506173e-05,
      "loss": 0.0169,
      "step": 2350
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 0.029041901230812073,
      "learning_rate": 4.814814814814815e-05,
      "loss": 0.088,
      "step": 2400
    },
    {
      "epoch": 3.7808641975308643,
      "grad_norm": 0.02270234003663063,
      "learning_rate": 4.810956790123457e-05,
      "loss": 0.0658,
      "step": 2450
    },
    {
      "epoch": 3.8580246913580245,
      "grad_norm": 0.39604857563972473,
      "learning_rate": 4.807098765432099e-05,
      "loss": 0.0451,
      "step": 2500
    },
    {
      "epoch": 3.935185185185185,
      "grad_norm": 0.05884864926338196,
      "learning_rate": 4.803240740740741e-05,
      "loss": 0.029,
      "step": 2550
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9899613899613899,
      "eval_f1": 0.9903774981495189,
      "eval_loss": 0.04961700364947319,
      "eval_precision": 0.9838235294117647,
      "eval_recall": 0.9970193740685543,
      "eval_runtime": 1.969,
      "eval_samples_per_second": 657.708,
      "eval_steps_per_second": 82.277,
      "step": 2592
    },
    {
      "epoch": 4.012345679012346,
      "grad_norm": 0.031790971755981445,
      "learning_rate": 4.799382716049383e-05,
      "loss": 0.0899,
      "step": 2600
    },
    {
      "epoch": 4.089506172839506,
      "grad_norm": 0.07725062221288681,
      "learning_rate": 4.795524691358025e-05,
      "loss": 0.0308,
      "step": 2650
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 7.756692886352539,
      "learning_rate": 4.791666666666667e-05,
      "loss": 0.0373,
      "step": 2700
    },
    {
      "epoch": 4.243827160493828,
      "grad_norm": 0.056879524141550064,
      "learning_rate": 4.7878086419753086e-05,
      "loss": 0.0789,
      "step": 2750
    },
    {
      "epoch": 4.320987654320987,
      "grad_norm": 3.049644708633423,
      "learning_rate": 4.783950617283951e-05,
      "loss": 0.0755,
      "step": 2800
    },
    {
      "epoch": 4.398148148148148,
      "grad_norm": 0.01840643584728241,
      "learning_rate": 4.780092592592593e-05,
      "loss": 0.0334,
      "step": 2850
    },
    {
      "epoch": 4.4753086419753085,
      "grad_norm": 0.02588556334376335,
      "learning_rate": 4.7762345679012346e-05,
      "loss": 0.0287,
      "step": 2900
    },
    {
      "epoch": 4.552469135802469,
      "grad_norm": 6.21358060836792,
      "learning_rate": 4.7723765432098764e-05,
      "loss": 0.0769,
      "step": 2950
    },
    {
      "epoch": 4.62962962962963,
      "grad_norm": 0.12934203445911407,
      "learning_rate": 4.768518518518519e-05,
      "loss": 0.0853,
      "step": 3000
    },
    {
      "epoch": 4.70679012345679,
      "grad_norm": 0.19996853172779083,
      "learning_rate": 4.7646604938271606e-05,
      "loss": 0.0625,
      "step": 3050
    },
    {
      "epoch": 4.783950617283951,
      "grad_norm": 3.6150214672088623,
      "learning_rate": 4.760802469135803e-05,
      "loss": 0.0186,
      "step": 3100
    },
    {
      "epoch": 4.861111111111111,
      "grad_norm": 0.05292239412665367,
      "learning_rate": 4.756944444444444e-05,
      "loss": 0.02,
      "step": 3150
    },
    {
      "epoch": 4.938271604938271,
      "grad_norm": 3.6908457279205322,
      "learning_rate": 4.7530864197530866e-05,
      "loss": 0.0874,
      "step": 3200
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9907335907335907,
      "eval_f1": 0.9911111111111112,
      "eval_loss": 0.042954426258802414,
      "eval_precision": 0.9852724594992637,
      "eval_recall": 0.9970193740685543,
      "eval_runtime": 1.9729,
      "eval_samples_per_second": 656.405,
      "eval_steps_per_second": 82.114,
      "step": 3240
    },
    {
      "epoch": 5.015432098765432,
      "grad_norm": 0.042140450328588486,
      "learning_rate": 4.749228395061729e-05,
      "loss": 0.0776,
      "step": 3250
    },
    {
      "epoch": 5.092592592592593,
      "grad_norm": 3.4812440872192383,
      "learning_rate": 4.745370370370371e-05,
      "loss": 0.053,
      "step": 3300
    },
    {
      "epoch": 5.169753086419753,
      "grad_norm": 0.08235400170087814,
      "learning_rate": 4.7415123456790126e-05,
      "loss": 0.075,
      "step": 3350
    },
    {
      "epoch": 5.246913580246914,
      "grad_norm": 0.021120639517903328,
      "learning_rate": 4.7376543209876543e-05,
      "loss": 0.0482,
      "step": 3400
    },
    {
      "epoch": 5.324074074074074,
      "grad_norm": 0.024060841649770737,
      "learning_rate": 4.733796296296297e-05,
      "loss": 0.0332,
      "step": 3450
    },
    {
      "epoch": 5.401234567901234,
      "grad_norm": 16.05644416809082,
      "learning_rate": 4.7299382716049386e-05,
      "loss": 0.1101,
      "step": 3500
    },
    {
      "epoch": 5.478395061728395,
      "grad_norm": 0.10815684497356415,
      "learning_rate": 4.72608024691358e-05,
      "loss": 0.0486,
      "step": 3550
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.019287681207060814,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.0156,
      "step": 3600
    },
    {
      "epoch": 5.632716049382716,
      "grad_norm": 12.1182222366333,
      "learning_rate": 4.7183641975308646e-05,
      "loss": 0.0717,
      "step": 3650
    },
    {
      "epoch": 5.709876543209877,
      "grad_norm": 0.021700473502278328,
      "learning_rate": 4.714506172839506e-05,
      "loss": 0.0453,
      "step": 3700
    },
    {
      "epoch": 5.787037037037037,
      "grad_norm": 0.0856749638915062,
      "learning_rate": 4.710648148148149e-05,
      "loss": 0.0479,
      "step": 3750
    },
    {
      "epoch": 5.864197530864198,
      "grad_norm": 0.043047018349170685,
      "learning_rate": 4.70679012345679e-05,
      "loss": 0.0539,
      "step": 3800
    },
    {
      "epoch": 5.9413580246913575,
      "grad_norm": 8.629820823669434,
      "learning_rate": 4.702932098765432e-05,
      "loss": 0.0552,
      "step": 3850
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9899613899613899,
      "eval_f1": 0.9903489235337788,
      "eval_loss": 0.04178621619939804,
      "eval_precision": 0.9866863905325444,
      "eval_recall": 0.9940387481371088,
      "eval_runtime": 1.9691,
      "eval_samples_per_second": 657.658,
      "eval_steps_per_second": 82.271,
      "step": 3888
    },
    {
      "epoch": 6.018518518518518,
      "grad_norm": 0.031427282840013504,
      "learning_rate": 4.699074074074074e-05,
      "loss": 0.0522,
      "step": 3900
    },
    {
      "epoch": 6.095679012345679,
      "grad_norm": 0.020951272919774055,
      "learning_rate": 4.6952160493827166e-05,
      "loss": 0.0578,
      "step": 3950
    },
    {
      "epoch": 6.172839506172839,
      "grad_norm": 0.17568348348140717,
      "learning_rate": 4.691358024691358e-05,
      "loss": 0.0223,
      "step": 4000
    },
    {
      "epoch": 6.25,
      "grad_norm": 5.8722991943359375,
      "learning_rate": 4.6875e-05,
      "loss": 0.0594,
      "step": 4050
    },
    {
      "epoch": 6.327160493827161,
      "grad_norm": 0.04021480306982994,
      "learning_rate": 4.6836419753086425e-05,
      "loss": 0.0458,
      "step": 4100
    },
    {
      "epoch": 6.404320987654321,
      "grad_norm": 0.05555739253759384,
      "learning_rate": 4.679783950617284e-05,
      "loss": 0.0916,
      "step": 4150
    },
    {
      "epoch": 6.481481481481482,
      "grad_norm": 0.021815873682498932,
      "learning_rate": 4.675925925925926e-05,
      "loss": 0.0138,
      "step": 4200
    },
    {
      "epoch": 6.5586419753086425,
      "grad_norm": 0.030014079064130783,
      "learning_rate": 4.672067901234568e-05,
      "loss": 0.0766,
      "step": 4250
    },
    {
      "epoch": 6.635802469135802,
      "grad_norm": 0.07242339849472046,
      "learning_rate": 4.66820987654321e-05,
      "loss": 0.0391,
      "step": 4300
    },
    {
      "epoch": 6.712962962962963,
      "grad_norm": 0.4009053111076355,
      "learning_rate": 4.664351851851852e-05,
      "loss": 0.0559,
      "step": 4350
    },
    {
      "epoch": 6.790123456790123,
      "grad_norm": 0.022466691210865974,
      "learning_rate": 4.6604938271604945e-05,
      "loss": 0.0293,
      "step": 4400
    },
    {
      "epoch": 6.867283950617284,
      "grad_norm": 0.07895848900079727,
      "learning_rate": 4.6566358024691356e-05,
      "loss": 0.0342,
      "step": 4450
    },
    {
      "epoch": 6.944444444444445,
      "grad_norm": 0.010365529917180538,
      "learning_rate": 4.652777777777778e-05,
      "loss": 0.03,
      "step": 4500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9915057915057915,
      "eval_f1": 0.9917971662938105,
      "eval_loss": 0.03834496811032295,
      "eval_precision": 0.9925373134328358,
      "eval_recall": 0.9910581222056631,
      "eval_runtime": 1.9721,
      "eval_samples_per_second": 656.664,
      "eval_steps_per_second": 82.146,
      "step": 4536
    },
    {
      "epoch": 7.021604938271605,
      "grad_norm": 6.129476547241211,
      "learning_rate": 4.64891975308642e-05,
      "loss": 0.1234,
      "step": 4550
    },
    {
      "epoch": 7.098765432098766,
      "grad_norm": 0.9942270517349243,
      "learning_rate": 4.645061728395062e-05,
      "loss": 0.0665,
      "step": 4600
    },
    {
      "epoch": 7.175925925925926,
      "grad_norm": 0.008898208849132061,
      "learning_rate": 4.6412037037037034e-05,
      "loss": 0.0279,
      "step": 4650
    },
    {
      "epoch": 7.253086419753086,
      "grad_norm": 0.04846688732504845,
      "learning_rate": 4.637345679012346e-05,
      "loss": 0.0745,
      "step": 4700
    },
    {
      "epoch": 7.330246913580247,
      "grad_norm": 0.03767933323979378,
      "learning_rate": 4.6334876543209876e-05,
      "loss": 0.0283,
      "step": 4750
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 0.0533294752240181,
      "learning_rate": 4.62962962962963e-05,
      "loss": 0.0709,
      "step": 4800
    },
    {
      "epoch": 7.484567901234568,
      "grad_norm": 0.006446461658924818,
      "learning_rate": 4.625771604938272e-05,
      "loss": 0.0066,
      "step": 4850
    },
    {
      "epoch": 7.561728395061729,
      "grad_norm": 0.027883360162377357,
      "learning_rate": 4.6219135802469136e-05,
      "loss": 0.0475,
      "step": 4900
    },
    {
      "epoch": 7.638888888888889,
      "grad_norm": 5.945392608642578,
      "learning_rate": 4.618055555555556e-05,
      "loss": 0.0874,
      "step": 4950
    },
    {
      "epoch": 7.716049382716049,
      "grad_norm": 0.01692816987633705,
      "learning_rate": 4.614197530864198e-05,
      "loss": 0.0318,
      "step": 5000
    },
    {
      "epoch": 7.79320987654321,
      "grad_norm": 0.009668455459177494,
      "learning_rate": 4.6103395061728396e-05,
      "loss": 0.0026,
      "step": 5050
    },
    {
      "epoch": 7.87037037037037,
      "grad_norm": 0.027084339410066605,
      "learning_rate": 4.6064814814814814e-05,
      "loss": 0.0675,
      "step": 5100
    },
    {
      "epoch": 7.947530864197531,
      "grad_norm": 0.03274150192737579,
      "learning_rate": 4.602623456790124e-05,
      "loss": 0.0553,
      "step": 5150
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9915057915057915,
      "eval_f1": 0.9918215613382899,
      "eval_loss": 0.03567201644182205,
      "eval_precision": 0.9896142433234422,
      "eval_recall": 0.9940387481371088,
      "eval_runtime": 1.969,
      "eval_samples_per_second": 657.703,
      "eval_steps_per_second": 82.276,
      "step": 5184
    },
    {
      "epoch": 8.024691358024691,
      "grad_norm": 4.347270488739014,
      "learning_rate": 4.5987654320987656e-05,
      "loss": 0.0782,
      "step": 5200
    },
    {
      "epoch": 8.101851851851851,
      "grad_norm": 0.01993035525083542,
      "learning_rate": 4.594907407407408e-05,
      "loss": 0.0444,
      "step": 5250
    },
    {
      "epoch": 8.179012345679013,
      "grad_norm": 0.013964183628559113,
      "learning_rate": 4.591049382716049e-05,
      "loss": 0.0568,
      "step": 5300
    },
    {
      "epoch": 8.256172839506172,
      "grad_norm": 0.014069858007133007,
      "learning_rate": 4.5871913580246916e-05,
      "loss": 0.0199,
      "step": 5350
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.05348311737179756,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.0474,
      "step": 5400
    },
    {
      "epoch": 8.410493827160494,
      "grad_norm": 0.054548125714063644,
      "learning_rate": 4.579475308641976e-05,
      "loss": 0.0783,
      "step": 5450
    },
    {
      "epoch": 8.487654320987655,
      "grad_norm": 0.01592850312590599,
      "learning_rate": 4.5756172839506176e-05,
      "loss": 0.0685,
      "step": 5500
    },
    {
      "epoch": 8.564814814814815,
      "grad_norm": 0.008869679644703865,
      "learning_rate": 4.5717592592592594e-05,
      "loss": 0.0296,
      "step": 5550
    },
    {
      "epoch": 8.641975308641975,
      "grad_norm": 0.3421914279460907,
      "learning_rate": 4.567901234567901e-05,
      "loss": 0.013,
      "step": 5600
    },
    {
      "epoch": 8.719135802469136,
      "grad_norm": 3.6630234718322754,
      "learning_rate": 4.5640432098765436e-05,
      "loss": 0.0221,
      "step": 5650
    },
    {
      "epoch": 8.796296296296296,
      "grad_norm": 0.004370361100882292,
      "learning_rate": 4.5601851851851854e-05,
      "loss": 0.0589,
      "step": 5700
    },
    {
      "epoch": 8.873456790123457,
      "grad_norm": 0.006575227715075016,
      "learning_rate": 4.556327160493827e-05,
      "loss": 0.026,
      "step": 5750
    },
    {
      "epoch": 8.950617283950617,
      "grad_norm": 0.023685693740844727,
      "learning_rate": 4.5524691358024696e-05,
      "loss": 0.0246,
      "step": 5800
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9915057915057915,
      "eval_f1": 0.9918215613382899,
      "eval_loss": 0.037436872720718384,
      "eval_precision": 0.9896142433234422,
      "eval_recall": 0.9940387481371088,
      "eval_runtime": 1.9754,
      "eval_samples_per_second": 655.569,
      "eval_steps_per_second": 82.009,
      "step": 5832
    },
    {
      "epoch": 9.027777777777779,
      "grad_norm": 0.008862984366714954,
      "learning_rate": 4.5486111111111114e-05,
      "loss": 0.0269,
      "step": 5850
    },
    {
      "epoch": 9.104938271604938,
      "grad_norm": 2.5840048789978027,
      "learning_rate": 4.544753086419754e-05,
      "loss": 0.0928,
      "step": 5900
    },
    {
      "epoch": 9.182098765432098,
      "grad_norm": 0.012977142818272114,
      "learning_rate": 4.540895061728395e-05,
      "loss": 0.0322,
      "step": 5950
    },
    {
      "epoch": 9.25925925925926,
      "grad_norm": 0.036671705543994904,
      "learning_rate": 4.5370370370370374e-05,
      "loss": 0.0619,
      "step": 6000
    },
    {
      "epoch": 9.33641975308642,
      "grad_norm": 0.02656795084476471,
      "learning_rate": 4.533179012345679e-05,
      "loss": 0.038,
      "step": 6050
    },
    {
      "epoch": 9.41358024691358,
      "grad_norm": 0.019658561795949936,
      "learning_rate": 4.5293209876543216e-05,
      "loss": 0.0735,
      "step": 6100
    },
    {
      "epoch": 9.49074074074074,
      "grad_norm": 5.110319137573242,
      "learning_rate": 4.525462962962963e-05,
      "loss": 0.038,
      "step": 6150
    },
    {
      "epoch": 9.567901234567902,
      "grad_norm": 0.03532613068819046,
      "learning_rate": 4.521604938271605e-05,
      "loss": 0.04,
      "step": 6200
    },
    {
      "epoch": 9.645061728395062,
      "grad_norm": 0.037401288747787476,
      "learning_rate": 4.517746913580247e-05,
      "loss": 0.0359,
      "step": 6250
    },
    {
      "epoch": 9.722222222222221,
      "grad_norm": 0.0202025193721056,
      "learning_rate": 4.5138888888888894e-05,
      "loss": 0.0198,
      "step": 6300
    },
    {
      "epoch": 9.799382716049383,
      "grad_norm": 0.010618405416607857,
      "learning_rate": 4.510030864197531e-05,
      "loss": 0.0298,
      "step": 6350
    },
    {
      "epoch": 9.876543209876543,
      "grad_norm": 0.01682555302977562,
      "learning_rate": 4.506172839506173e-05,
      "loss": 0.0267,
      "step": 6400
    },
    {
      "epoch": 9.953703703703704,
      "grad_norm": 0.02634512260556221,
      "learning_rate": 4.502314814814815e-05,
      "loss": 0.0026,
      "step": 6450
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9922779922779923,
      "eval_f1": 0.9925705794947994,
      "eval_loss": 0.030531423166394234,
      "eval_precision": 0.9896296296296296,
      "eval_recall": 0.9955290611028316,
      "eval_runtime": 1.9753,
      "eval_samples_per_second": 655.6,
      "eval_steps_per_second": 82.013,
      "step": 6480
    }
  ],
  "logging_steps": 50,
  "max_steps": 64800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3441553216266240.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
