{
  "best_metric": 0.11793120950460434,
  "best_model_checkpoint": "./results/checkpoint-61328",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 61328,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006522306287503261,
      "grad_norm": 1.8801383972167969,
      "learning_rate": 4.999673884685625e-05,
      "loss": 0.6968,
      "step": 50
    },
    {
      "epoch": 0.013044612575006522,
      "grad_norm": 3.191243886947632,
      "learning_rate": 4.99934776937125e-05,
      "loss": 0.696,
      "step": 100
    },
    {
      "epoch": 0.019566918862509785,
      "grad_norm": 2.002129077911377,
      "learning_rate": 4.999021654056875e-05,
      "loss": 0.695,
      "step": 150
    },
    {
      "epoch": 0.026089225150013044,
      "grad_norm": 3.3172030448913574,
      "learning_rate": 4.9986955387424994e-05,
      "loss": 0.6878,
      "step": 200
    },
    {
      "epoch": 0.03261153143751631,
      "grad_norm": 2.2084972858428955,
      "learning_rate": 4.998369423428124e-05,
      "loss": 0.6941,
      "step": 250
    },
    {
      "epoch": 0.03913383772501957,
      "grad_norm": 4.648697853088379,
      "learning_rate": 4.998043308113749e-05,
      "loss": 0.6869,
      "step": 300
    },
    {
      "epoch": 0.045656144012522826,
      "grad_norm": 2.2222774028778076,
      "learning_rate": 4.9977171927993746e-05,
      "loss": 0.6562,
      "step": 350
    },
    {
      "epoch": 0.05217845030002609,
      "grad_norm": 1.5503545999526978,
      "learning_rate": 4.997391077484999e-05,
      "loss": 0.5342,
      "step": 400
    },
    {
      "epoch": 0.05870075658752935,
      "grad_norm": 3.357682704925537,
      "learning_rate": 4.997064962170624e-05,
      "loss": 0.3405,
      "step": 450
    },
    {
      "epoch": 0.06522306287503261,
      "grad_norm": 8.73212718963623,
      "learning_rate": 4.9967388468562485e-05,
      "loss": 0.3507,
      "step": 500
    },
    {
      "epoch": 0.07174536916253588,
      "grad_norm": 9.173982620239258,
      "learning_rate": 4.996412731541874e-05,
      "loss": 0.2899,
      "step": 550
    },
    {
      "epoch": 0.07826767545003914,
      "grad_norm": 7.192420959472656,
      "learning_rate": 4.9960866162274984e-05,
      "loss": 0.299,
      "step": 600
    },
    {
      "epoch": 0.08478998173754239,
      "grad_norm": 0.5119972825050354,
      "learning_rate": 4.995760500913123e-05,
      "loss": 0.2261,
      "step": 650
    },
    {
      "epoch": 0.09131228802504565,
      "grad_norm": 0.4838067591190338,
      "learning_rate": 4.9954343855987476e-05,
      "loss": 0.3126,
      "step": 700
    },
    {
      "epoch": 0.09783459431254891,
      "grad_norm": 3.383789300918579,
      "learning_rate": 4.995108270284373e-05,
      "loss": 0.2897,
      "step": 750
    },
    {
      "epoch": 0.10435690060005218,
      "grad_norm": 2.0633838176727295,
      "learning_rate": 4.9947821549699975e-05,
      "loss": 0.2409,
      "step": 800
    },
    {
      "epoch": 0.11087920688755544,
      "grad_norm": 4.859091758728027,
      "learning_rate": 4.994456039655622e-05,
      "loss": 0.2816,
      "step": 850
    },
    {
      "epoch": 0.1174015131750587,
      "grad_norm": 7.501410484313965,
      "learning_rate": 4.994129924341247e-05,
      "loss": 0.2274,
      "step": 900
    },
    {
      "epoch": 0.12392381946256197,
      "grad_norm": 16.2131404876709,
      "learning_rate": 4.993803809026873e-05,
      "loss": 0.2721,
      "step": 950
    },
    {
      "epoch": 0.13044612575006523,
      "grad_norm": 12.01689338684082,
      "learning_rate": 4.9934776937124973e-05,
      "loss": 0.2732,
      "step": 1000
    },
    {
      "epoch": 0.13696843203756848,
      "grad_norm": 6.703930377960205,
      "learning_rate": 4.993151578398122e-05,
      "loss": 0.2668,
      "step": 1050
    },
    {
      "epoch": 0.14349073832507175,
      "grad_norm": 14.21306324005127,
      "learning_rate": 4.9928254630837466e-05,
      "loss": 0.1754,
      "step": 1100
    },
    {
      "epoch": 0.150013044612575,
      "grad_norm": 31.001014709472656,
      "learning_rate": 4.992499347769372e-05,
      "loss": 0.2363,
      "step": 1150
    },
    {
      "epoch": 0.15653535090007828,
      "grad_norm": 8.756136894226074,
      "learning_rate": 4.9921732324549965e-05,
      "loss": 0.1815,
      "step": 1200
    },
    {
      "epoch": 0.16305765718758153,
      "grad_norm": 0.2485734075307846,
      "learning_rate": 4.991847117140621e-05,
      "loss": 0.244,
      "step": 1250
    },
    {
      "epoch": 0.16957996347508478,
      "grad_norm": 1.5809521675109863,
      "learning_rate": 4.991521001826246e-05,
      "loss": 0.2463,
      "step": 1300
    },
    {
      "epoch": 0.17610226976258805,
      "grad_norm": 0.1712278127670288,
      "learning_rate": 4.991194886511871e-05,
      "loss": 0.3025,
      "step": 1350
    },
    {
      "epoch": 0.1826245760500913,
      "grad_norm": 11.780902862548828,
      "learning_rate": 4.9908687711974957e-05,
      "loss": 0.2574,
      "step": 1400
    },
    {
      "epoch": 0.18914688233759458,
      "grad_norm": 6.596933841705322,
      "learning_rate": 4.99054265588312e-05,
      "loss": 0.2211,
      "step": 1450
    },
    {
      "epoch": 0.19566918862509783,
      "grad_norm": 0.4336800277233124,
      "learning_rate": 4.990216540568745e-05,
      "loss": 0.2481,
      "step": 1500
    },
    {
      "epoch": 0.2021914949126011,
      "grad_norm": 0.3276211619377136,
      "learning_rate": 4.98989042525437e-05,
      "loss": 0.1763,
      "step": 1550
    },
    {
      "epoch": 0.20871380120010435,
      "grad_norm": 6.574683666229248,
      "learning_rate": 4.9895643099399955e-05,
      "loss": 0.1547,
      "step": 1600
    },
    {
      "epoch": 0.21523610748760763,
      "grad_norm": 0.08545052260160446,
      "learning_rate": 4.98923819462562e-05,
      "loss": 0.2383,
      "step": 1650
    },
    {
      "epoch": 0.22175841377511088,
      "grad_norm": 0.4472591280937195,
      "learning_rate": 4.988912079311245e-05,
      "loss": 0.2469,
      "step": 1700
    },
    {
      "epoch": 0.22828072006261413,
      "grad_norm": 3.154181480407715,
      "learning_rate": 4.988585963996869e-05,
      "loss": 0.2386,
      "step": 1750
    },
    {
      "epoch": 0.2348030263501174,
      "grad_norm": 4.079367637634277,
      "learning_rate": 4.9882598486824946e-05,
      "loss": 0.223,
      "step": 1800
    },
    {
      "epoch": 0.24132533263762065,
      "grad_norm": 14.305359840393066,
      "learning_rate": 4.987933733368119e-05,
      "loss": 0.2405,
      "step": 1850
    },
    {
      "epoch": 0.24784763892512393,
      "grad_norm": 10.176475524902344,
      "learning_rate": 4.987607618053744e-05,
      "loss": 0.1917,
      "step": 1900
    },
    {
      "epoch": 0.2543699452126272,
      "grad_norm": 11.492831230163574,
      "learning_rate": 4.9872815027393685e-05,
      "loss": 0.2046,
      "step": 1950
    },
    {
      "epoch": 0.26089225150013046,
      "grad_norm": 17.288833618164062,
      "learning_rate": 4.986955387424994e-05,
      "loss": 0.2491,
      "step": 2000
    },
    {
      "epoch": 0.26741455778763373,
      "grad_norm": 1.2900736331939697,
      "learning_rate": 4.9866292721106184e-05,
      "loss": 0.204,
      "step": 2050
    },
    {
      "epoch": 0.27393686407513695,
      "grad_norm": 3.021862268447876,
      "learning_rate": 4.986303156796243e-05,
      "loss": 0.1903,
      "step": 2100
    },
    {
      "epoch": 0.28045917036264023,
      "grad_norm": 11.424671173095703,
      "learning_rate": 4.985977041481868e-05,
      "loss": 0.2168,
      "step": 2150
    },
    {
      "epoch": 0.2869814766501435,
      "grad_norm": 0.10498014837503433,
      "learning_rate": 4.9856509261674936e-05,
      "loss": 0.1253,
      "step": 2200
    },
    {
      "epoch": 0.29350378293764673,
      "grad_norm": 18.671924591064453,
      "learning_rate": 4.985324810853118e-05,
      "loss": 0.2448,
      "step": 2250
    },
    {
      "epoch": 0.30002608922515,
      "grad_norm": 9.47288703918457,
      "learning_rate": 4.984998695538743e-05,
      "loss": 0.2387,
      "step": 2300
    },
    {
      "epoch": 0.3065483955126533,
      "grad_norm": 3.055468797683716,
      "learning_rate": 4.9846725802243675e-05,
      "loss": 0.1858,
      "step": 2350
    },
    {
      "epoch": 0.31307070180015656,
      "grad_norm": 12.78332805633545,
      "learning_rate": 4.984346464909993e-05,
      "loss": 0.2211,
      "step": 2400
    },
    {
      "epoch": 0.3195930080876598,
      "grad_norm": 12.09874439239502,
      "learning_rate": 4.9840203495956174e-05,
      "loss": 0.2343,
      "step": 2450
    },
    {
      "epoch": 0.32611531437516306,
      "grad_norm": 9.843269348144531,
      "learning_rate": 4.983694234281242e-05,
      "loss": 0.2632,
      "step": 2500
    },
    {
      "epoch": 0.33263762066266633,
      "grad_norm": 12.69819450378418,
      "learning_rate": 4.9833681189668666e-05,
      "loss": 0.2197,
      "step": 2550
    },
    {
      "epoch": 0.33915992695016955,
      "grad_norm": 0.19031094014644623,
      "learning_rate": 4.983042003652492e-05,
      "loss": 0.1929,
      "step": 2600
    },
    {
      "epoch": 0.34568223323767283,
      "grad_norm": 2.1541061401367188,
      "learning_rate": 4.9827158883381165e-05,
      "loss": 0.224,
      "step": 2650
    },
    {
      "epoch": 0.3522045395251761,
      "grad_norm": 0.2199256271123886,
      "learning_rate": 4.982389773023741e-05,
      "loss": 0.2201,
      "step": 2700
    },
    {
      "epoch": 0.3587268458126794,
      "grad_norm": 5.402563095092773,
      "learning_rate": 4.982063657709366e-05,
      "loss": 0.1473,
      "step": 2750
    },
    {
      "epoch": 0.3652491521001826,
      "grad_norm": 0.15416684746742249,
      "learning_rate": 4.981737542394991e-05,
      "loss": 0.1591,
      "step": 2800
    },
    {
      "epoch": 0.3717714583876859,
      "grad_norm": 0.0819464772939682,
      "learning_rate": 4.9814114270806164e-05,
      "loss": 0.193,
      "step": 2850
    },
    {
      "epoch": 0.37829376467518916,
      "grad_norm": 0.1729971021413803,
      "learning_rate": 4.981085311766241e-05,
      "loss": 0.1815,
      "step": 2900
    },
    {
      "epoch": 0.3848160709626924,
      "grad_norm": 10.588757514953613,
      "learning_rate": 4.9807591964518656e-05,
      "loss": 0.1895,
      "step": 2950
    },
    {
      "epoch": 0.39133837725019566,
      "grad_norm": 0.32037603855133057,
      "learning_rate": 4.98043308113749e-05,
      "loss": 0.2031,
      "step": 3000
    },
    {
      "epoch": 0.39786068353769893,
      "grad_norm": 0.4310210049152374,
      "learning_rate": 4.9801069658231155e-05,
      "loss": 0.1672,
      "step": 3050
    },
    {
      "epoch": 0.4043829898252022,
      "grad_norm": 0.10743264853954315,
      "learning_rate": 4.97978085050874e-05,
      "loss": 0.2188,
      "step": 3100
    },
    {
      "epoch": 0.41090529611270543,
      "grad_norm": 21.278209686279297,
      "learning_rate": 4.979454735194365e-05,
      "loss": 0.1742,
      "step": 3150
    },
    {
      "epoch": 0.4174276024002087,
      "grad_norm": 2.7129220962524414,
      "learning_rate": 4.9791286198799894e-05,
      "loss": 0.1701,
      "step": 3200
    },
    {
      "epoch": 0.423949908687712,
      "grad_norm": 1.2202503681182861,
      "learning_rate": 4.9788025045656147e-05,
      "loss": 0.1439,
      "step": 3250
    },
    {
      "epoch": 0.43047221497521526,
      "grad_norm": 0.9489358067512512,
      "learning_rate": 4.978476389251239e-05,
      "loss": 0.1901,
      "step": 3300
    },
    {
      "epoch": 0.4369945212627185,
      "grad_norm": 0.27583813667297363,
      "learning_rate": 4.978150273936864e-05,
      "loss": 0.1997,
      "step": 3350
    },
    {
      "epoch": 0.44351682755022176,
      "grad_norm": 3.4423253536224365,
      "learning_rate": 4.977824158622489e-05,
      "loss": 0.1924,
      "step": 3400
    },
    {
      "epoch": 0.45003913383772504,
      "grad_norm": 6.855611324310303,
      "learning_rate": 4.9774980433081145e-05,
      "loss": 0.1796,
      "step": 3450
    },
    {
      "epoch": 0.45656144012522826,
      "grad_norm": 0.05974139645695686,
      "learning_rate": 4.977171927993739e-05,
      "loss": 0.1403,
      "step": 3500
    },
    {
      "epoch": 0.46308374641273153,
      "grad_norm": 22.584850311279297,
      "learning_rate": 4.976845812679364e-05,
      "loss": 0.1854,
      "step": 3550
    },
    {
      "epoch": 0.4696060527002348,
      "grad_norm": 7.6830153465271,
      "learning_rate": 4.9765196973649883e-05,
      "loss": 0.1831,
      "step": 3600
    },
    {
      "epoch": 0.4761283589877381,
      "grad_norm": 20.336353302001953,
      "learning_rate": 4.9761935820506136e-05,
      "loss": 0.0747,
      "step": 3650
    },
    {
      "epoch": 0.4826506652752413,
      "grad_norm": 0.16972312331199646,
      "learning_rate": 4.975867466736238e-05,
      "loss": 0.2311,
      "step": 3700
    },
    {
      "epoch": 0.4891729715627446,
      "grad_norm": 15.695637702941895,
      "learning_rate": 4.975541351421863e-05,
      "loss": 0.2047,
      "step": 3750
    },
    {
      "epoch": 0.49569527785024786,
      "grad_norm": 0.22720612585544586,
      "learning_rate": 4.9752152361074875e-05,
      "loss": 0.0987,
      "step": 3800
    },
    {
      "epoch": 0.5022175841377511,
      "grad_norm": 0.18265967071056366,
      "learning_rate": 4.974889120793113e-05,
      "loss": 0.2294,
      "step": 3850
    },
    {
      "epoch": 0.5087398904252544,
      "grad_norm": 18.605350494384766,
      "learning_rate": 4.9745630054787374e-05,
      "loss": 0.263,
      "step": 3900
    },
    {
      "epoch": 0.5152621967127576,
      "grad_norm": 0.12067294120788574,
      "learning_rate": 4.974236890164362e-05,
      "loss": 0.1622,
      "step": 3950
    },
    {
      "epoch": 0.5217845030002609,
      "grad_norm": 0.26092758774757385,
      "learning_rate": 4.973910774849987e-05,
      "loss": 0.2226,
      "step": 4000
    },
    {
      "epoch": 0.5283068092877642,
      "grad_norm": 10.43722915649414,
      "learning_rate": 4.973584659535612e-05,
      "loss": 0.1609,
      "step": 4050
    },
    {
      "epoch": 0.5348291155752675,
      "grad_norm": 0.18499372899532318,
      "learning_rate": 4.973258544221237e-05,
      "loss": 0.1512,
      "step": 4100
    },
    {
      "epoch": 0.5413514218627706,
      "grad_norm": 9.374879837036133,
      "learning_rate": 4.972932428906862e-05,
      "loss": 0.1266,
      "step": 4150
    },
    {
      "epoch": 0.5478737281502739,
      "grad_norm": 8.308425903320312,
      "learning_rate": 4.9726063135924865e-05,
      "loss": 0.149,
      "step": 4200
    },
    {
      "epoch": 0.5543960344377772,
      "grad_norm": 0.8750492930412292,
      "learning_rate": 4.972280198278111e-05,
      "loss": 0.2094,
      "step": 4250
    },
    {
      "epoch": 0.5609183407252805,
      "grad_norm": 0.19748136401176453,
      "learning_rate": 4.9719540829637364e-05,
      "loss": 0.1871,
      "step": 4300
    },
    {
      "epoch": 0.5674406470127837,
      "grad_norm": 0.21060581505298615,
      "learning_rate": 4.971627967649361e-05,
      "loss": 0.2029,
      "step": 4350
    },
    {
      "epoch": 0.573962953300287,
      "grad_norm": 0.36269116401672363,
      "learning_rate": 4.9713018523349856e-05,
      "loss": 0.1675,
      "step": 4400
    },
    {
      "epoch": 0.5804852595877903,
      "grad_norm": 0.049797605723142624,
      "learning_rate": 4.970975737020611e-05,
      "loss": 0.1945,
      "step": 4450
    },
    {
      "epoch": 0.5870075658752935,
      "grad_norm": 8.526690483093262,
      "learning_rate": 4.9706496217062355e-05,
      "loss": 0.1685,
      "step": 4500
    },
    {
      "epoch": 0.5935298721627967,
      "grad_norm": 1.1158182621002197,
      "learning_rate": 4.97032350639186e-05,
      "loss": 0.1758,
      "step": 4550
    },
    {
      "epoch": 0.6000521784503,
      "grad_norm": 11.526693344116211,
      "learning_rate": 4.969997391077485e-05,
      "loss": 0.2071,
      "step": 4600
    },
    {
      "epoch": 0.6065744847378033,
      "grad_norm": 0.057317085564136505,
      "learning_rate": 4.96967127576311e-05,
      "loss": 0.186,
      "step": 4650
    },
    {
      "epoch": 0.6130967910253066,
      "grad_norm": 0.29793781042099,
      "learning_rate": 4.9693451604487354e-05,
      "loss": 0.2473,
      "step": 4700
    },
    {
      "epoch": 0.6196190973128098,
      "grad_norm": 6.793952465057373,
      "learning_rate": 4.96901904513436e-05,
      "loss": 0.1828,
      "step": 4750
    },
    {
      "epoch": 0.6261414036003131,
      "grad_norm": 19.73169708251953,
      "learning_rate": 4.9686929298199846e-05,
      "loss": 0.1672,
      "step": 4800
    },
    {
      "epoch": 0.6326637098878163,
      "grad_norm": 7.371987819671631,
      "learning_rate": 4.968366814505609e-05,
      "loss": 0.1919,
      "step": 4850
    },
    {
      "epoch": 0.6391860161753196,
      "grad_norm": 8.063996315002441,
      "learning_rate": 4.9680406991912345e-05,
      "loss": 0.1536,
      "step": 4900
    },
    {
      "epoch": 0.6457083224628228,
      "grad_norm": 0.19997385144233704,
      "learning_rate": 4.967714583876859e-05,
      "loss": 0.134,
      "step": 4950
    },
    {
      "epoch": 0.6522306287503261,
      "grad_norm": 5.502964496612549,
      "learning_rate": 4.967388468562484e-05,
      "loss": 0.2001,
      "step": 5000
    },
    {
      "epoch": 0.6587529350378294,
      "grad_norm": 5.224625587463379,
      "learning_rate": 4.9670623532481084e-05,
      "loss": 0.2024,
      "step": 5050
    },
    {
      "epoch": 0.6652752413253327,
      "grad_norm": 0.25403252243995667,
      "learning_rate": 4.966736237933734e-05,
      "loss": 0.2048,
      "step": 5100
    },
    {
      "epoch": 0.6717975476128359,
      "grad_norm": 10.792101860046387,
      "learning_rate": 4.966410122619358e-05,
      "loss": 0.1993,
      "step": 5150
    },
    {
      "epoch": 0.6783198539003391,
      "grad_norm": 8.054540634155273,
      "learning_rate": 4.966084007304983e-05,
      "loss": 0.177,
      "step": 5200
    },
    {
      "epoch": 0.6848421601878424,
      "grad_norm": 17.112627029418945,
      "learning_rate": 4.965757891990608e-05,
      "loss": 0.1929,
      "step": 5250
    },
    {
      "epoch": 0.6913644664753457,
      "grad_norm": 1.7757079601287842,
      "learning_rate": 4.9654317766762335e-05,
      "loss": 0.199,
      "step": 5300
    },
    {
      "epoch": 0.6978867727628489,
      "grad_norm": 15.546021461486816,
      "learning_rate": 4.965105661361858e-05,
      "loss": 0.1594,
      "step": 5350
    },
    {
      "epoch": 0.7044090790503522,
      "grad_norm": 7.581511974334717,
      "learning_rate": 4.964779546047483e-05,
      "loss": 0.11,
      "step": 5400
    },
    {
      "epoch": 0.7109313853378555,
      "grad_norm": 0.19975358247756958,
      "learning_rate": 4.9644534307331073e-05,
      "loss": 0.1155,
      "step": 5450
    },
    {
      "epoch": 0.7174536916253588,
      "grad_norm": 8.908049583435059,
      "learning_rate": 4.9641273154187326e-05,
      "loss": 0.1604,
      "step": 5500
    },
    {
      "epoch": 0.7239759979128619,
      "grad_norm": 0.07027339935302734,
      "learning_rate": 4.963801200104357e-05,
      "loss": 0.1534,
      "step": 5550
    },
    {
      "epoch": 0.7304983042003652,
      "grad_norm": 17.624116897583008,
      "learning_rate": 4.963475084789982e-05,
      "loss": 0.1817,
      "step": 5600
    },
    {
      "epoch": 0.7370206104878685,
      "grad_norm": 0.894631564617157,
      "learning_rate": 4.9631489694756065e-05,
      "loss": 0.1982,
      "step": 5650
    },
    {
      "epoch": 0.7435429167753718,
      "grad_norm": 12.729527473449707,
      "learning_rate": 4.962822854161232e-05,
      "loss": 0.1802,
      "step": 5700
    },
    {
      "epoch": 0.750065223062875,
      "grad_norm": 0.043765582144260406,
      "learning_rate": 4.9624967388468564e-05,
      "loss": 0.1812,
      "step": 5750
    },
    {
      "epoch": 0.7565875293503783,
      "grad_norm": 13.59774112701416,
      "learning_rate": 4.962170623532481e-05,
      "loss": 0.1958,
      "step": 5800
    },
    {
      "epoch": 0.7631098356378816,
      "grad_norm": 0.5671758651733398,
      "learning_rate": 4.961844508218106e-05,
      "loss": 0.1768,
      "step": 5850
    },
    {
      "epoch": 0.7696321419253848,
      "grad_norm": 7.920388221740723,
      "learning_rate": 4.961518392903731e-05,
      "loss": 0.1432,
      "step": 5900
    },
    {
      "epoch": 0.776154448212888,
      "grad_norm": 0.08332566171884537,
      "learning_rate": 4.961192277589356e-05,
      "loss": 0.1565,
      "step": 5950
    },
    {
      "epoch": 0.7826767545003913,
      "grad_norm": 3.010265350341797,
      "learning_rate": 4.960866162274981e-05,
      "loss": 0.1704,
      "step": 6000
    },
    {
      "epoch": 0.7891990607878946,
      "grad_norm": 8.356209754943848,
      "learning_rate": 4.9605400469606055e-05,
      "loss": 0.2018,
      "step": 6050
    },
    {
      "epoch": 0.7957213670753979,
      "grad_norm": 10.428191184997559,
      "learning_rate": 4.96021393164623e-05,
      "loss": 0.1132,
      "step": 6100
    },
    {
      "epoch": 0.8022436733629011,
      "grad_norm": 6.667311668395996,
      "learning_rate": 4.9598878163318554e-05,
      "loss": 0.169,
      "step": 6150
    },
    {
      "epoch": 0.8087659796504044,
      "grad_norm": 17.158523559570312,
      "learning_rate": 4.95956170101748e-05,
      "loss": 0.2112,
      "step": 6200
    },
    {
      "epoch": 0.8152882859379077,
      "grad_norm": 0.8648687601089478,
      "learning_rate": 4.9592355857031046e-05,
      "loss": 0.2067,
      "step": 6250
    },
    {
      "epoch": 0.8218105922254109,
      "grad_norm": 1.7152613401412964,
      "learning_rate": 4.958909470388729e-05,
      "loss": 0.1202,
      "step": 6300
    },
    {
      "epoch": 0.8283328985129141,
      "grad_norm": 0.08493966609239578,
      "learning_rate": 4.9585833550743545e-05,
      "loss": 0.1772,
      "step": 6350
    },
    {
      "epoch": 0.8348552048004174,
      "grad_norm": 12.647686004638672,
      "learning_rate": 4.958257239759979e-05,
      "loss": 0.1545,
      "step": 6400
    },
    {
      "epoch": 0.8413775110879207,
      "grad_norm": 6.218901634216309,
      "learning_rate": 4.9579311244456045e-05,
      "loss": 0.143,
      "step": 6450
    },
    {
      "epoch": 0.847899817375424,
      "grad_norm": 0.025705652311444283,
      "learning_rate": 4.957605009131229e-05,
      "loss": 0.1825,
      "step": 6500
    },
    {
      "epoch": 0.8544221236629272,
      "grad_norm": 0.08214743435382843,
      "learning_rate": 4.9572788938168544e-05,
      "loss": 0.1485,
      "step": 6550
    },
    {
      "epoch": 0.8609444299504305,
      "grad_norm": 0.05921783670783043,
      "learning_rate": 4.956952778502479e-05,
      "loss": 0.1486,
      "step": 6600
    },
    {
      "epoch": 0.8674667362379337,
      "grad_norm": 0.25372180342674255,
      "learning_rate": 4.9566266631881036e-05,
      "loss": 0.1611,
      "step": 6650
    },
    {
      "epoch": 0.873989042525437,
      "grad_norm": 5.443910598754883,
      "learning_rate": 4.956300547873728e-05,
      "loss": 0.1846,
      "step": 6700
    },
    {
      "epoch": 0.8805113488129402,
      "grad_norm": 0.03632281720638275,
      "learning_rate": 4.9559744325593535e-05,
      "loss": 0.185,
      "step": 6750
    },
    {
      "epoch": 0.8870336551004435,
      "grad_norm": 12.243874549865723,
      "learning_rate": 4.955648317244978e-05,
      "loss": 0.1725,
      "step": 6800
    },
    {
      "epoch": 0.8935559613879468,
      "grad_norm": 11.601298332214355,
      "learning_rate": 4.955322201930603e-05,
      "loss": 0.1279,
      "step": 6850
    },
    {
      "epoch": 0.9000782676754501,
      "grad_norm": 15.490622520446777,
      "learning_rate": 4.9549960866162274e-05,
      "loss": 0.1697,
      "step": 6900
    },
    {
      "epoch": 0.9066005739629533,
      "grad_norm": 0.3351600468158722,
      "learning_rate": 4.954669971301853e-05,
      "loss": 0.1846,
      "step": 6950
    },
    {
      "epoch": 0.9131228802504565,
      "grad_norm": 8.848963737487793,
      "learning_rate": 4.954343855987477e-05,
      "loss": 0.1676,
      "step": 7000
    },
    {
      "epoch": 0.9196451865379598,
      "grad_norm": 5.7007575035095215,
      "learning_rate": 4.954017740673102e-05,
      "loss": 0.1551,
      "step": 7050
    },
    {
      "epoch": 0.9261674928254631,
      "grad_norm": 0.03685647249221802,
      "learning_rate": 4.953691625358727e-05,
      "loss": 0.1747,
      "step": 7100
    },
    {
      "epoch": 0.9326897991129663,
      "grad_norm": 11.760647773742676,
      "learning_rate": 4.953365510044352e-05,
      "loss": 0.1934,
      "step": 7150
    },
    {
      "epoch": 0.9392121054004696,
      "grad_norm": 8.89401912689209,
      "learning_rate": 4.953039394729977e-05,
      "loss": 0.1306,
      "step": 7200
    },
    {
      "epoch": 0.9457344116879729,
      "grad_norm": 0.0476493239402771,
      "learning_rate": 4.952713279415602e-05,
      "loss": 0.1074,
      "step": 7250
    },
    {
      "epoch": 0.9522567179754762,
      "grad_norm": 19.18907356262207,
      "learning_rate": 4.9523871641012264e-05,
      "loss": 0.1221,
      "step": 7300
    },
    {
      "epoch": 0.9587790242629793,
      "grad_norm": 0.04121912270784378,
      "learning_rate": 4.952061048786851e-05,
      "loss": 0.1351,
      "step": 7350
    },
    {
      "epoch": 0.9653013305504826,
      "grad_norm": 18.135339736938477,
      "learning_rate": 4.951734933472476e-05,
      "loss": 0.1733,
      "step": 7400
    },
    {
      "epoch": 0.9718236368379859,
      "grad_norm": 17.0824031829834,
      "learning_rate": 4.951408818158101e-05,
      "loss": 0.1165,
      "step": 7450
    },
    {
      "epoch": 0.9783459431254892,
      "grad_norm": 0.09104923903942108,
      "learning_rate": 4.9510827028437255e-05,
      "loss": 0.138,
      "step": 7500
    },
    {
      "epoch": 0.9848682494129924,
      "grad_norm": 3.279834508895874,
      "learning_rate": 4.95075658752935e-05,
      "loss": 0.0997,
      "step": 7550
    },
    {
      "epoch": 0.9913905557004957,
      "grad_norm": 22.104568481445312,
      "learning_rate": 4.9504304722149754e-05,
      "loss": 0.2204,
      "step": 7600
    },
    {
      "epoch": 0.997912861987999,
      "grad_norm": 18.1333065032959,
      "learning_rate": 4.9501043569006e-05,
      "loss": 0.1294,
      "step": 7650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.952061048786851,
      "eval_f1": 0.9529720391579756,
      "eval_loss": 0.18929840624332428,
      "eval_precision": 0.9354352468282879,
      "eval_recall": 0.9711789254042775,
      "eval_runtime": 23.5615,
      "eval_samples_per_second": 650.722,
      "eval_steps_per_second": 81.361,
      "step": 7666
    },
    {
      "epoch": 1.0044351682755022,
      "grad_norm": 0.029680388048291206,
      "learning_rate": 4.949778241586225e-05,
      "loss": 0.1426,
      "step": 7700
    },
    {
      "epoch": 1.0109574745630054,
      "grad_norm": 0.08249599486589432,
      "learning_rate": 4.94945212627185e-05,
      "loss": 0.1901,
      "step": 7750
    },
    {
      "epoch": 1.0174797808505087,
      "grad_norm": 2.276320695877075,
      "learning_rate": 4.949126010957475e-05,
      "loss": 0.1187,
      "step": 7800
    },
    {
      "epoch": 1.024002087138012,
      "grad_norm": 0.06490237265825272,
      "learning_rate": 4.9487998956431e-05,
      "loss": 0.1038,
      "step": 7850
    },
    {
      "epoch": 1.0305243934255153,
      "grad_norm": 0.023925354704260826,
      "learning_rate": 4.9484737803287245e-05,
      "loss": 0.2552,
      "step": 7900
    },
    {
      "epoch": 1.0370466997130185,
      "grad_norm": 2.66922926902771,
      "learning_rate": 4.948147665014349e-05,
      "loss": 0.1634,
      "step": 7950
    },
    {
      "epoch": 1.0435690060005218,
      "grad_norm": 0.10835734754800797,
      "learning_rate": 4.9478215496999744e-05,
      "loss": 0.2142,
      "step": 8000
    },
    {
      "epoch": 1.050091312288025,
      "grad_norm": 0.25738993287086487,
      "learning_rate": 4.947495434385599e-05,
      "loss": 0.221,
      "step": 8050
    },
    {
      "epoch": 1.0566136185755284,
      "grad_norm": 9.672103881835938,
      "learning_rate": 4.9471693190712236e-05,
      "loss": 0.1306,
      "step": 8100
    },
    {
      "epoch": 1.0631359248630317,
      "grad_norm": 0.11298777163028717,
      "learning_rate": 4.946843203756848e-05,
      "loss": 0.2079,
      "step": 8150
    },
    {
      "epoch": 1.069658231150535,
      "grad_norm": 0.15063633024692535,
      "learning_rate": 4.9465170884424736e-05,
      "loss": 0.1245,
      "step": 8200
    },
    {
      "epoch": 1.076180537438038,
      "grad_norm": 0.08894822001457214,
      "learning_rate": 4.946190973128098e-05,
      "loss": 0.1527,
      "step": 8250
    },
    {
      "epoch": 1.0827028437255413,
      "grad_norm": 0.3505430519580841,
      "learning_rate": 4.9458648578137235e-05,
      "loss": 0.2072,
      "step": 8300
    },
    {
      "epoch": 1.0892251500130445,
      "grad_norm": 0.03174867853522301,
      "learning_rate": 4.945538742499348e-05,
      "loss": 0.1426,
      "step": 8350
    },
    {
      "epoch": 1.0957474563005478,
      "grad_norm": 9.296687126159668,
      "learning_rate": 4.945212627184973e-05,
      "loss": 0.224,
      "step": 8400
    },
    {
      "epoch": 1.102269762588051,
      "grad_norm": 6.648766040802002,
      "learning_rate": 4.944886511870598e-05,
      "loss": 0.1363,
      "step": 8450
    },
    {
      "epoch": 1.1087920688755544,
      "grad_norm": 0.19769112765789032,
      "learning_rate": 4.9445603965562226e-05,
      "loss": 0.1631,
      "step": 8500
    },
    {
      "epoch": 1.1153143751630576,
      "grad_norm": 1.1273980140686035,
      "learning_rate": 4.944234281241847e-05,
      "loss": 0.1224,
      "step": 8550
    },
    {
      "epoch": 1.121836681450561,
      "grad_norm": 2.854771137237549,
      "learning_rate": 4.943908165927472e-05,
      "loss": 0.1123,
      "step": 8600
    },
    {
      "epoch": 1.1283589877380642,
      "grad_norm": 3.507751226425171,
      "learning_rate": 4.943582050613097e-05,
      "loss": 0.2121,
      "step": 8650
    },
    {
      "epoch": 1.1348812940255675,
      "grad_norm": 0.06448671221733093,
      "learning_rate": 4.943255935298722e-05,
      "loss": 0.1651,
      "step": 8700
    },
    {
      "epoch": 1.1414036003130708,
      "grad_norm": 0.1402260959148407,
      "learning_rate": 4.9429298199843464e-05,
      "loss": 0.1265,
      "step": 8750
    },
    {
      "epoch": 1.147925906600574,
      "grad_norm": 11.904061317443848,
      "learning_rate": 4.942603704669972e-05,
      "loss": 0.2108,
      "step": 8800
    },
    {
      "epoch": 1.1544482128880773,
      "grad_norm": 1.5853979587554932,
      "learning_rate": 4.942277589355596e-05,
      "loss": 0.1768,
      "step": 8850
    },
    {
      "epoch": 1.1609705191755806,
      "grad_norm": 0.0902138352394104,
      "learning_rate": 4.941951474041221e-05,
      "loss": 0.1839,
      "step": 8900
    },
    {
      "epoch": 1.1674928254630839,
      "grad_norm": 0.05027575045824051,
      "learning_rate": 4.941625358726846e-05,
      "loss": 0.1263,
      "step": 8950
    },
    {
      "epoch": 1.174015131750587,
      "grad_norm": 5.000917911529541,
      "learning_rate": 4.941299243412471e-05,
      "loss": 0.1276,
      "step": 9000
    },
    {
      "epoch": 1.1805374380380902,
      "grad_norm": 0.8007508516311646,
      "learning_rate": 4.940973128098096e-05,
      "loss": 0.1841,
      "step": 9050
    },
    {
      "epoch": 1.1870597443255935,
      "grad_norm": 12.712356567382812,
      "learning_rate": 4.940647012783721e-05,
      "loss": 0.126,
      "step": 9100
    },
    {
      "epoch": 1.1935820506130967,
      "grad_norm": 12.789241790771484,
      "learning_rate": 4.9403208974693454e-05,
      "loss": 0.1811,
      "step": 9150
    },
    {
      "epoch": 1.2001043569006,
      "grad_norm": 9.286559104919434,
      "learning_rate": 4.93999478215497e-05,
      "loss": 0.1239,
      "step": 9200
    },
    {
      "epoch": 1.2066266631881033,
      "grad_norm": 0.03702450171113014,
      "learning_rate": 4.939668666840595e-05,
      "loss": 0.1509,
      "step": 9250
    },
    {
      "epoch": 1.2131489694756066,
      "grad_norm": 0.5341092348098755,
      "learning_rate": 4.93934255152622e-05,
      "loss": 0.1135,
      "step": 9300
    },
    {
      "epoch": 1.2196712757631099,
      "grad_norm": 0.14695686101913452,
      "learning_rate": 4.9390164362118445e-05,
      "loss": 0.2023,
      "step": 9350
    },
    {
      "epoch": 1.2261935820506131,
      "grad_norm": 0.26964622735977173,
      "learning_rate": 4.938690320897469e-05,
      "loss": 0.1857,
      "step": 9400
    },
    {
      "epoch": 1.2327158883381164,
      "grad_norm": 19.543212890625,
      "learning_rate": 4.9383642055830944e-05,
      "loss": 0.2221,
      "step": 9450
    },
    {
      "epoch": 1.2392381946256197,
      "grad_norm": 1.123460292816162,
      "learning_rate": 4.938038090268719e-05,
      "loss": 0.1134,
      "step": 9500
    },
    {
      "epoch": 1.245760500913123,
      "grad_norm": 26.01698112487793,
      "learning_rate": 4.9377119749543443e-05,
      "loss": 0.1466,
      "step": 9550
    },
    {
      "epoch": 1.252282807200626,
      "grad_norm": 0.130290225148201,
      "learning_rate": 4.937385859639969e-05,
      "loss": 0.207,
      "step": 9600
    },
    {
      "epoch": 1.2588051134881293,
      "grad_norm": 3.9848320484161377,
      "learning_rate": 4.937059744325594e-05,
      "loss": 0.1113,
      "step": 9650
    },
    {
      "epoch": 1.2653274197756326,
      "grad_norm": 4.527751445770264,
      "learning_rate": 4.936733629011219e-05,
      "loss": 0.1276,
      "step": 9700
    },
    {
      "epoch": 1.2718497260631358,
      "grad_norm": 0.2510732114315033,
      "learning_rate": 4.9364075136968435e-05,
      "loss": 0.1539,
      "step": 9750
    },
    {
      "epoch": 1.2783720323506391,
      "grad_norm": 0.4203438460826874,
      "learning_rate": 4.936081398382468e-05,
      "loss": 0.1347,
      "step": 9800
    },
    {
      "epoch": 1.2848943386381424,
      "grad_norm": 0.06154350936412811,
      "learning_rate": 4.9357552830680934e-05,
      "loss": 0.0969,
      "step": 9850
    },
    {
      "epoch": 1.2914166449256457,
      "grad_norm": 14.500316619873047,
      "learning_rate": 4.935429167753718e-05,
      "loss": 0.1309,
      "step": 9900
    },
    {
      "epoch": 1.297938951213149,
      "grad_norm": 10.916303634643555,
      "learning_rate": 4.9351030524393426e-05,
      "loss": 0.1102,
      "step": 9950
    },
    {
      "epoch": 1.3044612575006522,
      "grad_norm": 8.170787811279297,
      "learning_rate": 4.934776937124967e-05,
      "loss": 0.0916,
      "step": 10000
    },
    {
      "epoch": 1.3109835637881555,
      "grad_norm": 0.03792509436607361,
      "learning_rate": 4.9344508218105926e-05,
      "loss": 0.2148,
      "step": 10050
    },
    {
      "epoch": 1.3175058700756588,
      "grad_norm": 12.986190795898438,
      "learning_rate": 4.934124706496217e-05,
      "loss": 0.1366,
      "step": 10100
    },
    {
      "epoch": 1.324028176363162,
      "grad_norm": 0.3717796206474304,
      "learning_rate": 4.9337985911818425e-05,
      "loss": 0.187,
      "step": 10150
    },
    {
      "epoch": 1.3305504826506653,
      "grad_norm": 9.827569961547852,
      "learning_rate": 4.933472475867467e-05,
      "loss": 0.146,
      "step": 10200
    },
    {
      "epoch": 1.3370727889381686,
      "grad_norm": 0.03282866254448891,
      "learning_rate": 4.933146360553092e-05,
      "loss": 0.1581,
      "step": 10250
    },
    {
      "epoch": 1.3435950952256719,
      "grad_norm": 1.470916986465454,
      "learning_rate": 4.932820245238717e-05,
      "loss": 0.2296,
      "step": 10300
    },
    {
      "epoch": 1.3501174015131752,
      "grad_norm": 2.582913875579834,
      "learning_rate": 4.9324941299243416e-05,
      "loss": 0.2063,
      "step": 10350
    },
    {
      "epoch": 1.3566397078006784,
      "grad_norm": 9.903416633605957,
      "learning_rate": 4.932168014609966e-05,
      "loss": 0.1652,
      "step": 10400
    },
    {
      "epoch": 1.3631620140881817,
      "grad_norm": 7.475398063659668,
      "learning_rate": 4.931841899295591e-05,
      "loss": 0.1834,
      "step": 10450
    },
    {
      "epoch": 1.3696843203756848,
      "grad_norm": 8.163117408752441,
      "learning_rate": 4.931515783981216e-05,
      "loss": 0.095,
      "step": 10500
    },
    {
      "epoch": 1.376206626663188,
      "grad_norm": 1.3570138216018677,
      "learning_rate": 4.931189668666841e-05,
      "loss": 0.1467,
      "step": 10550
    },
    {
      "epoch": 1.3827289329506913,
      "grad_norm": 9.862037658691406,
      "learning_rate": 4.9308635533524654e-05,
      "loss": 0.1457,
      "step": 10600
    },
    {
      "epoch": 1.3892512392381946,
      "grad_norm": 0.07838203758001328,
      "learning_rate": 4.93053743803809e-05,
      "loss": 0.174,
      "step": 10650
    },
    {
      "epoch": 1.3957735455256979,
      "grad_norm": 2.6893179416656494,
      "learning_rate": 4.930211322723715e-05,
      "loss": 0.1387,
      "step": 10700
    },
    {
      "epoch": 1.4022958518132012,
      "grad_norm": 0.06259656697511673,
      "learning_rate": 4.9298852074093406e-05,
      "loss": 0.1555,
      "step": 10750
    },
    {
      "epoch": 1.4088181581007044,
      "grad_norm": 10.037821769714355,
      "learning_rate": 4.929559092094965e-05,
      "loss": 0.12,
      "step": 10800
    },
    {
      "epoch": 1.4153404643882077,
      "grad_norm": 0.05161977559328079,
      "learning_rate": 4.92923297678059e-05,
      "loss": 0.1343,
      "step": 10850
    },
    {
      "epoch": 1.421862770675711,
      "grad_norm": 4.908941745758057,
      "learning_rate": 4.928906861466215e-05,
      "loss": 0.1752,
      "step": 10900
    },
    {
      "epoch": 1.4283850769632143,
      "grad_norm": 8.48225212097168,
      "learning_rate": 4.92858074615184e-05,
      "loss": 0.1249,
      "step": 10950
    },
    {
      "epoch": 1.4349073832507173,
      "grad_norm": 0.11953075230121613,
      "learning_rate": 4.9282546308374644e-05,
      "loss": 0.1998,
      "step": 11000
    },
    {
      "epoch": 1.4414296895382206,
      "grad_norm": 0.7883279323577881,
      "learning_rate": 4.927928515523089e-05,
      "loss": 0.2415,
      "step": 11050
    },
    {
      "epoch": 1.4479519958257239,
      "grad_norm": 6.495589733123779,
      "learning_rate": 4.927602400208714e-05,
      "loss": 0.1629,
      "step": 11100
    },
    {
      "epoch": 1.4544743021132271,
      "grad_norm": 0.29720333218574524,
      "learning_rate": 4.927276284894339e-05,
      "loss": 0.1217,
      "step": 11150
    },
    {
      "epoch": 1.4609966084007304,
      "grad_norm": 13.479442596435547,
      "learning_rate": 4.9269501695799635e-05,
      "loss": 0.1279,
      "step": 11200
    },
    {
      "epoch": 1.4675189146882337,
      "grad_norm": 4.488462924957275,
      "learning_rate": 4.926624054265588e-05,
      "loss": 0.1225,
      "step": 11250
    },
    {
      "epoch": 1.474041220975737,
      "grad_norm": 15.128047943115234,
      "learning_rate": 4.9262979389512134e-05,
      "loss": 0.1555,
      "step": 11300
    },
    {
      "epoch": 1.4805635272632403,
      "grad_norm": 5.063409805297852,
      "learning_rate": 4.925971823636838e-05,
      "loss": 0.2358,
      "step": 11350
    },
    {
      "epoch": 1.4870858335507435,
      "grad_norm": 12.150768280029297,
      "learning_rate": 4.9256457083224634e-05,
      "loss": 0.1947,
      "step": 11400
    },
    {
      "epoch": 1.4936081398382468,
      "grad_norm": 3.5594606399536133,
      "learning_rate": 4.925319593008088e-05,
      "loss": 0.1643,
      "step": 11450
    },
    {
      "epoch": 1.50013044612575,
      "grad_norm": 0.08135796338319778,
      "learning_rate": 4.9249934776937126e-05,
      "loss": 0.0893,
      "step": 11500
    },
    {
      "epoch": 1.5066527524132534,
      "grad_norm": 12.55731201171875,
      "learning_rate": 4.924667362379338e-05,
      "loss": 0.1277,
      "step": 11550
    },
    {
      "epoch": 1.5131750587007566,
      "grad_norm": 0.6500549912452698,
      "learning_rate": 4.9243412470649625e-05,
      "loss": 0.1669,
      "step": 11600
    },
    {
      "epoch": 1.51969736498826,
      "grad_norm": 2.38120698928833,
      "learning_rate": 4.924015131750587e-05,
      "loss": 0.1834,
      "step": 11650
    },
    {
      "epoch": 1.5262196712757632,
      "grad_norm": 0.022633390501141548,
      "learning_rate": 4.923689016436212e-05,
      "loss": 0.1146,
      "step": 11700
    },
    {
      "epoch": 1.5327419775632665,
      "grad_norm": 7.943875312805176,
      "learning_rate": 4.923362901121837e-05,
      "loss": 0.1413,
      "step": 11750
    },
    {
      "epoch": 1.5392642838507697,
      "grad_norm": 0.024626685306429863,
      "learning_rate": 4.9230367858074617e-05,
      "loss": 0.1329,
      "step": 11800
    },
    {
      "epoch": 1.545786590138273,
      "grad_norm": 0.0882900133728981,
      "learning_rate": 4.922710670493086e-05,
      "loss": 0.1534,
      "step": 11850
    },
    {
      "epoch": 1.5523088964257763,
      "grad_norm": 16.158781051635742,
      "learning_rate": 4.922384555178711e-05,
      "loss": 0.1706,
      "step": 11900
    },
    {
      "epoch": 1.5588312027132796,
      "grad_norm": 0.13353069126605988,
      "learning_rate": 4.922058439864336e-05,
      "loss": 0.1753,
      "step": 11950
    },
    {
      "epoch": 1.5653535090007826,
      "grad_norm": 0.03527427464723587,
      "learning_rate": 4.9217323245499615e-05,
      "loss": 0.1499,
      "step": 12000
    },
    {
      "epoch": 1.571875815288286,
      "grad_norm": 0.3174355924129486,
      "learning_rate": 4.921406209235586e-05,
      "loss": 0.1339,
      "step": 12050
    },
    {
      "epoch": 1.5783981215757892,
      "grad_norm": 10.992573738098145,
      "learning_rate": 4.921080093921211e-05,
      "loss": 0.1125,
      "step": 12100
    },
    {
      "epoch": 1.5849204278632925,
      "grad_norm": 0.044996876269578934,
      "learning_rate": 4.920753978606836e-05,
      "loss": 0.1453,
      "step": 12150
    },
    {
      "epoch": 1.5914427341507957,
      "grad_norm": 0.19012446701526642,
      "learning_rate": 4.9204278632924606e-05,
      "loss": 0.1393,
      "step": 12200
    },
    {
      "epoch": 1.597965040438299,
      "grad_norm": 0.022473683580756187,
      "learning_rate": 4.920101747978085e-05,
      "loss": 0.1316,
      "step": 12250
    },
    {
      "epoch": 1.6044873467258023,
      "grad_norm": 8.740242958068848,
      "learning_rate": 4.91977563266371e-05,
      "loss": 0.1531,
      "step": 12300
    },
    {
      "epoch": 1.6110096530133053,
      "grad_norm": 26.715435028076172,
      "learning_rate": 4.919449517349335e-05,
      "loss": 0.1129,
      "step": 12350
    },
    {
      "epoch": 1.6175319593008086,
      "grad_norm": 8.216376304626465,
      "learning_rate": 4.91912340203496e-05,
      "loss": 0.1569,
      "step": 12400
    },
    {
      "epoch": 1.624054265588312,
      "grad_norm": 3.472539186477661,
      "learning_rate": 4.9187972867205844e-05,
      "loss": 0.1746,
      "step": 12450
    },
    {
      "epoch": 1.6305765718758152,
      "grad_norm": 0.047407086938619614,
      "learning_rate": 4.918471171406209e-05,
      "loss": 0.1627,
      "step": 12500
    },
    {
      "epoch": 1.6370988781633184,
      "grad_norm": 11.173812866210938,
      "learning_rate": 4.918145056091834e-05,
      "loss": 0.0814,
      "step": 12550
    },
    {
      "epoch": 1.6436211844508217,
      "grad_norm": 0.7784978747367859,
      "learning_rate": 4.9178189407774596e-05,
      "loss": 0.1676,
      "step": 12600
    },
    {
      "epoch": 1.650143490738325,
      "grad_norm": 0.041897229850292206,
      "learning_rate": 4.917492825463084e-05,
      "loss": 0.1218,
      "step": 12650
    },
    {
      "epoch": 1.6566657970258283,
      "grad_norm": 7.972092628479004,
      "learning_rate": 4.917166710148709e-05,
      "loss": 0.1636,
      "step": 12700
    },
    {
      "epoch": 1.6631881033133316,
      "grad_norm": 8.961977005004883,
      "learning_rate": 4.9168405948343335e-05,
      "loss": 0.1589,
      "step": 12750
    },
    {
      "epoch": 1.6697104096008348,
      "grad_norm": 15.051275253295898,
      "learning_rate": 4.916514479519959e-05,
      "loss": 0.1268,
      "step": 12800
    },
    {
      "epoch": 1.676232715888338,
      "grad_norm": 12.900424003601074,
      "learning_rate": 4.9161883642055834e-05,
      "loss": 0.1655,
      "step": 12850
    },
    {
      "epoch": 1.6827550221758414,
      "grad_norm": 7.558287620544434,
      "learning_rate": 4.915862248891208e-05,
      "loss": 0.1855,
      "step": 12900
    },
    {
      "epoch": 1.6892773284633447,
      "grad_norm": 4.653401851654053,
      "learning_rate": 4.915536133576833e-05,
      "loss": 0.1042,
      "step": 12950
    },
    {
      "epoch": 1.695799634750848,
      "grad_norm": 5.135610103607178,
      "learning_rate": 4.915210018262458e-05,
      "loss": 0.1336,
      "step": 13000
    },
    {
      "epoch": 1.7023219410383512,
      "grad_norm": 6.132026195526123,
      "learning_rate": 4.9148839029480825e-05,
      "loss": 0.174,
      "step": 13050
    },
    {
      "epoch": 1.7088442473258545,
      "grad_norm": 0.3347586393356323,
      "learning_rate": 4.914557787633707e-05,
      "loss": 0.1209,
      "step": 13100
    },
    {
      "epoch": 1.7153665536133578,
      "grad_norm": 0.12184639275074005,
      "learning_rate": 4.9142316723193324e-05,
      "loss": 0.1453,
      "step": 13150
    },
    {
      "epoch": 1.721888859900861,
      "grad_norm": 0.4861496686935425,
      "learning_rate": 4.913905557004957e-05,
      "loss": 0.1216,
      "step": 13200
    },
    {
      "epoch": 1.7284111661883643,
      "grad_norm": 0.30532968044281006,
      "learning_rate": 4.9135794416905824e-05,
      "loss": 0.1531,
      "step": 13250
    },
    {
      "epoch": 1.7349334724758676,
      "grad_norm": 0.12710657715797424,
      "learning_rate": 4.913253326376207e-05,
      "loss": 0.1365,
      "step": 13300
    },
    {
      "epoch": 1.7414557787633709,
      "grad_norm": 1.3087190389633179,
      "learning_rate": 4.9129272110618316e-05,
      "loss": 0.106,
      "step": 13350
    },
    {
      "epoch": 1.7479780850508742,
      "grad_norm": 0.8690595030784607,
      "learning_rate": 4.912601095747457e-05,
      "loss": 0.163,
      "step": 13400
    },
    {
      "epoch": 1.7545003913383772,
      "grad_norm": 10.750666618347168,
      "learning_rate": 4.9122749804330815e-05,
      "loss": 0.1085,
      "step": 13450
    },
    {
      "epoch": 1.7610226976258805,
      "grad_norm": 0.07144098728895187,
      "learning_rate": 4.911948865118706e-05,
      "loss": 0.0968,
      "step": 13500
    },
    {
      "epoch": 1.7675450039133838,
      "grad_norm": 0.02843225933611393,
      "learning_rate": 4.911622749804331e-05,
      "loss": 0.0873,
      "step": 13550
    },
    {
      "epoch": 1.774067310200887,
      "grad_norm": 16.843252182006836,
      "learning_rate": 4.911296634489956e-05,
      "loss": 0.1503,
      "step": 13600
    },
    {
      "epoch": 1.7805896164883903,
      "grad_norm": 0.15559811890125275,
      "learning_rate": 4.910970519175581e-05,
      "loss": 0.1616,
      "step": 13650
    },
    {
      "epoch": 1.7871119227758936,
      "grad_norm": 0.8442705273628235,
      "learning_rate": 4.910644403861205e-05,
      "loss": 0.1222,
      "step": 13700
    },
    {
      "epoch": 1.7936342290633969,
      "grad_norm": 0.05396546050906181,
      "learning_rate": 4.91031828854683e-05,
      "loss": 0.1076,
      "step": 13750
    },
    {
      "epoch": 1.8001565353509,
      "grad_norm": 0.5111071467399597,
      "learning_rate": 4.909992173232455e-05,
      "loss": 0.144,
      "step": 13800
    },
    {
      "epoch": 1.8066788416384032,
      "grad_norm": 11.133477210998535,
      "learning_rate": 4.9096660579180805e-05,
      "loss": 0.1155,
      "step": 13850
    },
    {
      "epoch": 1.8132011479259065,
      "grad_norm": 0.11929936707019806,
      "learning_rate": 4.909339942603705e-05,
      "loss": 0.1385,
      "step": 13900
    },
    {
      "epoch": 1.8197234542134098,
      "grad_norm": 7.797720432281494,
      "learning_rate": 4.90901382728933e-05,
      "loss": 0.1018,
      "step": 13950
    },
    {
      "epoch": 1.826245760500913,
      "grad_norm": 1.8990672826766968,
      "learning_rate": 4.908687711974955e-05,
      "loss": 0.1549,
      "step": 14000
    },
    {
      "epoch": 1.8327680667884163,
      "grad_norm": 7.085480213165283,
      "learning_rate": 4.9083615966605796e-05,
      "loss": 0.1649,
      "step": 14050
    },
    {
      "epoch": 1.8392903730759196,
      "grad_norm": 0.27459344267845154,
      "learning_rate": 4.908035481346204e-05,
      "loss": 0.1207,
      "step": 14100
    },
    {
      "epoch": 1.8458126793634229,
      "grad_norm": 0.04632557928562164,
      "learning_rate": 4.907709366031829e-05,
      "loss": 0.126,
      "step": 14150
    },
    {
      "epoch": 1.8523349856509261,
      "grad_norm": 0.03300482779741287,
      "learning_rate": 4.907383250717454e-05,
      "loss": 0.0858,
      "step": 14200
    },
    {
      "epoch": 1.8588572919384294,
      "grad_norm": 4.900163650512695,
      "learning_rate": 4.907057135403079e-05,
      "loss": 0.1084,
      "step": 14250
    },
    {
      "epoch": 1.8653795982259327,
      "grad_norm": 13.294913291931152,
      "learning_rate": 4.9067310200887034e-05,
      "loss": 0.1836,
      "step": 14300
    },
    {
      "epoch": 1.871901904513436,
      "grad_norm": 0.015999406576156616,
      "learning_rate": 4.906404904774328e-05,
      "loss": 0.1198,
      "step": 14350
    },
    {
      "epoch": 1.8784242108009392,
      "grad_norm": 0.8580827713012695,
      "learning_rate": 4.906078789459953e-05,
      "loss": 0.1439,
      "step": 14400
    },
    {
      "epoch": 1.8849465170884425,
      "grad_norm": 3.43243670463562,
      "learning_rate": 4.9057526741455786e-05,
      "loss": 0.1011,
      "step": 14450
    },
    {
      "epoch": 1.8914688233759458,
      "grad_norm": 0.05345770716667175,
      "learning_rate": 4.905426558831203e-05,
      "loss": 0.1802,
      "step": 14500
    },
    {
      "epoch": 1.897991129663449,
      "grad_norm": 0.04109487682580948,
      "learning_rate": 4.905100443516828e-05,
      "loss": 0.1975,
      "step": 14550
    },
    {
      "epoch": 1.9045134359509523,
      "grad_norm": 0.9615236520767212,
      "learning_rate": 4.9047743282024525e-05,
      "loss": 0.107,
      "step": 14600
    },
    {
      "epoch": 1.9110357422384556,
      "grad_norm": 13.571986198425293,
      "learning_rate": 4.904448212888078e-05,
      "loss": 0.0665,
      "step": 14650
    },
    {
      "epoch": 1.917558048525959,
      "grad_norm": 0.016818489879369736,
      "learning_rate": 4.9041220975737024e-05,
      "loss": 0.1249,
      "step": 14700
    },
    {
      "epoch": 1.9240803548134622,
      "grad_norm": 21.25214958190918,
      "learning_rate": 4.903795982259327e-05,
      "loss": 0.1184,
      "step": 14750
    },
    {
      "epoch": 1.9306026611009655,
      "grad_norm": 15.095853805541992,
      "learning_rate": 4.9034698669449516e-05,
      "loss": 0.1863,
      "step": 14800
    },
    {
      "epoch": 1.9371249673884685,
      "grad_norm": 9.835399627685547,
      "learning_rate": 4.903143751630577e-05,
      "loss": 0.1817,
      "step": 14850
    },
    {
      "epoch": 1.9436472736759718,
      "grad_norm": 0.08468219637870789,
      "learning_rate": 4.9028176363162015e-05,
      "loss": 0.161,
      "step": 14900
    },
    {
      "epoch": 1.950169579963475,
      "grad_norm": 0.5436407923698425,
      "learning_rate": 4.902491521001826e-05,
      "loss": 0.0884,
      "step": 14950
    },
    {
      "epoch": 1.9566918862509783,
      "grad_norm": 2.027010440826416,
      "learning_rate": 4.902165405687451e-05,
      "loss": 0.12,
      "step": 15000
    },
    {
      "epoch": 1.9632141925384816,
      "grad_norm": 0.115045927464962,
      "learning_rate": 4.901839290373077e-05,
      "loss": 0.1187,
      "step": 15050
    },
    {
      "epoch": 1.969736498825985,
      "grad_norm": 6.247152328491211,
      "learning_rate": 4.9015131750587014e-05,
      "loss": 0.1099,
      "step": 15100
    },
    {
      "epoch": 1.9762588051134882,
      "grad_norm": 0.4376659095287323,
      "learning_rate": 4.901187059744326e-05,
      "loss": 0.1172,
      "step": 15150
    },
    {
      "epoch": 1.9827811114009912,
      "grad_norm": 0.03244168683886528,
      "learning_rate": 4.9008609444299506e-05,
      "loss": 0.1904,
      "step": 15200
    },
    {
      "epoch": 1.9893034176884945,
      "grad_norm": 5.8642096519470215,
      "learning_rate": 4.900534829115576e-05,
      "loss": 0.1329,
      "step": 15250
    },
    {
      "epoch": 1.9958257239759978,
      "grad_norm": 0.12049510329961777,
      "learning_rate": 4.9002087138012005e-05,
      "loss": 0.1085,
      "step": 15300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9602791547091052,
      "eval_f1": 0.9602298700450598,
      "eval_loss": 0.14787346124649048,
      "eval_precision": 0.9616742969260955,
      "eval_recall": 0.9587897756911842,
      "eval_runtime": 23.7176,
      "eval_samples_per_second": 646.438,
      "eval_steps_per_second": 80.826,
      "step": 15332
    },
    {
      "epoch": 2.002348030263501,
      "grad_norm": 3.249213695526123,
      "learning_rate": 4.899882598486825e-05,
      "loss": 0.0973,
      "step": 15350
    },
    {
      "epoch": 2.0088703365510043,
      "grad_norm": 0.9948822259902954,
      "learning_rate": 4.89955648317245e-05,
      "loss": 0.12,
      "step": 15400
    },
    {
      "epoch": 2.0153926428385076,
      "grad_norm": 11.680874824523926,
      "learning_rate": 4.899230367858075e-05,
      "loss": 0.0961,
      "step": 15450
    },
    {
      "epoch": 2.021914949126011,
      "grad_norm": 0.04677614942193031,
      "learning_rate": 4.8989042525437e-05,
      "loss": 0.178,
      "step": 15500
    },
    {
      "epoch": 2.028437255413514,
      "grad_norm": 0.21565933525562286,
      "learning_rate": 4.898578137229324e-05,
      "loss": 0.1393,
      "step": 15550
    },
    {
      "epoch": 2.0349595617010174,
      "grad_norm": 0.11537119001150131,
      "learning_rate": 4.898252021914949e-05,
      "loss": 0.0957,
      "step": 15600
    },
    {
      "epoch": 2.0414818679885207,
      "grad_norm": 19.59784698486328,
      "learning_rate": 4.897925906600574e-05,
      "loss": 0.1156,
      "step": 15650
    },
    {
      "epoch": 2.048004174276024,
      "grad_norm": 0.038580965250730515,
      "learning_rate": 4.8975997912861995e-05,
      "loss": 0.1125,
      "step": 15700
    },
    {
      "epoch": 2.0545264805635273,
      "grad_norm": 0.08431347459554672,
      "learning_rate": 4.897273675971824e-05,
      "loss": 0.1561,
      "step": 15750
    },
    {
      "epoch": 2.0610487868510305,
      "grad_norm": 21.04488182067871,
      "learning_rate": 4.896947560657449e-05,
      "loss": 0.1205,
      "step": 15800
    },
    {
      "epoch": 2.067571093138534,
      "grad_norm": 0.027134958654642105,
      "learning_rate": 4.8966214453430734e-05,
      "loss": 0.1215,
      "step": 15850
    },
    {
      "epoch": 2.074093399426037,
      "grad_norm": 7.8175482749938965,
      "learning_rate": 4.8962953300286986e-05,
      "loss": 0.1722,
      "step": 15900
    },
    {
      "epoch": 2.0806157057135404,
      "grad_norm": 1.116195797920227,
      "learning_rate": 4.895969214714323e-05,
      "loss": 0.1425,
      "step": 15950
    },
    {
      "epoch": 2.0871380120010437,
      "grad_norm": 0.3147256076335907,
      "learning_rate": 4.895643099399948e-05,
      "loss": 0.1215,
      "step": 16000
    },
    {
      "epoch": 2.093660318288547,
      "grad_norm": 0.03945627436041832,
      "learning_rate": 4.8953169840855725e-05,
      "loss": 0.1151,
      "step": 16050
    },
    {
      "epoch": 2.10018262457605,
      "grad_norm": 0.01795448176562786,
      "learning_rate": 4.894990868771198e-05,
      "loss": 0.1576,
      "step": 16100
    },
    {
      "epoch": 2.1067049308635535,
      "grad_norm": 0.13094408810138702,
      "learning_rate": 4.8946647534568224e-05,
      "loss": 0.1813,
      "step": 16150
    },
    {
      "epoch": 2.1132272371510568,
      "grad_norm": 0.04321640357375145,
      "learning_rate": 4.894338638142447e-05,
      "loss": 0.1714,
      "step": 16200
    },
    {
      "epoch": 2.11974954343856,
      "grad_norm": 10.162964820861816,
      "learning_rate": 4.8940125228280717e-05,
      "loss": 0.118,
      "step": 16250
    },
    {
      "epoch": 2.1262718497260633,
      "grad_norm": 1.8500243425369263,
      "learning_rate": 4.8936864075136976e-05,
      "loss": 0.1149,
      "step": 16300
    },
    {
      "epoch": 2.1327941560135666,
      "grad_norm": 7.491021156311035,
      "learning_rate": 4.893360292199322e-05,
      "loss": 0.1293,
      "step": 16350
    },
    {
      "epoch": 2.13931646230107,
      "grad_norm": 0.04187360778450966,
      "learning_rate": 4.893034176884947e-05,
      "loss": 0.0836,
      "step": 16400
    },
    {
      "epoch": 2.1458387685885727,
      "grad_norm": 0.027175869792699814,
      "learning_rate": 4.8927080615705715e-05,
      "loss": 0.1023,
      "step": 16450
    },
    {
      "epoch": 2.152361074876076,
      "grad_norm": 0.045103520154953,
      "learning_rate": 4.892381946256197e-05,
      "loss": 0.1373,
      "step": 16500
    },
    {
      "epoch": 2.1588833811635793,
      "grad_norm": 0.04743971675634384,
      "learning_rate": 4.8920558309418214e-05,
      "loss": 0.116,
      "step": 16550
    },
    {
      "epoch": 2.1654056874510825,
      "grad_norm": 22.319108963012695,
      "learning_rate": 4.891729715627446e-05,
      "loss": 0.0533,
      "step": 16600
    },
    {
      "epoch": 2.171927993738586,
      "grad_norm": 0.013945340178906918,
      "learning_rate": 4.8914036003130706e-05,
      "loss": 0.1959,
      "step": 16650
    },
    {
      "epoch": 2.178450300026089,
      "grad_norm": 0.07885207235813141,
      "learning_rate": 4.891077484998696e-05,
      "loss": 0.1751,
      "step": 16700
    },
    {
      "epoch": 2.1849726063135924,
      "grad_norm": 0.009047884494066238,
      "learning_rate": 4.8907513696843205e-05,
      "loss": 0.0702,
      "step": 16750
    },
    {
      "epoch": 2.1914949126010956,
      "grad_norm": 9.787384986877441,
      "learning_rate": 4.890425254369945e-05,
      "loss": 0.1296,
      "step": 16800
    },
    {
      "epoch": 2.198017218888599,
      "grad_norm": 0.013560761697590351,
      "learning_rate": 4.89009913905557e-05,
      "loss": 0.1272,
      "step": 16850
    },
    {
      "epoch": 2.204539525176102,
      "grad_norm": 1.377099633216858,
      "learning_rate": 4.889773023741195e-05,
      "loss": 0.0993,
      "step": 16900
    },
    {
      "epoch": 2.2110618314636055,
      "grad_norm": 12.534353256225586,
      "learning_rate": 4.8894469084268204e-05,
      "loss": 0.1142,
      "step": 16950
    },
    {
      "epoch": 2.2175841377511087,
      "grad_norm": 5.688359260559082,
      "learning_rate": 4.889120793112445e-05,
      "loss": 0.1883,
      "step": 17000
    },
    {
      "epoch": 2.224106444038612,
      "grad_norm": 12.831389427185059,
      "learning_rate": 4.8887946777980696e-05,
      "loss": 0.1793,
      "step": 17050
    },
    {
      "epoch": 2.2306287503261153,
      "grad_norm": 0.3035546541213989,
      "learning_rate": 4.888468562483694e-05,
      "loss": 0.1538,
      "step": 17100
    },
    {
      "epoch": 2.2371510566136186,
      "grad_norm": 0.09603039920330048,
      "learning_rate": 4.8881424471693195e-05,
      "loss": 0.1302,
      "step": 17150
    },
    {
      "epoch": 2.243673362901122,
      "grad_norm": 9.31053352355957,
      "learning_rate": 4.887816331854944e-05,
      "loss": 0.1534,
      "step": 17200
    },
    {
      "epoch": 2.250195669188625,
      "grad_norm": 0.02772597223520279,
      "learning_rate": 4.887490216540569e-05,
      "loss": 0.1118,
      "step": 17250
    },
    {
      "epoch": 2.2567179754761284,
      "grad_norm": 1.0025675296783447,
      "learning_rate": 4.887164101226194e-05,
      "loss": 0.1345,
      "step": 17300
    },
    {
      "epoch": 2.2632402817636317,
      "grad_norm": 0.17971935868263245,
      "learning_rate": 4.886837985911819e-05,
      "loss": 0.1581,
      "step": 17350
    },
    {
      "epoch": 2.269762588051135,
      "grad_norm": 0.027639558538794518,
      "learning_rate": 4.886511870597443e-05,
      "loss": 0.1163,
      "step": 17400
    },
    {
      "epoch": 2.2762848943386382,
      "grad_norm": 1.8167327642440796,
      "learning_rate": 4.886185755283068e-05,
      "loss": 0.1776,
      "step": 17450
    },
    {
      "epoch": 2.2828072006261415,
      "grad_norm": 15.551276206970215,
      "learning_rate": 4.885859639968693e-05,
      "loss": 0.1151,
      "step": 17500
    },
    {
      "epoch": 2.289329506913645,
      "grad_norm": 0.12549079954624176,
      "learning_rate": 4.8855335246543185e-05,
      "loss": 0.1138,
      "step": 17550
    },
    {
      "epoch": 2.295851813201148,
      "grad_norm": 0.08478892594575882,
      "learning_rate": 4.885207409339943e-05,
      "loss": 0.1107,
      "step": 17600
    },
    {
      "epoch": 2.3023741194886513,
      "grad_norm": 5.96432638168335,
      "learning_rate": 4.884881294025568e-05,
      "loss": 0.1275,
      "step": 17650
    },
    {
      "epoch": 2.3088964257761546,
      "grad_norm": 10.5556001663208,
      "learning_rate": 4.8845551787111924e-05,
      "loss": 0.1396,
      "step": 17700
    },
    {
      "epoch": 2.315418732063658,
      "grad_norm": 9.008147239685059,
      "learning_rate": 4.8842290633968177e-05,
      "loss": 0.1437,
      "step": 17750
    },
    {
      "epoch": 2.321941038351161,
      "grad_norm": 0.4614361822605133,
      "learning_rate": 4.883902948082442e-05,
      "loss": 0.1622,
      "step": 17800
    },
    {
      "epoch": 2.3284633446386644,
      "grad_norm": 0.1346302330493927,
      "learning_rate": 4.883576832768067e-05,
      "loss": 0.1085,
      "step": 17850
    },
    {
      "epoch": 2.3349856509261677,
      "grad_norm": 0.5124818682670593,
      "learning_rate": 4.8832507174536915e-05,
      "loss": 0.1371,
      "step": 17900
    },
    {
      "epoch": 2.341507957213671,
      "grad_norm": 0.013003554195165634,
      "learning_rate": 4.882924602139317e-05,
      "loss": 0.081,
      "step": 17950
    },
    {
      "epoch": 2.348030263501174,
      "grad_norm": 5.560274600982666,
      "learning_rate": 4.8825984868249414e-05,
      "loss": 0.1251,
      "step": 18000
    },
    {
      "epoch": 2.354552569788677,
      "grad_norm": 0.4303499460220337,
      "learning_rate": 4.882272371510566e-05,
      "loss": 0.1476,
      "step": 18050
    },
    {
      "epoch": 2.3610748760761804,
      "grad_norm": 0.5838847756385803,
      "learning_rate": 4.881946256196191e-05,
      "loss": 0.1152,
      "step": 18100
    },
    {
      "epoch": 2.3675971823636837,
      "grad_norm": 0.021364407613873482,
      "learning_rate": 4.881620140881816e-05,
      "loss": 0.1372,
      "step": 18150
    },
    {
      "epoch": 2.374119488651187,
      "grad_norm": 0.09586470574140549,
      "learning_rate": 4.881294025567441e-05,
      "loss": 0.1595,
      "step": 18200
    },
    {
      "epoch": 2.38064179493869,
      "grad_norm": 9.373512268066406,
      "learning_rate": 4.880967910253066e-05,
      "loss": 0.111,
      "step": 18250
    },
    {
      "epoch": 2.3871641012261935,
      "grad_norm": 0.3540325164794922,
      "learning_rate": 4.8806417949386905e-05,
      "loss": 0.1279,
      "step": 18300
    },
    {
      "epoch": 2.3936864075136968,
      "grad_norm": 0.023643476888537407,
      "learning_rate": 4.880315679624316e-05,
      "loss": 0.0557,
      "step": 18350
    },
    {
      "epoch": 2.4002087138012,
      "grad_norm": 22.03118324279785,
      "learning_rate": 4.8799895643099404e-05,
      "loss": 0.1918,
      "step": 18400
    },
    {
      "epoch": 2.4067310200887033,
      "grad_norm": 0.16731254756450653,
      "learning_rate": 4.879663448995565e-05,
      "loss": 0.1167,
      "step": 18450
    },
    {
      "epoch": 2.4132533263762066,
      "grad_norm": 0.047949932515621185,
      "learning_rate": 4.8793373336811896e-05,
      "loss": 0.111,
      "step": 18500
    },
    {
      "epoch": 2.41977563266371,
      "grad_norm": 0.20919762551784515,
      "learning_rate": 4.879011218366815e-05,
      "loss": 0.1495,
      "step": 18550
    },
    {
      "epoch": 2.426297938951213,
      "grad_norm": 4.421270847320557,
      "learning_rate": 4.8786851030524396e-05,
      "loss": 0.1301,
      "step": 18600
    },
    {
      "epoch": 2.4328202452387164,
      "grad_norm": 0.8178529739379883,
      "learning_rate": 4.878358987738064e-05,
      "loss": 0.1161,
      "step": 18650
    },
    {
      "epoch": 2.4393425515262197,
      "grad_norm": 4.138066291809082,
      "learning_rate": 4.878032872423689e-05,
      "loss": 0.1333,
      "step": 18700
    },
    {
      "epoch": 2.445864857813723,
      "grad_norm": 0.059169791638851166,
      "learning_rate": 4.877706757109314e-05,
      "loss": 0.0944,
      "step": 18750
    },
    {
      "epoch": 2.4523871641012263,
      "grad_norm": 2.58329176902771,
      "learning_rate": 4.8773806417949394e-05,
      "loss": 0.1838,
      "step": 18800
    },
    {
      "epoch": 2.4589094703887295,
      "grad_norm": 0.03292403742671013,
      "learning_rate": 4.877054526480564e-05,
      "loss": 0.1535,
      "step": 18850
    },
    {
      "epoch": 2.465431776676233,
      "grad_norm": 3.918039321899414,
      "learning_rate": 4.8767284111661886e-05,
      "loss": 0.1264,
      "step": 18900
    },
    {
      "epoch": 2.471954082963736,
      "grad_norm": 2.1409130096435547,
      "learning_rate": 4.876402295851813e-05,
      "loss": 0.0844,
      "step": 18950
    },
    {
      "epoch": 2.4784763892512394,
      "grad_norm": 0.06626427918672562,
      "learning_rate": 4.8760761805374385e-05,
      "loss": 0.158,
      "step": 19000
    },
    {
      "epoch": 2.4849986955387426,
      "grad_norm": 7.238201141357422,
      "learning_rate": 4.875750065223063e-05,
      "loss": 0.1576,
      "step": 19050
    },
    {
      "epoch": 2.491521001826246,
      "grad_norm": 0.5739532709121704,
      "learning_rate": 4.875423949908688e-05,
      "loss": 0.1267,
      "step": 19100
    },
    {
      "epoch": 2.498043308113749,
      "grad_norm": 0.22054903209209442,
      "learning_rate": 4.8750978345943124e-05,
      "loss": 0.125,
      "step": 19150
    },
    {
      "epoch": 2.504565614401252,
      "grad_norm": 0.20945458114147186,
      "learning_rate": 4.874771719279938e-05,
      "loss": 0.13,
      "step": 19200
    },
    {
      "epoch": 2.5110879206887553,
      "grad_norm": 9.306782722473145,
      "learning_rate": 4.874445603965562e-05,
      "loss": 0.1669,
      "step": 19250
    },
    {
      "epoch": 2.5176102269762586,
      "grad_norm": 11.74720287322998,
      "learning_rate": 4.874119488651187e-05,
      "loss": 0.1515,
      "step": 19300
    },
    {
      "epoch": 2.524132533263762,
      "grad_norm": 5.875674724578857,
      "learning_rate": 4.873793373336812e-05,
      "loss": 0.1769,
      "step": 19350
    },
    {
      "epoch": 2.530654839551265,
      "grad_norm": 1.1879260540008545,
      "learning_rate": 4.8734672580224375e-05,
      "loss": 0.1228,
      "step": 19400
    },
    {
      "epoch": 2.5371771458387684,
      "grad_norm": 12.07332706451416,
      "learning_rate": 4.873141142708062e-05,
      "loss": 0.1013,
      "step": 19450
    },
    {
      "epoch": 2.5436994521262717,
      "grad_norm": 0.12083348631858826,
      "learning_rate": 4.872815027393687e-05,
      "loss": 0.1176,
      "step": 19500
    },
    {
      "epoch": 2.550221758413775,
      "grad_norm": 0.044624004513025284,
      "learning_rate": 4.8724889120793114e-05,
      "loss": 0.1756,
      "step": 19550
    },
    {
      "epoch": 2.5567440647012782,
      "grad_norm": 0.35098010301589966,
      "learning_rate": 4.872162796764937e-05,
      "loss": 0.0784,
      "step": 19600
    },
    {
      "epoch": 2.5632663709887815,
      "grad_norm": 0.15670108795166016,
      "learning_rate": 4.871836681450561e-05,
      "loss": 0.1135,
      "step": 19650
    },
    {
      "epoch": 2.569788677276285,
      "grad_norm": 0.1273307055234909,
      "learning_rate": 4.871510566136186e-05,
      "loss": 0.1335,
      "step": 19700
    },
    {
      "epoch": 2.576310983563788,
      "grad_norm": 0.04173067584633827,
      "learning_rate": 4.8711844508218105e-05,
      "loss": 0.0879,
      "step": 19750
    },
    {
      "epoch": 2.5828332898512913,
      "grad_norm": 1.453163743019104,
      "learning_rate": 4.870858335507436e-05,
      "loss": 0.1686,
      "step": 19800
    },
    {
      "epoch": 2.5893555961387946,
      "grad_norm": 6.966879844665527,
      "learning_rate": 4.8705322201930604e-05,
      "loss": 0.2111,
      "step": 19850
    },
    {
      "epoch": 2.595877902426298,
      "grad_norm": 0.10731982439756393,
      "learning_rate": 4.870206104878685e-05,
      "loss": 0.1035,
      "step": 19900
    },
    {
      "epoch": 2.602400208713801,
      "grad_norm": 8.8869047164917,
      "learning_rate": 4.86987998956431e-05,
      "loss": 0.1087,
      "step": 19950
    },
    {
      "epoch": 2.6089225150013045,
      "grad_norm": 0.14060541987419128,
      "learning_rate": 4.869553874249935e-05,
      "loss": 0.146,
      "step": 20000
    },
    {
      "epoch": 2.6154448212888077,
      "grad_norm": 0.04582321643829346,
      "learning_rate": 4.86922775893556e-05,
      "loss": 0.1195,
      "step": 20050
    },
    {
      "epoch": 2.621967127576311,
      "grad_norm": 0.1214534267783165,
      "learning_rate": 4.868901643621185e-05,
      "loss": 0.125,
      "step": 20100
    },
    {
      "epoch": 2.6284894338638143,
      "grad_norm": 0.013578822836279869,
      "learning_rate": 4.8685755283068095e-05,
      "loss": 0.0947,
      "step": 20150
    },
    {
      "epoch": 2.6350117401513176,
      "grad_norm": 0.043350331485271454,
      "learning_rate": 4.868249412992434e-05,
      "loss": 0.0729,
      "step": 20200
    },
    {
      "epoch": 2.641534046438821,
      "grad_norm": 0.3362872302532196,
      "learning_rate": 4.8679232976780594e-05,
      "loss": 0.1697,
      "step": 20250
    },
    {
      "epoch": 2.648056352726324,
      "grad_norm": 0.03047499991953373,
      "learning_rate": 4.867597182363684e-05,
      "loss": 0.0943,
      "step": 20300
    },
    {
      "epoch": 2.6545786590138274,
      "grad_norm": 0.6312831044197083,
      "learning_rate": 4.8672710670493087e-05,
      "loss": 0.1062,
      "step": 20350
    },
    {
      "epoch": 2.6611009653013307,
      "grad_norm": 0.12174314260482788,
      "learning_rate": 4.866944951734933e-05,
      "loss": 0.1357,
      "step": 20400
    },
    {
      "epoch": 2.667623271588834,
      "grad_norm": 0.07502441853284836,
      "learning_rate": 4.8666188364205586e-05,
      "loss": 0.1559,
      "step": 20450
    },
    {
      "epoch": 2.674145577876337,
      "grad_norm": 13.668098449707031,
      "learning_rate": 4.866292721106183e-05,
      "loss": 0.0798,
      "step": 20500
    },
    {
      "epoch": 2.6806678841638405,
      "grad_norm": 15.91521167755127,
      "learning_rate": 4.865966605791808e-05,
      "loss": 0.1243,
      "step": 20550
    },
    {
      "epoch": 2.6871901904513438,
      "grad_norm": 0.13763943314552307,
      "learning_rate": 4.865640490477433e-05,
      "loss": 0.1286,
      "step": 20600
    },
    {
      "epoch": 2.693712496738847,
      "grad_norm": 5.959499835968018,
      "learning_rate": 4.8653143751630584e-05,
      "loss": 0.1394,
      "step": 20650
    },
    {
      "epoch": 2.7002348030263503,
      "grad_norm": 0.09906020760536194,
      "learning_rate": 4.864988259848683e-05,
      "loss": 0.1769,
      "step": 20700
    },
    {
      "epoch": 2.7067571093138536,
      "grad_norm": 0.05475746467709541,
      "learning_rate": 4.8646621445343076e-05,
      "loss": 0.1123,
      "step": 20750
    },
    {
      "epoch": 2.713279415601357,
      "grad_norm": 0.09866230934858322,
      "learning_rate": 4.864336029219932e-05,
      "loss": 0.0881,
      "step": 20800
    },
    {
      "epoch": 2.71980172188886,
      "grad_norm": 17.68682289123535,
      "learning_rate": 4.8640099139055575e-05,
      "loss": 0.1357,
      "step": 20850
    },
    {
      "epoch": 2.7263240281763634,
      "grad_norm": 0.16397981345653534,
      "learning_rate": 4.863683798591182e-05,
      "loss": 0.1171,
      "step": 20900
    },
    {
      "epoch": 2.7328463344638663,
      "grad_norm": 0.016800304874777794,
      "learning_rate": 4.863357683276807e-05,
      "loss": 0.1497,
      "step": 20950
    },
    {
      "epoch": 2.7393686407513695,
      "grad_norm": 0.07612038403749466,
      "learning_rate": 4.8630315679624314e-05,
      "loss": 0.1216,
      "step": 21000
    },
    {
      "epoch": 2.745890947038873,
      "grad_norm": 0.017020730301737785,
      "learning_rate": 4.862705452648057e-05,
      "loss": 0.1383,
      "step": 21050
    },
    {
      "epoch": 2.752413253326376,
      "grad_norm": 0.03750573843717575,
      "learning_rate": 4.862379337333681e-05,
      "loss": 0.0649,
      "step": 21100
    },
    {
      "epoch": 2.7589355596138794,
      "grad_norm": 11.06453800201416,
      "learning_rate": 4.862053222019306e-05,
      "loss": 0.1564,
      "step": 21150
    },
    {
      "epoch": 2.7654578659013827,
      "grad_norm": 9.366470336914062,
      "learning_rate": 4.861727106704931e-05,
      "loss": 0.1278,
      "step": 21200
    },
    {
      "epoch": 2.771980172188886,
      "grad_norm": 6.8411970138549805,
      "learning_rate": 4.861400991390556e-05,
      "loss": 0.1296,
      "step": 21250
    },
    {
      "epoch": 2.778502478476389,
      "grad_norm": 0.031190350651741028,
      "learning_rate": 4.861074876076181e-05,
      "loss": 0.1409,
      "step": 21300
    },
    {
      "epoch": 2.7850247847638925,
      "grad_norm": 0.1187584176659584,
      "learning_rate": 4.860748760761806e-05,
      "loss": 0.1343,
      "step": 21350
    },
    {
      "epoch": 2.7915470910513958,
      "grad_norm": 0.11448048800230026,
      "learning_rate": 4.8604226454474304e-05,
      "loss": 0.0741,
      "step": 21400
    },
    {
      "epoch": 2.798069397338899,
      "grad_norm": 0.2349339723587036,
      "learning_rate": 4.860096530133055e-05,
      "loss": 0.1302,
      "step": 21450
    },
    {
      "epoch": 2.8045917036264023,
      "grad_norm": 0.08689109981060028,
      "learning_rate": 4.85977041481868e-05,
      "loss": 0.1172,
      "step": 21500
    },
    {
      "epoch": 2.8111140099139056,
      "grad_norm": 0.16140271723270416,
      "learning_rate": 4.859444299504305e-05,
      "loss": 0.1322,
      "step": 21550
    },
    {
      "epoch": 2.817636316201409,
      "grad_norm": 0.10578449815511703,
      "learning_rate": 4.8591181841899295e-05,
      "loss": 0.1651,
      "step": 21600
    },
    {
      "epoch": 2.824158622488912,
      "grad_norm": 26.558706283569336,
      "learning_rate": 4.858792068875555e-05,
      "loss": 0.1536,
      "step": 21650
    },
    {
      "epoch": 2.8306809287764154,
      "grad_norm": 0.057397618889808655,
      "learning_rate": 4.8584659535611794e-05,
      "loss": 0.0919,
      "step": 21700
    },
    {
      "epoch": 2.8372032350639187,
      "grad_norm": 4.99746561050415,
      "learning_rate": 4.858139838246804e-05,
      "loss": 0.2072,
      "step": 21750
    },
    {
      "epoch": 2.843725541351422,
      "grad_norm": 0.16302521526813507,
      "learning_rate": 4.857813722932429e-05,
      "loss": 0.1361,
      "step": 21800
    },
    {
      "epoch": 2.8502478476389252,
      "grad_norm": 5.0340094566345215,
      "learning_rate": 4.857487607618054e-05,
      "loss": 0.1499,
      "step": 21850
    },
    {
      "epoch": 2.8567701539264285,
      "grad_norm": 2.058542251586914,
      "learning_rate": 4.857161492303679e-05,
      "loss": 0.0682,
      "step": 21900
    },
    {
      "epoch": 2.863292460213932,
      "grad_norm": 0.5460566878318787,
      "learning_rate": 4.856835376989304e-05,
      "loss": 0.1223,
      "step": 21950
    },
    {
      "epoch": 2.8698147665014346,
      "grad_norm": 0.24393095076084137,
      "learning_rate": 4.8565092616749285e-05,
      "loss": 0.1317,
      "step": 22000
    },
    {
      "epoch": 2.876337072788938,
      "grad_norm": 2.3663249015808105,
      "learning_rate": 4.856183146360553e-05,
      "loss": 0.1178,
      "step": 22050
    },
    {
      "epoch": 2.882859379076441,
      "grad_norm": 10.030667304992676,
      "learning_rate": 4.8558570310461784e-05,
      "loss": 0.2136,
      "step": 22100
    },
    {
      "epoch": 2.8893816853639445,
      "grad_norm": 0.02532234974205494,
      "learning_rate": 4.855530915731803e-05,
      "loss": 0.1351,
      "step": 22150
    },
    {
      "epoch": 2.8959039916514477,
      "grad_norm": 9.759214401245117,
      "learning_rate": 4.8552048004174277e-05,
      "loss": 0.1617,
      "step": 22200
    },
    {
      "epoch": 2.902426297938951,
      "grad_norm": 0.036807455122470856,
      "learning_rate": 4.854878685103052e-05,
      "loss": 0.0922,
      "step": 22250
    },
    {
      "epoch": 2.9089486042264543,
      "grad_norm": 11.588142395019531,
      "learning_rate": 4.8545525697886776e-05,
      "loss": 0.1048,
      "step": 22300
    },
    {
      "epoch": 2.9154709105139576,
      "grad_norm": 10.70936107635498,
      "learning_rate": 4.854226454474302e-05,
      "loss": 0.2005,
      "step": 22350
    },
    {
      "epoch": 2.921993216801461,
      "grad_norm": 11.679827690124512,
      "learning_rate": 4.853900339159927e-05,
      "loss": 0.1162,
      "step": 22400
    },
    {
      "epoch": 2.928515523088964,
      "grad_norm": 0.08885807543992996,
      "learning_rate": 4.853574223845552e-05,
      "loss": 0.0771,
      "step": 22450
    },
    {
      "epoch": 2.9350378293764674,
      "grad_norm": 1.3520079851150513,
      "learning_rate": 4.8532481085311774e-05,
      "loss": 0.1457,
      "step": 22500
    },
    {
      "epoch": 2.9415601356639707,
      "grad_norm": 9.989048957824707,
      "learning_rate": 4.852921993216802e-05,
      "loss": 0.1353,
      "step": 22550
    },
    {
      "epoch": 2.948082441951474,
      "grad_norm": 0.012005927041172981,
      "learning_rate": 4.8525958779024266e-05,
      "loss": 0.0948,
      "step": 22600
    },
    {
      "epoch": 2.9546047482389772,
      "grad_norm": 0.04372735321521759,
      "learning_rate": 4.852269762588051e-05,
      "loss": 0.1029,
      "step": 22650
    },
    {
      "epoch": 2.9611270545264805,
      "grad_norm": 1.063582420349121,
      "learning_rate": 4.8519436472736766e-05,
      "loss": 0.089,
      "step": 22700
    },
    {
      "epoch": 2.967649360813984,
      "grad_norm": 0.11116020381450653,
      "learning_rate": 4.851617531959301e-05,
      "loss": 0.0943,
      "step": 22750
    },
    {
      "epoch": 2.974171667101487,
      "grad_norm": 0.08964784443378448,
      "learning_rate": 4.851291416644926e-05,
      "loss": 0.0826,
      "step": 22800
    },
    {
      "epoch": 2.9806939733889903,
      "grad_norm": 8.131078720092773,
      "learning_rate": 4.8509653013305504e-05,
      "loss": 0.0925,
      "step": 22850
    },
    {
      "epoch": 2.9872162796764936,
      "grad_norm": 0.00844633113592863,
      "learning_rate": 4.850639186016176e-05,
      "loss": 0.1756,
      "step": 22900
    },
    {
      "epoch": 2.993738585963997,
      "grad_norm": 10.085229873657227,
      "learning_rate": 4.8503130707018e-05,
      "loss": 0.1564,
      "step": 22950
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9628880772241064,
      "eval_f1": 0.9630447489770735,
      "eval_loss": 0.12807109951972961,
      "eval_precision": 0.9592444041920042,
      "eval_recall": 0.9668753260302556,
      "eval_runtime": 23.5523,
      "eval_samples_per_second": 650.977,
      "eval_steps_per_second": 81.393,
      "step": 22998
    },
    {
      "epoch": 3.0002608922515,
      "grad_norm": 0.08603353798389435,
      "learning_rate": 4.849986955387425e-05,
      "loss": 0.1573,
      "step": 23000
    },
    {
      "epoch": 3.0067831985390034,
      "grad_norm": 0.16820128262043,
      "learning_rate": 4.84966084007305e-05,
      "loss": 0.147,
      "step": 23050
    },
    {
      "epoch": 3.0133055048265067,
      "grad_norm": 3.9438557624816895,
      "learning_rate": 4.849334724758675e-05,
      "loss": 0.1049,
      "step": 23100
    },
    {
      "epoch": 3.01982781111401,
      "grad_norm": 0.6354667544364929,
      "learning_rate": 4.8490086094443e-05,
      "loss": 0.1065,
      "step": 23150
    },
    {
      "epoch": 3.0263501174015133,
      "grad_norm": 9.271449089050293,
      "learning_rate": 4.848682494129925e-05,
      "loss": 0.0927,
      "step": 23200
    },
    {
      "epoch": 3.0328724236890165,
      "grad_norm": 2.916853666305542,
      "learning_rate": 4.8483563788155494e-05,
      "loss": 0.0975,
      "step": 23250
    },
    {
      "epoch": 3.03939472997652,
      "grad_norm": 0.023985419422388077,
      "learning_rate": 4.848030263501174e-05,
      "loss": 0.1132,
      "step": 23300
    },
    {
      "epoch": 3.045917036264023,
      "grad_norm": 1.4119032621383667,
      "learning_rate": 4.847704148186799e-05,
      "loss": 0.1858,
      "step": 23350
    },
    {
      "epoch": 3.0524393425515264,
      "grad_norm": 0.03728432580828667,
      "learning_rate": 4.847378032872424e-05,
      "loss": 0.1219,
      "step": 23400
    },
    {
      "epoch": 3.0589616488390297,
      "grad_norm": 3.368609666824341,
      "learning_rate": 4.8470519175580485e-05,
      "loss": 0.146,
      "step": 23450
    },
    {
      "epoch": 3.065483955126533,
      "grad_norm": 0.03410864993929863,
      "learning_rate": 4.846725802243673e-05,
      "loss": 0.1558,
      "step": 23500
    },
    {
      "epoch": 3.072006261414036,
      "grad_norm": 0.5333698391914368,
      "learning_rate": 4.8463996869292985e-05,
      "loss": 0.1445,
      "step": 23550
    },
    {
      "epoch": 3.0785285677015395,
      "grad_norm": 13.049723625183105,
      "learning_rate": 4.846073571614923e-05,
      "loss": 0.1148,
      "step": 23600
    },
    {
      "epoch": 3.0850508739890423,
      "grad_norm": 0.04304514825344086,
      "learning_rate": 4.8457474563005484e-05,
      "loss": 0.0735,
      "step": 23650
    },
    {
      "epoch": 3.0915731802765456,
      "grad_norm": 0.09976735711097717,
      "learning_rate": 4.845421340986173e-05,
      "loss": 0.1159,
      "step": 23700
    },
    {
      "epoch": 3.098095486564049,
      "grad_norm": 0.0730561837553978,
      "learning_rate": 4.845095225671798e-05,
      "loss": 0.1726,
      "step": 23750
    },
    {
      "epoch": 3.104617792851552,
      "grad_norm": 0.12590740621089935,
      "learning_rate": 4.844769110357423e-05,
      "loss": 0.0866,
      "step": 23800
    },
    {
      "epoch": 3.1111400991390554,
      "grad_norm": 0.12416477501392365,
      "learning_rate": 4.8444429950430475e-05,
      "loss": 0.1116,
      "step": 23850
    },
    {
      "epoch": 3.1176624054265587,
      "grad_norm": 13.18589973449707,
      "learning_rate": 4.844116879728672e-05,
      "loss": 0.0886,
      "step": 23900
    },
    {
      "epoch": 3.124184711714062,
      "grad_norm": 0.024418113753199577,
      "learning_rate": 4.8437907644142974e-05,
      "loss": 0.0854,
      "step": 23950
    },
    {
      "epoch": 3.1307070180015653,
      "grad_norm": 11.37047004699707,
      "learning_rate": 4.843464649099922e-05,
      "loss": 0.1522,
      "step": 24000
    },
    {
      "epoch": 3.1372293242890685,
      "grad_norm": 12.439973831176758,
      "learning_rate": 4.843138533785547e-05,
      "loss": 0.1075,
      "step": 24050
    },
    {
      "epoch": 3.143751630576572,
      "grad_norm": 0.10436610877513885,
      "learning_rate": 4.842812418471171e-05,
      "loss": 0.2002,
      "step": 24100
    },
    {
      "epoch": 3.150273936864075,
      "grad_norm": 0.1328052580356598,
      "learning_rate": 4.8424863031567966e-05,
      "loss": 0.1854,
      "step": 24150
    },
    {
      "epoch": 3.1567962431515784,
      "grad_norm": 0.1359201967716217,
      "learning_rate": 4.842160187842421e-05,
      "loss": 0.1316,
      "step": 24200
    },
    {
      "epoch": 3.1633185494390816,
      "grad_norm": 5.717591762542725,
      "learning_rate": 4.841834072528046e-05,
      "loss": 0.0941,
      "step": 24250
    },
    {
      "epoch": 3.169840855726585,
      "grad_norm": 9.357577323913574,
      "learning_rate": 4.841507957213671e-05,
      "loss": 0.161,
      "step": 24300
    },
    {
      "epoch": 3.176363162014088,
      "grad_norm": 11.467288970947266,
      "learning_rate": 4.841181841899296e-05,
      "loss": 0.0555,
      "step": 24350
    },
    {
      "epoch": 3.1828854683015915,
      "grad_norm": 7.902487277984619,
      "learning_rate": 4.840855726584921e-05,
      "loss": 0.1034,
      "step": 24400
    },
    {
      "epoch": 3.1894077745890947,
      "grad_norm": 0.803754985332489,
      "learning_rate": 4.8405296112705456e-05,
      "loss": 0.1062,
      "step": 24450
    },
    {
      "epoch": 3.195930080876598,
      "grad_norm": 0.16006897389888763,
      "learning_rate": 4.84020349595617e-05,
      "loss": 0.1453,
      "step": 24500
    },
    {
      "epoch": 3.2024523871641013,
      "grad_norm": 0.058137182146310806,
      "learning_rate": 4.839877380641795e-05,
      "loss": 0.0968,
      "step": 24550
    },
    {
      "epoch": 3.2089746934516046,
      "grad_norm": 6.717907905578613,
      "learning_rate": 4.83955126532742e-05,
      "loss": 0.1077,
      "step": 24600
    },
    {
      "epoch": 3.215496999739108,
      "grad_norm": 8.348912239074707,
      "learning_rate": 4.839225150013045e-05,
      "loss": 0.1272,
      "step": 24650
    },
    {
      "epoch": 3.222019306026611,
      "grad_norm": 0.19125714898109436,
      "learning_rate": 4.8388990346986694e-05,
      "loss": 0.1337,
      "step": 24700
    },
    {
      "epoch": 3.2285416123141144,
      "grad_norm": 0.13301792740821838,
      "learning_rate": 4.838572919384294e-05,
      "loss": 0.0784,
      "step": 24750
    },
    {
      "epoch": 3.2350639186016177,
      "grad_norm": 0.1463221162557602,
      "learning_rate": 4.838246804069919e-05,
      "loss": 0.1452,
      "step": 24800
    },
    {
      "epoch": 3.241586224889121,
      "grad_norm": 5.999964237213135,
      "learning_rate": 4.837920688755544e-05,
      "loss": 0.1938,
      "step": 24850
    },
    {
      "epoch": 3.2481085311766242,
      "grad_norm": 0.10226442664861679,
      "learning_rate": 4.837594573441169e-05,
      "loss": 0.0865,
      "step": 24900
    },
    {
      "epoch": 3.254630837464127,
      "grad_norm": 4.04063606262207,
      "learning_rate": 4.837268458126794e-05,
      "loss": 0.1197,
      "step": 24950
    },
    {
      "epoch": 3.2611531437516303,
      "grad_norm": 0.020316317677497864,
      "learning_rate": 4.836942342812419e-05,
      "loss": 0.1136,
      "step": 25000
    },
    {
      "epoch": 3.2676754500391336,
      "grad_norm": 6.470431804656982,
      "learning_rate": 4.836616227498044e-05,
      "loss": 0.1368,
      "step": 25050
    },
    {
      "epoch": 3.274197756326637,
      "grad_norm": 11.018064498901367,
      "learning_rate": 4.8362901121836684e-05,
      "loss": 0.1496,
      "step": 25100
    },
    {
      "epoch": 3.28072006261414,
      "grad_norm": 0.5963701605796814,
      "learning_rate": 4.835963996869293e-05,
      "loss": 0.1568,
      "step": 25150
    },
    {
      "epoch": 3.2872423689016435,
      "grad_norm": 7.477075576782227,
      "learning_rate": 4.835637881554918e-05,
      "loss": 0.0981,
      "step": 25200
    },
    {
      "epoch": 3.2937646751891467,
      "grad_norm": 0.30224379897117615,
      "learning_rate": 4.835311766240543e-05,
      "loss": 0.1283,
      "step": 25250
    },
    {
      "epoch": 3.30028698147665,
      "grad_norm": 0.0884794220328331,
      "learning_rate": 4.8349856509261675e-05,
      "loss": 0.1846,
      "step": 25300
    },
    {
      "epoch": 3.3068092877641533,
      "grad_norm": 1.968050241470337,
      "learning_rate": 4.834659535611792e-05,
      "loss": 0.1006,
      "step": 25350
    },
    {
      "epoch": 3.3133315940516566,
      "grad_norm": 1.9564770460128784,
      "learning_rate": 4.8343334202974175e-05,
      "loss": 0.107,
      "step": 25400
    },
    {
      "epoch": 3.31985390033916,
      "grad_norm": 0.5322478413581848,
      "learning_rate": 4.834007304983042e-05,
      "loss": 0.1673,
      "step": 25450
    },
    {
      "epoch": 3.326376206626663,
      "grad_norm": 11.72161865234375,
      "learning_rate": 4.8336811896686674e-05,
      "loss": 0.0997,
      "step": 25500
    },
    {
      "epoch": 3.3328985129141664,
      "grad_norm": 0.03998780623078346,
      "learning_rate": 4.833355074354292e-05,
      "loss": 0.1143,
      "step": 25550
    },
    {
      "epoch": 3.3394208192016697,
      "grad_norm": 13.485870361328125,
      "learning_rate": 4.8330289590399166e-05,
      "loss": 0.0808,
      "step": 25600
    },
    {
      "epoch": 3.345943125489173,
      "grad_norm": 0.11748181283473969,
      "learning_rate": 4.832702843725542e-05,
      "loss": 0.1029,
      "step": 25650
    },
    {
      "epoch": 3.352465431776676,
      "grad_norm": 0.01708999276161194,
      "learning_rate": 4.8323767284111665e-05,
      "loss": 0.1463,
      "step": 25700
    },
    {
      "epoch": 3.3589877380641795,
      "grad_norm": 10.805835723876953,
      "learning_rate": 4.832050613096791e-05,
      "loss": 0.1144,
      "step": 25750
    },
    {
      "epoch": 3.3655100443516828,
      "grad_norm": 0.06768840551376343,
      "learning_rate": 4.831724497782416e-05,
      "loss": 0.157,
      "step": 25800
    },
    {
      "epoch": 3.372032350639186,
      "grad_norm": 0.01732317917048931,
      "learning_rate": 4.831398382468041e-05,
      "loss": 0.1001,
      "step": 25850
    },
    {
      "epoch": 3.3785546569266893,
      "grad_norm": 0.16805414855480194,
      "learning_rate": 4.831072267153666e-05,
      "loss": 0.1325,
      "step": 25900
    },
    {
      "epoch": 3.3850769632141926,
      "grad_norm": 5.371449947357178,
      "learning_rate": 4.83074615183929e-05,
      "loss": 0.1038,
      "step": 25950
    },
    {
      "epoch": 3.391599269501696,
      "grad_norm": 0.02688034251332283,
      "learning_rate": 4.8304200365249156e-05,
      "loss": 0.158,
      "step": 26000
    },
    {
      "epoch": 3.398121575789199,
      "grad_norm": 0.03147875890135765,
      "learning_rate": 4.83009392121054e-05,
      "loss": 0.1261,
      "step": 26050
    },
    {
      "epoch": 3.4046438820767024,
      "grad_norm": 0.32719171047210693,
      "learning_rate": 4.829767805896165e-05,
      "loss": 0.0885,
      "step": 26100
    },
    {
      "epoch": 3.4111661883642057,
      "grad_norm": 0.022104982286691666,
      "learning_rate": 4.82944169058179e-05,
      "loss": 0.1371,
      "step": 26150
    },
    {
      "epoch": 3.417688494651709,
      "grad_norm": 0.5638088583946228,
      "learning_rate": 4.829115575267415e-05,
      "loss": 0.0808,
      "step": 26200
    },
    {
      "epoch": 3.4242108009392123,
      "grad_norm": 0.0599256306886673,
      "learning_rate": 4.82878945995304e-05,
      "loss": 0.1177,
      "step": 26250
    },
    {
      "epoch": 3.4307331072267155,
      "grad_norm": 0.016083985567092896,
      "learning_rate": 4.8284633446386647e-05,
      "loss": 0.1081,
      "step": 26300
    },
    {
      "epoch": 3.437255413514219,
      "grad_norm": 0.023800740018486977,
      "learning_rate": 4.828137229324289e-05,
      "loss": 0.135,
      "step": 26350
    },
    {
      "epoch": 3.443777719801722,
      "grad_norm": 0.018534157425165176,
      "learning_rate": 4.827811114009914e-05,
      "loss": 0.0957,
      "step": 26400
    },
    {
      "epoch": 3.4503000260892254,
      "grad_norm": 0.6436807513237,
      "learning_rate": 4.827484998695539e-05,
      "loss": 0.0937,
      "step": 26450
    },
    {
      "epoch": 3.4568223323767286,
      "grad_norm": 0.605415940284729,
      "learning_rate": 4.827158883381164e-05,
      "loss": 0.1256,
      "step": 26500
    },
    {
      "epoch": 3.4633446386642315,
      "grad_norm": 10.278966903686523,
      "learning_rate": 4.8268327680667884e-05,
      "loss": 0.1294,
      "step": 26550
    },
    {
      "epoch": 3.4698669449517348,
      "grad_norm": 5.012243747711182,
      "learning_rate": 4.826506652752413e-05,
      "loss": 0.0796,
      "step": 26600
    },
    {
      "epoch": 3.476389251239238,
      "grad_norm": 0.2917768657207489,
      "learning_rate": 4.826180537438038e-05,
      "loss": 0.1619,
      "step": 26650
    },
    {
      "epoch": 3.4829115575267413,
      "grad_norm": 0.05887223035097122,
      "learning_rate": 4.825854422123663e-05,
      "loss": 0.0986,
      "step": 26700
    },
    {
      "epoch": 3.4894338638142446,
      "grad_norm": 8.064610481262207,
      "learning_rate": 4.825528306809288e-05,
      "loss": 0.0713,
      "step": 26750
    },
    {
      "epoch": 3.495956170101748,
      "grad_norm": 19.23297882080078,
      "learning_rate": 4.825202191494913e-05,
      "loss": 0.1244,
      "step": 26800
    },
    {
      "epoch": 3.502478476389251,
      "grad_norm": 0.03955613076686859,
      "learning_rate": 4.824876076180538e-05,
      "loss": 0.1234,
      "step": 26850
    },
    {
      "epoch": 3.5090007826767544,
      "grad_norm": 4.1109442710876465,
      "learning_rate": 4.824549960866163e-05,
      "loss": 0.0843,
      "step": 26900
    },
    {
      "epoch": 3.5155230889642577,
      "grad_norm": 3.6059515476226807,
      "learning_rate": 4.8242238455517874e-05,
      "loss": 0.0652,
      "step": 26950
    },
    {
      "epoch": 3.522045395251761,
      "grad_norm": 0.06374437361955643,
      "learning_rate": 4.823897730237412e-05,
      "loss": 0.153,
      "step": 27000
    },
    {
      "epoch": 3.5285677015392642,
      "grad_norm": 0.07143000513315201,
      "learning_rate": 4.823571614923037e-05,
      "loss": 0.2,
      "step": 27050
    },
    {
      "epoch": 3.5350900078267675,
      "grad_norm": 0.43435293436050415,
      "learning_rate": 4.823245499608662e-05,
      "loss": 0.0898,
      "step": 27100
    },
    {
      "epoch": 3.541612314114271,
      "grad_norm": 0.47666406631469727,
      "learning_rate": 4.8229193842942866e-05,
      "loss": 0.1074,
      "step": 27150
    },
    {
      "epoch": 3.548134620401774,
      "grad_norm": 0.06660549342632294,
      "learning_rate": 4.822593268979911e-05,
      "loss": 0.1192,
      "step": 27200
    },
    {
      "epoch": 3.5546569266892774,
      "grad_norm": 5.999230861663818,
      "learning_rate": 4.8222671536655365e-05,
      "loss": 0.1432,
      "step": 27250
    },
    {
      "epoch": 3.5611792329767806,
      "grad_norm": 0.1118115559220314,
      "learning_rate": 4.821941038351161e-05,
      "loss": 0.0998,
      "step": 27300
    },
    {
      "epoch": 3.567701539264284,
      "grad_norm": 0.030737467110157013,
      "learning_rate": 4.8216149230367864e-05,
      "loss": 0.1093,
      "step": 27350
    },
    {
      "epoch": 3.574223845551787,
      "grad_norm": 12.015538215637207,
      "learning_rate": 4.821288807722411e-05,
      "loss": 0.0837,
      "step": 27400
    },
    {
      "epoch": 3.5807461518392905,
      "grad_norm": 5.078526973724365,
      "learning_rate": 4.8209626924080356e-05,
      "loss": 0.1735,
      "step": 27450
    },
    {
      "epoch": 3.5872684581267937,
      "grad_norm": 0.21978776156902313,
      "learning_rate": 4.820636577093661e-05,
      "loss": 0.138,
      "step": 27500
    },
    {
      "epoch": 3.593790764414297,
      "grad_norm": 0.0995211973786354,
      "learning_rate": 4.8203104617792855e-05,
      "loss": 0.0721,
      "step": 27550
    },
    {
      "epoch": 3.6003130707018003,
      "grad_norm": 10.700380325317383,
      "learning_rate": 4.81998434646491e-05,
      "loss": 0.0759,
      "step": 27600
    },
    {
      "epoch": 3.6068353769893036,
      "grad_norm": 0.042120158672332764,
      "learning_rate": 4.819658231150535e-05,
      "loss": 0.1402,
      "step": 27650
    },
    {
      "epoch": 3.613357683276807,
      "grad_norm": 0.8760380148887634,
      "learning_rate": 4.81933211583616e-05,
      "loss": 0.0889,
      "step": 27700
    },
    {
      "epoch": 3.6198799895643097,
      "grad_norm": 0.45002028346061707,
      "learning_rate": 4.819006000521785e-05,
      "loss": 0.0838,
      "step": 27750
    },
    {
      "epoch": 3.626402295851813,
      "grad_norm": 0.06737886369228363,
      "learning_rate": 4.818679885207409e-05,
      "loss": 0.0869,
      "step": 27800
    },
    {
      "epoch": 3.6329246021393162,
      "grad_norm": 0.031037645414471626,
      "learning_rate": 4.818353769893034e-05,
      "loss": 0.1278,
      "step": 27850
    },
    {
      "epoch": 3.6394469084268195,
      "grad_norm": 0.04687510058283806,
      "learning_rate": 4.818027654578659e-05,
      "loss": 0.0832,
      "step": 27900
    },
    {
      "epoch": 3.645969214714323,
      "grad_norm": 0.11478991061449051,
      "learning_rate": 4.8177015392642845e-05,
      "loss": 0.1289,
      "step": 27950
    },
    {
      "epoch": 3.652491521001826,
      "grad_norm": 1.384671688079834,
      "learning_rate": 4.817375423949909e-05,
      "loss": 0.1089,
      "step": 28000
    },
    {
      "epoch": 3.6590138272893293,
      "grad_norm": 13.654194831848145,
      "learning_rate": 4.817049308635534e-05,
      "loss": 0.1706,
      "step": 28050
    },
    {
      "epoch": 3.6655361335768326,
      "grad_norm": 0.01547444798052311,
      "learning_rate": 4.816723193321159e-05,
      "loss": 0.1219,
      "step": 28100
    },
    {
      "epoch": 3.672058439864336,
      "grad_norm": 0.061643850058317184,
      "learning_rate": 4.816397078006784e-05,
      "loss": 0.1217,
      "step": 28150
    },
    {
      "epoch": 3.678580746151839,
      "grad_norm": 0.12724898755550385,
      "learning_rate": 4.816070962692408e-05,
      "loss": 0.1022,
      "step": 28200
    },
    {
      "epoch": 3.6851030524393424,
      "grad_norm": 12.434033393859863,
      "learning_rate": 4.815744847378033e-05,
      "loss": 0.1053,
      "step": 28250
    },
    {
      "epoch": 3.6916253587268457,
      "grad_norm": 0.07187862694263458,
      "learning_rate": 4.815418732063658e-05,
      "loss": 0.0993,
      "step": 28300
    },
    {
      "epoch": 3.698147665014349,
      "grad_norm": 0.11165053397417068,
      "learning_rate": 4.815092616749283e-05,
      "loss": 0.0999,
      "step": 28350
    },
    {
      "epoch": 3.7046699713018523,
      "grad_norm": 5.521913528442383,
      "learning_rate": 4.8147665014349074e-05,
      "loss": 0.1267,
      "step": 28400
    },
    {
      "epoch": 3.7111922775893555,
      "grad_norm": 0.07225354760885239,
      "learning_rate": 4.814440386120532e-05,
      "loss": 0.1491,
      "step": 28450
    },
    {
      "epoch": 3.717714583876859,
      "grad_norm": 0.011538097634911537,
      "learning_rate": 4.8141142708061573e-05,
      "loss": 0.097,
      "step": 28500
    },
    {
      "epoch": 3.724236890164362,
      "grad_norm": 0.21337653696537018,
      "learning_rate": 4.813788155491782e-05,
      "loss": 0.0902,
      "step": 28550
    },
    {
      "epoch": 3.7307591964518654,
      "grad_norm": 0.015351280570030212,
      "learning_rate": 4.813462040177407e-05,
      "loss": 0.1208,
      "step": 28600
    },
    {
      "epoch": 3.7372815027393687,
      "grad_norm": 0.15644127130508423,
      "learning_rate": 4.813135924863032e-05,
      "loss": 0.1412,
      "step": 28650
    },
    {
      "epoch": 3.743803809026872,
      "grad_norm": 0.056047018617391586,
      "learning_rate": 4.8128098095486565e-05,
      "loss": 0.1629,
      "step": 28700
    },
    {
      "epoch": 3.750326115314375,
      "grad_norm": 0.2686050236225128,
      "learning_rate": 4.812483694234282e-05,
      "loss": 0.1188,
      "step": 28750
    },
    {
      "epoch": 3.7568484216018785,
      "grad_norm": 2.2065389156341553,
      "learning_rate": 4.8121575789199064e-05,
      "loss": 0.1164,
      "step": 28800
    },
    {
      "epoch": 3.7633707278893818,
      "grad_norm": 11.656144142150879,
      "learning_rate": 4.811831463605531e-05,
      "loss": 0.1172,
      "step": 28850
    },
    {
      "epoch": 3.769893034176885,
      "grad_norm": 0.017672913148999214,
      "learning_rate": 4.8115053482911556e-05,
      "loss": 0.15,
      "step": 28900
    },
    {
      "epoch": 3.7764153404643883,
      "grad_norm": 15.1731595993042,
      "learning_rate": 4.811179232976781e-05,
      "loss": 0.1687,
      "step": 28950
    },
    {
      "epoch": 3.7829376467518916,
      "grad_norm": 5.575639724731445,
      "learning_rate": 4.8108531176624056e-05,
      "loss": 0.1439,
      "step": 29000
    },
    {
      "epoch": 3.789459953039395,
      "grad_norm": 0.2099088877439499,
      "learning_rate": 4.81052700234803e-05,
      "loss": 0.136,
      "step": 29050
    },
    {
      "epoch": 3.795982259326898,
      "grad_norm": 0.021420281380414963,
      "learning_rate": 4.810200887033655e-05,
      "loss": 0.0982,
      "step": 29100
    },
    {
      "epoch": 3.8025045656144014,
      "grad_norm": 0.3213875889778137,
      "learning_rate": 4.80987477171928e-05,
      "loss": 0.1332,
      "step": 29150
    },
    {
      "epoch": 3.8090268719019047,
      "grad_norm": 0.505139172077179,
      "learning_rate": 4.8095486564049054e-05,
      "loss": 0.1394,
      "step": 29200
    },
    {
      "epoch": 3.815549178189408,
      "grad_norm": 12.474764823913574,
      "learning_rate": 4.80922254109053e-05,
      "loss": 0.0687,
      "step": 29250
    },
    {
      "epoch": 3.8220714844769113,
      "grad_norm": 0.052831780165433884,
      "learning_rate": 4.8088964257761546e-05,
      "loss": 0.158,
      "step": 29300
    },
    {
      "epoch": 3.8285937907644145,
      "grad_norm": 1.0865797996520996,
      "learning_rate": 4.80857031046178e-05,
      "loss": 0.0749,
      "step": 29350
    },
    {
      "epoch": 3.835116097051918,
      "grad_norm": 16.22764778137207,
      "learning_rate": 4.8082441951474045e-05,
      "loss": 0.1883,
      "step": 29400
    },
    {
      "epoch": 3.841638403339421,
      "grad_norm": 0.021016739308834076,
      "learning_rate": 4.807918079833029e-05,
      "loss": 0.0795,
      "step": 29450
    },
    {
      "epoch": 3.848160709626924,
      "grad_norm": 11.978531837463379,
      "learning_rate": 4.807591964518654e-05,
      "loss": 0.1526,
      "step": 29500
    },
    {
      "epoch": 3.854683015914427,
      "grad_norm": 0.15030699968338013,
      "learning_rate": 4.807265849204279e-05,
      "loss": 0.102,
      "step": 29550
    },
    {
      "epoch": 3.8612053222019305,
      "grad_norm": 9.041769981384277,
      "learning_rate": 4.806939733889904e-05,
      "loss": 0.0925,
      "step": 29600
    },
    {
      "epoch": 3.8677276284894337,
      "grad_norm": 19.417346954345703,
      "learning_rate": 4.806613618575528e-05,
      "loss": 0.1284,
      "step": 29650
    },
    {
      "epoch": 3.874249934776937,
      "grad_norm": 0.023373974487185478,
      "learning_rate": 4.806287503261153e-05,
      "loss": 0.0637,
      "step": 29700
    },
    {
      "epoch": 3.8807722410644403,
      "grad_norm": 8.330972671508789,
      "learning_rate": 4.805961387946778e-05,
      "loss": 0.1062,
      "step": 29750
    },
    {
      "epoch": 3.8872945473519436,
      "grad_norm": 8.31502628326416,
      "learning_rate": 4.8056352726324035e-05,
      "loss": 0.1198,
      "step": 29800
    },
    {
      "epoch": 3.893816853639447,
      "grad_norm": 13.383082389831543,
      "learning_rate": 4.805309157318028e-05,
      "loss": 0.1538,
      "step": 29850
    },
    {
      "epoch": 3.90033915992695,
      "grad_norm": 0.9166167974472046,
      "learning_rate": 4.804983042003653e-05,
      "loss": 0.1545,
      "step": 29900
    },
    {
      "epoch": 3.9068614662144534,
      "grad_norm": 19.03786277770996,
      "learning_rate": 4.8046569266892774e-05,
      "loss": 0.1745,
      "step": 29950
    },
    {
      "epoch": 3.9133837725019567,
      "grad_norm": 0.03548644483089447,
      "learning_rate": 4.804330811374903e-05,
      "loss": 0.0773,
      "step": 30000
    },
    {
      "epoch": 3.91990607878946,
      "grad_norm": 0.0827176496386528,
      "learning_rate": 4.804004696060527e-05,
      "loss": 0.1097,
      "step": 30050
    },
    {
      "epoch": 3.9264283850769632,
      "grad_norm": 0.17154251039028168,
      "learning_rate": 4.803678580746152e-05,
      "loss": 0.1177,
      "step": 30100
    },
    {
      "epoch": 3.9329506913644665,
      "grad_norm": 0.007061158772557974,
      "learning_rate": 4.8033524654317765e-05,
      "loss": 0.0909,
      "step": 30150
    },
    {
      "epoch": 3.93947299765197,
      "grad_norm": 0.8168509006500244,
      "learning_rate": 4.803026350117402e-05,
      "loss": 0.1486,
      "step": 30200
    },
    {
      "epoch": 3.945995303939473,
      "grad_norm": 19.643884658813477,
      "learning_rate": 4.8027002348030264e-05,
      "loss": 0.1375,
      "step": 30250
    },
    {
      "epoch": 3.9525176102269763,
      "grad_norm": 0.011982867494225502,
      "learning_rate": 4.802374119488651e-05,
      "loss": 0.1311,
      "step": 30300
    },
    {
      "epoch": 3.9590399165144796,
      "grad_norm": 0.04391774162650108,
      "learning_rate": 4.8020480041742764e-05,
      "loss": 0.0991,
      "step": 30350
    },
    {
      "epoch": 3.965562222801983,
      "grad_norm": 0.008464294485747814,
      "learning_rate": 4.801721888859901e-05,
      "loss": 0.1455,
      "step": 30400
    },
    {
      "epoch": 3.972084529089486,
      "grad_norm": 0.04808374494314194,
      "learning_rate": 4.801395773545526e-05,
      "loss": 0.119,
      "step": 30450
    },
    {
      "epoch": 3.9786068353769894,
      "grad_norm": 0.2596229016780853,
      "learning_rate": 4.801069658231151e-05,
      "loss": 0.1576,
      "step": 30500
    },
    {
      "epoch": 3.9851291416644927,
      "grad_norm": 0.08902931958436966,
      "learning_rate": 4.8007435429167755e-05,
      "loss": 0.086,
      "step": 30550
    },
    {
      "epoch": 3.9916514479519956,
      "grad_norm": 0.03248949348926544,
      "learning_rate": 4.800417427602401e-05,
      "loss": 0.1286,
      "step": 30600
    },
    {
      "epoch": 3.998173754239499,
      "grad_norm": 0.09147144854068756,
      "learning_rate": 4.8000913122880254e-05,
      "loss": 0.1126,
      "step": 30650
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9654969997391077,
      "eval_f1": 0.9652955454962934,
      "eval_loss": 0.13639995455741882,
      "eval_precision": 0.9712211221122112,
      "eval_recall": 0.9594418362023995,
      "eval_runtime": 23.4609,
      "eval_samples_per_second": 653.513,
      "eval_steps_per_second": 81.71,
      "step": 30664
    },
    {
      "epoch": 4.004696060527002,
      "grad_norm": 0.453191876411438,
      "learning_rate": 4.79976519697365e-05,
      "loss": 0.1171,
      "step": 30700
    },
    {
      "epoch": 4.011218366814505,
      "grad_norm": 10.77808666229248,
      "learning_rate": 4.7994390816592747e-05,
      "loss": 0.1558,
      "step": 30750
    },
    {
      "epoch": 4.017740673102009,
      "grad_norm": 0.20459622144699097,
      "learning_rate": 4.7991129663449e-05,
      "loss": 0.075,
      "step": 30800
    },
    {
      "epoch": 4.024262979389512,
      "grad_norm": 0.07131659984588623,
      "learning_rate": 4.7987868510305246e-05,
      "loss": 0.0894,
      "step": 30850
    },
    {
      "epoch": 4.030785285677015,
      "grad_norm": 10.65898323059082,
      "learning_rate": 4.798460735716149e-05,
      "loss": 0.1128,
      "step": 30900
    },
    {
      "epoch": 4.0373075919645185,
      "grad_norm": 0.6238629221916199,
      "learning_rate": 4.798134620401774e-05,
      "loss": 0.1181,
      "step": 30950
    },
    {
      "epoch": 4.043829898252022,
      "grad_norm": 0.014928458258509636,
      "learning_rate": 4.797808505087399e-05,
      "loss": 0.1033,
      "step": 31000
    },
    {
      "epoch": 4.050352204539525,
      "grad_norm": 9.041189193725586,
      "learning_rate": 4.7974823897730244e-05,
      "loss": 0.0727,
      "step": 31050
    },
    {
      "epoch": 4.056874510827028,
      "grad_norm": 1.4188705682754517,
      "learning_rate": 4.797156274458649e-05,
      "loss": 0.1161,
      "step": 31100
    },
    {
      "epoch": 4.063396817114532,
      "grad_norm": 0.4478743374347687,
      "learning_rate": 4.7968301591442736e-05,
      "loss": 0.1483,
      "step": 31150
    },
    {
      "epoch": 4.069919123402035,
      "grad_norm": 17.200490951538086,
      "learning_rate": 4.796504043829899e-05,
      "loss": 0.0725,
      "step": 31200
    },
    {
      "epoch": 4.076441429689538,
      "grad_norm": 7.265129566192627,
      "learning_rate": 4.7961779285155235e-05,
      "loss": 0.1153,
      "step": 31250
    },
    {
      "epoch": 4.082963735977041,
      "grad_norm": 0.9450781941413879,
      "learning_rate": 4.795851813201148e-05,
      "loss": 0.061,
      "step": 31300
    },
    {
      "epoch": 4.089486042264545,
      "grad_norm": 30.492456436157227,
      "learning_rate": 4.795525697886773e-05,
      "loss": 0.1258,
      "step": 31350
    },
    {
      "epoch": 4.096008348552048,
      "grad_norm": 0.06542950123548508,
      "learning_rate": 4.795199582572398e-05,
      "loss": 0.1298,
      "step": 31400
    },
    {
      "epoch": 4.102530654839551,
      "grad_norm": 6.077010154724121,
      "learning_rate": 4.794873467258023e-05,
      "loss": 0.0503,
      "step": 31450
    },
    {
      "epoch": 4.1090529611270545,
      "grad_norm": 6.91702127456665,
      "learning_rate": 4.794547351943647e-05,
      "loss": 0.1156,
      "step": 31500
    },
    {
      "epoch": 4.115575267414558,
      "grad_norm": 0.05469920113682747,
      "learning_rate": 4.794221236629272e-05,
      "loss": 0.1389,
      "step": 31550
    },
    {
      "epoch": 4.122097573702061,
      "grad_norm": 0.04525505751371384,
      "learning_rate": 4.793895121314897e-05,
      "loss": 0.1405,
      "step": 31600
    },
    {
      "epoch": 4.128619879989564,
      "grad_norm": 0.22013115882873535,
      "learning_rate": 4.7935690060005225e-05,
      "loss": 0.104,
      "step": 31650
    },
    {
      "epoch": 4.135142186277068,
      "grad_norm": 7.926776885986328,
      "learning_rate": 4.793242890686147e-05,
      "loss": 0.1456,
      "step": 31700
    },
    {
      "epoch": 4.141664492564571,
      "grad_norm": 4.9480414390563965,
      "learning_rate": 4.792916775371772e-05,
      "loss": 0.0971,
      "step": 31750
    },
    {
      "epoch": 4.148186798852074,
      "grad_norm": 0.00926788616925478,
      "learning_rate": 4.7925906600573964e-05,
      "loss": 0.1278,
      "step": 31800
    },
    {
      "epoch": 4.1547091051395775,
      "grad_norm": 0.030321108177304268,
      "learning_rate": 4.792264544743022e-05,
      "loss": 0.0851,
      "step": 31850
    },
    {
      "epoch": 4.161231411427081,
      "grad_norm": 0.10001513361930847,
      "learning_rate": 4.791938429428646e-05,
      "loss": 0.0974,
      "step": 31900
    },
    {
      "epoch": 4.167753717714584,
      "grad_norm": 0.06371273100376129,
      "learning_rate": 4.791612314114271e-05,
      "loss": 0.1199,
      "step": 31950
    },
    {
      "epoch": 4.174276024002087,
      "grad_norm": 0.15082024037837982,
      "learning_rate": 4.7912861987998955e-05,
      "loss": 0.0964,
      "step": 32000
    },
    {
      "epoch": 4.180798330289591,
      "grad_norm": 1.4168939590454102,
      "learning_rate": 4.790960083485521e-05,
      "loss": 0.1867,
      "step": 32050
    },
    {
      "epoch": 4.187320636577094,
      "grad_norm": 1.4915038347244263,
      "learning_rate": 4.7906339681711454e-05,
      "loss": 0.1728,
      "step": 32100
    },
    {
      "epoch": 4.193842942864597,
      "grad_norm": 0.03479135036468506,
      "learning_rate": 4.79030785285677e-05,
      "loss": 0.0956,
      "step": 32150
    },
    {
      "epoch": 4.2003652491521,
      "grad_norm": 0.29630643129348755,
      "learning_rate": 4.789981737542395e-05,
      "loss": 0.1299,
      "step": 32200
    },
    {
      "epoch": 4.206887555439604,
      "grad_norm": 0.19786228239536285,
      "learning_rate": 4.7896556222280207e-05,
      "loss": 0.0962,
      "step": 32250
    },
    {
      "epoch": 4.213409861727107,
      "grad_norm": 0.032153017818927765,
      "learning_rate": 4.789329506913645e-05,
      "loss": 0.1156,
      "step": 32300
    },
    {
      "epoch": 4.21993216801461,
      "grad_norm": 1.284644365310669,
      "learning_rate": 4.78900339159927e-05,
      "loss": 0.1384,
      "step": 32350
    },
    {
      "epoch": 4.2264544743021135,
      "grad_norm": 23.143203735351562,
      "learning_rate": 4.7886772762848945e-05,
      "loss": 0.1031,
      "step": 32400
    },
    {
      "epoch": 4.232976780589617,
      "grad_norm": 0.09285025298595428,
      "learning_rate": 4.78835116097052e-05,
      "loss": 0.0641,
      "step": 32450
    },
    {
      "epoch": 4.23949908687712,
      "grad_norm": 0.023575911298394203,
      "learning_rate": 4.7880250456561444e-05,
      "loss": 0.0717,
      "step": 32500
    },
    {
      "epoch": 4.246021393164623,
      "grad_norm": 0.0286225788295269,
      "learning_rate": 4.787698930341769e-05,
      "loss": 0.136,
      "step": 32550
    },
    {
      "epoch": 4.252543699452127,
      "grad_norm": 0.01772409677505493,
      "learning_rate": 4.787372815027394e-05,
      "loss": 0.114,
      "step": 32600
    },
    {
      "epoch": 4.25906600573963,
      "grad_norm": 0.08202844858169556,
      "learning_rate": 4.787046699713019e-05,
      "loss": 0.116,
      "step": 32650
    },
    {
      "epoch": 4.265588312027133,
      "grad_norm": 0.11000234633684158,
      "learning_rate": 4.7867205843986436e-05,
      "loss": 0.1719,
      "step": 32700
    },
    {
      "epoch": 4.2721106183146365,
      "grad_norm": 4.38431453704834,
      "learning_rate": 4.786394469084268e-05,
      "loss": 0.1114,
      "step": 32750
    },
    {
      "epoch": 4.27863292460214,
      "grad_norm": 3.8100385665893555,
      "learning_rate": 4.786068353769893e-05,
      "loss": 0.1247,
      "step": 32800
    },
    {
      "epoch": 4.285155230889643,
      "grad_norm": 8.31334400177002,
      "learning_rate": 4.785742238455518e-05,
      "loss": 0.0906,
      "step": 32850
    },
    {
      "epoch": 4.291677537177145,
      "grad_norm": 2.7059643268585205,
      "learning_rate": 4.7854161231411434e-05,
      "loss": 0.0846,
      "step": 32900
    },
    {
      "epoch": 4.29819984346465,
      "grad_norm": 6.507017135620117,
      "learning_rate": 4.785090007826768e-05,
      "loss": 0.1086,
      "step": 32950
    },
    {
      "epoch": 4.304722149752152,
      "grad_norm": 6.392254829406738,
      "learning_rate": 4.7847638925123926e-05,
      "loss": 0.1163,
      "step": 33000
    },
    {
      "epoch": 4.311244456039655,
      "grad_norm": 5.021106243133545,
      "learning_rate": 4.784437777198017e-05,
      "loss": 0.1041,
      "step": 33050
    },
    {
      "epoch": 4.3177667623271585,
      "grad_norm": 0.06061580404639244,
      "learning_rate": 4.7841116618836426e-05,
      "loss": 0.092,
      "step": 33100
    },
    {
      "epoch": 4.324289068614662,
      "grad_norm": 6.390877723693848,
      "learning_rate": 4.783785546569267e-05,
      "loss": 0.1113,
      "step": 33150
    },
    {
      "epoch": 4.330811374902165,
      "grad_norm": 8.021600723266602,
      "learning_rate": 4.783459431254892e-05,
      "loss": 0.1062,
      "step": 33200
    },
    {
      "epoch": 4.337333681189668,
      "grad_norm": 0.02007942460477352,
      "learning_rate": 4.7831333159405164e-05,
      "loss": 0.145,
      "step": 33250
    },
    {
      "epoch": 4.343855987477172,
      "grad_norm": 13.680975914001465,
      "learning_rate": 4.782807200626142e-05,
      "loss": 0.0818,
      "step": 33300
    },
    {
      "epoch": 4.350378293764675,
      "grad_norm": 12.164780616760254,
      "learning_rate": 4.782481085311766e-05,
      "loss": 0.1307,
      "step": 33350
    },
    {
      "epoch": 4.356900600052178,
      "grad_norm": 0.04896073415875435,
      "learning_rate": 4.782154969997391e-05,
      "loss": 0.0766,
      "step": 33400
    },
    {
      "epoch": 4.363422906339681,
      "grad_norm": 1.947373628616333,
      "learning_rate": 4.7818288546830156e-05,
      "loss": 0.1422,
      "step": 33450
    },
    {
      "epoch": 4.369945212627185,
      "grad_norm": 0.22184766829013824,
      "learning_rate": 4.7815027393686415e-05,
      "loss": 0.136,
      "step": 33500
    },
    {
      "epoch": 4.376467518914688,
      "grad_norm": 0.031363844871520996,
      "learning_rate": 4.781176624054266e-05,
      "loss": 0.1616,
      "step": 33550
    },
    {
      "epoch": 4.382989825202191,
      "grad_norm": 0.11535365879535675,
      "learning_rate": 4.780850508739891e-05,
      "loss": 0.114,
      "step": 33600
    },
    {
      "epoch": 4.3895121314896945,
      "grad_norm": 16.345687866210938,
      "learning_rate": 4.7805243934255154e-05,
      "loss": 0.1036,
      "step": 33650
    },
    {
      "epoch": 4.396034437777198,
      "grad_norm": 0.06788883358240128,
      "learning_rate": 4.780198278111141e-05,
      "loss": 0.1235,
      "step": 33700
    },
    {
      "epoch": 4.402556744064701,
      "grad_norm": 0.1465149074792862,
      "learning_rate": 4.779872162796765e-05,
      "loss": 0.1423,
      "step": 33750
    },
    {
      "epoch": 4.409079050352204,
      "grad_norm": 12.393837928771973,
      "learning_rate": 4.77954604748239e-05,
      "loss": 0.1137,
      "step": 33800
    },
    {
      "epoch": 4.415601356639708,
      "grad_norm": 12.704448699951172,
      "learning_rate": 4.7792199321680145e-05,
      "loss": 0.1237,
      "step": 33850
    },
    {
      "epoch": 4.422123662927211,
      "grad_norm": 0.07360024005174637,
      "learning_rate": 4.77889381685364e-05,
      "loss": 0.1076,
      "step": 33900
    },
    {
      "epoch": 4.428645969214714,
      "grad_norm": 0.07830030471086502,
      "learning_rate": 4.7785677015392645e-05,
      "loss": 0.1268,
      "step": 33950
    },
    {
      "epoch": 4.4351682755022175,
      "grad_norm": 14.98625659942627,
      "learning_rate": 4.778241586224889e-05,
      "loss": 0.1412,
      "step": 34000
    },
    {
      "epoch": 4.441690581789721,
      "grad_norm": 0.23072931170463562,
      "learning_rate": 4.777915470910514e-05,
      "loss": 0.1262,
      "step": 34050
    },
    {
      "epoch": 4.448212888077224,
      "grad_norm": 0.007585608866065741,
      "learning_rate": 4.777589355596139e-05,
      "loss": 0.0827,
      "step": 34100
    },
    {
      "epoch": 4.454735194364727,
      "grad_norm": 0.08140402287244797,
      "learning_rate": 4.777263240281764e-05,
      "loss": 0.0989,
      "step": 34150
    },
    {
      "epoch": 4.461257500652231,
      "grad_norm": 22.171396255493164,
      "learning_rate": 4.776937124967389e-05,
      "loss": 0.1299,
      "step": 34200
    },
    {
      "epoch": 4.467779806939734,
      "grad_norm": 17.086841583251953,
      "learning_rate": 4.7766110096530135e-05,
      "loss": 0.1219,
      "step": 34250
    },
    {
      "epoch": 4.474302113227237,
      "grad_norm": 4.88931941986084,
      "learning_rate": 4.776284894338638e-05,
      "loss": 0.1251,
      "step": 34300
    },
    {
      "epoch": 4.48082441951474,
      "grad_norm": 0.13714805245399475,
      "learning_rate": 4.7759587790242634e-05,
      "loss": 0.1541,
      "step": 34350
    },
    {
      "epoch": 4.487346725802244,
      "grad_norm": 17.350048065185547,
      "learning_rate": 4.775632663709888e-05,
      "loss": 0.0776,
      "step": 34400
    },
    {
      "epoch": 4.493869032089747,
      "grad_norm": 0.40677306056022644,
      "learning_rate": 4.775306548395513e-05,
      "loss": 0.0959,
      "step": 34450
    },
    {
      "epoch": 4.50039133837725,
      "grad_norm": 0.06433175504207611,
      "learning_rate": 4.774980433081137e-05,
      "loss": 0.1069,
      "step": 34500
    },
    {
      "epoch": 4.5069136446647535,
      "grad_norm": 0.07518208026885986,
      "learning_rate": 4.7746543177667626e-05,
      "loss": 0.1276,
      "step": 34550
    },
    {
      "epoch": 4.513435950952257,
      "grad_norm": 0.02484213560819626,
      "learning_rate": 4.774328202452387e-05,
      "loss": 0.1519,
      "step": 34600
    },
    {
      "epoch": 4.51995825723976,
      "grad_norm": 20.489521026611328,
      "learning_rate": 4.774002087138012e-05,
      "loss": 0.0656,
      "step": 34650
    },
    {
      "epoch": 4.526480563527263,
      "grad_norm": 2.238368511199951,
      "learning_rate": 4.773675971823637e-05,
      "loss": 0.133,
      "step": 34700
    },
    {
      "epoch": 4.533002869814767,
      "grad_norm": 0.169210284948349,
      "learning_rate": 4.7733498565092624e-05,
      "loss": 0.0977,
      "step": 34750
    },
    {
      "epoch": 4.53952517610227,
      "grad_norm": 6.429010391235352,
      "learning_rate": 4.773023741194887e-05,
      "loss": 0.1378,
      "step": 34800
    },
    {
      "epoch": 4.546047482389773,
      "grad_norm": 9.512399673461914,
      "learning_rate": 4.7726976258805117e-05,
      "loss": 0.119,
      "step": 34850
    },
    {
      "epoch": 4.5525697886772765,
      "grad_norm": 0.3657292425632477,
      "learning_rate": 4.772371510566136e-05,
      "loss": 0.1127,
      "step": 34900
    },
    {
      "epoch": 4.55909209496478,
      "grad_norm": 0.04961250722408295,
      "learning_rate": 4.7720453952517616e-05,
      "loss": 0.0826,
      "step": 34950
    },
    {
      "epoch": 4.565614401252283,
      "grad_norm": 0.7028632760047913,
      "learning_rate": 4.771719279937386e-05,
      "loss": 0.0903,
      "step": 35000
    },
    {
      "epoch": 4.572136707539786,
      "grad_norm": 0.21273589134216309,
      "learning_rate": 4.771393164623011e-05,
      "loss": 0.1,
      "step": 35050
    },
    {
      "epoch": 4.57865901382729,
      "grad_norm": 0.03757775202393532,
      "learning_rate": 4.7710670493086354e-05,
      "loss": 0.1574,
      "step": 35100
    },
    {
      "epoch": 4.585181320114793,
      "grad_norm": 7.476578712463379,
      "learning_rate": 4.770740933994261e-05,
      "loss": 0.1774,
      "step": 35150
    },
    {
      "epoch": 4.591703626402296,
      "grad_norm": 0.023772377520799637,
      "learning_rate": 4.770414818679885e-05,
      "loss": 0.1052,
      "step": 35200
    },
    {
      "epoch": 4.598225932689799,
      "grad_norm": 0.15220192074775696,
      "learning_rate": 4.77008870336551e-05,
      "loss": 0.0735,
      "step": 35250
    },
    {
      "epoch": 4.604748238977303,
      "grad_norm": 2.815276622772217,
      "learning_rate": 4.7697625880511346e-05,
      "loss": 0.0887,
      "step": 35300
    },
    {
      "epoch": 4.611270545264806,
      "grad_norm": 0.2504759430885315,
      "learning_rate": 4.76943647273676e-05,
      "loss": 0.1175,
      "step": 35350
    },
    {
      "epoch": 4.617792851552309,
      "grad_norm": 0.17341536283493042,
      "learning_rate": 4.769110357422385e-05,
      "loss": 0.1149,
      "step": 35400
    },
    {
      "epoch": 4.6243151578398125,
      "grad_norm": 4.3232598304748535,
      "learning_rate": 4.76878424210801e-05,
      "loss": 0.1444,
      "step": 35450
    },
    {
      "epoch": 4.630837464127316,
      "grad_norm": 0.09205831587314606,
      "learning_rate": 4.7684581267936344e-05,
      "loss": 0.0954,
      "step": 35500
    },
    {
      "epoch": 4.637359770414819,
      "grad_norm": 0.20023316144943237,
      "learning_rate": 4.76813201147926e-05,
      "loss": 0.1595,
      "step": 35550
    },
    {
      "epoch": 4.643882076702322,
      "grad_norm": 0.06550494581460953,
      "learning_rate": 4.767805896164884e-05,
      "loss": 0.0768,
      "step": 35600
    },
    {
      "epoch": 4.650404382989825,
      "grad_norm": 7.614093780517578,
      "learning_rate": 4.767479780850509e-05,
      "loss": 0.0874,
      "step": 35650
    },
    {
      "epoch": 4.656926689277329,
      "grad_norm": 0.015135906636714935,
      "learning_rate": 4.7671536655361335e-05,
      "loss": 0.1164,
      "step": 35700
    },
    {
      "epoch": 4.663448995564831,
      "grad_norm": 0.1124037578701973,
      "learning_rate": 4.766827550221759e-05,
      "loss": 0.1721,
      "step": 35750
    },
    {
      "epoch": 4.669971301852335,
      "grad_norm": 4.679938316345215,
      "learning_rate": 4.7665014349073835e-05,
      "loss": 0.1105,
      "step": 35800
    },
    {
      "epoch": 4.676493608139838,
      "grad_norm": 0.24576111137866974,
      "learning_rate": 4.766175319593008e-05,
      "loss": 0.0769,
      "step": 35850
    },
    {
      "epoch": 4.683015914427342,
      "grad_norm": 4.550537109375,
      "learning_rate": 4.765849204278633e-05,
      "loss": 0.1231,
      "step": 35900
    },
    {
      "epoch": 4.689538220714844,
      "grad_norm": 0.014316500164568424,
      "learning_rate": 4.765523088964258e-05,
      "loss": 0.1347,
      "step": 35950
    },
    {
      "epoch": 4.696060527002348,
      "grad_norm": 12.466466903686523,
      "learning_rate": 4.765196973649883e-05,
      "loss": 0.1387,
      "step": 36000
    },
    {
      "epoch": 4.702582833289851,
      "grad_norm": 0.07128984481096268,
      "learning_rate": 4.764870858335508e-05,
      "loss": 0.0559,
      "step": 36050
    },
    {
      "epoch": 4.709105139577354,
      "grad_norm": 0.03919556736946106,
      "learning_rate": 4.7645447430211325e-05,
      "loss": 0.118,
      "step": 36100
    },
    {
      "epoch": 4.7156274458648575,
      "grad_norm": 0.01220694836229086,
      "learning_rate": 4.764218627706757e-05,
      "loss": 0.1312,
      "step": 36150
    },
    {
      "epoch": 4.722149752152361,
      "grad_norm": 0.4105813801288605,
      "learning_rate": 4.7638925123923824e-05,
      "loss": 0.0959,
      "step": 36200
    },
    {
      "epoch": 4.728672058439864,
      "grad_norm": 0.00868868175894022,
      "learning_rate": 4.763566397078007e-05,
      "loss": 0.058,
      "step": 36250
    },
    {
      "epoch": 4.735194364727367,
      "grad_norm": 0.08983626216650009,
      "learning_rate": 4.763240281763632e-05,
      "loss": 0.0895,
      "step": 36300
    },
    {
      "epoch": 4.741716671014871,
      "grad_norm": 0.14254970848560333,
      "learning_rate": 4.762914166449256e-05,
      "loss": 0.1098,
      "step": 36350
    },
    {
      "epoch": 4.748238977302374,
      "grad_norm": 0.060172758996486664,
      "learning_rate": 4.7625880511348816e-05,
      "loss": 0.1559,
      "step": 36400
    },
    {
      "epoch": 4.754761283589877,
      "grad_norm": 20.58713722229004,
      "learning_rate": 4.762261935820506e-05,
      "loss": 0.1318,
      "step": 36450
    },
    {
      "epoch": 4.76128358987738,
      "grad_norm": 0.016769660636782646,
      "learning_rate": 4.761935820506131e-05,
      "loss": 0.0866,
      "step": 36500
    },
    {
      "epoch": 4.767805896164884,
      "grad_norm": 25.157358169555664,
      "learning_rate": 4.761609705191756e-05,
      "loss": 0.0852,
      "step": 36550
    },
    {
      "epoch": 4.774328202452387,
      "grad_norm": 0.03168115392327309,
      "learning_rate": 4.7612835898773814e-05,
      "loss": 0.1746,
      "step": 36600
    },
    {
      "epoch": 4.78085050873989,
      "grad_norm": 14.065532684326172,
      "learning_rate": 4.760957474563006e-05,
      "loss": 0.1046,
      "step": 36650
    },
    {
      "epoch": 4.7873728150273935,
      "grad_norm": 13.98561954498291,
      "learning_rate": 4.7606313592486307e-05,
      "loss": 0.0859,
      "step": 36700
    },
    {
      "epoch": 4.793895121314897,
      "grad_norm": 3.226994276046753,
      "learning_rate": 4.760305243934255e-05,
      "loss": 0.0564,
      "step": 36750
    },
    {
      "epoch": 4.8004174276024,
      "grad_norm": 6.871775150299072,
      "learning_rate": 4.7599791286198806e-05,
      "loss": 0.079,
      "step": 36800
    },
    {
      "epoch": 4.806939733889903,
      "grad_norm": 0.02528897300362587,
      "learning_rate": 4.759653013305505e-05,
      "loss": 0.1523,
      "step": 36850
    },
    {
      "epoch": 4.813462040177407,
      "grad_norm": 0.3609875738620758,
      "learning_rate": 4.75932689799113e-05,
      "loss": 0.0901,
      "step": 36900
    },
    {
      "epoch": 4.81998434646491,
      "grad_norm": 0.05322669818997383,
      "learning_rate": 4.7590007826767544e-05,
      "loss": 0.1103,
      "step": 36950
    },
    {
      "epoch": 4.826506652752413,
      "grad_norm": 0.6033490300178528,
      "learning_rate": 4.75867466736238e-05,
      "loss": 0.0998,
      "step": 37000
    },
    {
      "epoch": 4.8330289590399165,
      "grad_norm": 0.04353488236665726,
      "learning_rate": 4.7583485520480043e-05,
      "loss": 0.0844,
      "step": 37050
    },
    {
      "epoch": 4.83955126532742,
      "grad_norm": 14.137455940246582,
      "learning_rate": 4.758022436733629e-05,
      "loss": 0.1307,
      "step": 37100
    },
    {
      "epoch": 4.846073571614923,
      "grad_norm": 5.944204807281494,
      "learning_rate": 4.7576963214192536e-05,
      "loss": 0.1457,
      "step": 37150
    },
    {
      "epoch": 4.852595877902426,
      "grad_norm": 17.76936149597168,
      "learning_rate": 4.757370206104879e-05,
      "loss": 0.0687,
      "step": 37200
    },
    {
      "epoch": 4.85911818418993,
      "grad_norm": 0.010982372798025608,
      "learning_rate": 4.757044090790504e-05,
      "loss": 0.2137,
      "step": 37250
    },
    {
      "epoch": 4.865640490477433,
      "grad_norm": 12.82055377960205,
      "learning_rate": 4.756717975476129e-05,
      "loss": 0.132,
      "step": 37300
    },
    {
      "epoch": 4.872162796764936,
      "grad_norm": 8.678489685058594,
      "learning_rate": 4.7563918601617534e-05,
      "loss": 0.166,
      "step": 37350
    },
    {
      "epoch": 4.878685103052439,
      "grad_norm": 4.008916854858398,
      "learning_rate": 4.756065744847378e-05,
      "loss": 0.1375,
      "step": 37400
    },
    {
      "epoch": 4.885207409339943,
      "grad_norm": 0.28242480754852295,
      "learning_rate": 4.755739629533003e-05,
      "loss": 0.0333,
      "step": 37450
    },
    {
      "epoch": 4.891729715627446,
      "grad_norm": 2.824951648712158,
      "learning_rate": 4.755413514218628e-05,
      "loss": 0.0957,
      "step": 37500
    },
    {
      "epoch": 4.898252021914949,
      "grad_norm": 0.03973115235567093,
      "learning_rate": 4.7550873989042526e-05,
      "loss": 0.1204,
      "step": 37550
    },
    {
      "epoch": 4.9047743282024525,
      "grad_norm": 0.17040923237800598,
      "learning_rate": 4.754761283589877e-05,
      "loss": 0.0947,
      "step": 37600
    },
    {
      "epoch": 4.911296634489956,
      "grad_norm": 1.1460609436035156,
      "learning_rate": 4.7544351682755025e-05,
      "loss": 0.0626,
      "step": 37650
    },
    {
      "epoch": 4.917818940777459,
      "grad_norm": 0.01036570779979229,
      "learning_rate": 4.754109052961127e-05,
      "loss": 0.127,
      "step": 37700
    },
    {
      "epoch": 4.924341247064962,
      "grad_norm": 0.015257945284247398,
      "learning_rate": 4.753782937646752e-05,
      "loss": 0.0429,
      "step": 37750
    },
    {
      "epoch": 4.930863553352466,
      "grad_norm": 0.10959092527627945,
      "learning_rate": 4.753456822332377e-05,
      "loss": 0.0661,
      "step": 37800
    },
    {
      "epoch": 4.937385859639969,
      "grad_norm": 0.5443191528320312,
      "learning_rate": 4.753130707018002e-05,
      "loss": 0.0678,
      "step": 37850
    },
    {
      "epoch": 4.943908165927472,
      "grad_norm": 8.560860633850098,
      "learning_rate": 4.752804591703627e-05,
      "loss": 0.116,
      "step": 37900
    },
    {
      "epoch": 4.9504304722149755,
      "grad_norm": 0.982545793056488,
      "learning_rate": 4.7524784763892515e-05,
      "loss": 0.1589,
      "step": 37950
    },
    {
      "epoch": 4.956952778502479,
      "grad_norm": 0.07322671264410019,
      "learning_rate": 4.752152361074876e-05,
      "loss": 0.0752,
      "step": 38000
    },
    {
      "epoch": 4.963475084789982,
      "grad_norm": 0.16746623814105988,
      "learning_rate": 4.7518262457605015e-05,
      "loss": 0.1592,
      "step": 38050
    },
    {
      "epoch": 4.969997391077485,
      "grad_norm": 0.2817957401275635,
      "learning_rate": 4.751500130446126e-05,
      "loss": 0.1207,
      "step": 38100
    },
    {
      "epoch": 4.976519697364989,
      "grad_norm": 9.312687873840332,
      "learning_rate": 4.751174015131751e-05,
      "loss": 0.1512,
      "step": 38150
    },
    {
      "epoch": 4.983042003652492,
      "grad_norm": 0.22664177417755127,
      "learning_rate": 4.750847899817375e-05,
      "loss": 0.0983,
      "step": 38200
    },
    {
      "epoch": 4.989564309939995,
      "grad_norm": 0.13768525421619415,
      "learning_rate": 4.7505217845030006e-05,
      "loss": 0.1097,
      "step": 38250
    },
    {
      "epoch": 4.996086616227498,
      "grad_norm": 0.01905123144388199,
      "learning_rate": 4.750195669188625e-05,
      "loss": 0.1227,
      "step": 38300
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9647143229846074,
      "eval_f1": 0.9647534041305622,
      "eval_loss": 0.12943419814109802,
      "eval_precision": 0.963936987371436,
      "eval_recall": 0.9655712050078247,
      "eval_runtime": 23.4512,
      "eval_samples_per_second": 653.782,
      "eval_steps_per_second": 81.744,
      "step": 38330
    },
    {
      "epoch": 5.002608922515002,
      "grad_norm": 0.04028914123773575,
      "learning_rate": 4.74986955387425e-05,
      "loss": 0.1235,
      "step": 38350
    },
    {
      "epoch": 5.009131228802505,
      "grad_norm": 0.03092561475932598,
      "learning_rate": 4.749543438559875e-05,
      "loss": 0.0877,
      "step": 38400
    },
    {
      "epoch": 5.015653535090008,
      "grad_norm": 0.9570609927177429,
      "learning_rate": 4.7492173232455e-05,
      "loss": 0.1333,
      "step": 38450
    },
    {
      "epoch": 5.0221758413775115,
      "grad_norm": 11.202052116394043,
      "learning_rate": 4.748891207931125e-05,
      "loss": 0.1012,
      "step": 38500
    },
    {
      "epoch": 5.028698147665015,
      "grad_norm": 3.975813388824463,
      "learning_rate": 4.74856509261675e-05,
      "loss": 0.1311,
      "step": 38550
    },
    {
      "epoch": 5.035220453952518,
      "grad_norm": 0.07506675273180008,
      "learning_rate": 4.748238977302374e-05,
      "loss": 0.1354,
      "step": 38600
    },
    {
      "epoch": 5.04174276024002,
      "grad_norm": 0.01521308720111847,
      "learning_rate": 4.747912861987999e-05,
      "loss": 0.094,
      "step": 38650
    },
    {
      "epoch": 5.048265066527524,
      "grad_norm": 3.860466718673706,
      "learning_rate": 4.747586746673624e-05,
      "loss": 0.0942,
      "step": 38700
    },
    {
      "epoch": 5.054787372815027,
      "grad_norm": 14.811984062194824,
      "learning_rate": 4.747260631359249e-05,
      "loss": 0.0864,
      "step": 38750
    },
    {
      "epoch": 5.06130967910253,
      "grad_norm": 19.96021270751953,
      "learning_rate": 4.7469345160448734e-05,
      "loss": 0.0698,
      "step": 38800
    },
    {
      "epoch": 5.0678319853900335,
      "grad_norm": 0.032985322177410126,
      "learning_rate": 4.746608400730499e-05,
      "loss": 0.1075,
      "step": 38850
    },
    {
      "epoch": 5.074354291677537,
      "grad_norm": 7.096651554107666,
      "learning_rate": 4.7462822854161233e-05,
      "loss": 0.1107,
      "step": 38900
    },
    {
      "epoch": 5.08087659796504,
      "grad_norm": 8.653759956359863,
      "learning_rate": 4.745956170101748e-05,
      "loss": 0.0876,
      "step": 38950
    },
    {
      "epoch": 5.087398904252543,
      "grad_norm": 6.2523908615112305,
      "learning_rate": 4.7456300547873726e-05,
      "loss": 0.1088,
      "step": 39000
    },
    {
      "epoch": 5.093921210540047,
      "grad_norm": 0.23812387883663177,
      "learning_rate": 4.745303939472998e-05,
      "loss": 0.131,
      "step": 39050
    },
    {
      "epoch": 5.10044351682755,
      "grad_norm": 0.6924415826797485,
      "learning_rate": 4.744977824158623e-05,
      "loss": 0.1201,
      "step": 39100
    },
    {
      "epoch": 5.106965823115053,
      "grad_norm": 11.069016456604004,
      "learning_rate": 4.744651708844248e-05,
      "loss": 0.1493,
      "step": 39150
    },
    {
      "epoch": 5.1134881294025565,
      "grad_norm": 0.17744871973991394,
      "learning_rate": 4.7443255935298724e-05,
      "loss": 0.0738,
      "step": 39200
    },
    {
      "epoch": 5.12001043569006,
      "grad_norm": 13.92912769317627,
      "learning_rate": 4.743999478215497e-05,
      "loss": 0.1001,
      "step": 39250
    },
    {
      "epoch": 5.126532741977563,
      "grad_norm": 0.111280657351017,
      "learning_rate": 4.743673362901122e-05,
      "loss": 0.1281,
      "step": 39300
    },
    {
      "epoch": 5.133055048265066,
      "grad_norm": 0.020326904952526093,
      "learning_rate": 4.743347247586747e-05,
      "loss": 0.0572,
      "step": 39350
    },
    {
      "epoch": 5.13957735455257,
      "grad_norm": 0.4692641496658325,
      "learning_rate": 4.7430211322723716e-05,
      "loss": 0.1265,
      "step": 39400
    },
    {
      "epoch": 5.146099660840073,
      "grad_norm": 0.1271870732307434,
      "learning_rate": 4.742695016957996e-05,
      "loss": 0.162,
      "step": 39450
    },
    {
      "epoch": 5.152621967127576,
      "grad_norm": 10.858503341674805,
      "learning_rate": 4.7423689016436215e-05,
      "loss": 0.1001,
      "step": 39500
    },
    {
      "epoch": 5.159144273415079,
      "grad_norm": 0.05305257439613342,
      "learning_rate": 4.742042786329246e-05,
      "loss": 0.1486,
      "step": 39550
    },
    {
      "epoch": 5.165666579702583,
      "grad_norm": 3.1849172115325928,
      "learning_rate": 4.741716671014871e-05,
      "loss": 0.1155,
      "step": 39600
    },
    {
      "epoch": 5.172188885990086,
      "grad_norm": 0.013349387794733047,
      "learning_rate": 4.741390555700496e-05,
      "loss": 0.0838,
      "step": 39650
    },
    {
      "epoch": 5.178711192277589,
      "grad_norm": 0.043609246611595154,
      "learning_rate": 4.7410644403861206e-05,
      "loss": 0.1236,
      "step": 39700
    },
    {
      "epoch": 5.1852334985650925,
      "grad_norm": 0.4255891442298889,
      "learning_rate": 4.740738325071746e-05,
      "loss": 0.0798,
      "step": 39750
    },
    {
      "epoch": 5.191755804852596,
      "grad_norm": 1.188627004623413,
      "learning_rate": 4.7404122097573705e-05,
      "loss": 0.0821,
      "step": 39800
    },
    {
      "epoch": 5.198278111140099,
      "grad_norm": 11.327986717224121,
      "learning_rate": 4.740086094442995e-05,
      "loss": 0.1197,
      "step": 39850
    },
    {
      "epoch": 5.204800417427602,
      "grad_norm": 10.287212371826172,
      "learning_rate": 4.7397599791286205e-05,
      "loss": 0.0827,
      "step": 39900
    },
    {
      "epoch": 5.211322723715106,
      "grad_norm": 6.391380786895752,
      "learning_rate": 4.739433863814245e-05,
      "loss": 0.1137,
      "step": 39950
    },
    {
      "epoch": 5.217845030002609,
      "grad_norm": 14.788503646850586,
      "learning_rate": 4.73910774849987e-05,
      "loss": 0.1398,
      "step": 40000
    },
    {
      "epoch": 5.224367336290112,
      "grad_norm": 0.022090772166848183,
      "learning_rate": 4.738781633185494e-05,
      "loss": 0.1097,
      "step": 40050
    },
    {
      "epoch": 5.2308896425776155,
      "grad_norm": 0.2563401460647583,
      "learning_rate": 4.7384555178711196e-05,
      "loss": 0.1036,
      "step": 40100
    },
    {
      "epoch": 5.237411948865119,
      "grad_norm": 0.39373865723609924,
      "learning_rate": 4.738129402556744e-05,
      "loss": 0.116,
      "step": 40150
    },
    {
      "epoch": 5.243934255152622,
      "grad_norm": 0.016520779579877853,
      "learning_rate": 4.737803287242369e-05,
      "loss": 0.1773,
      "step": 40200
    },
    {
      "epoch": 5.250456561440125,
      "grad_norm": 20.00724983215332,
      "learning_rate": 4.737477171927994e-05,
      "loss": 0.1549,
      "step": 40250
    },
    {
      "epoch": 5.256978867727629,
      "grad_norm": 16.417293548583984,
      "learning_rate": 4.737151056613619e-05,
      "loss": 0.0745,
      "step": 40300
    },
    {
      "epoch": 5.263501174015132,
      "grad_norm": 0.24526090919971466,
      "learning_rate": 4.736824941299244e-05,
      "loss": 0.1045,
      "step": 40350
    },
    {
      "epoch": 5.270023480302635,
      "grad_norm": 0.07962150126695633,
      "learning_rate": 4.736498825984869e-05,
      "loss": 0.0814,
      "step": 40400
    },
    {
      "epoch": 5.276545786590138,
      "grad_norm": 9.307746887207031,
      "learning_rate": 4.736172710670493e-05,
      "loss": 0.0946,
      "step": 40450
    },
    {
      "epoch": 5.283068092877642,
      "grad_norm": 0.007498130202293396,
      "learning_rate": 4.735846595356118e-05,
      "loss": 0.1519,
      "step": 40500
    },
    {
      "epoch": 5.289590399165145,
      "grad_norm": 0.5808177590370178,
      "learning_rate": 4.735520480041743e-05,
      "loss": 0.1006,
      "step": 40550
    },
    {
      "epoch": 5.296112705452648,
      "grad_norm": 3.440333843231201,
      "learning_rate": 4.735194364727368e-05,
      "loss": 0.0982,
      "step": 40600
    },
    {
      "epoch": 5.3026350117401515,
      "grad_norm": 7.631752967834473,
      "learning_rate": 4.7348682494129924e-05,
      "loss": 0.1276,
      "step": 40650
    },
    {
      "epoch": 5.309157318027655,
      "grad_norm": 0.021917419508099556,
      "learning_rate": 4.734542134098617e-05,
      "loss": 0.1108,
      "step": 40700
    },
    {
      "epoch": 5.315679624315158,
      "grad_norm": 0.8722369074821472,
      "learning_rate": 4.7342160187842424e-05,
      "loss": 0.0562,
      "step": 40750
    },
    {
      "epoch": 5.322201930602661,
      "grad_norm": 0.16449695825576782,
      "learning_rate": 4.733889903469867e-05,
      "loss": 0.1334,
      "step": 40800
    },
    {
      "epoch": 5.328724236890165,
      "grad_norm": 5.219664573669434,
      "learning_rate": 4.733563788155492e-05,
      "loss": 0.1525,
      "step": 40850
    },
    {
      "epoch": 5.335246543177668,
      "grad_norm": 0.07372026890516281,
      "learning_rate": 4.733237672841117e-05,
      "loss": 0.1677,
      "step": 40900
    },
    {
      "epoch": 5.341768849465171,
      "grad_norm": 17.02741241455078,
      "learning_rate": 4.732911557526742e-05,
      "loss": 0.076,
      "step": 40950
    },
    {
      "epoch": 5.348291155752674,
      "grad_norm": 0.01612117514014244,
      "learning_rate": 4.732585442212367e-05,
      "loss": 0.105,
      "step": 41000
    },
    {
      "epoch": 5.354813462040178,
      "grad_norm": 0.26026666164398193,
      "learning_rate": 4.7322593268979914e-05,
      "loss": 0.0777,
      "step": 41050
    },
    {
      "epoch": 5.361335768327681,
      "grad_norm": 10.109734535217285,
      "learning_rate": 4.731933211583616e-05,
      "loss": 0.0764,
      "step": 41100
    },
    {
      "epoch": 5.367858074615184,
      "grad_norm": 0.023909147828817368,
      "learning_rate": 4.731607096269241e-05,
      "loss": 0.1546,
      "step": 41150
    },
    {
      "epoch": 5.3743803809026875,
      "grad_norm": 0.23653273284435272,
      "learning_rate": 4.731280980954866e-05,
      "loss": 0.0745,
      "step": 41200
    },
    {
      "epoch": 5.380902687190191,
      "grad_norm": 0.020851874724030495,
      "learning_rate": 4.7309548656404906e-05,
      "loss": 0.0767,
      "step": 41250
    },
    {
      "epoch": 5.387424993477694,
      "grad_norm": 5.915147304534912,
      "learning_rate": 4.730628750326115e-05,
      "loss": 0.1758,
      "step": 41300
    },
    {
      "epoch": 5.393947299765197,
      "grad_norm": 0.022792819887399673,
      "learning_rate": 4.7303026350117405e-05,
      "loss": 0.0657,
      "step": 41350
    },
    {
      "epoch": 5.400469606052701,
      "grad_norm": 0.08161910623311996,
      "learning_rate": 4.729976519697365e-05,
      "loss": 0.1875,
      "step": 41400
    },
    {
      "epoch": 5.406991912340203,
      "grad_norm": 0.1318584680557251,
      "learning_rate": 4.72965040438299e-05,
      "loss": 0.0449,
      "step": 41450
    },
    {
      "epoch": 5.413514218627707,
      "grad_norm": 0.01516052894294262,
      "learning_rate": 4.729324289068615e-05,
      "loss": 0.07,
      "step": 41500
    },
    {
      "epoch": 5.42003652491521,
      "grad_norm": 5.71347713470459,
      "learning_rate": 4.7289981737542396e-05,
      "loss": 0.1093,
      "step": 41550
    },
    {
      "epoch": 5.426558831202713,
      "grad_norm": 4.910296440124512,
      "learning_rate": 4.728672058439865e-05,
      "loss": 0.1779,
      "step": 41600
    },
    {
      "epoch": 5.433081137490216,
      "grad_norm": 0.06539063155651093,
      "learning_rate": 4.7283459431254896e-05,
      "loss": 0.1422,
      "step": 41650
    },
    {
      "epoch": 5.439603443777719,
      "grad_norm": 1.0903193950653076,
      "learning_rate": 4.728019827811114e-05,
      "loss": 0.1181,
      "step": 41700
    },
    {
      "epoch": 5.446125750065223,
      "grad_norm": 0.014155277982354164,
      "learning_rate": 4.727693712496739e-05,
      "loss": 0.0788,
      "step": 41750
    },
    {
      "epoch": 5.452648056352726,
      "grad_norm": 5.025491714477539,
      "learning_rate": 4.727367597182364e-05,
      "loss": 0.1806,
      "step": 41800
    },
    {
      "epoch": 5.459170362640229,
      "grad_norm": 0.2762332856655121,
      "learning_rate": 4.727041481867989e-05,
      "loss": 0.0646,
      "step": 41850
    },
    {
      "epoch": 5.4656926689277325,
      "grad_norm": 0.02038143388926983,
      "learning_rate": 4.726715366553613e-05,
      "loss": 0.1036,
      "step": 41900
    },
    {
      "epoch": 5.472214975215236,
      "grad_norm": 5.708749294281006,
      "learning_rate": 4.726389251239238e-05,
      "loss": 0.1149,
      "step": 41950
    },
    {
      "epoch": 5.478737281502739,
      "grad_norm": 0.09858368337154388,
      "learning_rate": 4.726063135924863e-05,
      "loss": 0.0911,
      "step": 42000
    },
    {
      "epoch": 5.485259587790242,
      "grad_norm": 0.010657209903001785,
      "learning_rate": 4.725737020610488e-05,
      "loss": 0.1416,
      "step": 42050
    },
    {
      "epoch": 5.491781894077746,
      "grad_norm": 7.181554317474365,
      "learning_rate": 4.725410905296113e-05,
      "loss": 0.1172,
      "step": 42100
    },
    {
      "epoch": 5.498304200365249,
      "grad_norm": 0.1374051570892334,
      "learning_rate": 4.725084789981738e-05,
      "loss": 0.1231,
      "step": 42150
    },
    {
      "epoch": 5.504826506652752,
      "grad_norm": 0.12784723937511444,
      "learning_rate": 4.724758674667363e-05,
      "loss": 0.1177,
      "step": 42200
    },
    {
      "epoch": 5.5113488129402555,
      "grad_norm": 16.183609008789062,
      "learning_rate": 4.724432559352988e-05,
      "loss": 0.1328,
      "step": 42250
    },
    {
      "epoch": 5.517871119227759,
      "grad_norm": 0.06808295100927353,
      "learning_rate": 4.724106444038612e-05,
      "loss": 0.1049,
      "step": 42300
    },
    {
      "epoch": 5.524393425515262,
      "grad_norm": 1.450562596321106,
      "learning_rate": 4.723780328724237e-05,
      "loss": 0.0673,
      "step": 42350
    },
    {
      "epoch": 5.530915731802765,
      "grad_norm": 0.12282480299472809,
      "learning_rate": 4.723454213409862e-05,
      "loss": 0.0784,
      "step": 42400
    },
    {
      "epoch": 5.537438038090269,
      "grad_norm": 0.236640065908432,
      "learning_rate": 4.723128098095487e-05,
      "loss": 0.1208,
      "step": 42450
    },
    {
      "epoch": 5.543960344377772,
      "grad_norm": 0.07834607362747192,
      "learning_rate": 4.7228019827811115e-05,
      "loss": 0.0731,
      "step": 42500
    },
    {
      "epoch": 5.550482650665275,
      "grad_norm": 2.6561996936798096,
      "learning_rate": 4.722475867466736e-05,
      "loss": 0.1269,
      "step": 42550
    },
    {
      "epoch": 5.557004956952778,
      "grad_norm": 0.046193189918994904,
      "learning_rate": 4.7221497521523614e-05,
      "loss": 0.0845,
      "step": 42600
    },
    {
      "epoch": 5.563527263240282,
      "grad_norm": 2.967392921447754,
      "learning_rate": 4.721823636837986e-05,
      "loss": 0.1211,
      "step": 42650
    },
    {
      "epoch": 5.570049569527785,
      "grad_norm": 7.138376712799072,
      "learning_rate": 4.721497521523611e-05,
      "loss": 0.0981,
      "step": 42700
    },
    {
      "epoch": 5.576571875815288,
      "grad_norm": 6.576544284820557,
      "learning_rate": 4.721171406209236e-05,
      "loss": 0.1552,
      "step": 42750
    },
    {
      "epoch": 5.5830941821027915,
      "grad_norm": 0.3237883448600769,
      "learning_rate": 4.7208452908948605e-05,
      "loss": 0.0411,
      "step": 42800
    },
    {
      "epoch": 5.589616488390295,
      "grad_norm": 0.009185739792883396,
      "learning_rate": 4.720519175580486e-05,
      "loss": 0.1246,
      "step": 42850
    },
    {
      "epoch": 5.596138794677798,
      "grad_norm": 0.10010869055986404,
      "learning_rate": 4.7201930602661104e-05,
      "loss": 0.0843,
      "step": 42900
    },
    {
      "epoch": 5.602661100965301,
      "grad_norm": 0.005544047337025404,
      "learning_rate": 4.719866944951735e-05,
      "loss": 0.1003,
      "step": 42950
    },
    {
      "epoch": 5.609183407252805,
      "grad_norm": 0.032441407442092896,
      "learning_rate": 4.71954082963736e-05,
      "loss": 0.1349,
      "step": 43000
    },
    {
      "epoch": 5.615705713540308,
      "grad_norm": 0.0949685350060463,
      "learning_rate": 4.719214714322985e-05,
      "loss": 0.0585,
      "step": 43050
    },
    {
      "epoch": 5.622228019827811,
      "grad_norm": 0.4147612452507019,
      "learning_rate": 4.7188885990086096e-05,
      "loss": 0.1395,
      "step": 43100
    },
    {
      "epoch": 5.6287503261153145,
      "grad_norm": 0.009838780388236046,
      "learning_rate": 4.718562483694234e-05,
      "loss": 0.0808,
      "step": 43150
    },
    {
      "epoch": 5.635272632402818,
      "grad_norm": 0.003952804021537304,
      "learning_rate": 4.7182363683798595e-05,
      "loss": 0.0858,
      "step": 43200
    },
    {
      "epoch": 5.641794938690321,
      "grad_norm": 8.5612211227417,
      "learning_rate": 4.717910253065484e-05,
      "loss": 0.0864,
      "step": 43250
    },
    {
      "epoch": 5.648317244977824,
      "grad_norm": 0.00537010608240962,
      "learning_rate": 4.717584137751109e-05,
      "loss": 0.0882,
      "step": 43300
    },
    {
      "epoch": 5.654839551265328,
      "grad_norm": 0.029400479048490524,
      "learning_rate": 4.717258022436734e-05,
      "loss": 0.0974,
      "step": 43350
    },
    {
      "epoch": 5.661361857552831,
      "grad_norm": 10.93702220916748,
      "learning_rate": 4.7169319071223586e-05,
      "loss": 0.083,
      "step": 43400
    },
    {
      "epoch": 5.667884163840334,
      "grad_norm": 0.037462569773197174,
      "learning_rate": 4.716605791807984e-05,
      "loss": 0.0979,
      "step": 43450
    },
    {
      "epoch": 5.674406470127837,
      "grad_norm": 0.014180749654769897,
      "learning_rate": 4.7162796764936086e-05,
      "loss": 0.1153,
      "step": 43500
    },
    {
      "epoch": 5.680928776415341,
      "grad_norm": 1.9254794120788574,
      "learning_rate": 4.715953561179233e-05,
      "loss": 0.12,
      "step": 43550
    },
    {
      "epoch": 5.687451082702844,
      "grad_norm": 5.035402297973633,
      "learning_rate": 4.715627445864858e-05,
      "loss": 0.0888,
      "step": 43600
    },
    {
      "epoch": 5.693973388990347,
      "grad_norm": 0.0349418930709362,
      "learning_rate": 4.715301330550483e-05,
      "loss": 0.1041,
      "step": 43650
    },
    {
      "epoch": 5.7004956952778505,
      "grad_norm": 0.17211250960826874,
      "learning_rate": 4.714975215236108e-05,
      "loss": 0.1133,
      "step": 43700
    },
    {
      "epoch": 5.707018001565354,
      "grad_norm": 0.05577591434121132,
      "learning_rate": 4.714649099921732e-05,
      "loss": 0.152,
      "step": 43750
    },
    {
      "epoch": 5.713540307852857,
      "grad_norm": 0.09323400259017944,
      "learning_rate": 4.714322984607357e-05,
      "loss": 0.1242,
      "step": 43800
    },
    {
      "epoch": 5.72006261414036,
      "grad_norm": 0.6548336744308472,
      "learning_rate": 4.713996869292982e-05,
      "loss": 0.1534,
      "step": 43850
    },
    {
      "epoch": 5.726584920427864,
      "grad_norm": 0.45597848296165466,
      "learning_rate": 4.713670753978607e-05,
      "loss": 0.1154,
      "step": 43900
    },
    {
      "epoch": 5.733107226715367,
      "grad_norm": 1.001258373260498,
      "learning_rate": 4.713344638664232e-05,
      "loss": 0.0335,
      "step": 43950
    },
    {
      "epoch": 5.73962953300287,
      "grad_norm": 0.5250092148780823,
      "learning_rate": 4.713018523349857e-05,
      "loss": 0.1807,
      "step": 44000
    },
    {
      "epoch": 5.746151839290373,
      "grad_norm": 0.013627821579575539,
      "learning_rate": 4.7126924080354814e-05,
      "loss": 0.1003,
      "step": 44050
    },
    {
      "epoch": 5.752674145577877,
      "grad_norm": 0.8512813448905945,
      "learning_rate": 4.712366292721107e-05,
      "loss": 0.0415,
      "step": 44100
    },
    {
      "epoch": 5.75919645186538,
      "grad_norm": 0.04789122939109802,
      "learning_rate": 4.712040177406731e-05,
      "loss": 0.1118,
      "step": 44150
    },
    {
      "epoch": 5.765718758152882,
      "grad_norm": 0.14894485473632812,
      "learning_rate": 4.711714062092356e-05,
      "loss": 0.0668,
      "step": 44200
    },
    {
      "epoch": 5.7722410644403865,
      "grad_norm": 0.06336824595928192,
      "learning_rate": 4.711387946777981e-05,
      "loss": 0.1255,
      "step": 44250
    },
    {
      "epoch": 5.778763370727889,
      "grad_norm": 0.05599278584122658,
      "learning_rate": 4.711061831463606e-05,
      "loss": 0.133,
      "step": 44300
    },
    {
      "epoch": 5.785285677015393,
      "grad_norm": 5.969945430755615,
      "learning_rate": 4.7107357161492305e-05,
      "loss": 0.1202,
      "step": 44350
    },
    {
      "epoch": 5.7918079833028955,
      "grad_norm": 0.7601733207702637,
      "learning_rate": 4.710409600834855e-05,
      "loss": 0.1128,
      "step": 44400
    },
    {
      "epoch": 5.7983302895904,
      "grad_norm": 0.21851010620594025,
      "learning_rate": 4.7100834855204804e-05,
      "loss": 0.0766,
      "step": 44450
    },
    {
      "epoch": 5.804852595877902,
      "grad_norm": 0.010323423892259598,
      "learning_rate": 4.709757370206105e-05,
      "loss": 0.145,
      "step": 44500
    },
    {
      "epoch": 5.811374902165405,
      "grad_norm": 0.03755435720086098,
      "learning_rate": 4.70943125489173e-05,
      "loss": 0.1306,
      "step": 44550
    },
    {
      "epoch": 5.817897208452909,
      "grad_norm": 0.04777485132217407,
      "learning_rate": 4.709105139577355e-05,
      "loss": 0.1219,
      "step": 44600
    },
    {
      "epoch": 5.824419514740412,
      "grad_norm": 0.04012822359800339,
      "learning_rate": 4.7087790242629795e-05,
      "loss": 0.1049,
      "step": 44650
    },
    {
      "epoch": 5.830941821027915,
      "grad_norm": 0.026723425835371017,
      "learning_rate": 4.708452908948605e-05,
      "loss": 0.0992,
      "step": 44700
    },
    {
      "epoch": 5.837464127315418,
      "grad_norm": 0.1566232591867447,
      "learning_rate": 4.7081267936342294e-05,
      "loss": 0.1262,
      "step": 44750
    },
    {
      "epoch": 5.843986433602922,
      "grad_norm": 8.992632865905762,
      "learning_rate": 4.707800678319854e-05,
      "loss": 0.1346,
      "step": 44800
    },
    {
      "epoch": 5.850508739890425,
      "grad_norm": 0.0911390408873558,
      "learning_rate": 4.707474563005479e-05,
      "loss": 0.1105,
      "step": 44850
    },
    {
      "epoch": 5.857031046177928,
      "grad_norm": 0.33309927582740784,
      "learning_rate": 4.707148447691104e-05,
      "loss": 0.0953,
      "step": 44900
    },
    {
      "epoch": 5.8635533524654315,
      "grad_norm": 0.007194517180323601,
      "learning_rate": 4.7068223323767286e-05,
      "loss": 0.0983,
      "step": 44950
    },
    {
      "epoch": 5.870075658752935,
      "grad_norm": 0.3067668676376343,
      "learning_rate": 4.706496217062353e-05,
      "loss": 0.1774,
      "step": 45000
    },
    {
      "epoch": 5.876597965040438,
      "grad_norm": 0.878946840763092,
      "learning_rate": 4.706170101747978e-05,
      "loss": 0.0707,
      "step": 45050
    },
    {
      "epoch": 5.883120271327941,
      "grad_norm": 0.408515602350235,
      "learning_rate": 4.705843986433603e-05,
      "loss": 0.0734,
      "step": 45100
    },
    {
      "epoch": 5.889642577615445,
      "grad_norm": 0.016212098300457,
      "learning_rate": 4.7055178711192284e-05,
      "loss": 0.0773,
      "step": 45150
    },
    {
      "epoch": 5.896164883902948,
      "grad_norm": 0.007450279779732227,
      "learning_rate": 4.705191755804853e-05,
      "loss": 0.0945,
      "step": 45200
    },
    {
      "epoch": 5.902687190190451,
      "grad_norm": 0.22664271295070648,
      "learning_rate": 4.7048656404904777e-05,
      "loss": 0.1422,
      "step": 45250
    },
    {
      "epoch": 5.9092094964779545,
      "grad_norm": 0.040576253086328506,
      "learning_rate": 4.704539525176103e-05,
      "loss": 0.1529,
      "step": 45300
    },
    {
      "epoch": 5.915731802765458,
      "grad_norm": 0.10793948918581009,
      "learning_rate": 4.7042134098617276e-05,
      "loss": 0.1085,
      "step": 45350
    },
    {
      "epoch": 5.922254109052961,
      "grad_norm": 0.10690660029649734,
      "learning_rate": 4.703887294547352e-05,
      "loss": 0.0925,
      "step": 45400
    },
    {
      "epoch": 5.928776415340464,
      "grad_norm": 0.8479624390602112,
      "learning_rate": 4.703561179232977e-05,
      "loss": 0.0841,
      "step": 45450
    },
    {
      "epoch": 5.935298721627968,
      "grad_norm": 0.057787083089351654,
      "learning_rate": 4.703235063918602e-05,
      "loss": 0.164,
      "step": 45500
    },
    {
      "epoch": 5.941821027915471,
      "grad_norm": 5.749238967895508,
      "learning_rate": 4.702908948604227e-05,
      "loss": 0.1365,
      "step": 45550
    },
    {
      "epoch": 5.948343334202974,
      "grad_norm": 0.12676528096199036,
      "learning_rate": 4.702582833289851e-05,
      "loss": 0.1037,
      "step": 45600
    },
    {
      "epoch": 5.954865640490477,
      "grad_norm": 11.724051475524902,
      "learning_rate": 4.702256717975476e-05,
      "loss": 0.1212,
      "step": 45650
    },
    {
      "epoch": 5.961387946777981,
      "grad_norm": 0.0673976019024849,
      "learning_rate": 4.701930602661101e-05,
      "loss": 0.0809,
      "step": 45700
    },
    {
      "epoch": 5.967910253065484,
      "grad_norm": 1.3008439540863037,
      "learning_rate": 4.701604487346726e-05,
      "loss": 0.1503,
      "step": 45750
    },
    {
      "epoch": 5.974432559352987,
      "grad_norm": 5.8443427085876465,
      "learning_rate": 4.701278372032351e-05,
      "loss": 0.1245,
      "step": 45800
    },
    {
      "epoch": 5.9809548656404905,
      "grad_norm": 0.09693101048469543,
      "learning_rate": 4.700952256717976e-05,
      "loss": 0.0974,
      "step": 45850
    },
    {
      "epoch": 5.987477171927994,
      "grad_norm": 8.078956604003906,
      "learning_rate": 4.7006261414036004e-05,
      "loss": 0.0982,
      "step": 45900
    },
    {
      "epoch": 5.993999478215497,
      "grad_norm": 0.05613921955227852,
      "learning_rate": 4.700300026089226e-05,
      "loss": 0.098,
      "step": 45950
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9663448995564832,
      "eval_f1": 0.9663053415175656,
      "eval_loss": 0.12559598684310913,
      "eval_precision": 0.9676955270729793,
      "eval_recall": 0.9649191444966093,
      "eval_runtime": 23.4992,
      "eval_samples_per_second": 652.448,
      "eval_steps_per_second": 81.577,
      "step": 45996
    },
    {
      "epoch": 6.000521784503,
      "grad_norm": 0.008525049313902855,
      "learning_rate": 4.69997391077485e-05,
      "loss": 0.0835,
      "step": 46000
    },
    {
      "epoch": 6.007044090790504,
      "grad_norm": 0.14337654411792755,
      "learning_rate": 4.699647795460475e-05,
      "loss": 0.1515,
      "step": 46050
    },
    {
      "epoch": 6.013566397078007,
      "grad_norm": 0.1641186773777008,
      "learning_rate": 4.6993216801460996e-05,
      "loss": 0.0771,
      "step": 46100
    },
    {
      "epoch": 6.02008870336551,
      "grad_norm": 5.671788215637207,
      "learning_rate": 4.698995564831725e-05,
      "loss": 0.0935,
      "step": 46150
    },
    {
      "epoch": 6.026611009653013,
      "grad_norm": 1.2495298385620117,
      "learning_rate": 4.6986694495173495e-05,
      "loss": 0.1162,
      "step": 46200
    },
    {
      "epoch": 6.033133315940517,
      "grad_norm": 13.324028968811035,
      "learning_rate": 4.698343334202974e-05,
      "loss": 0.1386,
      "step": 46250
    },
    {
      "epoch": 6.03965562222802,
      "grad_norm": 8.876785278320312,
      "learning_rate": 4.698017218888599e-05,
      "loss": 0.0793,
      "step": 46300
    },
    {
      "epoch": 6.046177928515523,
      "grad_norm": 2.301255702972412,
      "learning_rate": 4.697691103574224e-05,
      "loss": 0.1131,
      "step": 46350
    },
    {
      "epoch": 6.0527002348030265,
      "grad_norm": 1.5134077072143555,
      "learning_rate": 4.697364988259849e-05,
      "loss": 0.0921,
      "step": 46400
    },
    {
      "epoch": 6.05922254109053,
      "grad_norm": 0.026310913264751434,
      "learning_rate": 4.697038872945474e-05,
      "loss": 0.084,
      "step": 46450
    },
    {
      "epoch": 6.065744847378033,
      "grad_norm": 0.005926217883825302,
      "learning_rate": 4.6967127576310985e-05,
      "loss": 0.1148,
      "step": 46500
    },
    {
      "epoch": 6.072267153665536,
      "grad_norm": 5.9118123054504395,
      "learning_rate": 4.696386642316724e-05,
      "loss": 0.1682,
      "step": 46550
    },
    {
      "epoch": 6.07878945995304,
      "grad_norm": 0.05913810431957245,
      "learning_rate": 4.6960605270023484e-05,
      "loss": 0.1029,
      "step": 46600
    },
    {
      "epoch": 6.085311766240543,
      "grad_norm": 0.038950104266405106,
      "learning_rate": 4.695734411687973e-05,
      "loss": 0.0674,
      "step": 46650
    },
    {
      "epoch": 6.091834072528046,
      "grad_norm": 0.03228548914194107,
      "learning_rate": 4.695408296373598e-05,
      "loss": 0.1323,
      "step": 46700
    },
    {
      "epoch": 6.0983563788155495,
      "grad_norm": 9.812000274658203,
      "learning_rate": 4.695082181059223e-05,
      "loss": 0.0945,
      "step": 46750
    },
    {
      "epoch": 6.104878685103053,
      "grad_norm": 0.03477673605084419,
      "learning_rate": 4.6947560657448476e-05,
      "loss": 0.0871,
      "step": 46800
    },
    {
      "epoch": 6.111400991390556,
      "grad_norm": 0.01280563697218895,
      "learning_rate": 4.694429950430472e-05,
      "loss": 0.1069,
      "step": 46850
    },
    {
      "epoch": 6.117923297678059,
      "grad_norm": 0.24005039036273956,
      "learning_rate": 4.694103835116097e-05,
      "loss": 0.0704,
      "step": 46900
    },
    {
      "epoch": 6.124445603965563,
      "grad_norm": 0.007704423274844885,
      "learning_rate": 4.693777719801722e-05,
      "loss": 0.1281,
      "step": 46950
    },
    {
      "epoch": 6.130967910253066,
      "grad_norm": 0.4374047517776489,
      "learning_rate": 4.6934516044873474e-05,
      "loss": 0.1169,
      "step": 47000
    },
    {
      "epoch": 6.137490216540569,
      "grad_norm": 0.028468716889619827,
      "learning_rate": 4.693125489172972e-05,
      "loss": 0.1104,
      "step": 47050
    },
    {
      "epoch": 6.144012522828072,
      "grad_norm": 0.08914600312709808,
      "learning_rate": 4.692799373858597e-05,
      "loss": 0.1296,
      "step": 47100
    },
    {
      "epoch": 6.150534829115576,
      "grad_norm": 0.15604431927204132,
      "learning_rate": 4.692473258544221e-05,
      "loss": 0.0956,
      "step": 47150
    },
    {
      "epoch": 6.157057135403079,
      "grad_norm": 0.31443920731544495,
      "learning_rate": 4.6921471432298466e-05,
      "loss": 0.0607,
      "step": 47200
    },
    {
      "epoch": 6.163579441690581,
      "grad_norm": 0.5412976741790771,
      "learning_rate": 4.691821027915471e-05,
      "loss": 0.0747,
      "step": 47250
    },
    {
      "epoch": 6.170101747978085,
      "grad_norm": 0.05108063668012619,
      "learning_rate": 4.691494912601096e-05,
      "loss": 0.0756,
      "step": 47300
    },
    {
      "epoch": 6.176624054265588,
      "grad_norm": 0.05223670229315758,
      "learning_rate": 4.6911687972867204e-05,
      "loss": 0.08,
      "step": 47350
    },
    {
      "epoch": 6.183146360553091,
      "grad_norm": 26.21829605102539,
      "learning_rate": 4.690842681972346e-05,
      "loss": 0.0619,
      "step": 47400
    },
    {
      "epoch": 6.1896686668405945,
      "grad_norm": 16.73124122619629,
      "learning_rate": 4.6905165666579703e-05,
      "loss": 0.1065,
      "step": 47450
    },
    {
      "epoch": 6.196190973128098,
      "grad_norm": 0.021350359544157982,
      "learning_rate": 4.690190451343595e-05,
      "loss": 0.0868,
      "step": 47500
    },
    {
      "epoch": 6.202713279415601,
      "grad_norm": 8.847426414489746,
      "learning_rate": 4.68986433602922e-05,
      "loss": 0.1547,
      "step": 47550
    },
    {
      "epoch": 6.209235585703104,
      "grad_norm": 0.18986016511917114,
      "learning_rate": 4.689538220714845e-05,
      "loss": 0.1221,
      "step": 47600
    },
    {
      "epoch": 6.215757891990608,
      "grad_norm": 12.060064315795898,
      "learning_rate": 4.68921210540047e-05,
      "loss": 0.1105,
      "step": 47650
    },
    {
      "epoch": 6.222280198278111,
      "grad_norm": 7.805107116699219,
      "learning_rate": 4.688885990086095e-05,
      "loss": 0.0688,
      "step": 47700
    },
    {
      "epoch": 6.228802504565614,
      "grad_norm": 0.1330523043870926,
      "learning_rate": 4.6885598747717194e-05,
      "loss": 0.1107,
      "step": 47750
    },
    {
      "epoch": 6.235324810853117,
      "grad_norm": 0.03036145120859146,
      "learning_rate": 4.688233759457345e-05,
      "loss": 0.1024,
      "step": 47800
    },
    {
      "epoch": 6.241847117140621,
      "grad_norm": 0.02131631039083004,
      "learning_rate": 4.687907644142969e-05,
      "loss": 0.0653,
      "step": 47850
    },
    {
      "epoch": 6.248369423428124,
      "grad_norm": 6.283058166503906,
      "learning_rate": 4.687581528828594e-05,
      "loss": 0.1091,
      "step": 47900
    },
    {
      "epoch": 6.254891729715627,
      "grad_norm": 0.06365881115198135,
      "learning_rate": 4.6872554135142186e-05,
      "loss": 0.1567,
      "step": 47950
    },
    {
      "epoch": 6.2614140360031305,
      "grad_norm": 0.33587217330932617,
      "learning_rate": 4.686929298199844e-05,
      "loss": 0.1465,
      "step": 48000
    },
    {
      "epoch": 6.267936342290634,
      "grad_norm": 1.4997984170913696,
      "learning_rate": 4.6866031828854685e-05,
      "loss": 0.1223,
      "step": 48050
    },
    {
      "epoch": 6.274458648578137,
      "grad_norm": 4.656951904296875,
      "learning_rate": 4.686277067571093e-05,
      "loss": 0.076,
      "step": 48100
    },
    {
      "epoch": 6.28098095486564,
      "grad_norm": 0.006840456277132034,
      "learning_rate": 4.685950952256718e-05,
      "loss": 0.1376,
      "step": 48150
    },
    {
      "epoch": 6.287503261153144,
      "grad_norm": 1.0547049045562744,
      "learning_rate": 4.685624836942343e-05,
      "loss": 0.0901,
      "step": 48200
    },
    {
      "epoch": 6.294025567440647,
      "grad_norm": 3.8509371280670166,
      "learning_rate": 4.685298721627968e-05,
      "loss": 0.0913,
      "step": 48250
    },
    {
      "epoch": 6.30054787372815,
      "grad_norm": 0.06773725152015686,
      "learning_rate": 4.684972606313593e-05,
      "loss": 0.1264,
      "step": 48300
    },
    {
      "epoch": 6.3070701800156534,
      "grad_norm": 0.28238824009895325,
      "learning_rate": 4.6846464909992175e-05,
      "loss": 0.1104,
      "step": 48350
    },
    {
      "epoch": 6.313592486303157,
      "grad_norm": 0.007755286991596222,
      "learning_rate": 4.684320375684843e-05,
      "loss": 0.093,
      "step": 48400
    },
    {
      "epoch": 6.32011479259066,
      "grad_norm": 6.966699123382568,
      "learning_rate": 4.6839942603704675e-05,
      "loss": 0.1705,
      "step": 48450
    },
    {
      "epoch": 6.326637098878163,
      "grad_norm": 0.03569883480668068,
      "learning_rate": 4.683668145056092e-05,
      "loss": 0.0613,
      "step": 48500
    },
    {
      "epoch": 6.3331594051656666,
      "grad_norm": 0.08199717849493027,
      "learning_rate": 4.683342029741717e-05,
      "loss": 0.0988,
      "step": 48550
    },
    {
      "epoch": 6.33968171145317,
      "grad_norm": 0.041644852608442307,
      "learning_rate": 4.683015914427342e-05,
      "loss": 0.0775,
      "step": 48600
    },
    {
      "epoch": 6.346204017740673,
      "grad_norm": 0.37548574805259705,
      "learning_rate": 4.6826897991129666e-05,
      "loss": 0.1026,
      "step": 48650
    },
    {
      "epoch": 6.352726324028176,
      "grad_norm": 0.09024839848279953,
      "learning_rate": 4.682363683798591e-05,
      "loss": 0.0979,
      "step": 48700
    },
    {
      "epoch": 6.35924863031568,
      "grad_norm": 0.016983192414045334,
      "learning_rate": 4.682037568484216e-05,
      "loss": 0.0631,
      "step": 48750
    },
    {
      "epoch": 6.365770936603183,
      "grad_norm": 0.18062478303909302,
      "learning_rate": 4.681711453169841e-05,
      "loss": 0.1221,
      "step": 48800
    },
    {
      "epoch": 6.372293242890686,
      "grad_norm": 0.11933206021785736,
      "learning_rate": 4.6813853378554664e-05,
      "loss": 0.0886,
      "step": 48850
    },
    {
      "epoch": 6.3788155491781895,
      "grad_norm": 0.02516045793890953,
      "learning_rate": 4.681059222541091e-05,
      "loss": 0.1087,
      "step": 48900
    },
    {
      "epoch": 6.385337855465693,
      "grad_norm": 12.89221477508545,
      "learning_rate": 4.680733107226716e-05,
      "loss": 0.1259,
      "step": 48950
    },
    {
      "epoch": 6.391860161753196,
      "grad_norm": 0.028525883331894875,
      "learning_rate": 4.68040699191234e-05,
      "loss": 0.1039,
      "step": 49000
    },
    {
      "epoch": 6.398382468040699,
      "grad_norm": 0.06406909227371216,
      "learning_rate": 4.6800808765979656e-05,
      "loss": 0.1022,
      "step": 49050
    },
    {
      "epoch": 6.404904774328203,
      "grad_norm": 0.406495600938797,
      "learning_rate": 4.67975476128359e-05,
      "loss": 0.1282,
      "step": 49100
    },
    {
      "epoch": 6.411427080615706,
      "grad_norm": 12.268770217895508,
      "learning_rate": 4.679428645969215e-05,
      "loss": 0.0706,
      "step": 49150
    },
    {
      "epoch": 6.417949386903209,
      "grad_norm": 16.406742095947266,
      "learning_rate": 4.6791025306548394e-05,
      "loss": 0.0822,
      "step": 49200
    },
    {
      "epoch": 6.424471693190712,
      "grad_norm": 0.17119847238063812,
      "learning_rate": 4.678776415340465e-05,
      "loss": 0.0578,
      "step": 49250
    },
    {
      "epoch": 6.430993999478216,
      "grad_norm": 0.2768633961677551,
      "learning_rate": 4.6784503000260894e-05,
      "loss": 0.1074,
      "step": 49300
    },
    {
      "epoch": 6.437516305765719,
      "grad_norm": 0.02416297234594822,
      "learning_rate": 4.678124184711714e-05,
      "loss": 0.0739,
      "step": 49350
    },
    {
      "epoch": 6.444038612053222,
      "grad_norm": 0.09369007498025894,
      "learning_rate": 4.6777980693973386e-05,
      "loss": 0.0797,
      "step": 49400
    },
    {
      "epoch": 6.4505609183407255,
      "grad_norm": 19.811996459960938,
      "learning_rate": 4.6774719540829646e-05,
      "loss": 0.1221,
      "step": 49450
    },
    {
      "epoch": 6.457083224628229,
      "grad_norm": 0.020992252975702286,
      "learning_rate": 4.677145838768589e-05,
      "loss": 0.0432,
      "step": 49500
    },
    {
      "epoch": 6.463605530915732,
      "grad_norm": 8.07565689086914,
      "learning_rate": 4.676819723454214e-05,
      "loss": 0.1001,
      "step": 49550
    },
    {
      "epoch": 6.470127837203235,
      "grad_norm": 10.234426498413086,
      "learning_rate": 4.6764936081398384e-05,
      "loss": 0.0819,
      "step": 49600
    },
    {
      "epoch": 6.476650143490739,
      "grad_norm": 1.2240219116210938,
      "learning_rate": 4.676167492825464e-05,
      "loss": 0.1206,
      "step": 49650
    },
    {
      "epoch": 6.483172449778242,
      "grad_norm": 0.30163106322288513,
      "learning_rate": 4.675841377511088e-05,
      "loss": 0.1505,
      "step": 49700
    },
    {
      "epoch": 6.489694756065745,
      "grad_norm": 0.0297248475253582,
      "learning_rate": 4.675515262196713e-05,
      "loss": 0.0737,
      "step": 49750
    },
    {
      "epoch": 6.4962170623532485,
      "grad_norm": 6.565523624420166,
      "learning_rate": 4.6751891468823376e-05,
      "loss": 0.1142,
      "step": 49800
    },
    {
      "epoch": 6.502739368640752,
      "grad_norm": 0.006926120724529028,
      "learning_rate": 4.674863031567963e-05,
      "loss": 0.1132,
      "step": 49850
    },
    {
      "epoch": 6.509261674928254,
      "grad_norm": 11.412134170532227,
      "learning_rate": 4.6745369162535875e-05,
      "loss": 0.0777,
      "step": 49900
    },
    {
      "epoch": 6.515783981215758,
      "grad_norm": 0.020710282027721405,
      "learning_rate": 4.674210800939212e-05,
      "loss": 0.074,
      "step": 49950
    },
    {
      "epoch": 6.522306287503261,
      "grad_norm": 2.672809600830078,
      "learning_rate": 4.673884685624837e-05,
      "loss": 0.1754,
      "step": 50000
    },
    {
      "epoch": 6.528828593790765,
      "grad_norm": 0.07043430954217911,
      "learning_rate": 4.673558570310462e-05,
      "loss": 0.0764,
      "step": 50050
    },
    {
      "epoch": 6.535350900078267,
      "grad_norm": 10.032307624816895,
      "learning_rate": 4.673232454996087e-05,
      "loss": 0.1586,
      "step": 50100
    },
    {
      "epoch": 6.541873206365771,
      "grad_norm": 26.473913192749023,
      "learning_rate": 4.672906339681712e-05,
      "loss": 0.082,
      "step": 50150
    },
    {
      "epoch": 6.548395512653274,
      "grad_norm": 0.007265605963766575,
      "learning_rate": 4.6725802243673365e-05,
      "loss": 0.1088,
      "step": 50200
    },
    {
      "epoch": 6.554917818940777,
      "grad_norm": 0.03916328027844429,
      "learning_rate": 4.672254109052961e-05,
      "loss": 0.0989,
      "step": 50250
    },
    {
      "epoch": 6.56144012522828,
      "grad_norm": 15.19751262664795,
      "learning_rate": 4.6719279937385865e-05,
      "loss": 0.1317,
      "step": 50300
    },
    {
      "epoch": 6.567962431515784,
      "grad_norm": 0.08556007593870163,
      "learning_rate": 4.671601878424211e-05,
      "loss": 0.1611,
      "step": 50350
    },
    {
      "epoch": 6.574484737803287,
      "grad_norm": 0.5672455430030823,
      "learning_rate": 4.671275763109836e-05,
      "loss": 0.0784,
      "step": 50400
    },
    {
      "epoch": 6.58100704409079,
      "grad_norm": 13.00597095489502,
      "learning_rate": 4.67094964779546e-05,
      "loss": 0.064,
      "step": 50450
    },
    {
      "epoch": 6.5875293503782935,
      "grad_norm": 5.575931549072266,
      "learning_rate": 4.6706235324810856e-05,
      "loss": 0.122,
      "step": 50500
    },
    {
      "epoch": 6.594051656665797,
      "grad_norm": 0.15035700798034668,
      "learning_rate": 4.67029741716671e-05,
      "loss": 0.1215,
      "step": 50550
    },
    {
      "epoch": 6.6005739629533,
      "grad_norm": 0.02807077206671238,
      "learning_rate": 4.669971301852335e-05,
      "loss": 0.1244,
      "step": 50600
    },
    {
      "epoch": 6.607096269240803,
      "grad_norm": 0.00965363159775734,
      "learning_rate": 4.6696451865379595e-05,
      "loss": 0.0911,
      "step": 50650
    },
    {
      "epoch": 6.613618575528307,
      "grad_norm": 7.309444427490234,
      "learning_rate": 4.6693190712235854e-05,
      "loss": 0.1018,
      "step": 50700
    },
    {
      "epoch": 6.62014088181581,
      "grad_norm": 1.4099878072738647,
      "learning_rate": 4.66899295590921e-05,
      "loss": 0.1366,
      "step": 50750
    },
    {
      "epoch": 6.626663188103313,
      "grad_norm": 0.10690834373235703,
      "learning_rate": 4.668666840594835e-05,
      "loss": 0.0661,
      "step": 50800
    },
    {
      "epoch": 6.633185494390816,
      "grad_norm": 0.09732143580913544,
      "learning_rate": 4.668340725280459e-05,
      "loss": 0.1156,
      "step": 50850
    },
    {
      "epoch": 6.63970780067832,
      "grad_norm": 0.37031227350234985,
      "learning_rate": 4.6680146099660846e-05,
      "loss": 0.1089,
      "step": 50900
    },
    {
      "epoch": 6.646230106965823,
      "grad_norm": 0.019602209329605103,
      "learning_rate": 4.667688494651709e-05,
      "loss": 0.0545,
      "step": 50950
    },
    {
      "epoch": 6.652752413253326,
      "grad_norm": 0.26656126976013184,
      "learning_rate": 4.667362379337334e-05,
      "loss": 0.0813,
      "step": 51000
    },
    {
      "epoch": 6.6592747195408295,
      "grad_norm": 0.10227920114994049,
      "learning_rate": 4.6670362640229584e-05,
      "loss": 0.1316,
      "step": 51050
    },
    {
      "epoch": 6.665797025828333,
      "grad_norm": 0.5137798190116882,
      "learning_rate": 4.666710148708584e-05,
      "loss": 0.1445,
      "step": 51100
    },
    {
      "epoch": 6.672319332115836,
      "grad_norm": 2.008157730102539,
      "learning_rate": 4.6663840333942084e-05,
      "loss": 0.0746,
      "step": 51150
    },
    {
      "epoch": 6.678841638403339,
      "grad_norm": 0.6104691624641418,
      "learning_rate": 4.666057918079833e-05,
      "loss": 0.1632,
      "step": 51200
    },
    {
      "epoch": 6.685363944690843,
      "grad_norm": 3.172224283218384,
      "learning_rate": 4.6657318027654576e-05,
      "loss": 0.0556,
      "step": 51250
    },
    {
      "epoch": 6.691886250978346,
      "grad_norm": 0.018479811027646065,
      "learning_rate": 4.665405687451083e-05,
      "loss": 0.1161,
      "step": 51300
    },
    {
      "epoch": 6.698408557265849,
      "grad_norm": 20.122650146484375,
      "learning_rate": 4.665079572136708e-05,
      "loss": 0.1427,
      "step": 51350
    },
    {
      "epoch": 6.704930863553352,
      "grad_norm": 0.30048251152038574,
      "learning_rate": 4.664753456822333e-05,
      "loss": 0.1162,
      "step": 51400
    },
    {
      "epoch": 6.711453169840856,
      "grad_norm": 0.06385956704616547,
      "learning_rate": 4.6644273415079574e-05,
      "loss": 0.1409,
      "step": 51450
    },
    {
      "epoch": 6.717975476128359,
      "grad_norm": 7.003762722015381,
      "learning_rate": 4.664101226193582e-05,
      "loss": 0.0664,
      "step": 51500
    },
    {
      "epoch": 6.724497782415862,
      "grad_norm": 0.015992475673556328,
      "learning_rate": 4.6637751108792073e-05,
      "loss": 0.0988,
      "step": 51550
    },
    {
      "epoch": 6.7310200887033655,
      "grad_norm": 0.06341581791639328,
      "learning_rate": 4.663448995564832e-05,
      "loss": 0.0885,
      "step": 51600
    },
    {
      "epoch": 6.737542394990869,
      "grad_norm": 0.02859988994896412,
      "learning_rate": 4.6631228802504566e-05,
      "loss": 0.1,
      "step": 51650
    },
    {
      "epoch": 6.744064701278372,
      "grad_norm": 7.151202201843262,
      "learning_rate": 4.662796764936081e-05,
      "loss": 0.0992,
      "step": 51700
    },
    {
      "epoch": 6.750587007565875,
      "grad_norm": 18.77947425842285,
      "learning_rate": 4.6624706496217065e-05,
      "loss": 0.083,
      "step": 51750
    },
    {
      "epoch": 6.757109313853379,
      "grad_norm": 6.35753059387207,
      "learning_rate": 4.662144534307331e-05,
      "loss": 0.1586,
      "step": 51800
    },
    {
      "epoch": 6.763631620140882,
      "grad_norm": 0.04217618331313133,
      "learning_rate": 4.661818418992956e-05,
      "loss": 0.1252,
      "step": 51850
    },
    {
      "epoch": 6.770153926428385,
      "grad_norm": 0.38114726543426514,
      "learning_rate": 4.661492303678581e-05,
      "loss": 0.1875,
      "step": 51900
    },
    {
      "epoch": 6.7766762327158885,
      "grad_norm": 1.332018256187439,
      "learning_rate": 4.661166188364206e-05,
      "loss": 0.1088,
      "step": 51950
    },
    {
      "epoch": 6.783198539003392,
      "grad_norm": 3.839010238647461,
      "learning_rate": 4.660840073049831e-05,
      "loss": 0.1001,
      "step": 52000
    },
    {
      "epoch": 6.789720845290895,
      "grad_norm": 0.07982391864061356,
      "learning_rate": 4.6605139577354556e-05,
      "loss": 0.1341,
      "step": 52050
    },
    {
      "epoch": 6.796243151578398,
      "grad_norm": 5.256348609924316,
      "learning_rate": 4.66018784242108e-05,
      "loss": 0.0616,
      "step": 52100
    },
    {
      "epoch": 6.802765457865902,
      "grad_norm": 0.9452507495880127,
      "learning_rate": 4.6598617271067055e-05,
      "loss": 0.0594,
      "step": 52150
    },
    {
      "epoch": 6.809287764153405,
      "grad_norm": 0.19265161454677582,
      "learning_rate": 4.65953561179233e-05,
      "loss": 0.1607,
      "step": 52200
    },
    {
      "epoch": 6.815810070440908,
      "grad_norm": 8.949320793151855,
      "learning_rate": 4.659209496477955e-05,
      "loss": 0.0847,
      "step": 52250
    },
    {
      "epoch": 6.822332376728411,
      "grad_norm": 0.044174980372190475,
      "learning_rate": 4.658883381163579e-05,
      "loss": 0.1164,
      "step": 52300
    },
    {
      "epoch": 6.828854683015915,
      "grad_norm": 14.368064880371094,
      "learning_rate": 4.6585572658492046e-05,
      "loss": 0.0615,
      "step": 52350
    },
    {
      "epoch": 6.835376989303418,
      "grad_norm": 0.28919291496276855,
      "learning_rate": 4.658231150534829e-05,
      "loss": 0.0505,
      "step": 52400
    },
    {
      "epoch": 6.841899295590921,
      "grad_norm": 9.139098167419434,
      "learning_rate": 4.657905035220454e-05,
      "loss": 0.1208,
      "step": 52450
    },
    {
      "epoch": 6.8484216018784245,
      "grad_norm": 2.0368781089782715,
      "learning_rate": 4.6575789199060785e-05,
      "loss": 0.0574,
      "step": 52500
    },
    {
      "epoch": 6.854943908165928,
      "grad_norm": 12.195295333862305,
      "learning_rate": 4.657252804591704e-05,
      "loss": 0.0552,
      "step": 52550
    },
    {
      "epoch": 6.861466214453431,
      "grad_norm": 0.36274397373199463,
      "learning_rate": 4.656926689277329e-05,
      "loss": 0.1059,
      "step": 52600
    },
    {
      "epoch": 6.867988520740934,
      "grad_norm": 0.02959899604320526,
      "learning_rate": 4.656600573962954e-05,
      "loss": 0.1119,
      "step": 52650
    },
    {
      "epoch": 6.874510827028438,
      "grad_norm": 0.014073939993977547,
      "learning_rate": 4.656274458648578e-05,
      "loss": 0.1236,
      "step": 52700
    },
    {
      "epoch": 6.88103313331594,
      "grad_norm": 0.10298680514097214,
      "learning_rate": 4.6559483433342036e-05,
      "loss": 0.0735,
      "step": 52750
    },
    {
      "epoch": 6.887555439603444,
      "grad_norm": 0.029054028913378716,
      "learning_rate": 4.655622228019828e-05,
      "loss": 0.0844,
      "step": 52800
    },
    {
      "epoch": 6.894077745890947,
      "grad_norm": 0.008755984716117382,
      "learning_rate": 4.655296112705453e-05,
      "loss": 0.1005,
      "step": 52850
    },
    {
      "epoch": 6.900600052178451,
      "grad_norm": 21.8084716796875,
      "learning_rate": 4.6549699973910775e-05,
      "loss": 0.1324,
      "step": 52900
    },
    {
      "epoch": 6.907122358465953,
      "grad_norm": 22.226669311523438,
      "learning_rate": 4.654643882076703e-05,
      "loss": 0.0767,
      "step": 52950
    },
    {
      "epoch": 6.913644664753457,
      "grad_norm": 0.008661513216793537,
      "learning_rate": 4.6543177667623274e-05,
      "loss": 0.1736,
      "step": 53000
    },
    {
      "epoch": 6.92016697104096,
      "grad_norm": 4.117105484008789,
      "learning_rate": 4.653991651447952e-05,
      "loss": 0.0785,
      "step": 53050
    },
    {
      "epoch": 6.926689277328463,
      "grad_norm": 27.29598617553711,
      "learning_rate": 4.6536655361335766e-05,
      "loss": 0.1197,
      "step": 53100
    },
    {
      "epoch": 6.933211583615966,
      "grad_norm": 0.09018132090568542,
      "learning_rate": 4.653339420819202e-05,
      "loss": 0.1412,
      "step": 53150
    },
    {
      "epoch": 6.9397338899034695,
      "grad_norm": 0.6508216857910156,
      "learning_rate": 4.653013305504827e-05,
      "loss": 0.0836,
      "step": 53200
    },
    {
      "epoch": 6.946256196190973,
      "grad_norm": 0.00898703746497631,
      "learning_rate": 4.652687190190452e-05,
      "loss": 0.0982,
      "step": 53250
    },
    {
      "epoch": 6.952778502478476,
      "grad_norm": 0.48470035195350647,
      "learning_rate": 4.6523610748760764e-05,
      "loss": 0.0812,
      "step": 53300
    },
    {
      "epoch": 6.959300808765979,
      "grad_norm": 0.050143759697675705,
      "learning_rate": 4.652034959561701e-05,
      "loss": 0.1747,
      "step": 53350
    },
    {
      "epoch": 6.965823115053483,
      "grad_norm": 7.8047990798950195,
      "learning_rate": 4.6517088442473263e-05,
      "loss": 0.0878,
      "step": 53400
    },
    {
      "epoch": 6.972345421340986,
      "grad_norm": 11.352972030639648,
      "learning_rate": 4.651382728932951e-05,
      "loss": 0.122,
      "step": 53450
    },
    {
      "epoch": 6.978867727628489,
      "grad_norm": 0.1408512145280838,
      "learning_rate": 4.6510566136185756e-05,
      "loss": 0.1002,
      "step": 53500
    },
    {
      "epoch": 6.9853900339159924,
      "grad_norm": 0.018968509510159492,
      "learning_rate": 4.6507304983042e-05,
      "loss": 0.0945,
      "step": 53550
    },
    {
      "epoch": 6.991912340203496,
      "grad_norm": 0.4760672152042389,
      "learning_rate": 4.6504043829898255e-05,
      "loss": 0.1448,
      "step": 53600
    },
    {
      "epoch": 6.998434646490999,
      "grad_norm": 8.874693870544434,
      "learning_rate": 4.65007826767545e-05,
      "loss": 0.1371,
      "step": 53650
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9666057918079833,
      "eval_f1": 0.9668436730993395,
      "eval_loss": 0.12216905504465103,
      "eval_precision": 0.9602521224594803,
      "eval_recall": 0.9735263432446531,
      "eval_runtime": 23.4683,
      "eval_samples_per_second": 653.306,
      "eval_steps_per_second": 81.685,
      "step": 53662
    },
    {
      "epoch": 7.004956952778502,
      "grad_norm": 0.17225868999958038,
      "learning_rate": 4.649752152361075e-05,
      "loss": 0.1013,
      "step": 53700
    },
    {
      "epoch": 7.0114792590660056,
      "grad_norm": 0.1938444823026657,
      "learning_rate": 4.6494260370467e-05,
      "loss": 0.0948,
      "step": 53750
    },
    {
      "epoch": 7.018001565353509,
      "grad_norm": 0.008657984435558319,
      "learning_rate": 4.649099921732325e-05,
      "loss": 0.1318,
      "step": 53800
    },
    {
      "epoch": 7.024523871641012,
      "grad_norm": 22.90399742126465,
      "learning_rate": 4.64877380641795e-05,
      "loss": 0.0825,
      "step": 53850
    },
    {
      "epoch": 7.031046177928515,
      "grad_norm": 0.10721366852521896,
      "learning_rate": 4.6484476911035746e-05,
      "loss": 0.0848,
      "step": 53900
    },
    {
      "epoch": 7.037568484216019,
      "grad_norm": 2.6090221405029297,
      "learning_rate": 4.648121575789199e-05,
      "loss": 0.085,
      "step": 53950
    },
    {
      "epoch": 7.044090790503522,
      "grad_norm": 0.016596442088484764,
      "learning_rate": 4.6477954604748245e-05,
      "loss": 0.0628,
      "step": 54000
    },
    {
      "epoch": 7.050613096791025,
      "grad_norm": 0.056335341185331345,
      "learning_rate": 4.647469345160449e-05,
      "loss": 0.0742,
      "step": 54050
    },
    {
      "epoch": 7.0571354030785285,
      "grad_norm": 0.012091501615941525,
      "learning_rate": 4.647143229846074e-05,
      "loss": 0.1163,
      "step": 54100
    },
    {
      "epoch": 7.063657709366032,
      "grad_norm": 6.075742721557617,
      "learning_rate": 4.646817114531698e-05,
      "loss": 0.1069,
      "step": 54150
    },
    {
      "epoch": 7.070180015653535,
      "grad_norm": 0.06110100448131561,
      "learning_rate": 4.6464909992173236e-05,
      "loss": 0.0689,
      "step": 54200
    },
    {
      "epoch": 7.076702321941038,
      "grad_norm": 9.938870429992676,
      "learning_rate": 4.646164883902948e-05,
      "loss": 0.1129,
      "step": 54250
    },
    {
      "epoch": 7.083224628228542,
      "grad_norm": 22.664844512939453,
      "learning_rate": 4.645838768588573e-05,
      "loss": 0.1367,
      "step": 54300
    },
    {
      "epoch": 7.089746934516045,
      "grad_norm": 0.46883371472358704,
      "learning_rate": 4.6455126532741975e-05,
      "loss": 0.0998,
      "step": 54350
    },
    {
      "epoch": 7.096269240803548,
      "grad_norm": 6.9474568367004395,
      "learning_rate": 4.645186537959823e-05,
      "loss": 0.1099,
      "step": 54400
    },
    {
      "epoch": 7.102791547091051,
      "grad_norm": 15.599600791931152,
      "learning_rate": 4.644860422645448e-05,
      "loss": 0.0933,
      "step": 54450
    },
    {
      "epoch": 7.109313853378555,
      "grad_norm": 0.024881167337298393,
      "learning_rate": 4.644534307331073e-05,
      "loss": 0.0992,
      "step": 54500
    },
    {
      "epoch": 7.115836159666058,
      "grad_norm": 0.024863988161087036,
      "learning_rate": 4.644208192016697e-05,
      "loss": 0.0606,
      "step": 54550
    },
    {
      "epoch": 7.122358465953561,
      "grad_norm": 0.12742097675800323,
      "learning_rate": 4.643882076702322e-05,
      "loss": 0.1543,
      "step": 54600
    },
    {
      "epoch": 7.1288807722410645,
      "grad_norm": 0.046912603080272675,
      "learning_rate": 4.643555961387947e-05,
      "loss": 0.113,
      "step": 54650
    },
    {
      "epoch": 7.135403078528568,
      "grad_norm": 10.456958770751953,
      "learning_rate": 4.643229846073572e-05,
      "loss": 0.0579,
      "step": 54700
    },
    {
      "epoch": 7.141925384816071,
      "grad_norm": 3.0992777347564697,
      "learning_rate": 4.6429037307591965e-05,
      "loss": 0.1033,
      "step": 54750
    },
    {
      "epoch": 7.148447691103574,
      "grad_norm": 0.2222319394350052,
      "learning_rate": 4.642577615444821e-05,
      "loss": 0.0453,
      "step": 54800
    },
    {
      "epoch": 7.154969997391078,
      "grad_norm": 0.2705828547477722,
      "learning_rate": 4.6422515001304464e-05,
      "loss": 0.1049,
      "step": 54850
    },
    {
      "epoch": 7.161492303678581,
      "grad_norm": 0.026321731507778168,
      "learning_rate": 4.641925384816071e-05,
      "loss": 0.1191,
      "step": 54900
    },
    {
      "epoch": 7.168014609966084,
      "grad_norm": 0.2732611894607544,
      "learning_rate": 4.6415992695016956e-05,
      "loss": 0.1029,
      "step": 54950
    },
    {
      "epoch": 7.1745369162535875,
      "grad_norm": 7.710212230682373,
      "learning_rate": 4.641273154187321e-05,
      "loss": 0.1209,
      "step": 55000
    },
    {
      "epoch": 7.181059222541091,
      "grad_norm": 0.5915830135345459,
      "learning_rate": 4.640947038872946e-05,
      "loss": 0.1268,
      "step": 55050
    },
    {
      "epoch": 7.187581528828594,
      "grad_norm": 0.03673674166202545,
      "learning_rate": 4.640620923558571e-05,
      "loss": 0.0681,
      "step": 55100
    },
    {
      "epoch": 7.194103835116097,
      "grad_norm": 11.623150825500488,
      "learning_rate": 4.6402948082441954e-05,
      "loss": 0.1147,
      "step": 55150
    },
    {
      "epoch": 7.200626141403601,
      "grad_norm": 0.010765510611236095,
      "learning_rate": 4.63996869292982e-05,
      "loss": 0.0741,
      "step": 55200
    },
    {
      "epoch": 7.207148447691104,
      "grad_norm": 0.12828338146209717,
      "learning_rate": 4.6396425776154454e-05,
      "loss": 0.0916,
      "step": 55250
    },
    {
      "epoch": 7.213670753978607,
      "grad_norm": 0.20377850532531738,
      "learning_rate": 4.63931646230107e-05,
      "loss": 0.0635,
      "step": 55300
    },
    {
      "epoch": 7.22019306026611,
      "grad_norm": 0.3060246706008911,
      "learning_rate": 4.6389903469866946e-05,
      "loss": 0.1236,
      "step": 55350
    },
    {
      "epoch": 7.226715366553614,
      "grad_norm": 0.33609864115715027,
      "learning_rate": 4.638664231672319e-05,
      "loss": 0.1015,
      "step": 55400
    },
    {
      "epoch": 7.233237672841117,
      "grad_norm": 0.09677861630916595,
      "learning_rate": 4.6383381163579445e-05,
      "loss": 0.0891,
      "step": 55450
    },
    {
      "epoch": 7.23975997912862,
      "grad_norm": 0.020606905221939087,
      "learning_rate": 4.638012001043569e-05,
      "loss": 0.0917,
      "step": 55500
    },
    {
      "epoch": 7.2462822854161235,
      "grad_norm": 0.11866017431020737,
      "learning_rate": 4.637685885729194e-05,
      "loss": 0.0933,
      "step": 55550
    },
    {
      "epoch": 7.252804591703627,
      "grad_norm": 0.020689718425273895,
      "learning_rate": 4.637359770414819e-05,
      "loss": 0.0874,
      "step": 55600
    },
    {
      "epoch": 7.25932689799113,
      "grad_norm": 0.011647098697721958,
      "learning_rate": 4.6370336551004437e-05,
      "loss": 0.1111,
      "step": 55650
    },
    {
      "epoch": 7.2658492042786325,
      "grad_norm": 0.18261246383190155,
      "learning_rate": 4.636707539786069e-05,
      "loss": 0.0793,
      "step": 55700
    },
    {
      "epoch": 7.272371510566137,
      "grad_norm": 0.009936896152794361,
      "learning_rate": 4.6363814244716936e-05,
      "loss": 0.1142,
      "step": 55750
    },
    {
      "epoch": 7.278893816853639,
      "grad_norm": 29.08095359802246,
      "learning_rate": 4.636055309157318e-05,
      "loss": 0.0976,
      "step": 55800
    },
    {
      "epoch": 7.285416123141143,
      "grad_norm": 0.16599856317043304,
      "learning_rate": 4.635729193842943e-05,
      "loss": 0.094,
      "step": 55850
    },
    {
      "epoch": 7.291938429428646,
      "grad_norm": 0.010323124937713146,
      "learning_rate": 4.635403078528568e-05,
      "loss": 0.1158,
      "step": 55900
    },
    {
      "epoch": 7.298460735716149,
      "grad_norm": 0.13033901154994965,
      "learning_rate": 4.635076963214193e-05,
      "loss": 0.1295,
      "step": 55950
    },
    {
      "epoch": 7.304983042003652,
      "grad_norm": 0.009049716405570507,
      "learning_rate": 4.6347508478998173e-05,
      "loss": 0.0889,
      "step": 56000
    },
    {
      "epoch": 7.311505348291155,
      "grad_norm": 16.10748291015625,
      "learning_rate": 4.634424732585442e-05,
      "loss": 0.1339,
      "step": 56050
    },
    {
      "epoch": 7.318027654578659,
      "grad_norm": 6.716403007507324,
      "learning_rate": 4.634098617271067e-05,
      "loss": 0.0818,
      "step": 56100
    },
    {
      "epoch": 7.324549960866162,
      "grad_norm": 3.401033639907837,
      "learning_rate": 4.633772501956692e-05,
      "loss": 0.0994,
      "step": 56150
    },
    {
      "epoch": 7.331072267153665,
      "grad_norm": 0.03592687472701073,
      "learning_rate": 4.6334463866423165e-05,
      "loss": 0.1158,
      "step": 56200
    },
    {
      "epoch": 7.3375945734411685,
      "grad_norm": 0.5022287964820862,
      "learning_rate": 4.633120271327942e-05,
      "loss": 0.1376,
      "step": 56250
    },
    {
      "epoch": 7.344116879728672,
      "grad_norm": 0.007208564318716526,
      "learning_rate": 4.632794156013567e-05,
      "loss": 0.0992,
      "step": 56300
    },
    {
      "epoch": 7.350639186016175,
      "grad_norm": 6.824552536010742,
      "learning_rate": 4.632468040699192e-05,
      "loss": 0.0927,
      "step": 56350
    },
    {
      "epoch": 7.357161492303678,
      "grad_norm": 22.92633628845215,
      "learning_rate": 4.632141925384816e-05,
      "loss": 0.1135,
      "step": 56400
    },
    {
      "epoch": 7.363683798591182,
      "grad_norm": 7.3948073387146,
      "learning_rate": 4.631815810070441e-05,
      "loss": 0.0935,
      "step": 56450
    },
    {
      "epoch": 7.370206104878685,
      "grad_norm": 0.24510078132152557,
      "learning_rate": 4.631489694756066e-05,
      "loss": 0.1067,
      "step": 56500
    },
    {
      "epoch": 7.376728411166188,
      "grad_norm": 0.1343134641647339,
      "learning_rate": 4.631163579441691e-05,
      "loss": 0.0846,
      "step": 56550
    },
    {
      "epoch": 7.383250717453691,
      "grad_norm": 4.340692520141602,
      "learning_rate": 4.6308374641273155e-05,
      "loss": 0.1436,
      "step": 56600
    },
    {
      "epoch": 7.389773023741195,
      "grad_norm": 0.3545721769332886,
      "learning_rate": 4.63051134881294e-05,
      "loss": 0.1548,
      "step": 56650
    },
    {
      "epoch": 7.396295330028698,
      "grad_norm": 0.06717149168252945,
      "learning_rate": 4.6301852334985654e-05,
      "loss": 0.0905,
      "step": 56700
    },
    {
      "epoch": 7.402817636316201,
      "grad_norm": 0.0568658821284771,
      "learning_rate": 4.62985911818419e-05,
      "loss": 0.0583,
      "step": 56750
    },
    {
      "epoch": 7.4093399426037045,
      "grad_norm": 14.095786094665527,
      "learning_rate": 4.6295330028698146e-05,
      "loss": 0.0773,
      "step": 56800
    },
    {
      "epoch": 7.415862248891208,
      "grad_norm": 0.09675734490156174,
      "learning_rate": 4.62920688755544e-05,
      "loss": 0.1391,
      "step": 56850
    },
    {
      "epoch": 7.422384555178711,
      "grad_norm": 0.6739328503608704,
      "learning_rate": 4.6288807722410645e-05,
      "loss": 0.0772,
      "step": 56900
    },
    {
      "epoch": 7.428906861466214,
      "grad_norm": 4.061469078063965,
      "learning_rate": 4.62855465692669e-05,
      "loss": 0.1126,
      "step": 56950
    },
    {
      "epoch": 7.435429167753718,
      "grad_norm": 0.046335481107234955,
      "learning_rate": 4.6282285416123145e-05,
      "loss": 0.107,
      "step": 57000
    },
    {
      "epoch": 7.441951474041221,
      "grad_norm": 0.03011573851108551,
      "learning_rate": 4.627902426297939e-05,
      "loss": 0.0905,
      "step": 57050
    },
    {
      "epoch": 7.448473780328724,
      "grad_norm": 12.630879402160645,
      "learning_rate": 4.6275763109835644e-05,
      "loss": 0.0995,
      "step": 57100
    },
    {
      "epoch": 7.4549960866162275,
      "grad_norm": 0.02748778648674488,
      "learning_rate": 4.627250195669189e-05,
      "loss": 0.0866,
      "step": 57150
    },
    {
      "epoch": 7.461518392903731,
      "grad_norm": 0.5401506423950195,
      "learning_rate": 4.6269240803548136e-05,
      "loss": 0.1503,
      "step": 57200
    },
    {
      "epoch": 7.468040699191234,
      "grad_norm": 0.34491392970085144,
      "learning_rate": 4.626597965040438e-05,
      "loss": 0.1496,
      "step": 57250
    },
    {
      "epoch": 7.474563005478737,
      "grad_norm": 6.899785995483398,
      "learning_rate": 4.6262718497260635e-05,
      "loss": 0.0829,
      "step": 57300
    },
    {
      "epoch": 7.481085311766241,
      "grad_norm": 0.03292357921600342,
      "learning_rate": 4.625945734411688e-05,
      "loss": 0.0759,
      "step": 57350
    },
    {
      "epoch": 7.487607618053744,
      "grad_norm": 0.029129628092050552,
      "learning_rate": 4.625619619097313e-05,
      "loss": 0.0682,
      "step": 57400
    },
    {
      "epoch": 7.494129924341247,
      "grad_norm": 0.18814456462860107,
      "learning_rate": 4.625293503782938e-05,
      "loss": 0.1216,
      "step": 57450
    },
    {
      "epoch": 7.50065223062875,
      "grad_norm": 12.327674865722656,
      "learning_rate": 4.624967388468563e-05,
      "loss": 0.1086,
      "step": 57500
    },
    {
      "epoch": 7.507174536916254,
      "grad_norm": 0.0830000787973404,
      "learning_rate": 4.624641273154188e-05,
      "loss": 0.1067,
      "step": 57550
    },
    {
      "epoch": 7.513696843203757,
      "grad_norm": 21.61375617980957,
      "learning_rate": 4.6243151578398126e-05,
      "loss": 0.0821,
      "step": 57600
    },
    {
      "epoch": 7.52021914949126,
      "grad_norm": 0.02806060016155243,
      "learning_rate": 4.623989042525437e-05,
      "loss": 0.0627,
      "step": 57650
    },
    {
      "epoch": 7.5267414557787635,
      "grad_norm": 11.373826026916504,
      "learning_rate": 4.623662927211062e-05,
      "loss": 0.1411,
      "step": 57700
    },
    {
      "epoch": 7.533263762066267,
      "grad_norm": 9.953689575195312,
      "learning_rate": 4.623336811896687e-05,
      "loss": 0.1112,
      "step": 57750
    },
    {
      "epoch": 7.53978606835377,
      "grad_norm": 0.010961346328258514,
      "learning_rate": 4.623010696582312e-05,
      "loss": 0.0918,
      "step": 57800
    },
    {
      "epoch": 7.546308374641273,
      "grad_norm": 0.05249818414449692,
      "learning_rate": 4.6226845812679363e-05,
      "loss": 0.0901,
      "step": 57850
    },
    {
      "epoch": 7.552830680928777,
      "grad_norm": 14.734254837036133,
      "learning_rate": 4.622358465953561e-05,
      "loss": 0.1294,
      "step": 57900
    },
    {
      "epoch": 7.55935298721628,
      "grad_norm": 0.32801005244255066,
      "learning_rate": 4.622032350639186e-05,
      "loss": 0.1436,
      "step": 57950
    },
    {
      "epoch": 7.565875293503783,
      "grad_norm": 0.10061690211296082,
      "learning_rate": 4.621706235324811e-05,
      "loss": 0.0931,
      "step": 58000
    },
    {
      "epoch": 7.5723975997912865,
      "grad_norm": 8.363006591796875,
      "learning_rate": 4.621380120010436e-05,
      "loss": 0.099,
      "step": 58050
    },
    {
      "epoch": 7.57891990607879,
      "grad_norm": 0.038420144468545914,
      "learning_rate": 4.621054004696061e-05,
      "loss": 0.0712,
      "step": 58100
    },
    {
      "epoch": 7.585442212366293,
      "grad_norm": 0.003944188356399536,
      "learning_rate": 4.620727889381686e-05,
      "loss": 0.087,
      "step": 58150
    },
    {
      "epoch": 7.591964518653796,
      "grad_norm": 9.828450202941895,
      "learning_rate": 4.620401774067311e-05,
      "loss": 0.1025,
      "step": 58200
    },
    {
      "epoch": 7.5984868249413,
      "grad_norm": 7.213794708251953,
      "learning_rate": 4.620075658752935e-05,
      "loss": 0.0792,
      "step": 58250
    },
    {
      "epoch": 7.605009131228803,
      "grad_norm": 0.16243667900562286,
      "learning_rate": 4.61974954343856e-05,
      "loss": 0.1222,
      "step": 58300
    },
    {
      "epoch": 7.611531437516306,
      "grad_norm": 0.010420799255371094,
      "learning_rate": 4.619423428124185e-05,
      "loss": 0.0705,
      "step": 58350
    },
    {
      "epoch": 7.618053743803809,
      "grad_norm": 0.19362980127334595,
      "learning_rate": 4.61909731280981e-05,
      "loss": 0.1208,
      "step": 58400
    },
    {
      "epoch": 7.624576050091313,
      "grad_norm": 0.2502523362636566,
      "learning_rate": 4.6187711974954345e-05,
      "loss": 0.0727,
      "step": 58450
    },
    {
      "epoch": 7.631098356378816,
      "grad_norm": 0.01012628898024559,
      "learning_rate": 4.618445082181059e-05,
      "loss": 0.1038,
      "step": 58500
    },
    {
      "epoch": 7.637620662666318,
      "grad_norm": 0.01485784538090229,
      "learning_rate": 4.6181189668666844e-05,
      "loss": 0.0972,
      "step": 58550
    },
    {
      "epoch": 7.6441429689538225,
      "grad_norm": 0.13542474806308746,
      "learning_rate": 4.617792851552309e-05,
      "loss": 0.1298,
      "step": 58600
    },
    {
      "epoch": 7.650665275241325,
      "grad_norm": 0.01369995716959238,
      "learning_rate": 4.6174667362379336e-05,
      "loss": 0.0735,
      "step": 58650
    },
    {
      "epoch": 7.657187581528829,
      "grad_norm": 3.7024052143096924,
      "learning_rate": 4.617140620923559e-05,
      "loss": 0.1218,
      "step": 58700
    },
    {
      "epoch": 7.6637098878163314,
      "grad_norm": 0.07486511766910553,
      "learning_rate": 4.6168145056091835e-05,
      "loss": 0.1237,
      "step": 58750
    },
    {
      "epoch": 7.670232194103836,
      "grad_norm": 0.11677654832601547,
      "learning_rate": 4.616488390294809e-05,
      "loss": 0.0564,
      "step": 58800
    },
    {
      "epoch": 7.676754500391338,
      "grad_norm": 20.80712127685547,
      "learning_rate": 4.6161622749804335e-05,
      "loss": 0.1493,
      "step": 58850
    },
    {
      "epoch": 7.683276806678841,
      "grad_norm": 0.00616430165246129,
      "learning_rate": 4.615836159666058e-05,
      "loss": 0.1074,
      "step": 58900
    },
    {
      "epoch": 7.6897991129663446,
      "grad_norm": 0.14729078114032745,
      "learning_rate": 4.615510044351683e-05,
      "loss": 0.0868,
      "step": 58950
    },
    {
      "epoch": 7.696321419253848,
      "grad_norm": 8.276369094848633,
      "learning_rate": 4.615183929037308e-05,
      "loss": 0.0582,
      "step": 59000
    },
    {
      "epoch": 7.702843725541351,
      "grad_norm": 14.489623069763184,
      "learning_rate": 4.6148578137229326e-05,
      "loss": 0.0712,
      "step": 59050
    },
    {
      "epoch": 7.709366031828854,
      "grad_norm": 0.0893782526254654,
      "learning_rate": 4.614531698408557e-05,
      "loss": 0.0907,
      "step": 59100
    },
    {
      "epoch": 7.715888338116358,
      "grad_norm": 1.798951268196106,
      "learning_rate": 4.614205583094182e-05,
      "loss": 0.1514,
      "step": 59150
    },
    {
      "epoch": 7.722410644403861,
      "grad_norm": 2.434514045715332,
      "learning_rate": 4.613879467779807e-05,
      "loss": 0.1192,
      "step": 59200
    },
    {
      "epoch": 7.728932950691364,
      "grad_norm": 26.16048240661621,
      "learning_rate": 4.613553352465432e-05,
      "loss": 0.0776,
      "step": 59250
    },
    {
      "epoch": 7.7354552569788675,
      "grad_norm": 9.972262382507324,
      "learning_rate": 4.613227237151057e-05,
      "loss": 0.0793,
      "step": 59300
    },
    {
      "epoch": 7.741977563266371,
      "grad_norm": 6.091166019439697,
      "learning_rate": 4.612901121836682e-05,
      "loss": 0.134,
      "step": 59350
    },
    {
      "epoch": 7.748499869553874,
      "grad_norm": 0.044631995260715485,
      "learning_rate": 4.612575006522307e-05,
      "loss": 0.0935,
      "step": 59400
    },
    {
      "epoch": 7.755022175841377,
      "grad_norm": 3.52508807182312,
      "learning_rate": 4.6122488912079316e-05,
      "loss": 0.0981,
      "step": 59450
    },
    {
      "epoch": 7.761544482128881,
      "grad_norm": 0.003708326257765293,
      "learning_rate": 4.611922775893556e-05,
      "loss": 0.07,
      "step": 59500
    },
    {
      "epoch": 7.768066788416384,
      "grad_norm": 0.18131421506404877,
      "learning_rate": 4.611596660579181e-05,
      "loss": 0.0347,
      "step": 59550
    },
    {
      "epoch": 7.774589094703887,
      "grad_norm": 0.0026311965193599463,
      "learning_rate": 4.611270545264806e-05,
      "loss": 0.0576,
      "step": 59600
    },
    {
      "epoch": 7.78111140099139,
      "grad_norm": 0.051519621163606644,
      "learning_rate": 4.610944429950431e-05,
      "loss": 0.1287,
      "step": 59650
    },
    {
      "epoch": 7.787633707278894,
      "grad_norm": 0.6131419539451599,
      "learning_rate": 4.6106183146360554e-05,
      "loss": 0.159,
      "step": 59700
    },
    {
      "epoch": 7.794156013566397,
      "grad_norm": 0.08873763680458069,
      "learning_rate": 4.61029219932168e-05,
      "loss": 0.0649,
      "step": 59750
    },
    {
      "epoch": 7.8006783198539,
      "grad_norm": 11.138104438781738,
      "learning_rate": 4.609966084007305e-05,
      "loss": 0.1634,
      "step": 59800
    },
    {
      "epoch": 7.8072006261414035,
      "grad_norm": 14.11976146697998,
      "learning_rate": 4.60963996869293e-05,
      "loss": 0.0889,
      "step": 59850
    },
    {
      "epoch": 7.813722932428907,
      "grad_norm": 0.3340354859828949,
      "learning_rate": 4.609313853378555e-05,
      "loss": 0.131,
      "step": 59900
    },
    {
      "epoch": 7.82024523871641,
      "grad_norm": 6.835176467895508,
      "learning_rate": 4.60898773806418e-05,
      "loss": 0.091,
      "step": 59950
    },
    {
      "epoch": 7.826767545003913,
      "grad_norm": 0.06574536859989166,
      "learning_rate": 4.6086616227498044e-05,
      "loss": 0.0577,
      "step": 60000
    },
    {
      "epoch": 7.833289851291417,
      "grad_norm": 0.1269722729921341,
      "learning_rate": 4.60833550743543e-05,
      "loss": 0.1593,
      "step": 60050
    },
    {
      "epoch": 7.83981215757892,
      "grad_norm": 0.1588946282863617,
      "learning_rate": 4.608009392121054e-05,
      "loss": 0.1225,
      "step": 60100
    },
    {
      "epoch": 7.846334463866423,
      "grad_norm": 0.8474873304367065,
      "learning_rate": 4.607683276806679e-05,
      "loss": 0.0625,
      "step": 60150
    },
    {
      "epoch": 7.8528567701539265,
      "grad_norm": 6.230020046234131,
      "learning_rate": 4.6073571614923036e-05,
      "loss": 0.1022,
      "step": 60200
    },
    {
      "epoch": 7.85937907644143,
      "grad_norm": 0.06561677902936935,
      "learning_rate": 4.607031046177929e-05,
      "loss": 0.0766,
      "step": 60250
    },
    {
      "epoch": 7.865901382728933,
      "grad_norm": 0.327665776014328,
      "learning_rate": 4.6067049308635535e-05,
      "loss": 0.0578,
      "step": 60300
    },
    {
      "epoch": 7.872423689016436,
      "grad_norm": 3.109546661376953,
      "learning_rate": 4.606378815549178e-05,
      "loss": 0.0526,
      "step": 60350
    },
    {
      "epoch": 7.87894599530394,
      "grad_norm": 0.14089089632034302,
      "learning_rate": 4.6060527002348034e-05,
      "loss": 0.1134,
      "step": 60400
    },
    {
      "epoch": 7.885468301591443,
      "grad_norm": 0.05507461354136467,
      "learning_rate": 4.605726584920428e-05,
      "loss": 0.1363,
      "step": 60450
    },
    {
      "epoch": 7.891990607878946,
      "grad_norm": 23.747032165527344,
      "learning_rate": 4.6054004696060526e-05,
      "loss": 0.0885,
      "step": 60500
    },
    {
      "epoch": 7.898512914166449,
      "grad_norm": 16.973247528076172,
      "learning_rate": 4.605074354291678e-05,
      "loss": 0.0658,
      "step": 60550
    },
    {
      "epoch": 7.905035220453953,
      "grad_norm": 0.05900226905941963,
      "learning_rate": 4.6047482389773026e-05,
      "loss": 0.0929,
      "step": 60600
    },
    {
      "epoch": 7.911557526741456,
      "grad_norm": 0.23562313616275787,
      "learning_rate": 4.604422123662928e-05,
      "loss": 0.0647,
      "step": 60650
    },
    {
      "epoch": 7.918079833028959,
      "grad_norm": 0.04807156324386597,
      "learning_rate": 4.6040960083485525e-05,
      "loss": 0.094,
      "step": 60700
    },
    {
      "epoch": 7.9246021393164625,
      "grad_norm": 14.119253158569336,
      "learning_rate": 4.603769893034177e-05,
      "loss": 0.0829,
      "step": 60750
    },
    {
      "epoch": 7.931124445603966,
      "grad_norm": 0.10439638048410416,
      "learning_rate": 4.603443777719802e-05,
      "loss": 0.1294,
      "step": 60800
    },
    {
      "epoch": 7.937646751891469,
      "grad_norm": 19.975276947021484,
      "learning_rate": 4.603117662405427e-05,
      "loss": 0.0826,
      "step": 60850
    },
    {
      "epoch": 7.944169058178972,
      "grad_norm": 0.018580617383122444,
      "learning_rate": 4.6027915470910516e-05,
      "loss": 0.1111,
      "step": 60900
    },
    {
      "epoch": 7.950691364466476,
      "grad_norm": 0.12058927118778229,
      "learning_rate": 4.602465431776676e-05,
      "loss": 0.1218,
      "step": 60950
    },
    {
      "epoch": 7.957213670753979,
      "grad_norm": 0.11495543271303177,
      "learning_rate": 4.602139316462301e-05,
      "loss": 0.1401,
      "step": 61000
    },
    {
      "epoch": 7.963735977041482,
      "grad_norm": 0.833391547203064,
      "learning_rate": 4.601813201147926e-05,
      "loss": 0.0451,
      "step": 61050
    },
    {
      "epoch": 7.9702582833289854,
      "grad_norm": 0.003934943117201328,
      "learning_rate": 4.601487085833551e-05,
      "loss": 0.1414,
      "step": 61100
    },
    {
      "epoch": 7.976780589616489,
      "grad_norm": 5.410806655883789,
      "learning_rate": 4.601160970519176e-05,
      "loss": 0.0688,
      "step": 61150
    },
    {
      "epoch": 7.983302895903992,
      "grad_norm": 16.277210235595703,
      "learning_rate": 4.600834855204801e-05,
      "loss": 0.0931,
      "step": 61200
    },
    {
      "epoch": 7.989825202191495,
      "grad_norm": 19.873241424560547,
      "learning_rate": 4.600508739890425e-05,
      "loss": 0.1008,
      "step": 61250
    },
    {
      "epoch": 7.9963475084789986,
      "grad_norm": 0.20047074556350708,
      "learning_rate": 4.6001826245760506e-05,
      "loss": 0.1236,
      "step": 61300
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9688233759457344,
      "eval_f1": 0.9688842598619971,
      "eval_loss": 0.11793120950460434,
      "eval_precision": 0.9672472056147647,
      "eval_recall": 0.9705268648930621,
      "eval_runtime": 23.5473,
      "eval_samples_per_second": 651.115,
      "eval_steps_per_second": 81.411,
      "step": 61328
    }
  ],
  "logging_steps": 50,
  "max_steps": 766600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.260928167588659e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
