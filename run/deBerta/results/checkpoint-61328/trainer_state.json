{
  "best_metric": 0.10951113700866699,
  "best_model_checkpoint": "./results/checkpoint-61328",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 61328,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006522306287503261,
      "grad_norm": 1.6039024591445923,
      "learning_rate": 4.999673884685625e-05,
      "loss": 0.7116,
      "step": 50
    },
    {
      "epoch": 0.013044612575006522,
      "grad_norm": 3.7399673461914062,
      "learning_rate": 4.99934776937125e-05,
      "loss": 0.6933,
      "step": 100
    },
    {
      "epoch": 0.019566918862509785,
      "grad_norm": 1.8319379091262817,
      "learning_rate": 4.999021654056875e-05,
      "loss": 0.6935,
      "step": 150
    },
    {
      "epoch": 0.026089225150013044,
      "grad_norm": 3.2863407135009766,
      "learning_rate": 4.9986955387424994e-05,
      "loss": 0.6909,
      "step": 200
    },
    {
      "epoch": 0.03261153143751631,
      "grad_norm": 2.271221160888672,
      "learning_rate": 4.998369423428124e-05,
      "loss": 0.6903,
      "step": 250
    },
    {
      "epoch": 0.03913383772501957,
      "grad_norm": 5.017037391662598,
      "learning_rate": 4.998043308113749e-05,
      "loss": 0.684,
      "step": 300
    },
    {
      "epoch": 0.045656144012522826,
      "grad_norm": 2.107727289199829,
      "learning_rate": 4.9977171927993746e-05,
      "loss": 0.6529,
      "step": 350
    },
    {
      "epoch": 0.05217845030002609,
      "grad_norm": 5.649381160736084,
      "learning_rate": 4.997391077484999e-05,
      "loss": 0.4489,
      "step": 400
    },
    {
      "epoch": 0.05870075658752935,
      "grad_norm": 2.503887414932251,
      "learning_rate": 4.997064962170624e-05,
      "loss": 0.3394,
      "step": 450
    },
    {
      "epoch": 0.06522306287503261,
      "grad_norm": 15.29302978515625,
      "learning_rate": 4.9967388468562485e-05,
      "loss": 0.3647,
      "step": 500
    },
    {
      "epoch": 0.07174536916253588,
      "grad_norm": 8.625175476074219,
      "learning_rate": 4.996412731541874e-05,
      "loss": 0.3055,
      "step": 550
    },
    {
      "epoch": 0.07826767545003914,
      "grad_norm": 2.4684276580810547,
      "learning_rate": 4.9960866162274984e-05,
      "loss": 0.3422,
      "step": 600
    },
    {
      "epoch": 0.08478998173754239,
      "grad_norm": 1.6215450763702393,
      "learning_rate": 4.995760500913123e-05,
      "loss": 0.2393,
      "step": 650
    },
    {
      "epoch": 0.09131228802504565,
      "grad_norm": 0.5624474287033081,
      "learning_rate": 4.9954343855987476e-05,
      "loss": 0.2638,
      "step": 700
    },
    {
      "epoch": 0.09783459431254891,
      "grad_norm": 2.1560678482055664,
      "learning_rate": 4.995108270284373e-05,
      "loss": 0.2772,
      "step": 750
    },
    {
      "epoch": 0.10435690060005218,
      "grad_norm": 2.022919178009033,
      "learning_rate": 4.9947821549699975e-05,
      "loss": 0.2407,
      "step": 800
    },
    {
      "epoch": 0.11087920688755544,
      "grad_norm": 2.6951262950897217,
      "learning_rate": 4.994456039655622e-05,
      "loss": 0.2988,
      "step": 850
    },
    {
      "epoch": 0.1174015131750587,
      "grad_norm": 2.51407790184021,
      "learning_rate": 4.994129924341247e-05,
      "loss": 0.2777,
      "step": 900
    },
    {
      "epoch": 0.12392381946256197,
      "grad_norm": 0.378945916891098,
      "learning_rate": 4.993803809026873e-05,
      "loss": 0.2681,
      "step": 950
    },
    {
      "epoch": 0.13044612575006523,
      "grad_norm": 14.668327331542969,
      "learning_rate": 4.9934776937124973e-05,
      "loss": 0.2531,
      "step": 1000
    },
    {
      "epoch": 0.13696843203756848,
      "grad_norm": 16.662912368774414,
      "learning_rate": 4.993151578398122e-05,
      "loss": 0.3136,
      "step": 1050
    },
    {
      "epoch": 0.14349073832507175,
      "grad_norm": 14.866545677185059,
      "learning_rate": 4.9928254630837466e-05,
      "loss": 0.18,
      "step": 1100
    },
    {
      "epoch": 0.150013044612575,
      "grad_norm": 25.816438674926758,
      "learning_rate": 4.992499347769372e-05,
      "loss": 0.2563,
      "step": 1150
    },
    {
      "epoch": 0.15653535090007828,
      "grad_norm": 9.857342720031738,
      "learning_rate": 4.9921732324549965e-05,
      "loss": 0.1703,
      "step": 1200
    },
    {
      "epoch": 0.16305765718758153,
      "grad_norm": 2.368826150894165,
      "learning_rate": 4.991847117140621e-05,
      "loss": 0.2422,
      "step": 1250
    },
    {
      "epoch": 0.16957996347508478,
      "grad_norm": 12.481566429138184,
      "learning_rate": 4.991521001826246e-05,
      "loss": 0.2134,
      "step": 1300
    },
    {
      "epoch": 0.17610226976258805,
      "grad_norm": 0.2116517573595047,
      "learning_rate": 4.991194886511871e-05,
      "loss": 0.279,
      "step": 1350
    },
    {
      "epoch": 0.1826245760500913,
      "grad_norm": 3.298370122909546,
      "learning_rate": 4.9908687711974957e-05,
      "loss": 0.2465,
      "step": 1400
    },
    {
      "epoch": 0.18914688233759458,
      "grad_norm": 1.7025574445724487,
      "learning_rate": 4.99054265588312e-05,
      "loss": 0.2356,
      "step": 1450
    },
    {
      "epoch": 0.19566918862509783,
      "grad_norm": 0.32886385917663574,
      "learning_rate": 4.990216540568745e-05,
      "loss": 0.2572,
      "step": 1500
    },
    {
      "epoch": 0.2021914949126011,
      "grad_norm": 11.409533500671387,
      "learning_rate": 4.98989042525437e-05,
      "loss": 0.2236,
      "step": 1550
    },
    {
      "epoch": 0.20871380120010435,
      "grad_norm": 16.399559020996094,
      "learning_rate": 4.9895643099399955e-05,
      "loss": 0.1945,
      "step": 1600
    },
    {
      "epoch": 0.21523610748760763,
      "grad_norm": 0.31986457109451294,
      "learning_rate": 4.98923819462562e-05,
      "loss": 0.2298,
      "step": 1650
    },
    {
      "epoch": 0.22175841377511088,
      "grad_norm": 0.7071670293807983,
      "learning_rate": 4.988912079311245e-05,
      "loss": 0.2551,
      "step": 1700
    },
    {
      "epoch": 0.22828072006261413,
      "grad_norm": 1.3316141366958618,
      "learning_rate": 4.988585963996869e-05,
      "loss": 0.2664,
      "step": 1750
    },
    {
      "epoch": 0.2348030263501174,
      "grad_norm": 2.4644863605499268,
      "learning_rate": 4.9882598486824946e-05,
      "loss": 0.2224,
      "step": 1800
    },
    {
      "epoch": 0.24132533263762065,
      "grad_norm": 18.538150787353516,
      "learning_rate": 4.987933733368119e-05,
      "loss": 0.2538,
      "step": 1850
    },
    {
      "epoch": 0.24784763892512393,
      "grad_norm": 10.795157432556152,
      "learning_rate": 4.987607618053744e-05,
      "loss": 0.1983,
      "step": 1900
    },
    {
      "epoch": 0.2543699452126272,
      "grad_norm": 15.692934036254883,
      "learning_rate": 4.9872815027393685e-05,
      "loss": 0.2412,
      "step": 1950
    },
    {
      "epoch": 0.26089225150013046,
      "grad_norm": 4.302797794342041,
      "learning_rate": 4.986955387424994e-05,
      "loss": 0.2686,
      "step": 2000
    },
    {
      "epoch": 0.26741455778763373,
      "grad_norm": 0.2808930575847626,
      "learning_rate": 4.9866292721106184e-05,
      "loss": 0.2106,
      "step": 2050
    },
    {
      "epoch": 0.27393686407513695,
      "grad_norm": 6.644847393035889,
      "learning_rate": 4.986303156796243e-05,
      "loss": 0.2064,
      "step": 2100
    },
    {
      "epoch": 0.28045917036264023,
      "grad_norm": 3.5709142684936523,
      "learning_rate": 4.985977041481868e-05,
      "loss": 0.2008,
      "step": 2150
    },
    {
      "epoch": 0.2869814766501435,
      "grad_norm": 0.1300462931394577,
      "learning_rate": 4.9856509261674936e-05,
      "loss": 0.169,
      "step": 2200
    },
    {
      "epoch": 0.29350378293764673,
      "grad_norm": 13.392607688903809,
      "learning_rate": 4.985324810853118e-05,
      "loss": 0.2499,
      "step": 2250
    },
    {
      "epoch": 0.30002608922515,
      "grad_norm": 2.0626745223999023,
      "learning_rate": 4.984998695538743e-05,
      "loss": 0.2207,
      "step": 2300
    },
    {
      "epoch": 0.3065483955126533,
      "grad_norm": 4.1128058433532715,
      "learning_rate": 4.9846725802243675e-05,
      "loss": 0.2071,
      "step": 2350
    },
    {
      "epoch": 0.31307070180015656,
      "grad_norm": 18.769611358642578,
      "learning_rate": 4.984346464909993e-05,
      "loss": 0.2289,
      "step": 2400
    },
    {
      "epoch": 0.3195930080876598,
      "grad_norm": 10.633797645568848,
      "learning_rate": 4.9840203495956174e-05,
      "loss": 0.2343,
      "step": 2450
    },
    {
      "epoch": 0.32611531437516306,
      "grad_norm": 23.922386169433594,
      "learning_rate": 4.983694234281242e-05,
      "loss": 0.2635,
      "step": 2500
    },
    {
      "epoch": 0.33263762066266633,
      "grad_norm": 5.717768669128418,
      "learning_rate": 4.9833681189668666e-05,
      "loss": 0.2198,
      "step": 2550
    },
    {
      "epoch": 0.33915992695016955,
      "grad_norm": 0.13526861369609833,
      "learning_rate": 4.983042003652492e-05,
      "loss": 0.207,
      "step": 2600
    },
    {
      "epoch": 0.34568223323767283,
      "grad_norm": 1.9732683897018433,
      "learning_rate": 4.9827158883381165e-05,
      "loss": 0.2353,
      "step": 2650
    },
    {
      "epoch": 0.3522045395251761,
      "grad_norm": 0.24033471941947937,
      "learning_rate": 4.982389773023741e-05,
      "loss": 0.2248,
      "step": 2700
    },
    {
      "epoch": 0.3587268458126794,
      "grad_norm": 4.232443332672119,
      "learning_rate": 4.982063657709366e-05,
      "loss": 0.2063,
      "step": 2750
    },
    {
      "epoch": 0.3652491521001826,
      "grad_norm": 11.665452003479004,
      "learning_rate": 4.981737542394991e-05,
      "loss": 0.1659,
      "step": 2800
    },
    {
      "epoch": 0.3717714583876859,
      "grad_norm": 0.09233258664608002,
      "learning_rate": 4.9814114270806164e-05,
      "loss": 0.1751,
      "step": 2850
    },
    {
      "epoch": 0.37829376467518916,
      "grad_norm": 0.09598216414451599,
      "learning_rate": 4.981085311766241e-05,
      "loss": 0.1926,
      "step": 2900
    },
    {
      "epoch": 0.3848160709626924,
      "grad_norm": 0.4634624719619751,
      "learning_rate": 4.9807591964518656e-05,
      "loss": 0.1865,
      "step": 2950
    },
    {
      "epoch": 0.39133837725019566,
      "grad_norm": 1.051722526550293,
      "learning_rate": 4.98043308113749e-05,
      "loss": 0.2354,
      "step": 3000
    },
    {
      "epoch": 0.39786068353769893,
      "grad_norm": 0.2627568244934082,
      "learning_rate": 4.9801069658231155e-05,
      "loss": 0.199,
      "step": 3050
    },
    {
      "epoch": 0.4043829898252022,
      "grad_norm": 2.4330286979675293,
      "learning_rate": 4.97978085050874e-05,
      "loss": 0.2888,
      "step": 3100
    },
    {
      "epoch": 0.41090529611270543,
      "grad_norm": 11.872820854187012,
      "learning_rate": 4.979454735194365e-05,
      "loss": 0.2085,
      "step": 3150
    },
    {
      "epoch": 0.4174276024002087,
      "grad_norm": 7.542423725128174,
      "learning_rate": 4.9791286198799894e-05,
      "loss": 0.1654,
      "step": 3200
    },
    {
      "epoch": 0.423949908687712,
      "grad_norm": 18.0332088470459,
      "learning_rate": 4.9788025045656147e-05,
      "loss": 0.1911,
      "step": 3250
    },
    {
      "epoch": 0.43047221497521526,
      "grad_norm": 0.591703474521637,
      "learning_rate": 4.978476389251239e-05,
      "loss": 0.2061,
      "step": 3300
    },
    {
      "epoch": 0.4369945212627185,
      "grad_norm": 0.6848665475845337,
      "learning_rate": 4.978150273936864e-05,
      "loss": 0.1681,
      "step": 3350
    },
    {
      "epoch": 0.44351682755022176,
      "grad_norm": 1.3499329090118408,
      "learning_rate": 4.977824158622489e-05,
      "loss": 0.2195,
      "step": 3400
    },
    {
      "epoch": 0.45003913383772504,
      "grad_norm": 8.051526069641113,
      "learning_rate": 4.9774980433081145e-05,
      "loss": 0.1509,
      "step": 3450
    },
    {
      "epoch": 0.45656144012522826,
      "grad_norm": 0.20056599378585815,
      "learning_rate": 4.977171927993739e-05,
      "loss": 0.168,
      "step": 3500
    },
    {
      "epoch": 0.46308374641273153,
      "grad_norm": 7.007735729217529,
      "learning_rate": 4.976845812679364e-05,
      "loss": 0.1986,
      "step": 3550
    },
    {
      "epoch": 0.4696060527002348,
      "grad_norm": 7.712243556976318,
      "learning_rate": 4.9765196973649883e-05,
      "loss": 0.1977,
      "step": 3600
    },
    {
      "epoch": 0.4761283589877381,
      "grad_norm": 4.085496425628662,
      "learning_rate": 4.9761935820506136e-05,
      "loss": 0.1041,
      "step": 3650
    },
    {
      "epoch": 0.4826506652752413,
      "grad_norm": 0.12452055513858795,
      "learning_rate": 4.975867466736238e-05,
      "loss": 0.2434,
      "step": 3700
    },
    {
      "epoch": 0.4891729715627446,
      "grad_norm": 11.60506534576416,
      "learning_rate": 4.975541351421863e-05,
      "loss": 0.2128,
      "step": 3750
    },
    {
      "epoch": 0.49569527785024786,
      "grad_norm": 0.0920732170343399,
      "learning_rate": 4.9752152361074875e-05,
      "loss": 0.1221,
      "step": 3800
    },
    {
      "epoch": 0.5022175841377511,
      "grad_norm": 0.6541131734848022,
      "learning_rate": 4.974889120793113e-05,
      "loss": 0.2182,
      "step": 3850
    },
    {
      "epoch": 0.5087398904252544,
      "grad_norm": 17.875890731811523,
      "learning_rate": 4.9745630054787374e-05,
      "loss": 0.2279,
      "step": 3900
    },
    {
      "epoch": 0.5152621967127576,
      "grad_norm": 0.14340591430664062,
      "learning_rate": 4.974236890164362e-05,
      "loss": 0.1966,
      "step": 3950
    },
    {
      "epoch": 0.5217845030002609,
      "grad_norm": 0.23474794626235962,
      "learning_rate": 4.973910774849987e-05,
      "loss": 0.2682,
      "step": 4000
    },
    {
      "epoch": 0.5283068092877642,
      "grad_norm": 6.599801063537598,
      "learning_rate": 4.973584659535612e-05,
      "loss": 0.2067,
      "step": 4050
    },
    {
      "epoch": 0.5348291155752675,
      "grad_norm": 0.0922505110502243,
      "learning_rate": 4.973258544221237e-05,
      "loss": 0.1327,
      "step": 4100
    },
    {
      "epoch": 0.5413514218627706,
      "grad_norm": 0.3166314363479614,
      "learning_rate": 4.972932428906862e-05,
      "loss": 0.1353,
      "step": 4150
    },
    {
      "epoch": 0.5478737281502739,
      "grad_norm": 10.089959144592285,
      "learning_rate": 4.9726063135924865e-05,
      "loss": 0.1558,
      "step": 4200
    },
    {
      "epoch": 0.5543960344377772,
      "grad_norm": 3.8992507457733154,
      "learning_rate": 4.972280198278111e-05,
      "loss": 0.2033,
      "step": 4250
    },
    {
      "epoch": 0.5609183407252805,
      "grad_norm": 0.07149039953947067,
      "learning_rate": 4.9719540829637364e-05,
      "loss": 0.1864,
      "step": 4300
    },
    {
      "epoch": 0.5674406470127837,
      "grad_norm": 0.16683438420295715,
      "learning_rate": 4.971627967649361e-05,
      "loss": 0.1948,
      "step": 4350
    },
    {
      "epoch": 0.573962953300287,
      "grad_norm": 0.6579174995422363,
      "learning_rate": 4.9713018523349856e-05,
      "loss": 0.1386,
      "step": 4400
    },
    {
      "epoch": 0.5804852595877903,
      "grad_norm": 0.0554412379860878,
      "learning_rate": 4.970975737020611e-05,
      "loss": 0.1732,
      "step": 4450
    },
    {
      "epoch": 0.5870075658752935,
      "grad_norm": 6.278128623962402,
      "learning_rate": 4.9706496217062355e-05,
      "loss": 0.2389,
      "step": 4500
    },
    {
      "epoch": 0.5935298721627967,
      "grad_norm": 6.221490383148193,
      "learning_rate": 4.97032350639186e-05,
      "loss": 0.1767,
      "step": 4550
    },
    {
      "epoch": 0.6000521784503,
      "grad_norm": 6.30308198928833,
      "learning_rate": 4.969997391077485e-05,
      "loss": 0.2013,
      "step": 4600
    },
    {
      "epoch": 0.6065744847378033,
      "grad_norm": 0.08512930572032928,
      "learning_rate": 4.96967127576311e-05,
      "loss": 0.1791,
      "step": 4650
    },
    {
      "epoch": 0.6130967910253066,
      "grad_norm": 1.630074381828308,
      "learning_rate": 4.9693451604487354e-05,
      "loss": 0.2149,
      "step": 4700
    },
    {
      "epoch": 0.6196190973128098,
      "grad_norm": 6.84087610244751,
      "learning_rate": 4.96901904513436e-05,
      "loss": 0.1723,
      "step": 4750
    },
    {
      "epoch": 0.6261414036003131,
      "grad_norm": 11.00961685180664,
      "learning_rate": 4.9686929298199846e-05,
      "loss": 0.2024,
      "step": 4800
    },
    {
      "epoch": 0.6326637098878163,
      "grad_norm": 4.566066741943359,
      "learning_rate": 4.968366814505609e-05,
      "loss": 0.175,
      "step": 4850
    },
    {
      "epoch": 0.6391860161753196,
      "grad_norm": 9.485406875610352,
      "learning_rate": 4.9680406991912345e-05,
      "loss": 0.142,
      "step": 4900
    },
    {
      "epoch": 0.6457083224628228,
      "grad_norm": 0.06944386661052704,
      "learning_rate": 4.967714583876859e-05,
      "loss": 0.1294,
      "step": 4950
    },
    {
      "epoch": 0.6522306287503261,
      "grad_norm": 9.071986198425293,
      "learning_rate": 4.967388468562484e-05,
      "loss": 0.2138,
      "step": 5000
    },
    {
      "epoch": 0.6587529350378294,
      "grad_norm": 1.527880072593689,
      "learning_rate": 4.9670623532481084e-05,
      "loss": 0.1813,
      "step": 5050
    },
    {
      "epoch": 0.6652752413253327,
      "grad_norm": 0.08192650973796844,
      "learning_rate": 4.966736237933734e-05,
      "loss": 0.1965,
      "step": 5100
    },
    {
      "epoch": 0.6717975476128359,
      "grad_norm": 4.118531703948975,
      "learning_rate": 4.966410122619358e-05,
      "loss": 0.2024,
      "step": 5150
    },
    {
      "epoch": 0.6783198539003391,
      "grad_norm": 9.481165885925293,
      "learning_rate": 4.966084007304983e-05,
      "loss": 0.2311,
      "step": 5200
    },
    {
      "epoch": 0.6848421601878424,
      "grad_norm": 1.1444252729415894,
      "learning_rate": 4.965757891990608e-05,
      "loss": 0.169,
      "step": 5250
    },
    {
      "epoch": 0.6913644664753457,
      "grad_norm": 0.6210014224052429,
      "learning_rate": 4.9654317766762335e-05,
      "loss": 0.1999,
      "step": 5300
    },
    {
      "epoch": 0.6978867727628489,
      "grad_norm": 12.379622459411621,
      "learning_rate": 4.965105661361858e-05,
      "loss": 0.1799,
      "step": 5350
    },
    {
      "epoch": 0.7044090790503522,
      "grad_norm": 9.894948959350586,
      "learning_rate": 4.964779546047483e-05,
      "loss": 0.1302,
      "step": 5400
    },
    {
      "epoch": 0.7109313853378555,
      "grad_norm": 0.4482159912586212,
      "learning_rate": 4.9644534307331073e-05,
      "loss": 0.1194,
      "step": 5450
    },
    {
      "epoch": 0.7174536916253588,
      "grad_norm": 5.974234580993652,
      "learning_rate": 4.9641273154187326e-05,
      "loss": 0.1542,
      "step": 5500
    },
    {
      "epoch": 0.7239759979128619,
      "grad_norm": 0.20790795981884003,
      "learning_rate": 4.963801200104357e-05,
      "loss": 0.1389,
      "step": 5550
    },
    {
      "epoch": 0.7304983042003652,
      "grad_norm": 11.405787467956543,
      "learning_rate": 4.963475084789982e-05,
      "loss": 0.1935,
      "step": 5600
    },
    {
      "epoch": 0.7370206104878685,
      "grad_norm": 10.755694389343262,
      "learning_rate": 4.9631489694756065e-05,
      "loss": 0.1755,
      "step": 5650
    },
    {
      "epoch": 0.7435429167753718,
      "grad_norm": 9.881012916564941,
      "learning_rate": 4.962822854161232e-05,
      "loss": 0.1608,
      "step": 5700
    },
    {
      "epoch": 0.750065223062875,
      "grad_norm": 0.020322157070040703,
      "learning_rate": 4.9624967388468564e-05,
      "loss": 0.2134,
      "step": 5750
    },
    {
      "epoch": 0.7565875293503783,
      "grad_norm": 8.54430866241455,
      "learning_rate": 4.962170623532481e-05,
      "loss": 0.2031,
      "step": 5800
    },
    {
      "epoch": 0.7631098356378816,
      "grad_norm": 14.318734169006348,
      "learning_rate": 4.961844508218106e-05,
      "loss": 0.1784,
      "step": 5850
    },
    {
      "epoch": 0.7696321419253848,
      "grad_norm": 20.012693405151367,
      "learning_rate": 4.961518392903731e-05,
      "loss": 0.1371,
      "step": 5900
    },
    {
      "epoch": 0.776154448212888,
      "grad_norm": 0.1958593875169754,
      "learning_rate": 4.961192277589356e-05,
      "loss": 0.1783,
      "step": 5950
    },
    {
      "epoch": 0.7826767545003913,
      "grad_norm": 2.031363010406494,
      "learning_rate": 4.960866162274981e-05,
      "loss": 0.1683,
      "step": 6000
    },
    {
      "epoch": 0.7891990607878946,
      "grad_norm": 7.011994361877441,
      "learning_rate": 4.9605400469606055e-05,
      "loss": 0.2197,
      "step": 6050
    },
    {
      "epoch": 0.7957213670753979,
      "grad_norm": 3.608588695526123,
      "learning_rate": 4.96021393164623e-05,
      "loss": 0.1006,
      "step": 6100
    },
    {
      "epoch": 0.8022436733629011,
      "grad_norm": 9.256744384765625,
      "learning_rate": 4.9598878163318554e-05,
      "loss": 0.1745,
      "step": 6150
    },
    {
      "epoch": 0.8087659796504044,
      "grad_norm": 1.453463077545166,
      "learning_rate": 4.95956170101748e-05,
      "loss": 0.2037,
      "step": 6200
    },
    {
      "epoch": 0.8152882859379077,
      "grad_norm": 5.615911960601807,
      "learning_rate": 4.9592355857031046e-05,
      "loss": 0.1951,
      "step": 6250
    },
    {
      "epoch": 0.8218105922254109,
      "grad_norm": 2.49527907371521,
      "learning_rate": 4.958909470388729e-05,
      "loss": 0.1414,
      "step": 6300
    },
    {
      "epoch": 0.8283328985129141,
      "grad_norm": 0.08372315764427185,
      "learning_rate": 4.9585833550743545e-05,
      "loss": 0.1671,
      "step": 6350
    },
    {
      "epoch": 0.8348552048004174,
      "grad_norm": 15.97634506225586,
      "learning_rate": 4.958257239759979e-05,
      "loss": 0.159,
      "step": 6400
    },
    {
      "epoch": 0.8413775110879207,
      "grad_norm": 9.611945152282715,
      "learning_rate": 4.9579311244456045e-05,
      "loss": 0.1548,
      "step": 6450
    },
    {
      "epoch": 0.847899817375424,
      "grad_norm": 0.04522886872291565,
      "learning_rate": 4.957605009131229e-05,
      "loss": 0.1556,
      "step": 6500
    },
    {
      "epoch": 0.8544221236629272,
      "grad_norm": 0.10662293434143066,
      "learning_rate": 4.9572788938168544e-05,
      "loss": 0.1476,
      "step": 6550
    },
    {
      "epoch": 0.8609444299504305,
      "grad_norm": 0.09625887125730515,
      "learning_rate": 4.956952778502479e-05,
      "loss": 0.1508,
      "step": 6600
    },
    {
      "epoch": 0.8674667362379337,
      "grad_norm": 1.5701897144317627,
      "learning_rate": 4.9566266631881036e-05,
      "loss": 0.1903,
      "step": 6650
    },
    {
      "epoch": 0.873989042525437,
      "grad_norm": 3.7294232845306396,
      "learning_rate": 4.956300547873728e-05,
      "loss": 0.1483,
      "step": 6700
    },
    {
      "epoch": 0.8805113488129402,
      "grad_norm": 0.052279215306043625,
      "learning_rate": 4.9559744325593535e-05,
      "loss": 0.2119,
      "step": 6750
    },
    {
      "epoch": 0.8870336551004435,
      "grad_norm": 1.0971661806106567,
      "learning_rate": 4.955648317244978e-05,
      "loss": 0.1446,
      "step": 6800
    },
    {
      "epoch": 0.8935559613879468,
      "grad_norm": 14.05420970916748,
      "learning_rate": 4.955322201930603e-05,
      "loss": 0.1309,
      "step": 6850
    },
    {
      "epoch": 0.9000782676754501,
      "grad_norm": 25.32265281677246,
      "learning_rate": 4.9549960866162274e-05,
      "loss": 0.1789,
      "step": 6900
    },
    {
      "epoch": 0.9066005739629533,
      "grad_norm": 5.6210713386535645,
      "learning_rate": 4.954669971301853e-05,
      "loss": 0.2025,
      "step": 6950
    },
    {
      "epoch": 0.9131228802504565,
      "grad_norm": 11.843395233154297,
      "learning_rate": 4.954343855987477e-05,
      "loss": 0.1608,
      "step": 7000
    },
    {
      "epoch": 0.9196451865379598,
      "grad_norm": 0.927522599697113,
      "learning_rate": 4.954017740673102e-05,
      "loss": 0.1525,
      "step": 7050
    },
    {
      "epoch": 0.9261674928254631,
      "grad_norm": 0.10619712620973587,
      "learning_rate": 4.953691625358727e-05,
      "loss": 0.1729,
      "step": 7100
    },
    {
      "epoch": 0.9326897991129663,
      "grad_norm": 13.714495658874512,
      "learning_rate": 4.953365510044352e-05,
      "loss": 0.176,
      "step": 7150
    },
    {
      "epoch": 0.9392121054004696,
      "grad_norm": 8.745734214782715,
      "learning_rate": 4.953039394729977e-05,
      "loss": 0.1485,
      "step": 7200
    },
    {
      "epoch": 0.9457344116879729,
      "grad_norm": 0.060390833765268326,
      "learning_rate": 4.952713279415602e-05,
      "loss": 0.088,
      "step": 7250
    },
    {
      "epoch": 0.9522567179754762,
      "grad_norm": 0.8619897961616516,
      "learning_rate": 4.9523871641012264e-05,
      "loss": 0.1341,
      "step": 7300
    },
    {
      "epoch": 0.9587790242629793,
      "grad_norm": 0.041929200291633606,
      "learning_rate": 4.952061048786851e-05,
      "loss": 0.1318,
      "step": 7350
    },
    {
      "epoch": 0.9653013305504826,
      "grad_norm": 17.326454162597656,
      "learning_rate": 4.951734933472476e-05,
      "loss": 0.183,
      "step": 7400
    },
    {
      "epoch": 0.9718236368379859,
      "grad_norm": 1.1549875736236572,
      "learning_rate": 4.951408818158101e-05,
      "loss": 0.1098,
      "step": 7450
    },
    {
      "epoch": 0.9783459431254892,
      "grad_norm": 0.32235777378082275,
      "learning_rate": 4.9510827028437255e-05,
      "loss": 0.1725,
      "step": 7500
    },
    {
      "epoch": 0.9848682494129924,
      "grad_norm": 3.333839178085327,
      "learning_rate": 4.95075658752935e-05,
      "loss": 0.1293,
      "step": 7550
    },
    {
      "epoch": 0.9913905557004957,
      "grad_norm": 17.94868278503418,
      "learning_rate": 4.9504304722149754e-05,
      "loss": 0.2111,
      "step": 7600
    },
    {
      "epoch": 0.997912861987999,
      "grad_norm": 9.05250072479248,
      "learning_rate": 4.9501043569006e-05,
      "loss": 0.1107,
      "step": 7650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9523871641012261,
      "eval_f1": 0.9526895657809462,
      "eval_loss": 0.1778559684753418,
      "eval_precision": 0.9469208966761145,
      "eval_recall": 0.9585289514866979,
      "eval_runtime": 27.0655,
      "eval_samples_per_second": 566.478,
      "eval_steps_per_second": 70.828,
      "step": 7666
    },
    {
      "epoch": 1.0044351682755022,
      "grad_norm": 0.03551388159394264,
      "learning_rate": 4.949778241586225e-05,
      "loss": 0.1367,
      "step": 7700
    },
    {
      "epoch": 1.0109574745630054,
      "grad_norm": 0.05154154822230339,
      "learning_rate": 4.94945212627185e-05,
      "loss": 0.172,
      "step": 7750
    },
    {
      "epoch": 1.0174797808505087,
      "grad_norm": 2.4729697704315186,
      "learning_rate": 4.949126010957475e-05,
      "loss": 0.1328,
      "step": 7800
    },
    {
      "epoch": 1.024002087138012,
      "grad_norm": 0.05103343352675438,
      "learning_rate": 4.9487998956431e-05,
      "loss": 0.1234,
      "step": 7850
    },
    {
      "epoch": 1.0305243934255153,
      "grad_norm": 0.03262234851717949,
      "learning_rate": 4.9484737803287245e-05,
      "loss": 0.2097,
      "step": 7900
    },
    {
      "epoch": 1.0370466997130185,
      "grad_norm": 3.0729353427886963,
      "learning_rate": 4.948147665014349e-05,
      "loss": 0.1512,
      "step": 7950
    },
    {
      "epoch": 1.0435690060005218,
      "grad_norm": 0.10497350245714188,
      "learning_rate": 4.9478215496999744e-05,
      "loss": 0.2217,
      "step": 8000
    },
    {
      "epoch": 1.050091312288025,
      "grad_norm": 0.2120985984802246,
      "learning_rate": 4.947495434385599e-05,
      "loss": 0.204,
      "step": 8050
    },
    {
      "epoch": 1.0566136185755284,
      "grad_norm": 11.238527297973633,
      "learning_rate": 4.9471693190712236e-05,
      "loss": 0.1424,
      "step": 8100
    },
    {
      "epoch": 1.0631359248630317,
      "grad_norm": 0.18392601609230042,
      "learning_rate": 4.946843203756848e-05,
      "loss": 0.219,
      "step": 8150
    },
    {
      "epoch": 1.069658231150535,
      "grad_norm": 0.20609016716480255,
      "learning_rate": 4.9465170884424736e-05,
      "loss": 0.1333,
      "step": 8200
    },
    {
      "epoch": 1.076180537438038,
      "grad_norm": 0.22115342319011688,
      "learning_rate": 4.946190973128098e-05,
      "loss": 0.1188,
      "step": 8250
    },
    {
      "epoch": 1.0827028437255413,
      "grad_norm": 0.096296027302742,
      "learning_rate": 4.9458648578137235e-05,
      "loss": 0.1451,
      "step": 8300
    },
    {
      "epoch": 1.0892251500130445,
      "grad_norm": 0.12767371535301208,
      "learning_rate": 4.945538742499348e-05,
      "loss": 0.1604,
      "step": 8350
    },
    {
      "epoch": 1.0957474563005478,
      "grad_norm": 1.4423785209655762,
      "learning_rate": 4.945212627184973e-05,
      "loss": 0.2192,
      "step": 8400
    },
    {
      "epoch": 1.102269762588051,
      "grad_norm": 7.713229179382324,
      "learning_rate": 4.944886511870598e-05,
      "loss": 0.138,
      "step": 8450
    },
    {
      "epoch": 1.1087920688755544,
      "grad_norm": 0.050974588841199875,
      "learning_rate": 4.9445603965562226e-05,
      "loss": 0.1766,
      "step": 8500
    },
    {
      "epoch": 1.1153143751630576,
      "grad_norm": 0.2303534746170044,
      "learning_rate": 4.944234281241847e-05,
      "loss": 0.1306,
      "step": 8550
    },
    {
      "epoch": 1.121836681450561,
      "grad_norm": 12.614108085632324,
      "learning_rate": 4.943908165927472e-05,
      "loss": 0.1375,
      "step": 8600
    },
    {
      "epoch": 1.1283589877380642,
      "grad_norm": 2.953073501586914,
      "learning_rate": 4.943582050613097e-05,
      "loss": 0.1744,
      "step": 8650
    },
    {
      "epoch": 1.1348812940255675,
      "grad_norm": 0.06829036772251129,
      "learning_rate": 4.943255935298722e-05,
      "loss": 0.1506,
      "step": 8700
    },
    {
      "epoch": 1.1414036003130708,
      "grad_norm": 16.068815231323242,
      "learning_rate": 4.9429298199843464e-05,
      "loss": 0.1485,
      "step": 8750
    },
    {
      "epoch": 1.147925906600574,
      "grad_norm": 17.06357192993164,
      "learning_rate": 4.942603704669972e-05,
      "loss": 0.1881,
      "step": 8800
    },
    {
      "epoch": 1.1544482128880773,
      "grad_norm": 3.543102979660034,
      "learning_rate": 4.942277589355596e-05,
      "loss": 0.1607,
      "step": 8850
    },
    {
      "epoch": 1.1609705191755806,
      "grad_norm": 0.5670142769813538,
      "learning_rate": 4.941951474041221e-05,
      "loss": 0.1729,
      "step": 8900
    },
    {
      "epoch": 1.1674928254630839,
      "grad_norm": 0.06410808861255646,
      "learning_rate": 4.941625358726846e-05,
      "loss": 0.1043,
      "step": 8950
    },
    {
      "epoch": 1.174015131750587,
      "grad_norm": 4.788722991943359,
      "learning_rate": 4.941299243412471e-05,
      "loss": 0.1198,
      "step": 9000
    },
    {
      "epoch": 1.1805374380380902,
      "grad_norm": 0.23664943873882294,
      "learning_rate": 4.940973128098096e-05,
      "loss": 0.172,
      "step": 9050
    },
    {
      "epoch": 1.1870597443255935,
      "grad_norm": 0.0786704421043396,
      "learning_rate": 4.940647012783721e-05,
      "loss": 0.1152,
      "step": 9100
    },
    {
      "epoch": 1.1935820506130967,
      "grad_norm": 2.554100751876831,
      "learning_rate": 4.9403208974693454e-05,
      "loss": 0.1892,
      "step": 9150
    },
    {
      "epoch": 1.2001043569006,
      "grad_norm": 1.8458985090255737,
      "learning_rate": 4.93999478215497e-05,
      "loss": 0.1499,
      "step": 9200
    },
    {
      "epoch": 1.2066266631881033,
      "grad_norm": 0.03828823193907738,
      "learning_rate": 4.939668666840595e-05,
      "loss": 0.143,
      "step": 9250
    },
    {
      "epoch": 1.2131489694756066,
      "grad_norm": 1.0462377071380615,
      "learning_rate": 4.93934255152622e-05,
      "loss": 0.1334,
      "step": 9300
    },
    {
      "epoch": 1.2196712757631099,
      "grad_norm": 0.8770698308944702,
      "learning_rate": 4.9390164362118445e-05,
      "loss": 0.1792,
      "step": 9350
    },
    {
      "epoch": 1.2261935820506131,
      "grad_norm": 5.220945358276367,
      "learning_rate": 4.938690320897469e-05,
      "loss": 0.1588,
      "step": 9400
    },
    {
      "epoch": 1.2327158883381164,
      "grad_norm": 10.630529403686523,
      "learning_rate": 4.9383642055830944e-05,
      "loss": 0.1989,
      "step": 9450
    },
    {
      "epoch": 1.2392381946256197,
      "grad_norm": 1.8887852430343628,
      "learning_rate": 4.938038090268719e-05,
      "loss": 0.1053,
      "step": 9500
    },
    {
      "epoch": 1.245760500913123,
      "grad_norm": 27.574539184570312,
      "learning_rate": 4.9377119749543443e-05,
      "loss": 0.1442,
      "step": 9550
    },
    {
      "epoch": 1.252282807200626,
      "grad_norm": 0.7531234622001648,
      "learning_rate": 4.937385859639969e-05,
      "loss": 0.1549,
      "step": 9600
    },
    {
      "epoch": 1.2588051134881293,
      "grad_norm": 6.054254055023193,
      "learning_rate": 4.937059744325594e-05,
      "loss": 0.1051,
      "step": 9650
    },
    {
      "epoch": 1.2653274197756326,
      "grad_norm": 0.3611387014389038,
      "learning_rate": 4.936733629011219e-05,
      "loss": 0.1167,
      "step": 9700
    },
    {
      "epoch": 1.2718497260631358,
      "grad_norm": 0.33159664273262024,
      "learning_rate": 4.9364075136968435e-05,
      "loss": 0.1594,
      "step": 9750
    },
    {
      "epoch": 1.2783720323506391,
      "grad_norm": 0.044040266424417496,
      "learning_rate": 4.936081398382468e-05,
      "loss": 0.1376,
      "step": 9800
    },
    {
      "epoch": 1.2848943386381424,
      "grad_norm": 1.0202971696853638,
      "learning_rate": 4.9357552830680934e-05,
      "loss": 0.1127,
      "step": 9850
    },
    {
      "epoch": 1.2914166449256457,
      "grad_norm": 6.6856794357299805,
      "learning_rate": 4.935429167753718e-05,
      "loss": 0.0877,
      "step": 9900
    },
    {
      "epoch": 1.297938951213149,
      "grad_norm": 0.5554817914962769,
      "learning_rate": 4.9351030524393426e-05,
      "loss": 0.0944,
      "step": 9950
    },
    {
      "epoch": 1.3044612575006522,
      "grad_norm": 6.700798034667969,
      "learning_rate": 4.934776937124967e-05,
      "loss": 0.0898,
      "step": 10000
    },
    {
      "epoch": 1.3109835637881555,
      "grad_norm": 0.03663022071123123,
      "learning_rate": 4.9344508218105926e-05,
      "loss": 0.2222,
      "step": 10050
    },
    {
      "epoch": 1.3175058700756588,
      "grad_norm": 12.831268310546875,
      "learning_rate": 4.934124706496217e-05,
      "loss": 0.1385,
      "step": 10100
    },
    {
      "epoch": 1.324028176363162,
      "grad_norm": 0.08095245063304901,
      "learning_rate": 4.9337985911818425e-05,
      "loss": 0.1956,
      "step": 10150
    },
    {
      "epoch": 1.3305504826506653,
      "grad_norm": 9.787972450256348,
      "learning_rate": 4.933472475867467e-05,
      "loss": 0.1788,
      "step": 10200
    },
    {
      "epoch": 1.3370727889381686,
      "grad_norm": 0.0555025078356266,
      "learning_rate": 4.933146360553092e-05,
      "loss": 0.1725,
      "step": 10250
    },
    {
      "epoch": 1.3435950952256719,
      "grad_norm": 0.5193374752998352,
      "learning_rate": 4.932820245238717e-05,
      "loss": 0.2184,
      "step": 10300
    },
    {
      "epoch": 1.3501174015131752,
      "grad_norm": 0.650844156742096,
      "learning_rate": 4.9324941299243416e-05,
      "loss": 0.1729,
      "step": 10350
    },
    {
      "epoch": 1.3566397078006784,
      "grad_norm": 8.514175415039062,
      "learning_rate": 4.932168014609966e-05,
      "loss": 0.1471,
      "step": 10400
    },
    {
      "epoch": 1.3631620140881817,
      "grad_norm": 9.499547958374023,
      "learning_rate": 4.931841899295591e-05,
      "loss": 0.1933,
      "step": 10450
    },
    {
      "epoch": 1.3696843203756848,
      "grad_norm": 0.5520533919334412,
      "learning_rate": 4.931515783981216e-05,
      "loss": 0.0594,
      "step": 10500
    },
    {
      "epoch": 1.376206626663188,
      "grad_norm": 3.2038681507110596,
      "learning_rate": 4.931189668666841e-05,
      "loss": 0.1684,
      "step": 10550
    },
    {
      "epoch": 1.3827289329506913,
      "grad_norm": 5.739981651306152,
      "learning_rate": 4.9308635533524654e-05,
      "loss": 0.1545,
      "step": 10600
    },
    {
      "epoch": 1.3892512392381946,
      "grad_norm": 4.23087739944458,
      "learning_rate": 4.93053743803809e-05,
      "loss": 0.1735,
      "step": 10650
    },
    {
      "epoch": 1.3957735455256979,
      "grad_norm": 12.484185218811035,
      "learning_rate": 4.930211322723715e-05,
      "loss": 0.1291,
      "step": 10700
    },
    {
      "epoch": 1.4022958518132012,
      "grad_norm": 0.16876135766506195,
      "learning_rate": 4.9298852074093406e-05,
      "loss": 0.1601,
      "step": 10750
    },
    {
      "epoch": 1.4088181581007044,
      "grad_norm": 4.375044345855713,
      "learning_rate": 4.929559092094965e-05,
      "loss": 0.1378,
      "step": 10800
    },
    {
      "epoch": 1.4153404643882077,
      "grad_norm": 0.027747513726353645,
      "learning_rate": 4.92923297678059e-05,
      "loss": 0.1592,
      "step": 10850
    },
    {
      "epoch": 1.421862770675711,
      "grad_norm": 6.763843059539795,
      "learning_rate": 4.928906861466215e-05,
      "loss": 0.1428,
      "step": 10900
    },
    {
      "epoch": 1.4283850769632143,
      "grad_norm": 1.1138883829116821,
      "learning_rate": 4.92858074615184e-05,
      "loss": 0.0977,
      "step": 10950
    },
    {
      "epoch": 1.4349073832507173,
      "grad_norm": 3.8679020404815674,
      "learning_rate": 4.9282546308374644e-05,
      "loss": 0.2084,
      "step": 11000
    },
    {
      "epoch": 1.4414296895382206,
      "grad_norm": 0.1908465176820755,
      "learning_rate": 4.927928515523089e-05,
      "loss": 0.2161,
      "step": 11050
    },
    {
      "epoch": 1.4479519958257239,
      "grad_norm": 9.453307151794434,
      "learning_rate": 4.927602400208714e-05,
      "loss": 0.1476,
      "step": 11100
    },
    {
      "epoch": 1.4544743021132271,
      "grad_norm": 0.32214465737342834,
      "learning_rate": 4.927276284894339e-05,
      "loss": 0.1234,
      "step": 11150
    },
    {
      "epoch": 1.4609966084007304,
      "grad_norm": 5.257240295410156,
      "learning_rate": 4.9269501695799635e-05,
      "loss": 0.1178,
      "step": 11200
    },
    {
      "epoch": 1.4675189146882337,
      "grad_norm": 17.90579605102539,
      "learning_rate": 4.926624054265588e-05,
      "loss": 0.1205,
      "step": 11250
    },
    {
      "epoch": 1.474041220975737,
      "grad_norm": 10.525940895080566,
      "learning_rate": 4.9262979389512134e-05,
      "loss": 0.1616,
      "step": 11300
    },
    {
      "epoch": 1.4805635272632403,
      "grad_norm": 3.5768706798553467,
      "learning_rate": 4.925971823636838e-05,
      "loss": 0.2332,
      "step": 11350
    },
    {
      "epoch": 1.4870858335507435,
      "grad_norm": 5.31540060043335,
      "learning_rate": 4.9256457083224634e-05,
      "loss": 0.19,
      "step": 11400
    },
    {
      "epoch": 1.4936081398382468,
      "grad_norm": 7.143049240112305,
      "learning_rate": 4.925319593008088e-05,
      "loss": 0.1901,
      "step": 11450
    },
    {
      "epoch": 1.50013044612575,
      "grad_norm": 0.05896890535950661,
      "learning_rate": 4.9249934776937126e-05,
      "loss": 0.0976,
      "step": 11500
    },
    {
      "epoch": 1.5066527524132534,
      "grad_norm": 2.3611114025115967,
      "learning_rate": 4.924667362379338e-05,
      "loss": 0.1245,
      "step": 11550
    },
    {
      "epoch": 1.5131750587007566,
      "grad_norm": 0.21970327198505402,
      "learning_rate": 4.9243412470649625e-05,
      "loss": 0.1715,
      "step": 11600
    },
    {
      "epoch": 1.51969736498826,
      "grad_norm": 14.420392036437988,
      "learning_rate": 4.924015131750587e-05,
      "loss": 0.1657,
      "step": 11650
    },
    {
      "epoch": 1.5262196712757632,
      "grad_norm": 0.02176167443394661,
      "learning_rate": 4.923689016436212e-05,
      "loss": 0.1417,
      "step": 11700
    },
    {
      "epoch": 1.5327419775632665,
      "grad_norm": 7.6837615966796875,
      "learning_rate": 4.923362901121837e-05,
      "loss": 0.1552,
      "step": 11750
    },
    {
      "epoch": 1.5392642838507697,
      "grad_norm": 0.026841865852475166,
      "learning_rate": 4.9230367858074617e-05,
      "loss": 0.1656,
      "step": 11800
    },
    {
      "epoch": 1.545786590138273,
      "grad_norm": 0.5209607481956482,
      "learning_rate": 4.922710670493086e-05,
      "loss": 0.1304,
      "step": 11850
    },
    {
      "epoch": 1.5523088964257763,
      "grad_norm": 16.344083786010742,
      "learning_rate": 4.922384555178711e-05,
      "loss": 0.1655,
      "step": 11900
    },
    {
      "epoch": 1.5588312027132796,
      "grad_norm": 0.059051062911748886,
      "learning_rate": 4.922058439864336e-05,
      "loss": 0.1829,
      "step": 11950
    },
    {
      "epoch": 1.5653535090007826,
      "grad_norm": 0.3367200791835785,
      "learning_rate": 4.9217323245499615e-05,
      "loss": 0.1626,
      "step": 12000
    },
    {
      "epoch": 1.571875815288286,
      "grad_norm": 0.7025331258773804,
      "learning_rate": 4.921406209235586e-05,
      "loss": 0.1276,
      "step": 12050
    },
    {
      "epoch": 1.5783981215757892,
      "grad_norm": 3.7258567810058594,
      "learning_rate": 4.921080093921211e-05,
      "loss": 0.1103,
      "step": 12100
    },
    {
      "epoch": 1.5849204278632925,
      "grad_norm": 0.032037246972322464,
      "learning_rate": 4.920753978606836e-05,
      "loss": 0.159,
      "step": 12150
    },
    {
      "epoch": 1.5914427341507957,
      "grad_norm": 0.0913233682513237,
      "learning_rate": 4.9204278632924606e-05,
      "loss": 0.153,
      "step": 12200
    },
    {
      "epoch": 1.597965040438299,
      "grad_norm": 0.030514800921082497,
      "learning_rate": 4.920101747978085e-05,
      "loss": 0.1329,
      "step": 12250
    },
    {
      "epoch": 1.6044873467258023,
      "grad_norm": 8.160726547241211,
      "learning_rate": 4.91977563266371e-05,
      "loss": 0.154,
      "step": 12300
    },
    {
      "epoch": 1.6110096530133053,
      "grad_norm": 12.5989351272583,
      "learning_rate": 4.919449517349335e-05,
      "loss": 0.1014,
      "step": 12350
    },
    {
      "epoch": 1.6175319593008086,
      "grad_norm": 14.642120361328125,
      "learning_rate": 4.91912340203496e-05,
      "loss": 0.1252,
      "step": 12400
    },
    {
      "epoch": 1.624054265588312,
      "grad_norm": 2.270275831222534,
      "learning_rate": 4.9187972867205844e-05,
      "loss": 0.2078,
      "step": 12450
    },
    {
      "epoch": 1.6305765718758152,
      "grad_norm": 0.05828874558210373,
      "learning_rate": 4.918471171406209e-05,
      "loss": 0.192,
      "step": 12500
    },
    {
      "epoch": 1.6370988781633184,
      "grad_norm": 4.360011577606201,
      "learning_rate": 4.918145056091834e-05,
      "loss": 0.0545,
      "step": 12550
    },
    {
      "epoch": 1.6436211844508217,
      "grad_norm": 0.07751137763261795,
      "learning_rate": 4.9178189407774596e-05,
      "loss": 0.1565,
      "step": 12600
    },
    {
      "epoch": 1.650143490738325,
      "grad_norm": 0.04143630713224411,
      "learning_rate": 4.917492825463084e-05,
      "loss": 0.1097,
      "step": 12650
    },
    {
      "epoch": 1.6566657970258283,
      "grad_norm": 9.329910278320312,
      "learning_rate": 4.917166710148709e-05,
      "loss": 0.1607,
      "step": 12700
    },
    {
      "epoch": 1.6631881033133316,
      "grad_norm": 11.80648136138916,
      "learning_rate": 4.9168405948343335e-05,
      "loss": 0.1551,
      "step": 12750
    },
    {
      "epoch": 1.6697104096008348,
      "grad_norm": 7.217404842376709,
      "learning_rate": 4.916514479519959e-05,
      "loss": 0.1279,
      "step": 12800
    },
    {
      "epoch": 1.676232715888338,
      "grad_norm": 4.969616889953613,
      "learning_rate": 4.9161883642055834e-05,
      "loss": 0.1339,
      "step": 12850
    },
    {
      "epoch": 1.6827550221758414,
      "grad_norm": 0.7627280354499817,
      "learning_rate": 4.915862248891208e-05,
      "loss": 0.1629,
      "step": 12900
    },
    {
      "epoch": 1.6892773284633447,
      "grad_norm": 9.416893005371094,
      "learning_rate": 4.915536133576833e-05,
      "loss": 0.1256,
      "step": 12950
    },
    {
      "epoch": 1.695799634750848,
      "grad_norm": 1.110310673713684,
      "learning_rate": 4.915210018262458e-05,
      "loss": 0.1161,
      "step": 13000
    },
    {
      "epoch": 1.7023219410383512,
      "grad_norm": 5.166549205780029,
      "learning_rate": 4.9148839029480825e-05,
      "loss": 0.1803,
      "step": 13050
    },
    {
      "epoch": 1.7088442473258545,
      "grad_norm": 2.637517213821411,
      "learning_rate": 4.914557787633707e-05,
      "loss": 0.1299,
      "step": 13100
    },
    {
      "epoch": 1.7153665536133578,
      "grad_norm": 0.28324782848358154,
      "learning_rate": 4.9142316723193324e-05,
      "loss": 0.1516,
      "step": 13150
    },
    {
      "epoch": 1.721888859900861,
      "grad_norm": 0.10424856096506119,
      "learning_rate": 4.913905557004957e-05,
      "loss": 0.1214,
      "step": 13200
    },
    {
      "epoch": 1.7284111661883643,
      "grad_norm": 1.339049220085144,
      "learning_rate": 4.9135794416905824e-05,
      "loss": 0.1382,
      "step": 13250
    },
    {
      "epoch": 1.7349334724758676,
      "grad_norm": 2.28879714012146,
      "learning_rate": 4.913253326376207e-05,
      "loss": 0.1298,
      "step": 13300
    },
    {
      "epoch": 1.7414557787633709,
      "grad_norm": 0.2609920799732208,
      "learning_rate": 4.9129272110618316e-05,
      "loss": 0.1222,
      "step": 13350
    },
    {
      "epoch": 1.7479780850508742,
      "grad_norm": 17.60823631286621,
      "learning_rate": 4.912601095747457e-05,
      "loss": 0.1503,
      "step": 13400
    },
    {
      "epoch": 1.7545003913383772,
      "grad_norm": 0.21466821432113647,
      "learning_rate": 4.9122749804330815e-05,
      "loss": 0.1147,
      "step": 13450
    },
    {
      "epoch": 1.7610226976258805,
      "grad_norm": 0.03275853395462036,
      "learning_rate": 4.911948865118706e-05,
      "loss": 0.1486,
      "step": 13500
    },
    {
      "epoch": 1.7675450039133838,
      "grad_norm": 0.0691835805773735,
      "learning_rate": 4.911622749804331e-05,
      "loss": 0.057,
      "step": 13550
    },
    {
      "epoch": 1.774067310200887,
      "grad_norm": 11.31114673614502,
      "learning_rate": 4.911296634489956e-05,
      "loss": 0.1295,
      "step": 13600
    },
    {
      "epoch": 1.7805896164883903,
      "grad_norm": 0.07491961121559143,
      "learning_rate": 4.910970519175581e-05,
      "loss": 0.1735,
      "step": 13650
    },
    {
      "epoch": 1.7871119227758936,
      "grad_norm": 0.695263147354126,
      "learning_rate": 4.910644403861205e-05,
      "loss": 0.1092,
      "step": 13700
    },
    {
      "epoch": 1.7936342290633969,
      "grad_norm": 0.02593519166111946,
      "learning_rate": 4.91031828854683e-05,
      "loss": 0.0873,
      "step": 13750
    },
    {
      "epoch": 1.8001565353509,
      "grad_norm": 1.8789008855819702,
      "learning_rate": 4.909992173232455e-05,
      "loss": 0.1082,
      "step": 13800
    },
    {
      "epoch": 1.8066788416384032,
      "grad_norm": 0.6101415157318115,
      "learning_rate": 4.9096660579180805e-05,
      "loss": 0.1118,
      "step": 13850
    },
    {
      "epoch": 1.8132011479259065,
      "grad_norm": 0.9265682697296143,
      "learning_rate": 4.909339942603705e-05,
      "loss": 0.1504,
      "step": 13900
    },
    {
      "epoch": 1.8197234542134098,
      "grad_norm": 9.630681037902832,
      "learning_rate": 4.90901382728933e-05,
      "loss": 0.0853,
      "step": 13950
    },
    {
      "epoch": 1.826245760500913,
      "grad_norm": 0.07625571638345718,
      "learning_rate": 4.908687711974955e-05,
      "loss": 0.1171,
      "step": 14000
    },
    {
      "epoch": 1.8327680667884163,
      "grad_norm": 6.168160915374756,
      "learning_rate": 4.9083615966605796e-05,
      "loss": 0.1373,
      "step": 14050
    },
    {
      "epoch": 1.8392903730759196,
      "grad_norm": 0.3574906885623932,
      "learning_rate": 4.908035481346204e-05,
      "loss": 0.0961,
      "step": 14100
    },
    {
      "epoch": 1.8458126793634229,
      "grad_norm": 0.10006733983755112,
      "learning_rate": 4.907709366031829e-05,
      "loss": 0.1447,
      "step": 14150
    },
    {
      "epoch": 1.8523349856509261,
      "grad_norm": 0.021180465817451477,
      "learning_rate": 4.907383250717454e-05,
      "loss": 0.114,
      "step": 14200
    },
    {
      "epoch": 1.8588572919384294,
      "grad_norm": 4.933926582336426,
      "learning_rate": 4.907057135403079e-05,
      "loss": 0.1324,
      "step": 14250
    },
    {
      "epoch": 1.8653795982259327,
      "grad_norm": 5.8449883460998535,
      "learning_rate": 4.9067310200887034e-05,
      "loss": 0.1584,
      "step": 14300
    },
    {
      "epoch": 1.871901904513436,
      "grad_norm": 0.020155102014541626,
      "learning_rate": 4.906404904774328e-05,
      "loss": 0.0961,
      "step": 14350
    },
    {
      "epoch": 1.8784242108009392,
      "grad_norm": 6.727707386016846,
      "learning_rate": 4.906078789459953e-05,
      "loss": 0.1523,
      "step": 14400
    },
    {
      "epoch": 1.8849465170884425,
      "grad_norm": 10.199116706848145,
      "learning_rate": 4.9057526741455786e-05,
      "loss": 0.1217,
      "step": 14450
    },
    {
      "epoch": 1.8914688233759458,
      "grad_norm": 0.08084617555141449,
      "learning_rate": 4.905426558831203e-05,
      "loss": 0.1729,
      "step": 14500
    },
    {
      "epoch": 1.897991129663449,
      "grad_norm": 0.21013082563877106,
      "learning_rate": 4.905100443516828e-05,
      "loss": 0.2045,
      "step": 14550
    },
    {
      "epoch": 1.9045134359509523,
      "grad_norm": 0.32439401745796204,
      "learning_rate": 4.9047743282024525e-05,
      "loss": 0.1182,
      "step": 14600
    },
    {
      "epoch": 1.9110357422384556,
      "grad_norm": 1.5142894983291626,
      "learning_rate": 4.904448212888078e-05,
      "loss": 0.0837,
      "step": 14650
    },
    {
      "epoch": 1.917558048525959,
      "grad_norm": 0.016823986545205116,
      "learning_rate": 4.9041220975737024e-05,
      "loss": 0.1149,
      "step": 14700
    },
    {
      "epoch": 1.9240803548134622,
      "grad_norm": 8.780552864074707,
      "learning_rate": 4.903795982259327e-05,
      "loss": 0.1083,
      "step": 14750
    },
    {
      "epoch": 1.9306026611009655,
      "grad_norm": 12.227291107177734,
      "learning_rate": 4.9034698669449516e-05,
      "loss": 0.18,
      "step": 14800
    },
    {
      "epoch": 1.9371249673884685,
      "grad_norm": 14.0917329788208,
      "learning_rate": 4.903143751630577e-05,
      "loss": 0.1782,
      "step": 14850
    },
    {
      "epoch": 1.9436472736759718,
      "grad_norm": 0.40433168411254883,
      "learning_rate": 4.9028176363162015e-05,
      "loss": 0.1558,
      "step": 14900
    },
    {
      "epoch": 1.950169579963475,
      "grad_norm": 13.509841918945312,
      "learning_rate": 4.902491521001826e-05,
      "loss": 0.0977,
      "step": 14950
    },
    {
      "epoch": 1.9566918862509783,
      "grad_norm": 0.3070526123046875,
      "learning_rate": 4.902165405687451e-05,
      "loss": 0.1224,
      "step": 15000
    },
    {
      "epoch": 1.9632141925384816,
      "grad_norm": 0.23205822706222534,
      "learning_rate": 4.901839290373077e-05,
      "loss": 0.1178,
      "step": 15050
    },
    {
      "epoch": 1.969736498825985,
      "grad_norm": 7.074039459228516,
      "learning_rate": 4.9015131750587014e-05,
      "loss": 0.1184,
      "step": 15100
    },
    {
      "epoch": 1.9762588051134882,
      "grad_norm": 0.24846813082695007,
      "learning_rate": 4.901187059744326e-05,
      "loss": 0.1241,
      "step": 15150
    },
    {
      "epoch": 1.9827811114009912,
      "grad_norm": 0.016353832557797432,
      "learning_rate": 4.9008609444299506e-05,
      "loss": 0.1699,
      "step": 15200
    },
    {
      "epoch": 1.9893034176884945,
      "grad_norm": 0.8764422535896301,
      "learning_rate": 4.900534829115576e-05,
      "loss": 0.1189,
      "step": 15250
    },
    {
      "epoch": 1.9958257239759978,
      "grad_norm": 1.4345749616622925,
      "learning_rate": 4.9002087138012005e-05,
      "loss": 0.1215,
      "step": 15300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9557787633707279,
      "eval_f1": 0.9551231135822081,
      "eval_loss": 0.15446414053440094,
      "eval_precision": 0.969758064516129,
      "eval_recall": 0.940923317683881,
      "eval_runtime": 27.0885,
      "eval_samples_per_second": 565.997,
      "eval_steps_per_second": 70.768,
      "step": 15332
    },
    {
      "epoch": 2.002348030263501,
      "grad_norm": 0.5165838599205017,
      "learning_rate": 4.899882598486825e-05,
      "loss": 0.0958,
      "step": 15350
    },
    {
      "epoch": 2.0088703365510043,
      "grad_norm": 2.8934473991394043,
      "learning_rate": 4.89955648317245e-05,
      "loss": 0.1072,
      "step": 15400
    },
    {
      "epoch": 2.0153926428385076,
      "grad_norm": 2.7488982677459717,
      "learning_rate": 4.899230367858075e-05,
      "loss": 0.1347,
      "step": 15450
    },
    {
      "epoch": 2.021914949126011,
      "grad_norm": 0.05036918446421623,
      "learning_rate": 4.8989042525437e-05,
      "loss": 0.1603,
      "step": 15500
    },
    {
      "epoch": 2.028437255413514,
      "grad_norm": 0.34591156244277954,
      "learning_rate": 4.898578137229324e-05,
      "loss": 0.1471,
      "step": 15550
    },
    {
      "epoch": 2.0349595617010174,
      "grad_norm": 0.8166012167930603,
      "learning_rate": 4.898252021914949e-05,
      "loss": 0.0724,
      "step": 15600
    },
    {
      "epoch": 2.0414818679885207,
      "grad_norm": 2.007643699645996,
      "learning_rate": 4.897925906600574e-05,
      "loss": 0.1291,
      "step": 15650
    },
    {
      "epoch": 2.048004174276024,
      "grad_norm": 0.11312483996152878,
      "learning_rate": 4.8975997912861995e-05,
      "loss": 0.101,
      "step": 15700
    },
    {
      "epoch": 2.0545264805635273,
      "grad_norm": 2.635119915008545,
      "learning_rate": 4.897273675971824e-05,
      "loss": 0.1444,
      "step": 15750
    },
    {
      "epoch": 2.0610487868510305,
      "grad_norm": 0.610041618347168,
      "learning_rate": 4.896947560657449e-05,
      "loss": 0.1301,
      "step": 15800
    },
    {
      "epoch": 2.067571093138534,
      "grad_norm": 0.031040433794260025,
      "learning_rate": 4.8966214453430734e-05,
      "loss": 0.1285,
      "step": 15850
    },
    {
      "epoch": 2.074093399426037,
      "grad_norm": 6.2446770668029785,
      "learning_rate": 4.8962953300286986e-05,
      "loss": 0.1555,
      "step": 15900
    },
    {
      "epoch": 2.0806157057135404,
      "grad_norm": 0.1297210156917572,
      "learning_rate": 4.895969214714323e-05,
      "loss": 0.1339,
      "step": 15950
    },
    {
      "epoch": 2.0871380120010437,
      "grad_norm": 0.3456422686576843,
      "learning_rate": 4.895643099399948e-05,
      "loss": 0.1396,
      "step": 16000
    },
    {
      "epoch": 2.093660318288547,
      "grad_norm": 0.07041338831186295,
      "learning_rate": 4.8953169840855725e-05,
      "loss": 0.0941,
      "step": 16050
    },
    {
      "epoch": 2.10018262457605,
      "grad_norm": 0.02119642309844494,
      "learning_rate": 4.894990868771198e-05,
      "loss": 0.1575,
      "step": 16100
    },
    {
      "epoch": 2.1067049308635535,
      "grad_norm": 0.1325700432062149,
      "learning_rate": 4.8946647534568224e-05,
      "loss": 0.1779,
      "step": 16150
    },
    {
      "epoch": 2.1132272371510568,
      "grad_norm": 0.03371185064315796,
      "learning_rate": 4.894338638142447e-05,
      "loss": 0.1491,
      "step": 16200
    },
    {
      "epoch": 2.11974954343856,
      "grad_norm": 10.011978149414062,
      "learning_rate": 4.8940125228280717e-05,
      "loss": 0.1219,
      "step": 16250
    },
    {
      "epoch": 2.1262718497260633,
      "grad_norm": 4.467887878417969,
      "learning_rate": 4.8936864075136976e-05,
      "loss": 0.1223,
      "step": 16300
    },
    {
      "epoch": 2.1327941560135666,
      "grad_norm": 4.631340503692627,
      "learning_rate": 4.893360292199322e-05,
      "loss": 0.1284,
      "step": 16350
    },
    {
      "epoch": 2.13931646230107,
      "grad_norm": 0.032759130001068115,
      "learning_rate": 4.893034176884947e-05,
      "loss": 0.0958,
      "step": 16400
    },
    {
      "epoch": 2.1458387685885727,
      "grad_norm": 0.11440693587064743,
      "learning_rate": 4.8927080615705715e-05,
      "loss": 0.1216,
      "step": 16450
    },
    {
      "epoch": 2.152361074876076,
      "grad_norm": 0.04368358477950096,
      "learning_rate": 4.892381946256197e-05,
      "loss": 0.1235,
      "step": 16500
    },
    {
      "epoch": 2.1588833811635793,
      "grad_norm": 0.02839222550392151,
      "learning_rate": 4.8920558309418214e-05,
      "loss": 0.0992,
      "step": 16550
    },
    {
      "epoch": 2.1654056874510825,
      "grad_norm": 15.671881675720215,
      "learning_rate": 4.891729715627446e-05,
      "loss": 0.0768,
      "step": 16600
    },
    {
      "epoch": 2.171927993738586,
      "grad_norm": 0.009901069104671478,
      "learning_rate": 4.8914036003130706e-05,
      "loss": 0.2268,
      "step": 16650
    },
    {
      "epoch": 2.178450300026089,
      "grad_norm": 0.07518180459737778,
      "learning_rate": 4.891077484998696e-05,
      "loss": 0.1618,
      "step": 16700
    },
    {
      "epoch": 2.1849726063135924,
      "grad_norm": 0.012091780081391335,
      "learning_rate": 4.8907513696843205e-05,
      "loss": 0.0612,
      "step": 16750
    },
    {
      "epoch": 2.1914949126010956,
      "grad_norm": 5.235929489135742,
      "learning_rate": 4.890425254369945e-05,
      "loss": 0.1434,
      "step": 16800
    },
    {
      "epoch": 2.198017218888599,
      "grad_norm": 0.01712249033153057,
      "learning_rate": 4.89009913905557e-05,
      "loss": 0.1308,
      "step": 16850
    },
    {
      "epoch": 2.204539525176102,
      "grad_norm": 1.1636122465133667,
      "learning_rate": 4.889773023741195e-05,
      "loss": 0.1389,
      "step": 16900
    },
    {
      "epoch": 2.2110618314636055,
      "grad_norm": 1.0791056156158447,
      "learning_rate": 4.8894469084268204e-05,
      "loss": 0.0836,
      "step": 16950
    },
    {
      "epoch": 2.2175841377511087,
      "grad_norm": 4.638478755950928,
      "learning_rate": 4.889120793112445e-05,
      "loss": 0.1684,
      "step": 17000
    },
    {
      "epoch": 2.224106444038612,
      "grad_norm": 15.70816421508789,
      "learning_rate": 4.8887946777980696e-05,
      "loss": 0.1623,
      "step": 17050
    },
    {
      "epoch": 2.2306287503261153,
      "grad_norm": 3.0364391803741455,
      "learning_rate": 4.888468562483694e-05,
      "loss": 0.1889,
      "step": 17100
    },
    {
      "epoch": 2.2371510566136186,
      "grad_norm": 0.032231174409389496,
      "learning_rate": 4.8881424471693195e-05,
      "loss": 0.1284,
      "step": 17150
    },
    {
      "epoch": 2.243673362901122,
      "grad_norm": 8.346039772033691,
      "learning_rate": 4.887816331854944e-05,
      "loss": 0.1341,
      "step": 17200
    },
    {
      "epoch": 2.250195669188625,
      "grad_norm": 0.02935761958360672,
      "learning_rate": 4.887490216540569e-05,
      "loss": 0.0965,
      "step": 17250
    },
    {
      "epoch": 2.2567179754761284,
      "grad_norm": 7.924602031707764,
      "learning_rate": 4.887164101226194e-05,
      "loss": 0.1403,
      "step": 17300
    },
    {
      "epoch": 2.2632402817636317,
      "grad_norm": 0.1276177018880844,
      "learning_rate": 4.886837985911819e-05,
      "loss": 0.1594,
      "step": 17350
    },
    {
      "epoch": 2.269762588051135,
      "grad_norm": 0.024016590788960457,
      "learning_rate": 4.886511870597443e-05,
      "loss": 0.0929,
      "step": 17400
    },
    {
      "epoch": 2.2762848943386382,
      "grad_norm": 1.3953750133514404,
      "learning_rate": 4.886185755283068e-05,
      "loss": 0.2003,
      "step": 17450
    },
    {
      "epoch": 2.2828072006261415,
      "grad_norm": 11.164057731628418,
      "learning_rate": 4.885859639968693e-05,
      "loss": 0.1046,
      "step": 17500
    },
    {
      "epoch": 2.289329506913645,
      "grad_norm": 0.1728837788105011,
      "learning_rate": 4.8855335246543185e-05,
      "loss": 0.1482,
      "step": 17550
    },
    {
      "epoch": 2.295851813201148,
      "grad_norm": 0.12035677582025528,
      "learning_rate": 4.885207409339943e-05,
      "loss": 0.1264,
      "step": 17600
    },
    {
      "epoch": 2.3023741194886513,
      "grad_norm": 6.5161309242248535,
      "learning_rate": 4.884881294025568e-05,
      "loss": 0.1351,
      "step": 17650
    },
    {
      "epoch": 2.3088964257761546,
      "grad_norm": 9.992522239685059,
      "learning_rate": 4.8845551787111924e-05,
      "loss": 0.114,
      "step": 17700
    },
    {
      "epoch": 2.315418732063658,
      "grad_norm": 14.209612846374512,
      "learning_rate": 4.8842290633968177e-05,
      "loss": 0.1246,
      "step": 17750
    },
    {
      "epoch": 2.321941038351161,
      "grad_norm": 9.006670951843262,
      "learning_rate": 4.883902948082442e-05,
      "loss": 0.181,
      "step": 17800
    },
    {
      "epoch": 2.3284633446386644,
      "grad_norm": 0.14109337329864502,
      "learning_rate": 4.883576832768067e-05,
      "loss": 0.0991,
      "step": 17850
    },
    {
      "epoch": 2.3349856509261677,
      "grad_norm": 0.44827133417129517,
      "learning_rate": 4.8832507174536915e-05,
      "loss": 0.1407,
      "step": 17900
    },
    {
      "epoch": 2.341507957213671,
      "grad_norm": 0.01729659177362919,
      "learning_rate": 4.882924602139317e-05,
      "loss": 0.0722,
      "step": 17950
    },
    {
      "epoch": 2.348030263501174,
      "grad_norm": 4.937082290649414,
      "learning_rate": 4.8825984868249414e-05,
      "loss": 0.098,
      "step": 18000
    },
    {
      "epoch": 2.354552569788677,
      "grad_norm": 0.2504434585571289,
      "learning_rate": 4.882272371510566e-05,
      "loss": 0.1448,
      "step": 18050
    },
    {
      "epoch": 2.3610748760761804,
      "grad_norm": 6.310827732086182,
      "learning_rate": 4.881946256196191e-05,
      "loss": 0.1168,
      "step": 18100
    },
    {
      "epoch": 2.3675971823636837,
      "grad_norm": 0.027957187965512276,
      "learning_rate": 4.881620140881816e-05,
      "loss": 0.1413,
      "step": 18150
    },
    {
      "epoch": 2.374119488651187,
      "grad_norm": 0.09506935626268387,
      "learning_rate": 4.881294025567441e-05,
      "loss": 0.167,
      "step": 18200
    },
    {
      "epoch": 2.38064179493869,
      "grad_norm": 12.731308937072754,
      "learning_rate": 4.880967910253066e-05,
      "loss": 0.1241,
      "step": 18250
    },
    {
      "epoch": 2.3871641012261935,
      "grad_norm": 0.1538475602865219,
      "learning_rate": 4.8806417949386905e-05,
      "loss": 0.1536,
      "step": 18300
    },
    {
      "epoch": 2.3936864075136968,
      "grad_norm": 0.05200781300663948,
      "learning_rate": 4.880315679624316e-05,
      "loss": 0.0918,
      "step": 18350
    },
    {
      "epoch": 2.4002087138012,
      "grad_norm": 11.670418739318848,
      "learning_rate": 4.8799895643099404e-05,
      "loss": 0.1579,
      "step": 18400
    },
    {
      "epoch": 2.4067310200887033,
      "grad_norm": 0.10715681314468384,
      "learning_rate": 4.879663448995565e-05,
      "loss": 0.109,
      "step": 18450
    },
    {
      "epoch": 2.4132533263762066,
      "grad_norm": 0.052051227539777756,
      "learning_rate": 4.8793373336811896e-05,
      "loss": 0.1278,
      "step": 18500
    },
    {
      "epoch": 2.41977563266371,
      "grad_norm": 0.35353147983551025,
      "learning_rate": 4.879011218366815e-05,
      "loss": 0.1627,
      "step": 18550
    },
    {
      "epoch": 2.426297938951213,
      "grad_norm": 0.2856748700141907,
      "learning_rate": 4.8786851030524396e-05,
      "loss": 0.1251,
      "step": 18600
    },
    {
      "epoch": 2.4328202452387164,
      "grad_norm": 0.23231390118598938,
      "learning_rate": 4.878358987738064e-05,
      "loss": 0.119,
      "step": 18650
    },
    {
      "epoch": 2.4393425515262197,
      "grad_norm": 14.702672004699707,
      "learning_rate": 4.878032872423689e-05,
      "loss": 0.1293,
      "step": 18700
    },
    {
      "epoch": 2.445864857813723,
      "grad_norm": 0.06145373359322548,
      "learning_rate": 4.877706757109314e-05,
      "loss": 0.0816,
      "step": 18750
    },
    {
      "epoch": 2.4523871641012263,
      "grad_norm": 1.2994349002838135,
      "learning_rate": 4.8773806417949394e-05,
      "loss": 0.1831,
      "step": 18800
    },
    {
      "epoch": 2.4589094703887295,
      "grad_norm": 0.05157052353024483,
      "learning_rate": 4.877054526480564e-05,
      "loss": 0.1392,
      "step": 18850
    },
    {
      "epoch": 2.465431776676233,
      "grad_norm": 3.768632173538208,
      "learning_rate": 4.8767284111661886e-05,
      "loss": 0.1088,
      "step": 18900
    },
    {
      "epoch": 2.471954082963736,
      "grad_norm": 7.194169521331787,
      "learning_rate": 4.876402295851813e-05,
      "loss": 0.0888,
      "step": 18950
    },
    {
      "epoch": 2.4784763892512394,
      "grad_norm": 0.04020017385482788,
      "learning_rate": 4.8760761805374385e-05,
      "loss": 0.1435,
      "step": 19000
    },
    {
      "epoch": 2.4849986955387426,
      "grad_norm": 4.864092826843262,
      "learning_rate": 4.875750065223063e-05,
      "loss": 0.1578,
      "step": 19050
    },
    {
      "epoch": 2.491521001826246,
      "grad_norm": 0.03223351389169693,
      "learning_rate": 4.875423949908688e-05,
      "loss": 0.116,
      "step": 19100
    },
    {
      "epoch": 2.498043308113749,
      "grad_norm": 0.1922614425420761,
      "learning_rate": 4.8750978345943124e-05,
      "loss": 0.1189,
      "step": 19150
    },
    {
      "epoch": 2.504565614401252,
      "grad_norm": 0.10495205223560333,
      "learning_rate": 4.874771719279938e-05,
      "loss": 0.1177,
      "step": 19200
    },
    {
      "epoch": 2.5110879206887553,
      "grad_norm": 5.780263900756836,
      "learning_rate": 4.874445603965562e-05,
      "loss": 0.1657,
      "step": 19250
    },
    {
      "epoch": 2.5176102269762586,
      "grad_norm": 0.2229381799697876,
      "learning_rate": 4.874119488651187e-05,
      "loss": 0.1584,
      "step": 19300
    },
    {
      "epoch": 2.524132533263762,
      "grad_norm": 3.86562180519104,
      "learning_rate": 4.873793373336812e-05,
      "loss": 0.1635,
      "step": 19350
    },
    {
      "epoch": 2.530654839551265,
      "grad_norm": 3.7168147563934326,
      "learning_rate": 4.8734672580224375e-05,
      "loss": 0.124,
      "step": 19400
    },
    {
      "epoch": 2.5371771458387684,
      "grad_norm": 15.791695594787598,
      "learning_rate": 4.873141142708062e-05,
      "loss": 0.1158,
      "step": 19450
    },
    {
      "epoch": 2.5436994521262717,
      "grad_norm": 0.03076394461095333,
      "learning_rate": 4.872815027393687e-05,
      "loss": 0.1196,
      "step": 19500
    },
    {
      "epoch": 2.550221758413775,
      "grad_norm": 0.06485407054424286,
      "learning_rate": 4.8724889120793114e-05,
      "loss": 0.1796,
      "step": 19550
    },
    {
      "epoch": 2.5567440647012782,
      "grad_norm": 0.1365847885608673,
      "learning_rate": 4.872162796764937e-05,
      "loss": 0.0919,
      "step": 19600
    },
    {
      "epoch": 2.5632663709887815,
      "grad_norm": 0.1177474707365036,
      "learning_rate": 4.871836681450561e-05,
      "loss": 0.1162,
      "step": 19650
    },
    {
      "epoch": 2.569788677276285,
      "grad_norm": 0.3689923584461212,
      "learning_rate": 4.871510566136186e-05,
      "loss": 0.1273,
      "step": 19700
    },
    {
      "epoch": 2.576310983563788,
      "grad_norm": 0.04298771172761917,
      "learning_rate": 4.8711844508218105e-05,
      "loss": 0.0672,
      "step": 19750
    },
    {
      "epoch": 2.5828332898512913,
      "grad_norm": 4.612065315246582,
      "learning_rate": 4.870858335507436e-05,
      "loss": 0.1645,
      "step": 19800
    },
    {
      "epoch": 2.5893555961387946,
      "grad_norm": 6.165155410766602,
      "learning_rate": 4.8705322201930604e-05,
      "loss": 0.1987,
      "step": 19850
    },
    {
      "epoch": 2.595877902426298,
      "grad_norm": 0.1941128373146057,
      "learning_rate": 4.870206104878685e-05,
      "loss": 0.1198,
      "step": 19900
    },
    {
      "epoch": 2.602400208713801,
      "grad_norm": 7.703914165496826,
      "learning_rate": 4.86987998956431e-05,
      "loss": 0.1467,
      "step": 19950
    },
    {
      "epoch": 2.6089225150013045,
      "grad_norm": 0.023349830880761147,
      "learning_rate": 4.869553874249935e-05,
      "loss": 0.1825,
      "step": 20000
    },
    {
      "epoch": 2.6154448212888077,
      "grad_norm": 0.050054386258125305,
      "learning_rate": 4.86922775893556e-05,
      "loss": 0.1054,
      "step": 20050
    },
    {
      "epoch": 2.621967127576311,
      "grad_norm": 0.23930194973945618,
      "learning_rate": 4.868901643621185e-05,
      "loss": 0.1166,
      "step": 20100
    },
    {
      "epoch": 2.6284894338638143,
      "grad_norm": 0.02187907136976719,
      "learning_rate": 4.8685755283068095e-05,
      "loss": 0.1202,
      "step": 20150
    },
    {
      "epoch": 2.6350117401513176,
      "grad_norm": 0.08532539010047913,
      "learning_rate": 4.868249412992434e-05,
      "loss": 0.1006,
      "step": 20200
    },
    {
      "epoch": 2.641534046438821,
      "grad_norm": 0.6425157189369202,
      "learning_rate": 4.8679232976780594e-05,
      "loss": 0.1807,
      "step": 20250
    },
    {
      "epoch": 2.648056352726324,
      "grad_norm": 0.03503644838929176,
      "learning_rate": 4.867597182363684e-05,
      "loss": 0.0969,
      "step": 20300
    },
    {
      "epoch": 2.6545786590138274,
      "grad_norm": 0.11025235801935196,
      "learning_rate": 4.8672710670493087e-05,
      "loss": 0.0904,
      "step": 20350
    },
    {
      "epoch": 2.6611009653013307,
      "grad_norm": 12.264158248901367,
      "learning_rate": 4.866944951734933e-05,
      "loss": 0.1463,
      "step": 20400
    },
    {
      "epoch": 2.667623271588834,
      "grad_norm": 0.11111877113580704,
      "learning_rate": 4.8666188364205586e-05,
      "loss": 0.1522,
      "step": 20450
    },
    {
      "epoch": 2.674145577876337,
      "grad_norm": 24.474849700927734,
      "learning_rate": 4.866292721106183e-05,
      "loss": 0.1119,
      "step": 20500
    },
    {
      "epoch": 2.6806678841638405,
      "grad_norm": 1.1164095401763916,
      "learning_rate": 4.865966605791808e-05,
      "loss": 0.1108,
      "step": 20550
    },
    {
      "epoch": 2.6871901904513438,
      "grad_norm": 0.07531920075416565,
      "learning_rate": 4.865640490477433e-05,
      "loss": 0.1008,
      "step": 20600
    },
    {
      "epoch": 2.693712496738847,
      "grad_norm": 8.119826316833496,
      "learning_rate": 4.8653143751630584e-05,
      "loss": 0.1455,
      "step": 20650
    },
    {
      "epoch": 2.7002348030263503,
      "grad_norm": 0.26132550835609436,
      "learning_rate": 4.864988259848683e-05,
      "loss": 0.1299,
      "step": 20700
    },
    {
      "epoch": 2.7067571093138536,
      "grad_norm": 0.02826596610248089,
      "learning_rate": 4.8646621445343076e-05,
      "loss": 0.1112,
      "step": 20750
    },
    {
      "epoch": 2.713279415601357,
      "grad_norm": 0.09327897429466248,
      "learning_rate": 4.864336029219932e-05,
      "loss": 0.091,
      "step": 20800
    },
    {
      "epoch": 2.71980172188886,
      "grad_norm": 12.138653755187988,
      "learning_rate": 4.8640099139055575e-05,
      "loss": 0.1134,
      "step": 20850
    },
    {
      "epoch": 2.7263240281763634,
      "grad_norm": 0.16067089140415192,
      "learning_rate": 4.863683798591182e-05,
      "loss": 0.1298,
      "step": 20900
    },
    {
      "epoch": 2.7328463344638663,
      "grad_norm": 0.016024274751544,
      "learning_rate": 4.863357683276807e-05,
      "loss": 0.1318,
      "step": 20950
    },
    {
      "epoch": 2.7393686407513695,
      "grad_norm": 0.029537227004766464,
      "learning_rate": 4.8630315679624314e-05,
      "loss": 0.1354,
      "step": 21000
    },
    {
      "epoch": 2.745890947038873,
      "grad_norm": 0.020635860040783882,
      "learning_rate": 4.862705452648057e-05,
      "loss": 0.1217,
      "step": 21050
    },
    {
      "epoch": 2.752413253326376,
      "grad_norm": 0.12089214473962784,
      "learning_rate": 4.862379337333681e-05,
      "loss": 0.0594,
      "step": 21100
    },
    {
      "epoch": 2.7589355596138794,
      "grad_norm": 14.425934791564941,
      "learning_rate": 4.862053222019306e-05,
      "loss": 0.1367,
      "step": 21150
    },
    {
      "epoch": 2.7654578659013827,
      "grad_norm": 1.9750006198883057,
      "learning_rate": 4.861727106704931e-05,
      "loss": 0.1648,
      "step": 21200
    },
    {
      "epoch": 2.771980172188886,
      "grad_norm": 31.091548919677734,
      "learning_rate": 4.861400991390556e-05,
      "loss": 0.1256,
      "step": 21250
    },
    {
      "epoch": 2.778502478476389,
      "grad_norm": 0.03407343477010727,
      "learning_rate": 4.861074876076181e-05,
      "loss": 0.1872,
      "step": 21300
    },
    {
      "epoch": 2.7850247847638925,
      "grad_norm": 0.27412715554237366,
      "learning_rate": 4.860748760761806e-05,
      "loss": 0.1134,
      "step": 21350
    },
    {
      "epoch": 2.7915470910513958,
      "grad_norm": 0.0873265415430069,
      "learning_rate": 4.8604226454474304e-05,
      "loss": 0.0821,
      "step": 21400
    },
    {
      "epoch": 2.798069397338899,
      "grad_norm": 0.6013961434364319,
      "learning_rate": 4.860096530133055e-05,
      "loss": 0.1324,
      "step": 21450
    },
    {
      "epoch": 2.8045917036264023,
      "grad_norm": 0.03240063041448593,
      "learning_rate": 4.85977041481868e-05,
      "loss": 0.0959,
      "step": 21500
    },
    {
      "epoch": 2.8111140099139056,
      "grad_norm": 0.4123345911502838,
      "learning_rate": 4.859444299504305e-05,
      "loss": 0.1704,
      "step": 21550
    },
    {
      "epoch": 2.817636316201409,
      "grad_norm": 0.19740110635757446,
      "learning_rate": 4.8591181841899295e-05,
      "loss": 0.1558,
      "step": 21600
    },
    {
      "epoch": 2.824158622488912,
      "grad_norm": 11.101648330688477,
      "learning_rate": 4.858792068875555e-05,
      "loss": 0.0959,
      "step": 21650
    },
    {
      "epoch": 2.8306809287764154,
      "grad_norm": 0.04090948402881622,
      "learning_rate": 4.8584659535611794e-05,
      "loss": 0.1153,
      "step": 21700
    },
    {
      "epoch": 2.8372032350639187,
      "grad_norm": 7.305883407592773,
      "learning_rate": 4.858139838246804e-05,
      "loss": 0.1913,
      "step": 21750
    },
    {
      "epoch": 2.843725541351422,
      "grad_norm": 0.43642500042915344,
      "learning_rate": 4.857813722932429e-05,
      "loss": 0.1299,
      "step": 21800
    },
    {
      "epoch": 2.8502478476389252,
      "grad_norm": 6.646767616271973,
      "learning_rate": 4.857487607618054e-05,
      "loss": 0.1475,
      "step": 21850
    },
    {
      "epoch": 2.8567701539264285,
      "grad_norm": 0.22731688618659973,
      "learning_rate": 4.857161492303679e-05,
      "loss": 0.0781,
      "step": 21900
    },
    {
      "epoch": 2.863292460213932,
      "grad_norm": 0.5920910239219666,
      "learning_rate": 4.856835376989304e-05,
      "loss": 0.1253,
      "step": 21950
    },
    {
      "epoch": 2.8698147665014346,
      "grad_norm": 0.06774459779262543,
      "learning_rate": 4.8565092616749285e-05,
      "loss": 0.1265,
      "step": 22000
    },
    {
      "epoch": 2.876337072788938,
      "grad_norm": 6.129946708679199,
      "learning_rate": 4.856183146360553e-05,
      "loss": 0.1356,
      "step": 22050
    },
    {
      "epoch": 2.882859379076441,
      "grad_norm": 10.93480110168457,
      "learning_rate": 4.8558570310461784e-05,
      "loss": 0.2083,
      "step": 22100
    },
    {
      "epoch": 2.8893816853639445,
      "grad_norm": 0.024561116471886635,
      "learning_rate": 4.855530915731803e-05,
      "loss": 0.133,
      "step": 22150
    },
    {
      "epoch": 2.8959039916514477,
      "grad_norm": 8.978404998779297,
      "learning_rate": 4.8552048004174277e-05,
      "loss": 0.157,
      "step": 22200
    },
    {
      "epoch": 2.902426297938951,
      "grad_norm": 0.010745661333203316,
      "learning_rate": 4.854878685103052e-05,
      "loss": 0.0887,
      "step": 22250
    },
    {
      "epoch": 2.9089486042264543,
      "grad_norm": 14.361804962158203,
      "learning_rate": 4.8545525697886776e-05,
      "loss": 0.1044,
      "step": 22300
    },
    {
      "epoch": 2.9154709105139576,
      "grad_norm": 13.801833152770996,
      "learning_rate": 4.854226454474302e-05,
      "loss": 0.1684,
      "step": 22350
    },
    {
      "epoch": 2.921993216801461,
      "grad_norm": 4.5551676750183105,
      "learning_rate": 4.853900339159927e-05,
      "loss": 0.114,
      "step": 22400
    },
    {
      "epoch": 2.928515523088964,
      "grad_norm": 0.04116450995206833,
      "learning_rate": 4.853574223845552e-05,
      "loss": 0.077,
      "step": 22450
    },
    {
      "epoch": 2.9350378293764674,
      "grad_norm": 0.1695617437362671,
      "learning_rate": 4.8532481085311774e-05,
      "loss": 0.1363,
      "step": 22500
    },
    {
      "epoch": 2.9415601356639707,
      "grad_norm": 7.265661239624023,
      "learning_rate": 4.852921993216802e-05,
      "loss": 0.1219,
      "step": 22550
    },
    {
      "epoch": 2.948082441951474,
      "grad_norm": 0.030099883675575256,
      "learning_rate": 4.8525958779024266e-05,
      "loss": 0.0893,
      "step": 22600
    },
    {
      "epoch": 2.9546047482389772,
      "grad_norm": 0.07747209072113037,
      "learning_rate": 4.852269762588051e-05,
      "loss": 0.1073,
      "step": 22650
    },
    {
      "epoch": 2.9611270545264805,
      "grad_norm": 0.06178167834877968,
      "learning_rate": 4.8519436472736766e-05,
      "loss": 0.0959,
      "step": 22700
    },
    {
      "epoch": 2.967649360813984,
      "grad_norm": 0.1471334844827652,
      "learning_rate": 4.851617531959301e-05,
      "loss": 0.1057,
      "step": 22750
    },
    {
      "epoch": 2.974171667101487,
      "grad_norm": 0.11625943332910538,
      "learning_rate": 4.851291416644926e-05,
      "loss": 0.0963,
      "step": 22800
    },
    {
      "epoch": 2.9806939733889903,
      "grad_norm": 4.501331806182861,
      "learning_rate": 4.8509653013305504e-05,
      "loss": 0.1129,
      "step": 22850
    },
    {
      "epoch": 2.9872162796764936,
      "grad_norm": 0.013503731228411198,
      "learning_rate": 4.850639186016176e-05,
      "loss": 0.1535,
      "step": 22900
    },
    {
      "epoch": 2.993738585963997,
      "grad_norm": 14.780393600463867,
      "learning_rate": 4.8503130707018e-05,
      "loss": 0.1495,
      "step": 22950
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9637359770414818,
      "eval_f1": 0.96388672382437,
      "eval_loss": 0.12886467576026917,
      "eval_precision": 0.9601449275362319,
      "eval_recall": 0.9676577986437142,
      "eval_runtime": 27.08,
      "eval_samples_per_second": 566.175,
      "eval_steps_per_second": 70.79,
      "step": 22998
    },
    {
      "epoch": 3.0002608922515,
      "grad_norm": 0.08404208719730377,
      "learning_rate": 4.849986955387425e-05,
      "loss": 0.159,
      "step": 23000
    },
    {
      "epoch": 3.0067831985390034,
      "grad_norm": 0.0503198467195034,
      "learning_rate": 4.84966084007305e-05,
      "loss": 0.1575,
      "step": 23050
    },
    {
      "epoch": 3.0133055048265067,
      "grad_norm": 1.2895708084106445,
      "learning_rate": 4.849334724758675e-05,
      "loss": 0.1115,
      "step": 23100
    },
    {
      "epoch": 3.01982781111401,
      "grad_norm": 0.8755640387535095,
      "learning_rate": 4.8490086094443e-05,
      "loss": 0.083,
      "step": 23150
    },
    {
      "epoch": 3.0263501174015133,
      "grad_norm": 0.863589346408844,
      "learning_rate": 4.848682494129925e-05,
      "loss": 0.1137,
      "step": 23200
    },
    {
      "epoch": 3.0328724236890165,
      "grad_norm": 0.057146407663822174,
      "learning_rate": 4.8483563788155494e-05,
      "loss": 0.1101,
      "step": 23250
    },
    {
      "epoch": 3.03939472997652,
      "grad_norm": 0.0780874565243721,
      "learning_rate": 4.848030263501174e-05,
      "loss": 0.1408,
      "step": 23300
    },
    {
      "epoch": 3.045917036264023,
      "grad_norm": 6.186034202575684,
      "learning_rate": 4.847704148186799e-05,
      "loss": 0.1506,
      "step": 23350
    },
    {
      "epoch": 3.0524393425515264,
      "grad_norm": 0.03220989182591438,
      "learning_rate": 4.847378032872424e-05,
      "loss": 0.0947,
      "step": 23400
    },
    {
      "epoch": 3.0589616488390297,
      "grad_norm": 0.7057467699050903,
      "learning_rate": 4.8470519175580485e-05,
      "loss": 0.147,
      "step": 23450
    },
    {
      "epoch": 3.065483955126533,
      "grad_norm": 0.052208349108695984,
      "learning_rate": 4.846725802243673e-05,
      "loss": 0.1435,
      "step": 23500
    },
    {
      "epoch": 3.072006261414036,
      "grad_norm": 8.810426712036133,
      "learning_rate": 4.8463996869292985e-05,
      "loss": 0.1442,
      "step": 23550
    },
    {
      "epoch": 3.0785285677015395,
      "grad_norm": 5.53562068939209,
      "learning_rate": 4.846073571614923e-05,
      "loss": 0.1412,
      "step": 23600
    },
    {
      "epoch": 3.0850508739890423,
      "grad_norm": 0.016412047669291496,
      "learning_rate": 4.8457474563005484e-05,
      "loss": 0.0854,
      "step": 23650
    },
    {
      "epoch": 3.0915731802765456,
      "grad_norm": 0.12245754152536392,
      "learning_rate": 4.845421340986173e-05,
      "loss": 0.098,
      "step": 23700
    },
    {
      "epoch": 3.098095486564049,
      "grad_norm": 0.09804880619049072,
      "learning_rate": 4.845095225671798e-05,
      "loss": 0.1563,
      "step": 23750
    },
    {
      "epoch": 3.104617792851552,
      "grad_norm": 0.208158478140831,
      "learning_rate": 4.844769110357423e-05,
      "loss": 0.1063,
      "step": 23800
    },
    {
      "epoch": 3.1111400991390554,
      "grad_norm": 0.7527519464492798,
      "learning_rate": 4.8444429950430475e-05,
      "loss": 0.1021,
      "step": 23850
    },
    {
      "epoch": 3.1176624054265587,
      "grad_norm": 6.545111179351807,
      "learning_rate": 4.844116879728672e-05,
      "loss": 0.1193,
      "step": 23900
    },
    {
      "epoch": 3.124184711714062,
      "grad_norm": 0.04136979207396507,
      "learning_rate": 4.8437907644142974e-05,
      "loss": 0.1124,
      "step": 23950
    },
    {
      "epoch": 3.1307070180015653,
      "grad_norm": 7.842288494110107,
      "learning_rate": 4.843464649099922e-05,
      "loss": 0.1597,
      "step": 24000
    },
    {
      "epoch": 3.1372293242890685,
      "grad_norm": 19.734798431396484,
      "learning_rate": 4.843138533785547e-05,
      "loss": 0.0913,
      "step": 24050
    },
    {
      "epoch": 3.143751630576572,
      "grad_norm": 0.04253799840807915,
      "learning_rate": 4.842812418471171e-05,
      "loss": 0.1911,
      "step": 24100
    },
    {
      "epoch": 3.150273936864075,
      "grad_norm": 0.05669982358813286,
      "learning_rate": 4.8424863031567966e-05,
      "loss": 0.1686,
      "step": 24150
    },
    {
      "epoch": 3.1567962431515784,
      "grad_norm": 0.5057231783866882,
      "learning_rate": 4.842160187842421e-05,
      "loss": 0.1441,
      "step": 24200
    },
    {
      "epoch": 3.1633185494390816,
      "grad_norm": 7.294979095458984,
      "learning_rate": 4.841834072528046e-05,
      "loss": 0.1058,
      "step": 24250
    },
    {
      "epoch": 3.169840855726585,
      "grad_norm": 13.358798027038574,
      "learning_rate": 4.841507957213671e-05,
      "loss": 0.1564,
      "step": 24300
    },
    {
      "epoch": 3.176363162014088,
      "grad_norm": 8.039969444274902,
      "learning_rate": 4.841181841899296e-05,
      "loss": 0.0646,
      "step": 24350
    },
    {
      "epoch": 3.1828854683015915,
      "grad_norm": 8.119638442993164,
      "learning_rate": 4.840855726584921e-05,
      "loss": 0.0732,
      "step": 24400
    },
    {
      "epoch": 3.1894077745890947,
      "grad_norm": 1.2052372694015503,
      "learning_rate": 4.8405296112705456e-05,
      "loss": 0.1032,
      "step": 24450
    },
    {
      "epoch": 3.195930080876598,
      "grad_norm": 0.10544618964195251,
      "learning_rate": 4.84020349595617e-05,
      "loss": 0.138,
      "step": 24500
    },
    {
      "epoch": 3.2024523871641013,
      "grad_norm": 0.5330145955085754,
      "learning_rate": 4.839877380641795e-05,
      "loss": 0.0924,
      "step": 24550
    },
    {
      "epoch": 3.2089746934516046,
      "grad_norm": 2.0803396701812744,
      "learning_rate": 4.83955126532742e-05,
      "loss": 0.1008,
      "step": 24600
    },
    {
      "epoch": 3.215496999739108,
      "grad_norm": 10.246583938598633,
      "learning_rate": 4.839225150013045e-05,
      "loss": 0.1259,
      "step": 24650
    },
    {
      "epoch": 3.222019306026611,
      "grad_norm": 0.27052605152130127,
      "learning_rate": 4.8388990346986694e-05,
      "loss": 0.1157,
      "step": 24700
    },
    {
      "epoch": 3.2285416123141144,
      "grad_norm": 0.1409793496131897,
      "learning_rate": 4.838572919384294e-05,
      "loss": 0.0689,
      "step": 24750
    },
    {
      "epoch": 3.2350639186016177,
      "grad_norm": 0.35660648345947266,
      "learning_rate": 4.838246804069919e-05,
      "loss": 0.1245,
      "step": 24800
    },
    {
      "epoch": 3.241586224889121,
      "grad_norm": 12.941964149475098,
      "learning_rate": 4.837920688755544e-05,
      "loss": 0.1768,
      "step": 24850
    },
    {
      "epoch": 3.2481085311766242,
      "grad_norm": 0.06276005506515503,
      "learning_rate": 4.837594573441169e-05,
      "loss": 0.0982,
      "step": 24900
    },
    {
      "epoch": 3.254630837464127,
      "grad_norm": 3.2705702781677246,
      "learning_rate": 4.837268458126794e-05,
      "loss": 0.0901,
      "step": 24950
    },
    {
      "epoch": 3.2611531437516303,
      "grad_norm": 0.032433122396469116,
      "learning_rate": 4.836942342812419e-05,
      "loss": 0.1089,
      "step": 25000
    },
    {
      "epoch": 3.2676754500391336,
      "grad_norm": 5.278552532196045,
      "learning_rate": 4.836616227498044e-05,
      "loss": 0.1506,
      "step": 25050
    },
    {
      "epoch": 3.274197756326637,
      "grad_norm": 1.4498672485351562,
      "learning_rate": 4.8362901121836684e-05,
      "loss": 0.1674,
      "step": 25100
    },
    {
      "epoch": 3.28072006261414,
      "grad_norm": 1.042065143585205,
      "learning_rate": 4.835963996869293e-05,
      "loss": 0.134,
      "step": 25150
    },
    {
      "epoch": 3.2872423689016435,
      "grad_norm": 7.787869453430176,
      "learning_rate": 4.835637881554918e-05,
      "loss": 0.0923,
      "step": 25200
    },
    {
      "epoch": 3.2937646751891467,
      "grad_norm": 0.055648043751716614,
      "learning_rate": 4.835311766240543e-05,
      "loss": 0.1232,
      "step": 25250
    },
    {
      "epoch": 3.30028698147665,
      "grad_norm": 0.09871658682823181,
      "learning_rate": 4.8349856509261675e-05,
      "loss": 0.1717,
      "step": 25300
    },
    {
      "epoch": 3.3068092877641533,
      "grad_norm": 0.32251277565956116,
      "learning_rate": 4.834659535611792e-05,
      "loss": 0.1047,
      "step": 25350
    },
    {
      "epoch": 3.3133315940516566,
      "grad_norm": 0.3810313045978546,
      "learning_rate": 4.8343334202974175e-05,
      "loss": 0.1249,
      "step": 25400
    },
    {
      "epoch": 3.31985390033916,
      "grad_norm": 12.347023963928223,
      "learning_rate": 4.834007304983042e-05,
      "loss": 0.1607,
      "step": 25450
    },
    {
      "epoch": 3.326376206626663,
      "grad_norm": 8.978865623474121,
      "learning_rate": 4.8336811896686674e-05,
      "loss": 0.0933,
      "step": 25500
    },
    {
      "epoch": 3.3328985129141664,
      "grad_norm": 0.05600004643201828,
      "learning_rate": 4.833355074354292e-05,
      "loss": 0.1288,
      "step": 25550
    },
    {
      "epoch": 3.3394208192016697,
      "grad_norm": 4.05842924118042,
      "learning_rate": 4.8330289590399166e-05,
      "loss": 0.1114,
      "step": 25600
    },
    {
      "epoch": 3.345943125489173,
      "grad_norm": 0.06587892025709152,
      "learning_rate": 4.832702843725542e-05,
      "loss": 0.103,
      "step": 25650
    },
    {
      "epoch": 3.352465431776676,
      "grad_norm": 0.02734486758708954,
      "learning_rate": 4.8323767284111665e-05,
      "loss": 0.1514,
      "step": 25700
    },
    {
      "epoch": 3.3589877380641795,
      "grad_norm": 17.187610626220703,
      "learning_rate": 4.832050613096791e-05,
      "loss": 0.1309,
      "step": 25750
    },
    {
      "epoch": 3.3655100443516828,
      "grad_norm": 2.3288419246673584,
      "learning_rate": 4.831724497782416e-05,
      "loss": 0.1494,
      "step": 25800
    },
    {
      "epoch": 3.372032350639186,
      "grad_norm": 0.019161585718393326,
      "learning_rate": 4.831398382468041e-05,
      "loss": 0.103,
      "step": 25850
    },
    {
      "epoch": 3.3785546569266893,
      "grad_norm": 0.05775776505470276,
      "learning_rate": 4.831072267153666e-05,
      "loss": 0.1164,
      "step": 25900
    },
    {
      "epoch": 3.3850769632141926,
      "grad_norm": 22.12996482849121,
      "learning_rate": 4.83074615183929e-05,
      "loss": 0.1242,
      "step": 25950
    },
    {
      "epoch": 3.391599269501696,
      "grad_norm": 0.025893928483128548,
      "learning_rate": 4.8304200365249156e-05,
      "loss": 0.1251,
      "step": 26000
    },
    {
      "epoch": 3.398121575789199,
      "grad_norm": 0.019521940499544144,
      "learning_rate": 4.83009392121054e-05,
      "loss": 0.1238,
      "step": 26050
    },
    {
      "epoch": 3.4046438820767024,
      "grad_norm": 0.23425109684467316,
      "learning_rate": 4.829767805896165e-05,
      "loss": 0.1023,
      "step": 26100
    },
    {
      "epoch": 3.4111661883642057,
      "grad_norm": 0.012521670199930668,
      "learning_rate": 4.82944169058179e-05,
      "loss": 0.1369,
      "step": 26150
    },
    {
      "epoch": 3.417688494651709,
      "grad_norm": 0.6872681975364685,
      "learning_rate": 4.829115575267415e-05,
      "loss": 0.1032,
      "step": 26200
    },
    {
      "epoch": 3.4242108009392123,
      "grad_norm": 0.06636708229780197,
      "learning_rate": 4.82878945995304e-05,
      "loss": 0.1188,
      "step": 26250
    },
    {
      "epoch": 3.4307331072267155,
      "grad_norm": 0.058007922023534775,
      "learning_rate": 4.8284633446386647e-05,
      "loss": 0.0995,
      "step": 26300
    },
    {
      "epoch": 3.437255413514219,
      "grad_norm": 0.046171125024557114,
      "learning_rate": 4.828137229324289e-05,
      "loss": 0.1124,
      "step": 26350
    },
    {
      "epoch": 3.443777719801722,
      "grad_norm": 0.014447730965912342,
      "learning_rate": 4.827811114009914e-05,
      "loss": 0.0859,
      "step": 26400
    },
    {
      "epoch": 3.4503000260892254,
      "grad_norm": 4.726897716522217,
      "learning_rate": 4.827484998695539e-05,
      "loss": 0.0831,
      "step": 26450
    },
    {
      "epoch": 3.4568223323767286,
      "grad_norm": 3.100756883621216,
      "learning_rate": 4.827158883381164e-05,
      "loss": 0.1185,
      "step": 26500
    },
    {
      "epoch": 3.4633446386642315,
      "grad_norm": 0.34736430644989014,
      "learning_rate": 4.8268327680667884e-05,
      "loss": 0.1342,
      "step": 26550
    },
    {
      "epoch": 3.4698669449517348,
      "grad_norm": 0.34453532099723816,
      "learning_rate": 4.826506652752413e-05,
      "loss": 0.0744,
      "step": 26600
    },
    {
      "epoch": 3.476389251239238,
      "grad_norm": 0.019029254093766212,
      "learning_rate": 4.826180537438038e-05,
      "loss": 0.1957,
      "step": 26650
    },
    {
      "epoch": 3.4829115575267413,
      "grad_norm": 0.02572728507220745,
      "learning_rate": 4.825854422123663e-05,
      "loss": 0.0731,
      "step": 26700
    },
    {
      "epoch": 3.4894338638142446,
      "grad_norm": 7.249569416046143,
      "learning_rate": 4.825528306809288e-05,
      "loss": 0.0849,
      "step": 26750
    },
    {
      "epoch": 3.495956170101748,
      "grad_norm": 7.903285980224609,
      "learning_rate": 4.825202191494913e-05,
      "loss": 0.1194,
      "step": 26800
    },
    {
      "epoch": 3.502478476389251,
      "grad_norm": 0.01598772406578064,
      "learning_rate": 4.824876076180538e-05,
      "loss": 0.1114,
      "step": 26850
    },
    {
      "epoch": 3.5090007826767544,
      "grad_norm": 8.313806533813477,
      "learning_rate": 4.824549960866163e-05,
      "loss": 0.0768,
      "step": 26900
    },
    {
      "epoch": 3.5155230889642577,
      "grad_norm": 0.6679573059082031,
      "learning_rate": 4.8242238455517874e-05,
      "loss": 0.0742,
      "step": 26950
    },
    {
      "epoch": 3.522045395251761,
      "grad_norm": 0.11047568172216415,
      "learning_rate": 4.823897730237412e-05,
      "loss": 0.1581,
      "step": 27000
    },
    {
      "epoch": 3.5285677015392642,
      "grad_norm": 0.06975744664669037,
      "learning_rate": 4.823571614923037e-05,
      "loss": 0.1855,
      "step": 27050
    },
    {
      "epoch": 3.5350900078267675,
      "grad_norm": 1.4377100467681885,
      "learning_rate": 4.823245499608662e-05,
      "loss": 0.1109,
      "step": 27100
    },
    {
      "epoch": 3.541612314114271,
      "grad_norm": 0.06962220370769501,
      "learning_rate": 4.8229193842942866e-05,
      "loss": 0.1301,
      "step": 27150
    },
    {
      "epoch": 3.548134620401774,
      "grad_norm": 9.12778091430664,
      "learning_rate": 4.822593268979911e-05,
      "loss": 0.1175,
      "step": 27200
    },
    {
      "epoch": 3.5546569266892774,
      "grad_norm": 9.580707550048828,
      "learning_rate": 4.8222671536655365e-05,
      "loss": 0.1353,
      "step": 27250
    },
    {
      "epoch": 3.5611792329767806,
      "grad_norm": 0.4000582993030548,
      "learning_rate": 4.821941038351161e-05,
      "loss": 0.0907,
      "step": 27300
    },
    {
      "epoch": 3.567701539264284,
      "grad_norm": 0.07754554599523544,
      "learning_rate": 4.8216149230367864e-05,
      "loss": 0.0998,
      "step": 27350
    },
    {
      "epoch": 3.574223845551787,
      "grad_norm": 9.762519836425781,
      "learning_rate": 4.821288807722411e-05,
      "loss": 0.1335,
      "step": 27400
    },
    {
      "epoch": 3.5807461518392905,
      "grad_norm": 4.559277057647705,
      "learning_rate": 4.8209626924080356e-05,
      "loss": 0.1707,
      "step": 27450
    },
    {
      "epoch": 3.5872684581267937,
      "grad_norm": 0.3572259247303009,
      "learning_rate": 4.820636577093661e-05,
      "loss": 0.1287,
      "step": 27500
    },
    {
      "epoch": 3.593790764414297,
      "grad_norm": 0.06159883365035057,
      "learning_rate": 4.8203104617792855e-05,
      "loss": 0.064,
      "step": 27550
    },
    {
      "epoch": 3.6003130707018003,
      "grad_norm": 10.031310081481934,
      "learning_rate": 4.81998434646491e-05,
      "loss": 0.0792,
      "step": 27600
    },
    {
      "epoch": 3.6068353769893036,
      "grad_norm": 0.040900468826293945,
      "learning_rate": 4.819658231150535e-05,
      "loss": 0.116,
      "step": 27650
    },
    {
      "epoch": 3.613357683276807,
      "grad_norm": 0.15478961169719696,
      "learning_rate": 4.81933211583616e-05,
      "loss": 0.1055,
      "step": 27700
    },
    {
      "epoch": 3.6198799895643097,
      "grad_norm": 0.20438919961452484,
      "learning_rate": 4.819006000521785e-05,
      "loss": 0.0765,
      "step": 27750
    },
    {
      "epoch": 3.626402295851813,
      "grad_norm": 13.441669464111328,
      "learning_rate": 4.818679885207409e-05,
      "loss": 0.0604,
      "step": 27800
    },
    {
      "epoch": 3.6329246021393162,
      "grad_norm": 0.04033775255084038,
      "learning_rate": 4.818353769893034e-05,
      "loss": 0.1278,
      "step": 27850
    },
    {
      "epoch": 3.6394469084268195,
      "grad_norm": 0.0652599036693573,
      "learning_rate": 4.818027654578659e-05,
      "loss": 0.0717,
      "step": 27900
    },
    {
      "epoch": 3.645969214714323,
      "grad_norm": 0.024938905611634254,
      "learning_rate": 4.8177015392642845e-05,
      "loss": 0.1099,
      "step": 27950
    },
    {
      "epoch": 3.652491521001826,
      "grad_norm": 3.449397563934326,
      "learning_rate": 4.817375423949909e-05,
      "loss": 0.1362,
      "step": 28000
    },
    {
      "epoch": 3.6590138272893293,
      "grad_norm": 9.543269157409668,
      "learning_rate": 4.817049308635534e-05,
      "loss": 0.1746,
      "step": 28050
    },
    {
      "epoch": 3.6655361335768326,
      "grad_norm": 0.030102375894784927,
      "learning_rate": 4.816723193321159e-05,
      "loss": 0.1091,
      "step": 28100
    },
    {
      "epoch": 3.672058439864336,
      "grad_norm": 0.021444594487547874,
      "learning_rate": 4.816397078006784e-05,
      "loss": 0.1427,
      "step": 28150
    },
    {
      "epoch": 3.678580746151839,
      "grad_norm": 0.18901611864566803,
      "learning_rate": 4.816070962692408e-05,
      "loss": 0.0965,
      "step": 28200
    },
    {
      "epoch": 3.6851030524393424,
      "grad_norm": 7.478692054748535,
      "learning_rate": 4.815744847378033e-05,
      "loss": 0.1068,
      "step": 28250
    },
    {
      "epoch": 3.6916253587268457,
      "grad_norm": 0.12528161704540253,
      "learning_rate": 4.815418732063658e-05,
      "loss": 0.1176,
      "step": 28300
    },
    {
      "epoch": 3.698147665014349,
      "grad_norm": 0.07410528510808945,
      "learning_rate": 4.815092616749283e-05,
      "loss": 0.0929,
      "step": 28350
    },
    {
      "epoch": 3.7046699713018523,
      "grad_norm": 18.548076629638672,
      "learning_rate": 4.8147665014349074e-05,
      "loss": 0.1411,
      "step": 28400
    },
    {
      "epoch": 3.7111922775893555,
      "grad_norm": 0.06842046231031418,
      "learning_rate": 4.814440386120532e-05,
      "loss": 0.1326,
      "step": 28450
    },
    {
      "epoch": 3.717714583876859,
      "grad_norm": 0.014823468402028084,
      "learning_rate": 4.8141142708061573e-05,
      "loss": 0.1181,
      "step": 28500
    },
    {
      "epoch": 3.724236890164362,
      "grad_norm": 0.9543550610542297,
      "learning_rate": 4.813788155491782e-05,
      "loss": 0.0846,
      "step": 28550
    },
    {
      "epoch": 3.7307591964518654,
      "grad_norm": 5.602874755859375,
      "learning_rate": 4.813462040177407e-05,
      "loss": 0.1238,
      "step": 28600
    },
    {
      "epoch": 3.7372815027393687,
      "grad_norm": 0.607927143573761,
      "learning_rate": 4.813135924863032e-05,
      "loss": 0.1124,
      "step": 28650
    },
    {
      "epoch": 3.743803809026872,
      "grad_norm": 0.21305733919143677,
      "learning_rate": 4.8128098095486565e-05,
      "loss": 0.1657,
      "step": 28700
    },
    {
      "epoch": 3.750326115314375,
      "grad_norm": 1.106113076210022,
      "learning_rate": 4.812483694234282e-05,
      "loss": 0.1178,
      "step": 28750
    },
    {
      "epoch": 3.7568484216018785,
      "grad_norm": 2.8854317665100098,
      "learning_rate": 4.8121575789199064e-05,
      "loss": 0.109,
      "step": 28800
    },
    {
      "epoch": 3.7633707278893818,
      "grad_norm": 11.22216796875,
      "learning_rate": 4.811831463605531e-05,
      "loss": 0.1329,
      "step": 28850
    },
    {
      "epoch": 3.769893034176885,
      "grad_norm": 0.03997145593166351,
      "learning_rate": 4.8115053482911556e-05,
      "loss": 0.1411,
      "step": 28900
    },
    {
      "epoch": 3.7764153404643883,
      "grad_norm": 13.350313186645508,
      "learning_rate": 4.811179232976781e-05,
      "loss": 0.1347,
      "step": 28950
    },
    {
      "epoch": 3.7829376467518916,
      "grad_norm": 0.7297230362892151,
      "learning_rate": 4.8108531176624056e-05,
      "loss": 0.1563,
      "step": 29000
    },
    {
      "epoch": 3.789459953039395,
      "grad_norm": 0.17509619891643524,
      "learning_rate": 4.81052700234803e-05,
      "loss": 0.1447,
      "step": 29050
    },
    {
      "epoch": 3.795982259326898,
      "grad_norm": 0.02902519889175892,
      "learning_rate": 4.810200887033655e-05,
      "loss": 0.0976,
      "step": 29100
    },
    {
      "epoch": 3.8025045656144014,
      "grad_norm": 0.2502838373184204,
      "learning_rate": 4.80987477171928e-05,
      "loss": 0.1426,
      "step": 29150
    },
    {
      "epoch": 3.8090268719019047,
      "grad_norm": 0.16131260991096497,
      "learning_rate": 4.8095486564049054e-05,
      "loss": 0.1235,
      "step": 29200
    },
    {
      "epoch": 3.815549178189408,
      "grad_norm": 17.201107025146484,
      "learning_rate": 4.80922254109053e-05,
      "loss": 0.0956,
      "step": 29250
    },
    {
      "epoch": 3.8220714844769113,
      "grad_norm": 0.05774306505918503,
      "learning_rate": 4.8088964257761546e-05,
      "loss": 0.1309,
      "step": 29300
    },
    {
      "epoch": 3.8285937907644145,
      "grad_norm": 0.07513356953859329,
      "learning_rate": 4.80857031046178e-05,
      "loss": 0.0784,
      "step": 29350
    },
    {
      "epoch": 3.835116097051918,
      "grad_norm": 1.5488439798355103,
      "learning_rate": 4.8082441951474045e-05,
      "loss": 0.1656,
      "step": 29400
    },
    {
      "epoch": 3.841638403339421,
      "grad_norm": 0.01885943114757538,
      "learning_rate": 4.807918079833029e-05,
      "loss": 0.0964,
      "step": 29450
    },
    {
      "epoch": 3.848160709626924,
      "grad_norm": 8.798924446105957,
      "learning_rate": 4.807591964518654e-05,
      "loss": 0.1252,
      "step": 29500
    },
    {
      "epoch": 3.854683015914427,
      "grad_norm": 0.21702001988887787,
      "learning_rate": 4.807265849204279e-05,
      "loss": 0.0995,
      "step": 29550
    },
    {
      "epoch": 3.8612053222019305,
      "grad_norm": 0.1981602907180786,
      "learning_rate": 4.806939733889904e-05,
      "loss": 0.0892,
      "step": 29600
    },
    {
      "epoch": 3.8677276284894337,
      "grad_norm": 12.993474960327148,
      "learning_rate": 4.806613618575528e-05,
      "loss": 0.1279,
      "step": 29650
    },
    {
      "epoch": 3.874249934776937,
      "grad_norm": 0.04082448035478592,
      "learning_rate": 4.806287503261153e-05,
      "loss": 0.0726,
      "step": 29700
    },
    {
      "epoch": 3.8807722410644403,
      "grad_norm": 8.597990989685059,
      "learning_rate": 4.805961387946778e-05,
      "loss": 0.0886,
      "step": 29750
    },
    {
      "epoch": 3.8872945473519436,
      "grad_norm": 5.476086616516113,
      "learning_rate": 4.8056352726324035e-05,
      "loss": 0.0932,
      "step": 29800
    },
    {
      "epoch": 3.893816853639447,
      "grad_norm": 11.478145599365234,
      "learning_rate": 4.805309157318028e-05,
      "loss": 0.1488,
      "step": 29850
    },
    {
      "epoch": 3.90033915992695,
      "grad_norm": 1.6870118379592896,
      "learning_rate": 4.804983042003653e-05,
      "loss": 0.1469,
      "step": 29900
    },
    {
      "epoch": 3.9068614662144534,
      "grad_norm": 3.0259110927581787,
      "learning_rate": 4.8046569266892774e-05,
      "loss": 0.1737,
      "step": 29950
    },
    {
      "epoch": 3.9133837725019567,
      "grad_norm": 0.03052356466650963,
      "learning_rate": 4.804330811374903e-05,
      "loss": 0.0992,
      "step": 30000
    },
    {
      "epoch": 3.91990607878946,
      "grad_norm": 0.04214174672961235,
      "learning_rate": 4.804004696060527e-05,
      "loss": 0.1207,
      "step": 30050
    },
    {
      "epoch": 3.9264283850769632,
      "grad_norm": 0.14747658371925354,
      "learning_rate": 4.803678580746152e-05,
      "loss": 0.1403,
      "step": 30100
    },
    {
      "epoch": 3.9329506913644665,
      "grad_norm": 0.022873176261782646,
      "learning_rate": 4.8033524654317765e-05,
      "loss": 0.1112,
      "step": 30150
    },
    {
      "epoch": 3.93947299765197,
      "grad_norm": 0.1265159696340561,
      "learning_rate": 4.803026350117402e-05,
      "loss": 0.1519,
      "step": 30200
    },
    {
      "epoch": 3.945995303939473,
      "grad_norm": 13.509907722473145,
      "learning_rate": 4.8027002348030264e-05,
      "loss": 0.1289,
      "step": 30250
    },
    {
      "epoch": 3.9525176102269763,
      "grad_norm": 0.01881665363907814,
      "learning_rate": 4.802374119488651e-05,
      "loss": 0.1257,
      "step": 30300
    },
    {
      "epoch": 3.9590399165144796,
      "grad_norm": 0.17576979100704193,
      "learning_rate": 4.8020480041742764e-05,
      "loss": 0.0815,
      "step": 30350
    },
    {
      "epoch": 3.965562222801983,
      "grad_norm": 0.006326934322714806,
      "learning_rate": 4.801721888859901e-05,
      "loss": 0.1392,
      "step": 30400
    },
    {
      "epoch": 3.972084529089486,
      "grad_norm": 0.06365787237882614,
      "learning_rate": 4.801395773545526e-05,
      "loss": 0.1278,
      "step": 30450
    },
    {
      "epoch": 3.9786068353769894,
      "grad_norm": 0.4555409550666809,
      "learning_rate": 4.801069658231151e-05,
      "loss": 0.1215,
      "step": 30500
    },
    {
      "epoch": 3.9851291416644927,
      "grad_norm": 0.14541901648044586,
      "learning_rate": 4.8007435429167755e-05,
      "loss": 0.1023,
      "step": 30550
    },
    {
      "epoch": 3.9916514479519956,
      "grad_norm": 0.040449488908052444,
      "learning_rate": 4.800417427602401e-05,
      "loss": 0.1332,
      "step": 30600
    },
    {
      "epoch": 3.998173754239499,
      "grad_norm": 0.08085238933563232,
      "learning_rate": 4.8000913122880254e-05,
      "loss": 0.112,
      "step": 30650
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9585181320114793,
      "eval_f1": 0.957605652579656,
      "eval_loss": 0.14695990085601807,
      "eval_precision": 0.97941096263976,
      "eval_recall": 0.9367501304121022,
      "eval_runtime": 27.0816,
      "eval_samples_per_second": 566.141,
      "eval_steps_per_second": 70.786,
      "step": 30664
    },
    {
      "epoch": 4.004696060527002,
      "grad_norm": 0.8171015977859497,
      "learning_rate": 4.79976519697365e-05,
      "loss": 0.077,
      "step": 30700
    },
    {
      "epoch": 4.011218366814505,
      "grad_norm": 15.108087539672852,
      "learning_rate": 4.7994390816592747e-05,
      "loss": 0.1751,
      "step": 30750
    },
    {
      "epoch": 4.017740673102009,
      "grad_norm": 0.16200505197048187,
      "learning_rate": 4.7991129663449e-05,
      "loss": 0.0828,
      "step": 30800
    },
    {
      "epoch": 4.024262979389512,
      "grad_norm": 0.42507311701774597,
      "learning_rate": 4.7987868510305246e-05,
      "loss": 0.091,
      "step": 30850
    },
    {
      "epoch": 4.030785285677015,
      "grad_norm": 15.672708511352539,
      "learning_rate": 4.798460735716149e-05,
      "loss": 0.1013,
      "step": 30900
    },
    {
      "epoch": 4.0373075919645185,
      "grad_norm": 0.1595926731824875,
      "learning_rate": 4.798134620401774e-05,
      "loss": 0.1096,
      "step": 30950
    },
    {
      "epoch": 4.043829898252022,
      "grad_norm": 0.03346388414502144,
      "learning_rate": 4.797808505087399e-05,
      "loss": 0.1361,
      "step": 31000
    },
    {
      "epoch": 4.050352204539525,
      "grad_norm": 8.909187316894531,
      "learning_rate": 4.7974823897730244e-05,
      "loss": 0.0745,
      "step": 31050
    },
    {
      "epoch": 4.056874510827028,
      "grad_norm": 12.045482635498047,
      "learning_rate": 4.797156274458649e-05,
      "loss": 0.1032,
      "step": 31100
    },
    {
      "epoch": 4.063396817114532,
      "grad_norm": 2.6914291381835938,
      "learning_rate": 4.7968301591442736e-05,
      "loss": 0.1203,
      "step": 31150
    },
    {
      "epoch": 4.069919123402035,
      "grad_norm": 3.8051021099090576,
      "learning_rate": 4.796504043829899e-05,
      "loss": 0.0775,
      "step": 31200
    },
    {
      "epoch": 4.076441429689538,
      "grad_norm": 6.156591892242432,
      "learning_rate": 4.7961779285155235e-05,
      "loss": 0.111,
      "step": 31250
    },
    {
      "epoch": 4.082963735977041,
      "grad_norm": 0.1378464698791504,
      "learning_rate": 4.795851813201148e-05,
      "loss": 0.0919,
      "step": 31300
    },
    {
      "epoch": 4.089486042264545,
      "grad_norm": 16.64385986328125,
      "learning_rate": 4.795525697886773e-05,
      "loss": 0.1634,
      "step": 31350
    },
    {
      "epoch": 4.096008348552048,
      "grad_norm": 0.8820328116416931,
      "learning_rate": 4.795199582572398e-05,
      "loss": 0.1079,
      "step": 31400
    },
    {
      "epoch": 4.102530654839551,
      "grad_norm": 14.81922721862793,
      "learning_rate": 4.794873467258023e-05,
      "loss": 0.0526,
      "step": 31450
    },
    {
      "epoch": 4.1090529611270545,
      "grad_norm": 1.698403239250183,
      "learning_rate": 4.794547351943647e-05,
      "loss": 0.134,
      "step": 31500
    },
    {
      "epoch": 4.115575267414558,
      "grad_norm": 0.043372511863708496,
      "learning_rate": 4.794221236629272e-05,
      "loss": 0.1101,
      "step": 31550
    },
    {
      "epoch": 4.122097573702061,
      "grad_norm": 0.026290766894817352,
      "learning_rate": 4.793895121314897e-05,
      "loss": 0.1194,
      "step": 31600
    },
    {
      "epoch": 4.128619879989564,
      "grad_norm": 0.32722020149230957,
      "learning_rate": 4.7935690060005225e-05,
      "loss": 0.0903,
      "step": 31650
    },
    {
      "epoch": 4.135142186277068,
      "grad_norm": 13.258179664611816,
      "learning_rate": 4.793242890686147e-05,
      "loss": 0.1504,
      "step": 31700
    },
    {
      "epoch": 4.141664492564571,
      "grad_norm": 14.6251859664917,
      "learning_rate": 4.792916775371772e-05,
      "loss": 0.0994,
      "step": 31750
    },
    {
      "epoch": 4.148186798852074,
      "grad_norm": 0.014679895713925362,
      "learning_rate": 4.7925906600573964e-05,
      "loss": 0.1297,
      "step": 31800
    },
    {
      "epoch": 4.1547091051395775,
      "grad_norm": 0.03883162513375282,
      "learning_rate": 4.792264544743022e-05,
      "loss": 0.0873,
      "step": 31850
    },
    {
      "epoch": 4.161231411427081,
      "grad_norm": 0.0965283215045929,
      "learning_rate": 4.791938429428646e-05,
      "loss": 0.1106,
      "step": 31900
    },
    {
      "epoch": 4.167753717714584,
      "grad_norm": 0.02751658856868744,
      "learning_rate": 4.791612314114271e-05,
      "loss": 0.1256,
      "step": 31950
    },
    {
      "epoch": 4.174276024002087,
      "grad_norm": 0.5519434213638306,
      "learning_rate": 4.7912861987998955e-05,
      "loss": 0.1092,
      "step": 32000
    },
    {
      "epoch": 4.180798330289591,
      "grad_norm": 10.26736831665039,
      "learning_rate": 4.790960083485521e-05,
      "loss": 0.1863,
      "step": 32050
    },
    {
      "epoch": 4.187320636577094,
      "grad_norm": 7.935031890869141,
      "learning_rate": 4.7906339681711454e-05,
      "loss": 0.1541,
      "step": 32100
    },
    {
      "epoch": 4.193842942864597,
      "grad_norm": 0.03899597376585007,
      "learning_rate": 4.79030785285677e-05,
      "loss": 0.1045,
      "step": 32150
    },
    {
      "epoch": 4.2003652491521,
      "grad_norm": 0.09322908520698547,
      "learning_rate": 4.789981737542395e-05,
      "loss": 0.1394,
      "step": 32200
    },
    {
      "epoch": 4.206887555439604,
      "grad_norm": 0.038495298475027084,
      "learning_rate": 4.7896556222280207e-05,
      "loss": 0.1265,
      "step": 32250
    },
    {
      "epoch": 4.213409861727107,
      "grad_norm": 0.15378449857234955,
      "learning_rate": 4.789329506913645e-05,
      "loss": 0.1065,
      "step": 32300
    },
    {
      "epoch": 4.21993216801461,
      "grad_norm": 0.6186784505844116,
      "learning_rate": 4.78900339159927e-05,
      "loss": 0.1326,
      "step": 32350
    },
    {
      "epoch": 4.2264544743021135,
      "grad_norm": 0.7158569693565369,
      "learning_rate": 4.7886772762848945e-05,
      "loss": 0.1274,
      "step": 32400
    },
    {
      "epoch": 4.232976780589617,
      "grad_norm": 0.27956143021583557,
      "learning_rate": 4.78835116097052e-05,
      "loss": 0.0612,
      "step": 32450
    },
    {
      "epoch": 4.23949908687712,
      "grad_norm": 0.019935550168156624,
      "learning_rate": 4.7880250456561444e-05,
      "loss": 0.0704,
      "step": 32500
    },
    {
      "epoch": 4.246021393164623,
      "grad_norm": 0.013302678242325783,
      "learning_rate": 4.787698930341769e-05,
      "loss": 0.1202,
      "step": 32550
    },
    {
      "epoch": 4.252543699452127,
      "grad_norm": 0.010548794642090797,
      "learning_rate": 4.787372815027394e-05,
      "loss": 0.1499,
      "step": 32600
    },
    {
      "epoch": 4.25906600573963,
      "grad_norm": 0.05843920633196831,
      "learning_rate": 4.787046699713019e-05,
      "loss": 0.1089,
      "step": 32650
    },
    {
      "epoch": 4.265588312027133,
      "grad_norm": 0.02939155511558056,
      "learning_rate": 4.7867205843986436e-05,
      "loss": 0.1528,
      "step": 32700
    },
    {
      "epoch": 4.2721106183146365,
      "grad_norm": 3.9033756256103516,
      "learning_rate": 4.786394469084268e-05,
      "loss": 0.1146,
      "step": 32750
    },
    {
      "epoch": 4.27863292460214,
      "grad_norm": 0.8185054063796997,
      "learning_rate": 4.786068353769893e-05,
      "loss": 0.1251,
      "step": 32800
    },
    {
      "epoch": 4.285155230889643,
      "grad_norm": 6.1971755027771,
      "learning_rate": 4.785742238455518e-05,
      "loss": 0.1015,
      "step": 32850
    },
    {
      "epoch": 4.291677537177145,
      "grad_norm": 1.3708956241607666,
      "learning_rate": 4.7854161231411434e-05,
      "loss": 0.0735,
      "step": 32900
    },
    {
      "epoch": 4.29819984346465,
      "grad_norm": 0.27618592977523804,
      "learning_rate": 4.785090007826768e-05,
      "loss": 0.0922,
      "step": 32950
    },
    {
      "epoch": 4.304722149752152,
      "grad_norm": 8.292909622192383,
      "learning_rate": 4.7847638925123926e-05,
      "loss": 0.1185,
      "step": 33000
    },
    {
      "epoch": 4.311244456039655,
      "grad_norm": 10.738866806030273,
      "learning_rate": 4.784437777198017e-05,
      "loss": 0.109,
      "step": 33050
    },
    {
      "epoch": 4.3177667623271585,
      "grad_norm": 0.11923936009407043,
      "learning_rate": 4.7841116618836426e-05,
      "loss": 0.1112,
      "step": 33100
    },
    {
      "epoch": 4.324289068614662,
      "grad_norm": 19.13982582092285,
      "learning_rate": 4.783785546569267e-05,
      "loss": 0.1192,
      "step": 33150
    },
    {
      "epoch": 4.330811374902165,
      "grad_norm": 17.03771209716797,
      "learning_rate": 4.783459431254892e-05,
      "loss": 0.0935,
      "step": 33200
    },
    {
      "epoch": 4.337333681189668,
      "grad_norm": 0.07226201146841049,
      "learning_rate": 4.7831333159405164e-05,
      "loss": 0.1362,
      "step": 33250
    },
    {
      "epoch": 4.343855987477172,
      "grad_norm": 12.779220581054688,
      "learning_rate": 4.782807200626142e-05,
      "loss": 0.0945,
      "step": 33300
    },
    {
      "epoch": 4.350378293764675,
      "grad_norm": 15.128331184387207,
      "learning_rate": 4.782481085311766e-05,
      "loss": 0.1266,
      "step": 33350
    },
    {
      "epoch": 4.356900600052178,
      "grad_norm": 0.04902809485793114,
      "learning_rate": 4.782154969997391e-05,
      "loss": 0.0594,
      "step": 33400
    },
    {
      "epoch": 4.363422906339681,
      "grad_norm": 0.2101689726114273,
      "learning_rate": 4.7818288546830156e-05,
      "loss": 0.1411,
      "step": 33450
    },
    {
      "epoch": 4.369945212627185,
      "grad_norm": 0.38658469915390015,
      "learning_rate": 4.7815027393686415e-05,
      "loss": 0.099,
      "step": 33500
    },
    {
      "epoch": 4.376467518914688,
      "grad_norm": 0.014130200259387493,
      "learning_rate": 4.781176624054266e-05,
      "loss": 0.1546,
      "step": 33550
    },
    {
      "epoch": 4.382989825202191,
      "grad_norm": 0.0186244435608387,
      "learning_rate": 4.780850508739891e-05,
      "loss": 0.1056,
      "step": 33600
    },
    {
      "epoch": 4.3895121314896945,
      "grad_norm": 15.507847785949707,
      "learning_rate": 4.7805243934255154e-05,
      "loss": 0.1116,
      "step": 33650
    },
    {
      "epoch": 4.396034437777198,
      "grad_norm": 0.09062898904085159,
      "learning_rate": 4.780198278111141e-05,
      "loss": 0.1202,
      "step": 33700
    },
    {
      "epoch": 4.402556744064701,
      "grad_norm": 12.779808044433594,
      "learning_rate": 4.779872162796765e-05,
      "loss": 0.1689,
      "step": 33750
    },
    {
      "epoch": 4.409079050352204,
      "grad_norm": 0.9279221892356873,
      "learning_rate": 4.77954604748239e-05,
      "loss": 0.1165,
      "step": 33800
    },
    {
      "epoch": 4.415601356639708,
      "grad_norm": 1.3627320528030396,
      "learning_rate": 4.7792199321680145e-05,
      "loss": 0.1229,
      "step": 33850
    },
    {
      "epoch": 4.422123662927211,
      "grad_norm": 0.07705621421337128,
      "learning_rate": 4.77889381685364e-05,
      "loss": 0.1254,
      "step": 33900
    },
    {
      "epoch": 4.428645969214714,
      "grad_norm": 0.037564363330602646,
      "learning_rate": 4.7785677015392645e-05,
      "loss": 0.1345,
      "step": 33950
    },
    {
      "epoch": 4.4351682755022175,
      "grad_norm": 19.40177345275879,
      "learning_rate": 4.778241586224889e-05,
      "loss": 0.1144,
      "step": 34000
    },
    {
      "epoch": 4.441690581789721,
      "grad_norm": 0.0474248006939888,
      "learning_rate": 4.777915470910514e-05,
      "loss": 0.1539,
      "step": 34050
    },
    {
      "epoch": 4.448212888077224,
      "grad_norm": 0.034299012273550034,
      "learning_rate": 4.777589355596139e-05,
      "loss": 0.1031,
      "step": 34100
    },
    {
      "epoch": 4.454735194364727,
      "grad_norm": 0.0501970537006855,
      "learning_rate": 4.777263240281764e-05,
      "loss": 0.0849,
      "step": 34150
    },
    {
      "epoch": 4.461257500652231,
      "grad_norm": 14.382023811340332,
      "learning_rate": 4.776937124967389e-05,
      "loss": 0.1101,
      "step": 34200
    },
    {
      "epoch": 4.467779806939734,
      "grad_norm": 2.500593423843384,
      "learning_rate": 4.7766110096530135e-05,
      "loss": 0.1385,
      "step": 34250
    },
    {
      "epoch": 4.474302113227237,
      "grad_norm": 10.254659652709961,
      "learning_rate": 4.776284894338638e-05,
      "loss": 0.1189,
      "step": 34300
    },
    {
      "epoch": 4.48082441951474,
      "grad_norm": 0.15580013394355774,
      "learning_rate": 4.7759587790242634e-05,
      "loss": 0.1622,
      "step": 34350
    },
    {
      "epoch": 4.487346725802244,
      "grad_norm": 3.6884515285491943,
      "learning_rate": 4.775632663709888e-05,
      "loss": 0.0695,
      "step": 34400
    },
    {
      "epoch": 4.493869032089747,
      "grad_norm": 0.08468830585479736,
      "learning_rate": 4.775306548395513e-05,
      "loss": 0.0919,
      "step": 34450
    },
    {
      "epoch": 4.50039133837725,
      "grad_norm": 0.0370466448366642,
      "learning_rate": 4.774980433081137e-05,
      "loss": 0.129,
      "step": 34500
    },
    {
      "epoch": 4.5069136446647535,
      "grad_norm": 0.2928506135940552,
      "learning_rate": 4.7746543177667626e-05,
      "loss": 0.1001,
      "step": 34550
    },
    {
      "epoch": 4.513435950952257,
      "grad_norm": 0.04135274887084961,
      "learning_rate": 4.774328202452387e-05,
      "loss": 0.1106,
      "step": 34600
    },
    {
      "epoch": 4.51995825723976,
      "grad_norm": 0.25973445177078247,
      "learning_rate": 4.774002087138012e-05,
      "loss": 0.0975,
      "step": 34650
    },
    {
      "epoch": 4.526480563527263,
      "grad_norm": 0.6671241521835327,
      "learning_rate": 4.773675971823637e-05,
      "loss": 0.1338,
      "step": 34700
    },
    {
      "epoch": 4.533002869814767,
      "grad_norm": 0.24549400806427002,
      "learning_rate": 4.7733498565092624e-05,
      "loss": 0.0944,
      "step": 34750
    },
    {
      "epoch": 4.53952517610227,
      "grad_norm": 4.706800937652588,
      "learning_rate": 4.773023741194887e-05,
      "loss": 0.1146,
      "step": 34800
    },
    {
      "epoch": 4.546047482389773,
      "grad_norm": 0.2258986234664917,
      "learning_rate": 4.7726976258805117e-05,
      "loss": 0.1247,
      "step": 34850
    },
    {
      "epoch": 4.5525697886772765,
      "grad_norm": 0.18203143775463104,
      "learning_rate": 4.772371510566136e-05,
      "loss": 0.1308,
      "step": 34900
    },
    {
      "epoch": 4.55909209496478,
      "grad_norm": 0.02733200043439865,
      "learning_rate": 4.7720453952517616e-05,
      "loss": 0.064,
      "step": 34950
    },
    {
      "epoch": 4.565614401252283,
      "grad_norm": 13.568702697753906,
      "learning_rate": 4.771719279937386e-05,
      "loss": 0.1371,
      "step": 35000
    },
    {
      "epoch": 4.572136707539786,
      "grad_norm": 0.09597769379615784,
      "learning_rate": 4.771393164623011e-05,
      "loss": 0.0822,
      "step": 35050
    },
    {
      "epoch": 4.57865901382729,
      "grad_norm": 0.01220439001917839,
      "learning_rate": 4.7710670493086354e-05,
      "loss": 0.1201,
      "step": 35100
    },
    {
      "epoch": 4.585181320114793,
      "grad_norm": 4.188328742980957,
      "learning_rate": 4.770740933994261e-05,
      "loss": 0.1721,
      "step": 35150
    },
    {
      "epoch": 4.591703626402296,
      "grad_norm": 0.026982055976986885,
      "learning_rate": 4.770414818679885e-05,
      "loss": 0.0814,
      "step": 35200
    },
    {
      "epoch": 4.598225932689799,
      "grad_norm": 0.18434926867485046,
      "learning_rate": 4.77008870336551e-05,
      "loss": 0.0557,
      "step": 35250
    },
    {
      "epoch": 4.604748238977303,
      "grad_norm": 0.675886332988739,
      "learning_rate": 4.7697625880511346e-05,
      "loss": 0.0881,
      "step": 35300
    },
    {
      "epoch": 4.611270545264806,
      "grad_norm": 14.389206886291504,
      "learning_rate": 4.76943647273676e-05,
      "loss": 0.0924,
      "step": 35350
    },
    {
      "epoch": 4.617792851552309,
      "grad_norm": 0.04566190391778946,
      "learning_rate": 4.769110357422385e-05,
      "loss": 0.0986,
      "step": 35400
    },
    {
      "epoch": 4.6243151578398125,
      "grad_norm": 0.17212925851345062,
      "learning_rate": 4.76878424210801e-05,
      "loss": 0.1643,
      "step": 35450
    },
    {
      "epoch": 4.630837464127316,
      "grad_norm": 0.07682927697896957,
      "learning_rate": 4.7684581267936344e-05,
      "loss": 0.1251,
      "step": 35500
    },
    {
      "epoch": 4.637359770414819,
      "grad_norm": 11.173455238342285,
      "learning_rate": 4.76813201147926e-05,
      "loss": 0.1448,
      "step": 35550
    },
    {
      "epoch": 4.643882076702322,
      "grad_norm": 0.07809271663427353,
      "learning_rate": 4.767805896164884e-05,
      "loss": 0.0867,
      "step": 35600
    },
    {
      "epoch": 4.650404382989825,
      "grad_norm": 5.980954170227051,
      "learning_rate": 4.767479780850509e-05,
      "loss": 0.1105,
      "step": 35650
    },
    {
      "epoch": 4.656926689277329,
      "grad_norm": 0.016922740265727043,
      "learning_rate": 4.7671536655361335e-05,
      "loss": 0.1347,
      "step": 35700
    },
    {
      "epoch": 4.663448995564831,
      "grad_norm": 1.1334666013717651,
      "learning_rate": 4.766827550221759e-05,
      "loss": 0.1307,
      "step": 35750
    },
    {
      "epoch": 4.669971301852335,
      "grad_norm": 10.926126480102539,
      "learning_rate": 4.7665014349073835e-05,
      "loss": 0.1375,
      "step": 35800
    },
    {
      "epoch": 4.676493608139838,
      "grad_norm": 0.026312053203582764,
      "learning_rate": 4.766175319593008e-05,
      "loss": 0.0669,
      "step": 35850
    },
    {
      "epoch": 4.683015914427342,
      "grad_norm": 19.43301773071289,
      "learning_rate": 4.765849204278633e-05,
      "loss": 0.1266,
      "step": 35900
    },
    {
      "epoch": 4.689538220714844,
      "grad_norm": 0.018246393650770187,
      "learning_rate": 4.765523088964258e-05,
      "loss": 0.1157,
      "step": 35950
    },
    {
      "epoch": 4.696060527002348,
      "grad_norm": 2.298530340194702,
      "learning_rate": 4.765196973649883e-05,
      "loss": 0.1579,
      "step": 36000
    },
    {
      "epoch": 4.702582833289851,
      "grad_norm": 0.2374657690525055,
      "learning_rate": 4.764870858335508e-05,
      "loss": 0.0503,
      "step": 36050
    },
    {
      "epoch": 4.709105139577354,
      "grad_norm": 0.02911572903394699,
      "learning_rate": 4.7645447430211325e-05,
      "loss": 0.1369,
      "step": 36100
    },
    {
      "epoch": 4.7156274458648575,
      "grad_norm": 0.011043923906981945,
      "learning_rate": 4.764218627706757e-05,
      "loss": 0.1413,
      "step": 36150
    },
    {
      "epoch": 4.722149752152361,
      "grad_norm": 6.981532096862793,
      "learning_rate": 4.7638925123923824e-05,
      "loss": 0.1143,
      "step": 36200
    },
    {
      "epoch": 4.728672058439864,
      "grad_norm": 0.01118177454918623,
      "learning_rate": 4.763566397078007e-05,
      "loss": 0.0654,
      "step": 36250
    },
    {
      "epoch": 4.735194364727367,
      "grad_norm": 0.089815154671669,
      "learning_rate": 4.763240281763632e-05,
      "loss": 0.0639,
      "step": 36300
    },
    {
      "epoch": 4.741716671014871,
      "grad_norm": 0.3620584011077881,
      "learning_rate": 4.762914166449256e-05,
      "loss": 0.1106,
      "step": 36350
    },
    {
      "epoch": 4.748238977302374,
      "grad_norm": 0.040415793657302856,
      "learning_rate": 4.7625880511348816e-05,
      "loss": 0.1512,
      "step": 36400
    },
    {
      "epoch": 4.754761283589877,
      "grad_norm": 11.325450897216797,
      "learning_rate": 4.762261935820506e-05,
      "loss": 0.123,
      "step": 36450
    },
    {
      "epoch": 4.76128358987738,
      "grad_norm": 0.05129385367035866,
      "learning_rate": 4.761935820506131e-05,
      "loss": 0.0778,
      "step": 36500
    },
    {
      "epoch": 4.767805896164884,
      "grad_norm": 11.556736946105957,
      "learning_rate": 4.761609705191756e-05,
      "loss": 0.0939,
      "step": 36550
    },
    {
      "epoch": 4.774328202452387,
      "grad_norm": 0.0415329709649086,
      "learning_rate": 4.7612835898773814e-05,
      "loss": 0.1728,
      "step": 36600
    },
    {
      "epoch": 4.78085050873989,
      "grad_norm": 0.43891143798828125,
      "learning_rate": 4.760957474563006e-05,
      "loss": 0.0946,
      "step": 36650
    },
    {
      "epoch": 4.7873728150273935,
      "grad_norm": 14.831704139709473,
      "learning_rate": 4.7606313592486307e-05,
      "loss": 0.094,
      "step": 36700
    },
    {
      "epoch": 4.793895121314897,
      "grad_norm": 3.1593239307403564,
      "learning_rate": 4.760305243934255e-05,
      "loss": 0.068,
      "step": 36750
    },
    {
      "epoch": 4.8004174276024,
      "grad_norm": 10.19289779663086,
      "learning_rate": 4.7599791286198806e-05,
      "loss": 0.1003,
      "step": 36800
    },
    {
      "epoch": 4.806939733889903,
      "grad_norm": 0.010504353791475296,
      "learning_rate": 4.759653013305505e-05,
      "loss": 0.1553,
      "step": 36850
    },
    {
      "epoch": 4.813462040177407,
      "grad_norm": 4.559432029724121,
      "learning_rate": 4.75932689799113e-05,
      "loss": 0.0823,
      "step": 36900
    },
    {
      "epoch": 4.81998434646491,
      "grad_norm": 0.019123882055282593,
      "learning_rate": 4.7590007826767544e-05,
      "loss": 0.1244,
      "step": 36950
    },
    {
      "epoch": 4.826506652752413,
      "grad_norm": 0.3439895808696747,
      "learning_rate": 4.75867466736238e-05,
      "loss": 0.1134,
      "step": 37000
    },
    {
      "epoch": 4.8330289590399165,
      "grad_norm": 0.06591805815696716,
      "learning_rate": 4.7583485520480043e-05,
      "loss": 0.0646,
      "step": 37050
    },
    {
      "epoch": 4.83955126532742,
      "grad_norm": 0.8713257312774658,
      "learning_rate": 4.758022436733629e-05,
      "loss": 0.1397,
      "step": 37100
    },
    {
      "epoch": 4.846073571614923,
      "grad_norm": 1.5077283382415771,
      "learning_rate": 4.7576963214192536e-05,
      "loss": 0.1596,
      "step": 37150
    },
    {
      "epoch": 4.852595877902426,
      "grad_norm": 8.378199577331543,
      "learning_rate": 4.757370206104879e-05,
      "loss": 0.0801,
      "step": 37200
    },
    {
      "epoch": 4.85911818418993,
      "grad_norm": 0.005207075271755457,
      "learning_rate": 4.757044090790504e-05,
      "loss": 0.1749,
      "step": 37250
    },
    {
      "epoch": 4.865640490477433,
      "grad_norm": 29.2852725982666,
      "learning_rate": 4.756717975476129e-05,
      "loss": 0.1453,
      "step": 37300
    },
    {
      "epoch": 4.872162796764936,
      "grad_norm": 13.17208480834961,
      "learning_rate": 4.7563918601617534e-05,
      "loss": 0.1558,
      "step": 37350
    },
    {
      "epoch": 4.878685103052439,
      "grad_norm": 0.09559620171785355,
      "learning_rate": 4.756065744847378e-05,
      "loss": 0.1304,
      "step": 37400
    },
    {
      "epoch": 4.885207409339943,
      "grad_norm": 0.7256997227668762,
      "learning_rate": 4.755739629533003e-05,
      "loss": 0.0625,
      "step": 37450
    },
    {
      "epoch": 4.891729715627446,
      "grad_norm": 0.13798056542873383,
      "learning_rate": 4.755413514218628e-05,
      "loss": 0.0725,
      "step": 37500
    },
    {
      "epoch": 4.898252021914949,
      "grad_norm": 0.013691714033484459,
      "learning_rate": 4.7550873989042526e-05,
      "loss": 0.1316,
      "step": 37550
    },
    {
      "epoch": 4.9047743282024525,
      "grad_norm": 0.1791042685508728,
      "learning_rate": 4.754761283589877e-05,
      "loss": 0.0956,
      "step": 37600
    },
    {
      "epoch": 4.911296634489956,
      "grad_norm": 14.668547630310059,
      "learning_rate": 4.7544351682755025e-05,
      "loss": 0.0813,
      "step": 37650
    },
    {
      "epoch": 4.917818940777459,
      "grad_norm": 0.0852779895067215,
      "learning_rate": 4.754109052961127e-05,
      "loss": 0.105,
      "step": 37700
    },
    {
      "epoch": 4.924341247064962,
      "grad_norm": 0.04523483291268349,
      "learning_rate": 4.753782937646752e-05,
      "loss": 0.0531,
      "step": 37750
    },
    {
      "epoch": 4.930863553352466,
      "grad_norm": 0.04254187270998955,
      "learning_rate": 4.753456822332377e-05,
      "loss": 0.0868,
      "step": 37800
    },
    {
      "epoch": 4.937385859639969,
      "grad_norm": 0.061542823910713196,
      "learning_rate": 4.753130707018002e-05,
      "loss": 0.0762,
      "step": 37850
    },
    {
      "epoch": 4.943908165927472,
      "grad_norm": 4.5638427734375,
      "learning_rate": 4.752804591703627e-05,
      "loss": 0.1177,
      "step": 37900
    },
    {
      "epoch": 4.9504304722149755,
      "grad_norm": 0.11317522078752518,
      "learning_rate": 4.7524784763892515e-05,
      "loss": 0.1421,
      "step": 37950
    },
    {
      "epoch": 4.956952778502479,
      "grad_norm": 0.05453682318329811,
      "learning_rate": 4.752152361074876e-05,
      "loss": 0.0744,
      "step": 38000
    },
    {
      "epoch": 4.963475084789982,
      "grad_norm": 0.11887884885072708,
      "learning_rate": 4.7518262457605015e-05,
      "loss": 0.1674,
      "step": 38050
    },
    {
      "epoch": 4.969997391077485,
      "grad_norm": 0.05849141627550125,
      "learning_rate": 4.751500130446126e-05,
      "loss": 0.0852,
      "step": 38100
    },
    {
      "epoch": 4.976519697364989,
      "grad_norm": 10.777227401733398,
      "learning_rate": 4.751174015131751e-05,
      "loss": 0.1536,
      "step": 38150
    },
    {
      "epoch": 4.983042003652492,
      "grad_norm": 0.20349837839603424,
      "learning_rate": 4.750847899817375e-05,
      "loss": 0.0632,
      "step": 38200
    },
    {
      "epoch": 4.989564309939995,
      "grad_norm": 0.041491661220788956,
      "learning_rate": 4.7505217845030006e-05,
      "loss": 0.1196,
      "step": 38250
    },
    {
      "epoch": 4.996086616227498,
      "grad_norm": 0.011202899739146233,
      "learning_rate": 4.750195669188625e-05,
      "loss": 0.1015,
      "step": 38300
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.966084007304983,
      "eval_f1": 0.9660308335510844,
      "eval_loss": 0.11984848976135254,
      "eval_precision": 0.9678010471204188,
      "eval_recall": 0.9642670839853938,
      "eval_runtime": 27.0839,
      "eval_samples_per_second": 566.092,
      "eval_steps_per_second": 70.78,
      "step": 38330
    },
    {
      "epoch": 5.002608922515002,
      "grad_norm": 0.08185367286205292,
      "learning_rate": 4.74986955387425e-05,
      "loss": 0.1133,
      "step": 38350
    },
    {
      "epoch": 5.009131228802505,
      "grad_norm": 0.016274817287921906,
      "learning_rate": 4.749543438559875e-05,
      "loss": 0.081,
      "step": 38400
    },
    {
      "epoch": 5.015653535090008,
      "grad_norm": 0.7282936573028564,
      "learning_rate": 4.7492173232455e-05,
      "loss": 0.0959,
      "step": 38450
    },
    {
      "epoch": 5.0221758413775115,
      "grad_norm": 9.28611946105957,
      "learning_rate": 4.748891207931125e-05,
      "loss": 0.097,
      "step": 38500
    },
    {
      "epoch": 5.028698147665015,
      "grad_norm": 19.571508407592773,
      "learning_rate": 4.74856509261675e-05,
      "loss": 0.1268,
      "step": 38550
    },
    {
      "epoch": 5.035220453952518,
      "grad_norm": 0.05612136423587799,
      "learning_rate": 4.748238977302374e-05,
      "loss": 0.1276,
      "step": 38600
    },
    {
      "epoch": 5.04174276024002,
      "grad_norm": 0.010760024189949036,
      "learning_rate": 4.747912861987999e-05,
      "loss": 0.0831,
      "step": 38650
    },
    {
      "epoch": 5.048265066527524,
      "grad_norm": 0.18116049468517303,
      "learning_rate": 4.747586746673624e-05,
      "loss": 0.1222,
      "step": 38700
    },
    {
      "epoch": 5.054787372815027,
      "grad_norm": 10.744951248168945,
      "learning_rate": 4.747260631359249e-05,
      "loss": 0.1219,
      "step": 38750
    },
    {
      "epoch": 5.06130967910253,
      "grad_norm": 1.7025156021118164,
      "learning_rate": 4.7469345160448734e-05,
      "loss": 0.0562,
      "step": 38800
    },
    {
      "epoch": 5.0678319853900335,
      "grad_norm": 0.048754628747701645,
      "learning_rate": 4.746608400730499e-05,
      "loss": 0.1013,
      "step": 38850
    },
    {
      "epoch": 5.074354291677537,
      "grad_norm": 9.567330360412598,
      "learning_rate": 4.7462822854161233e-05,
      "loss": 0.1178,
      "step": 38900
    },
    {
      "epoch": 5.08087659796504,
      "grad_norm": 9.003628730773926,
      "learning_rate": 4.745956170101748e-05,
      "loss": 0.0801,
      "step": 38950
    },
    {
      "epoch": 5.087398904252543,
      "grad_norm": 17.181324005126953,
      "learning_rate": 4.7456300547873726e-05,
      "loss": 0.0706,
      "step": 39000
    },
    {
      "epoch": 5.093921210540047,
      "grad_norm": 0.1526489108800888,
      "learning_rate": 4.745303939472998e-05,
      "loss": 0.1381,
      "step": 39050
    },
    {
      "epoch": 5.10044351682755,
      "grad_norm": 6.150488376617432,
      "learning_rate": 4.744977824158623e-05,
      "loss": 0.1257,
      "step": 39100
    },
    {
      "epoch": 5.106965823115053,
      "grad_norm": 12.365554809570312,
      "learning_rate": 4.744651708844248e-05,
      "loss": 0.1503,
      "step": 39150
    },
    {
      "epoch": 5.1134881294025565,
      "grad_norm": 0.1329280585050583,
      "learning_rate": 4.7443255935298724e-05,
      "loss": 0.0728,
      "step": 39200
    },
    {
      "epoch": 5.12001043569006,
      "grad_norm": 16.84139060974121,
      "learning_rate": 4.743999478215497e-05,
      "loss": 0.1044,
      "step": 39250
    },
    {
      "epoch": 5.126532741977563,
      "grad_norm": 0.056829508394002914,
      "learning_rate": 4.743673362901122e-05,
      "loss": 0.1347,
      "step": 39300
    },
    {
      "epoch": 5.133055048265066,
      "grad_norm": 0.05334519222378731,
      "learning_rate": 4.743347247586747e-05,
      "loss": 0.0525,
      "step": 39350
    },
    {
      "epoch": 5.13957735455257,
      "grad_norm": 0.1445329487323761,
      "learning_rate": 4.7430211322723716e-05,
      "loss": 0.1003,
      "step": 39400
    },
    {
      "epoch": 5.146099660840073,
      "grad_norm": 0.026415394619107246,
      "learning_rate": 4.742695016957996e-05,
      "loss": 0.1542,
      "step": 39450
    },
    {
      "epoch": 5.152621967127576,
      "grad_norm": 6.833134651184082,
      "learning_rate": 4.7423689016436215e-05,
      "loss": 0.1034,
      "step": 39500
    },
    {
      "epoch": 5.159144273415079,
      "grad_norm": 0.02136288210749626,
      "learning_rate": 4.742042786329246e-05,
      "loss": 0.1061,
      "step": 39550
    },
    {
      "epoch": 5.165666579702583,
      "grad_norm": 0.7924440503120422,
      "learning_rate": 4.741716671014871e-05,
      "loss": 0.1151,
      "step": 39600
    },
    {
      "epoch": 5.172188885990086,
      "grad_norm": 0.007431745063513517,
      "learning_rate": 4.741390555700496e-05,
      "loss": 0.0807,
      "step": 39650
    },
    {
      "epoch": 5.178711192277589,
      "grad_norm": 0.03750301152467728,
      "learning_rate": 4.7410644403861206e-05,
      "loss": 0.1288,
      "step": 39700
    },
    {
      "epoch": 5.1852334985650925,
      "grad_norm": 0.26652365922927856,
      "learning_rate": 4.740738325071746e-05,
      "loss": 0.0715,
      "step": 39750
    },
    {
      "epoch": 5.191755804852596,
      "grad_norm": 14.614816665649414,
      "learning_rate": 4.7404122097573705e-05,
      "loss": 0.1015,
      "step": 39800
    },
    {
      "epoch": 5.198278111140099,
      "grad_norm": 15.373574256896973,
      "learning_rate": 4.740086094442995e-05,
      "loss": 0.1274,
      "step": 39850
    },
    {
      "epoch": 5.204800417427602,
      "grad_norm": 6.4613518714904785,
      "learning_rate": 4.7397599791286205e-05,
      "loss": 0.0882,
      "step": 39900
    },
    {
      "epoch": 5.211322723715106,
      "grad_norm": 16.220726013183594,
      "learning_rate": 4.739433863814245e-05,
      "loss": 0.0625,
      "step": 39950
    },
    {
      "epoch": 5.217845030002609,
      "grad_norm": 7.653876781463623,
      "learning_rate": 4.73910774849987e-05,
      "loss": 0.1408,
      "step": 40000
    },
    {
      "epoch": 5.224367336290112,
      "grad_norm": 0.045365117490291595,
      "learning_rate": 4.738781633185494e-05,
      "loss": 0.1283,
      "step": 40050
    },
    {
      "epoch": 5.2308896425776155,
      "grad_norm": 0.48962894082069397,
      "learning_rate": 4.7384555178711196e-05,
      "loss": 0.0894,
      "step": 40100
    },
    {
      "epoch": 5.237411948865119,
      "grad_norm": 0.5066455602645874,
      "learning_rate": 4.738129402556744e-05,
      "loss": 0.1308,
      "step": 40150
    },
    {
      "epoch": 5.243934255152622,
      "grad_norm": 0.018220949918031693,
      "learning_rate": 4.737803287242369e-05,
      "loss": 0.1486,
      "step": 40200
    },
    {
      "epoch": 5.250456561440125,
      "grad_norm": 13.101410865783691,
      "learning_rate": 4.737477171927994e-05,
      "loss": 0.1779,
      "step": 40250
    },
    {
      "epoch": 5.256978867727629,
      "grad_norm": 1.7691057920455933,
      "learning_rate": 4.737151056613619e-05,
      "loss": 0.0986,
      "step": 40300
    },
    {
      "epoch": 5.263501174015132,
      "grad_norm": 0.49668899178504944,
      "learning_rate": 4.736824941299244e-05,
      "loss": 0.0855,
      "step": 40350
    },
    {
      "epoch": 5.270023480302635,
      "grad_norm": 0.03907535597681999,
      "learning_rate": 4.736498825984869e-05,
      "loss": 0.0748,
      "step": 40400
    },
    {
      "epoch": 5.276545786590138,
      "grad_norm": 0.6381570100784302,
      "learning_rate": 4.736172710670493e-05,
      "loss": 0.09,
      "step": 40450
    },
    {
      "epoch": 5.283068092877642,
      "grad_norm": 0.006262775976210833,
      "learning_rate": 4.735846595356118e-05,
      "loss": 0.1453,
      "step": 40500
    },
    {
      "epoch": 5.289590399165145,
      "grad_norm": 8.81913948059082,
      "learning_rate": 4.735520480041743e-05,
      "loss": 0.0768,
      "step": 40550
    },
    {
      "epoch": 5.296112705452648,
      "grad_norm": 0.25871384143829346,
      "learning_rate": 4.735194364727368e-05,
      "loss": 0.1216,
      "step": 40600
    },
    {
      "epoch": 5.3026350117401515,
      "grad_norm": 0.2383120059967041,
      "learning_rate": 4.7348682494129924e-05,
      "loss": 0.1147,
      "step": 40650
    },
    {
      "epoch": 5.309157318027655,
      "grad_norm": 0.019940486177802086,
      "learning_rate": 4.734542134098617e-05,
      "loss": 0.0909,
      "step": 40700
    },
    {
      "epoch": 5.315679624315158,
      "grad_norm": 23.822721481323242,
      "learning_rate": 4.7342160187842424e-05,
      "loss": 0.0535,
      "step": 40750
    },
    {
      "epoch": 5.322201930602661,
      "grad_norm": 0.11268637329339981,
      "learning_rate": 4.733889903469867e-05,
      "loss": 0.1154,
      "step": 40800
    },
    {
      "epoch": 5.328724236890165,
      "grad_norm": 0.06549278646707535,
      "learning_rate": 4.733563788155492e-05,
      "loss": 0.1484,
      "step": 40850
    },
    {
      "epoch": 5.335246543177668,
      "grad_norm": 0.06281505525112152,
      "learning_rate": 4.733237672841117e-05,
      "loss": 0.1378,
      "step": 40900
    },
    {
      "epoch": 5.341768849465171,
      "grad_norm": 7.572970390319824,
      "learning_rate": 4.732911557526742e-05,
      "loss": 0.0936,
      "step": 40950
    },
    {
      "epoch": 5.348291155752674,
      "grad_norm": 0.021248484030365944,
      "learning_rate": 4.732585442212367e-05,
      "loss": 0.0903,
      "step": 41000
    },
    {
      "epoch": 5.354813462040178,
      "grad_norm": 0.22618986666202545,
      "learning_rate": 4.7322593268979914e-05,
      "loss": 0.0788,
      "step": 41050
    },
    {
      "epoch": 5.361335768327681,
      "grad_norm": 15.612491607666016,
      "learning_rate": 4.731933211583616e-05,
      "loss": 0.0758,
      "step": 41100
    },
    {
      "epoch": 5.367858074615184,
      "grad_norm": 0.014889306388795376,
      "learning_rate": 4.731607096269241e-05,
      "loss": 0.1117,
      "step": 41150
    },
    {
      "epoch": 5.3743803809026875,
      "grad_norm": 0.10545232892036438,
      "learning_rate": 4.731280980954866e-05,
      "loss": 0.0783,
      "step": 41200
    },
    {
      "epoch": 5.380902687190191,
      "grad_norm": 0.02306225337088108,
      "learning_rate": 4.7309548656404906e-05,
      "loss": 0.0721,
      "step": 41250
    },
    {
      "epoch": 5.387424993477694,
      "grad_norm": 0.4415617287158966,
      "learning_rate": 4.730628750326115e-05,
      "loss": 0.1453,
      "step": 41300
    },
    {
      "epoch": 5.393947299765197,
      "grad_norm": 0.19812250137329102,
      "learning_rate": 4.7303026350117405e-05,
      "loss": 0.0877,
      "step": 41350
    },
    {
      "epoch": 5.400469606052701,
      "grad_norm": 0.04361037537455559,
      "learning_rate": 4.729976519697365e-05,
      "loss": 0.1691,
      "step": 41400
    },
    {
      "epoch": 5.406991912340203,
      "grad_norm": 0.1560976654291153,
      "learning_rate": 4.72965040438299e-05,
      "loss": 0.0763,
      "step": 41450
    },
    {
      "epoch": 5.413514218627707,
      "grad_norm": 0.009246661327779293,
      "learning_rate": 4.729324289068615e-05,
      "loss": 0.1019,
      "step": 41500
    },
    {
      "epoch": 5.42003652491521,
      "grad_norm": 23.072248458862305,
      "learning_rate": 4.7289981737542396e-05,
      "loss": 0.1007,
      "step": 41550
    },
    {
      "epoch": 5.426558831202713,
      "grad_norm": 4.136942386627197,
      "learning_rate": 4.728672058439865e-05,
      "loss": 0.1984,
      "step": 41600
    },
    {
      "epoch": 5.433081137490216,
      "grad_norm": 0.08534648269414902,
      "learning_rate": 4.7283459431254896e-05,
      "loss": 0.1319,
      "step": 41650
    },
    {
      "epoch": 5.439603443777719,
      "grad_norm": 0.7726010680198669,
      "learning_rate": 4.728019827811114e-05,
      "loss": 0.1277,
      "step": 41700
    },
    {
      "epoch": 5.446125750065223,
      "grad_norm": 0.011808646842837334,
      "learning_rate": 4.727693712496739e-05,
      "loss": 0.086,
      "step": 41750
    },
    {
      "epoch": 5.452648056352726,
      "grad_norm": 4.664257049560547,
      "learning_rate": 4.727367597182364e-05,
      "loss": 0.1792,
      "step": 41800
    },
    {
      "epoch": 5.459170362640229,
      "grad_norm": 0.30630096793174744,
      "learning_rate": 4.727041481867989e-05,
      "loss": 0.0603,
      "step": 41850
    },
    {
      "epoch": 5.4656926689277325,
      "grad_norm": 0.04114558547735214,
      "learning_rate": 4.726715366553613e-05,
      "loss": 0.1207,
      "step": 41900
    },
    {
      "epoch": 5.472214975215236,
      "grad_norm": 1.208733320236206,
      "learning_rate": 4.726389251239238e-05,
      "loss": 0.0848,
      "step": 41950
    },
    {
      "epoch": 5.478737281502739,
      "grad_norm": 13.435320854187012,
      "learning_rate": 4.726063135924863e-05,
      "loss": 0.0959,
      "step": 42000
    },
    {
      "epoch": 5.485259587790242,
      "grad_norm": 0.03278743103146553,
      "learning_rate": 4.725737020610488e-05,
      "loss": 0.133,
      "step": 42050
    },
    {
      "epoch": 5.491781894077746,
      "grad_norm": 4.853589057922363,
      "learning_rate": 4.725410905296113e-05,
      "loss": 0.1108,
      "step": 42100
    },
    {
      "epoch": 5.498304200365249,
      "grad_norm": 0.05799790099263191,
      "learning_rate": 4.725084789981738e-05,
      "loss": 0.1341,
      "step": 42150
    },
    {
      "epoch": 5.504826506652752,
      "grad_norm": 0.047454871237277985,
      "learning_rate": 4.724758674667363e-05,
      "loss": 0.1251,
      "step": 42200
    },
    {
      "epoch": 5.5113488129402555,
      "grad_norm": 23.702978134155273,
      "learning_rate": 4.724432559352988e-05,
      "loss": 0.1238,
      "step": 42250
    },
    {
      "epoch": 5.517871119227759,
      "grad_norm": 0.05790027603507042,
      "learning_rate": 4.724106444038612e-05,
      "loss": 0.1266,
      "step": 42300
    },
    {
      "epoch": 5.524393425515262,
      "grad_norm": 12.858560562133789,
      "learning_rate": 4.723780328724237e-05,
      "loss": 0.0759,
      "step": 42350
    },
    {
      "epoch": 5.530915731802765,
      "grad_norm": 0.11034851521253586,
      "learning_rate": 4.723454213409862e-05,
      "loss": 0.0761,
      "step": 42400
    },
    {
      "epoch": 5.537438038090269,
      "grad_norm": 0.1292518973350525,
      "learning_rate": 4.723128098095487e-05,
      "loss": 0.0925,
      "step": 42450
    },
    {
      "epoch": 5.543960344377772,
      "grad_norm": 0.046767544001340866,
      "learning_rate": 4.7228019827811115e-05,
      "loss": 0.0794,
      "step": 42500
    },
    {
      "epoch": 5.550482650665275,
      "grad_norm": 9.430322647094727,
      "learning_rate": 4.722475867466736e-05,
      "loss": 0.0892,
      "step": 42550
    },
    {
      "epoch": 5.557004956952778,
      "grad_norm": 0.046071913093328476,
      "learning_rate": 4.7221497521523614e-05,
      "loss": 0.0604,
      "step": 42600
    },
    {
      "epoch": 5.563527263240282,
      "grad_norm": 0.4276888966560364,
      "learning_rate": 4.721823636837986e-05,
      "loss": 0.1121,
      "step": 42650
    },
    {
      "epoch": 5.570049569527785,
      "grad_norm": 10.576674461364746,
      "learning_rate": 4.721497521523611e-05,
      "loss": 0.1056,
      "step": 42700
    },
    {
      "epoch": 5.576571875815288,
      "grad_norm": 2.0860517024993896,
      "learning_rate": 4.721171406209236e-05,
      "loss": 0.1274,
      "step": 42750
    },
    {
      "epoch": 5.5830941821027915,
      "grad_norm": 33.27995681762695,
      "learning_rate": 4.7208452908948605e-05,
      "loss": 0.062,
      "step": 42800
    },
    {
      "epoch": 5.589616488390295,
      "grad_norm": 0.004875952377915382,
      "learning_rate": 4.720519175580486e-05,
      "loss": 0.1337,
      "step": 42850
    },
    {
      "epoch": 5.596138794677798,
      "grad_norm": 0.14914433658123016,
      "learning_rate": 4.7201930602661104e-05,
      "loss": 0.0743,
      "step": 42900
    },
    {
      "epoch": 5.602661100965301,
      "grad_norm": 0.03677184134721756,
      "learning_rate": 4.719866944951735e-05,
      "loss": 0.1322,
      "step": 42950
    },
    {
      "epoch": 5.609183407252805,
      "grad_norm": 0.047699663788080215,
      "learning_rate": 4.71954082963736e-05,
      "loss": 0.0956,
      "step": 43000
    },
    {
      "epoch": 5.615705713540308,
      "grad_norm": 0.08812308311462402,
      "learning_rate": 4.719214714322985e-05,
      "loss": 0.0586,
      "step": 43050
    },
    {
      "epoch": 5.622228019827811,
      "grad_norm": 0.39855286478996277,
      "learning_rate": 4.7188885990086096e-05,
      "loss": 0.1466,
      "step": 43100
    },
    {
      "epoch": 5.6287503261153145,
      "grad_norm": 0.018702831119298935,
      "learning_rate": 4.718562483694234e-05,
      "loss": 0.0863,
      "step": 43150
    },
    {
      "epoch": 5.635272632402818,
      "grad_norm": 0.007676202803850174,
      "learning_rate": 4.7182363683798595e-05,
      "loss": 0.0883,
      "step": 43200
    },
    {
      "epoch": 5.641794938690321,
      "grad_norm": 23.67412757873535,
      "learning_rate": 4.717910253065484e-05,
      "loss": 0.0769,
      "step": 43250
    },
    {
      "epoch": 5.648317244977824,
      "grad_norm": 0.007784701883792877,
      "learning_rate": 4.717584137751109e-05,
      "loss": 0.0991,
      "step": 43300
    },
    {
      "epoch": 5.654839551265328,
      "grad_norm": 0.20228853821754456,
      "learning_rate": 4.717258022436734e-05,
      "loss": 0.0879,
      "step": 43350
    },
    {
      "epoch": 5.661361857552831,
      "grad_norm": 4.751634120941162,
      "learning_rate": 4.7169319071223586e-05,
      "loss": 0.081,
      "step": 43400
    },
    {
      "epoch": 5.667884163840334,
      "grad_norm": 0.11185550689697266,
      "learning_rate": 4.716605791807984e-05,
      "loss": 0.1029,
      "step": 43450
    },
    {
      "epoch": 5.674406470127837,
      "grad_norm": 0.011530839838087559,
      "learning_rate": 4.7162796764936086e-05,
      "loss": 0.1078,
      "step": 43500
    },
    {
      "epoch": 5.680928776415341,
      "grad_norm": 0.06360449641942978,
      "learning_rate": 4.715953561179233e-05,
      "loss": 0.1114,
      "step": 43550
    },
    {
      "epoch": 5.687451082702844,
      "grad_norm": 4.042237281799316,
      "learning_rate": 4.715627445864858e-05,
      "loss": 0.1023,
      "step": 43600
    },
    {
      "epoch": 5.693973388990347,
      "grad_norm": 0.029581524431705475,
      "learning_rate": 4.715301330550483e-05,
      "loss": 0.101,
      "step": 43650
    },
    {
      "epoch": 5.7004956952778505,
      "grad_norm": 0.5738285183906555,
      "learning_rate": 4.714975215236108e-05,
      "loss": 0.1247,
      "step": 43700
    },
    {
      "epoch": 5.707018001565354,
      "grad_norm": 0.05854681879281998,
      "learning_rate": 4.714649099921732e-05,
      "loss": 0.1159,
      "step": 43750
    },
    {
      "epoch": 5.713540307852857,
      "grad_norm": 0.1401919573545456,
      "learning_rate": 4.714322984607357e-05,
      "loss": 0.1264,
      "step": 43800
    },
    {
      "epoch": 5.72006261414036,
      "grad_norm": 1.8122695684432983,
      "learning_rate": 4.713996869292982e-05,
      "loss": 0.1519,
      "step": 43850
    },
    {
      "epoch": 5.726584920427864,
      "grad_norm": 0.1131657138466835,
      "learning_rate": 4.713670753978607e-05,
      "loss": 0.0644,
      "step": 43900
    },
    {
      "epoch": 5.733107226715367,
      "grad_norm": 15.53213119506836,
      "learning_rate": 4.713344638664232e-05,
      "loss": 0.0631,
      "step": 43950
    },
    {
      "epoch": 5.73962953300287,
      "grad_norm": 0.13841129839420319,
      "learning_rate": 4.713018523349857e-05,
      "loss": 0.1738,
      "step": 44000
    },
    {
      "epoch": 5.746151839290373,
      "grad_norm": 0.009021138772368431,
      "learning_rate": 4.7126924080354814e-05,
      "loss": 0.1089,
      "step": 44050
    },
    {
      "epoch": 5.752674145577877,
      "grad_norm": 0.38990047574043274,
      "learning_rate": 4.712366292721107e-05,
      "loss": 0.0302,
      "step": 44100
    },
    {
      "epoch": 5.75919645186538,
      "grad_norm": 0.049559336155653,
      "learning_rate": 4.712040177406731e-05,
      "loss": 0.1011,
      "step": 44150
    },
    {
      "epoch": 5.765718758152882,
      "grad_norm": 0.09496656805276871,
      "learning_rate": 4.711714062092356e-05,
      "loss": 0.0868,
      "step": 44200
    },
    {
      "epoch": 5.7722410644403865,
      "grad_norm": 0.3408556282520294,
      "learning_rate": 4.711387946777981e-05,
      "loss": 0.1467,
      "step": 44250
    },
    {
      "epoch": 5.778763370727889,
      "grad_norm": 1.319055438041687,
      "learning_rate": 4.711061831463606e-05,
      "loss": 0.1445,
      "step": 44300
    },
    {
      "epoch": 5.785285677015393,
      "grad_norm": 7.402459144592285,
      "learning_rate": 4.7107357161492305e-05,
      "loss": 0.1137,
      "step": 44350
    },
    {
      "epoch": 5.7918079833028955,
      "grad_norm": 0.5320228338241577,
      "learning_rate": 4.710409600834855e-05,
      "loss": 0.1147,
      "step": 44400
    },
    {
      "epoch": 5.7983302895904,
      "grad_norm": 0.7638485431671143,
      "learning_rate": 4.7100834855204804e-05,
      "loss": 0.0723,
      "step": 44450
    },
    {
      "epoch": 5.804852595877902,
      "grad_norm": 0.03243379294872284,
      "learning_rate": 4.709757370206105e-05,
      "loss": 0.1531,
      "step": 44500
    },
    {
      "epoch": 5.811374902165405,
      "grad_norm": 0.15885800123214722,
      "learning_rate": 4.70943125489173e-05,
      "loss": 0.1434,
      "step": 44550
    },
    {
      "epoch": 5.817897208452909,
      "grad_norm": 0.03434689715504646,
      "learning_rate": 4.709105139577355e-05,
      "loss": 0.1029,
      "step": 44600
    },
    {
      "epoch": 5.824419514740412,
      "grad_norm": 0.021051404997706413,
      "learning_rate": 4.7087790242629795e-05,
      "loss": 0.0784,
      "step": 44650
    },
    {
      "epoch": 5.830941821027915,
      "grad_norm": 0.02288518287241459,
      "learning_rate": 4.708452908948605e-05,
      "loss": 0.1266,
      "step": 44700
    },
    {
      "epoch": 5.837464127315418,
      "grad_norm": 0.1550176590681076,
      "learning_rate": 4.7081267936342294e-05,
      "loss": 0.1267,
      "step": 44750
    },
    {
      "epoch": 5.843986433602922,
      "grad_norm": 0.4953097999095917,
      "learning_rate": 4.707800678319854e-05,
      "loss": 0.1412,
      "step": 44800
    },
    {
      "epoch": 5.850508739890425,
      "grad_norm": 0.05164690688252449,
      "learning_rate": 4.707474563005479e-05,
      "loss": 0.1045,
      "step": 44850
    },
    {
      "epoch": 5.857031046177928,
      "grad_norm": 5.975170612335205,
      "learning_rate": 4.707148447691104e-05,
      "loss": 0.0967,
      "step": 44900
    },
    {
      "epoch": 5.8635533524654315,
      "grad_norm": 0.010078947991132736,
      "learning_rate": 4.7068223323767286e-05,
      "loss": 0.1008,
      "step": 44950
    },
    {
      "epoch": 5.870075658752935,
      "grad_norm": 0.14968983829021454,
      "learning_rate": 4.706496217062353e-05,
      "loss": 0.1615,
      "step": 45000
    },
    {
      "epoch": 5.876597965040438,
      "grad_norm": 1.0479477643966675,
      "learning_rate": 4.706170101747978e-05,
      "loss": 0.0655,
      "step": 45050
    },
    {
      "epoch": 5.883120271327941,
      "grad_norm": 0.24448014795780182,
      "learning_rate": 4.705843986433603e-05,
      "loss": 0.0824,
      "step": 45100
    },
    {
      "epoch": 5.889642577615445,
      "grad_norm": 0.04168679937720299,
      "learning_rate": 4.7055178711192284e-05,
      "loss": 0.0595,
      "step": 45150
    },
    {
      "epoch": 5.896164883902948,
      "grad_norm": 0.02489437907934189,
      "learning_rate": 4.705191755804853e-05,
      "loss": 0.1189,
      "step": 45200
    },
    {
      "epoch": 5.902687190190451,
      "grad_norm": 0.18141047656536102,
      "learning_rate": 4.7048656404904777e-05,
      "loss": 0.1382,
      "step": 45250
    },
    {
      "epoch": 5.9092094964779545,
      "grad_norm": 0.052310485392808914,
      "learning_rate": 4.704539525176103e-05,
      "loss": 0.1414,
      "step": 45300
    },
    {
      "epoch": 5.915731802765458,
      "grad_norm": 0.09271609038114548,
      "learning_rate": 4.7042134098617276e-05,
      "loss": 0.1211,
      "step": 45350
    },
    {
      "epoch": 5.922254109052961,
      "grad_norm": 0.03312982618808746,
      "learning_rate": 4.703887294547352e-05,
      "loss": 0.105,
      "step": 45400
    },
    {
      "epoch": 5.928776415340464,
      "grad_norm": 0.7941651940345764,
      "learning_rate": 4.703561179232977e-05,
      "loss": 0.0676,
      "step": 45450
    },
    {
      "epoch": 5.935298721627968,
      "grad_norm": 0.05050959810614586,
      "learning_rate": 4.703235063918602e-05,
      "loss": 0.1565,
      "step": 45500
    },
    {
      "epoch": 5.941821027915471,
      "grad_norm": 3.631791353225708,
      "learning_rate": 4.702908948604227e-05,
      "loss": 0.135,
      "step": 45550
    },
    {
      "epoch": 5.948343334202974,
      "grad_norm": 0.14476823806762695,
      "learning_rate": 4.702582833289851e-05,
      "loss": 0.1093,
      "step": 45600
    },
    {
      "epoch": 5.954865640490477,
      "grad_norm": 3.978032112121582,
      "learning_rate": 4.702256717975476e-05,
      "loss": 0.096,
      "step": 45650
    },
    {
      "epoch": 5.961387946777981,
      "grad_norm": 8.194241523742676,
      "learning_rate": 4.701930602661101e-05,
      "loss": 0.0685,
      "step": 45700
    },
    {
      "epoch": 5.967910253065484,
      "grad_norm": 0.5214846134185791,
      "learning_rate": 4.701604487346726e-05,
      "loss": 0.1311,
      "step": 45750
    },
    {
      "epoch": 5.974432559352987,
      "grad_norm": 3.607393264770508,
      "learning_rate": 4.701278372032351e-05,
      "loss": 0.1207,
      "step": 45800
    },
    {
      "epoch": 5.9809548656404905,
      "grad_norm": 0.21015599370002747,
      "learning_rate": 4.700952256717976e-05,
      "loss": 0.1226,
      "step": 45850
    },
    {
      "epoch": 5.987477171927994,
      "grad_norm": 7.996279716491699,
      "learning_rate": 4.7006261414036004e-05,
      "loss": 0.0889,
      "step": 45900
    },
    {
      "epoch": 5.993999478215497,
      "grad_norm": 0.0985889732837677,
      "learning_rate": 4.700300026089226e-05,
      "loss": 0.0728,
      "step": 45950
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9669971301852335,
      "eval_f1": 0.9670744403956273,
      "eval_loss": 0.11856622993946075,
      "eval_precision": 0.9650649350649351,
      "eval_recall": 0.9690923317683882,
      "eval_runtime": 27.0859,
      "eval_samples_per_second": 566.052,
      "eval_steps_per_second": 70.775,
      "step": 45996
    },
    {
      "epoch": 6.000521784503,
      "grad_norm": 0.030571047216653824,
      "learning_rate": 4.69997391077485e-05,
      "loss": 0.0977,
      "step": 46000
    },
    {
      "epoch": 6.007044090790504,
      "grad_norm": 0.027266325429081917,
      "learning_rate": 4.699647795460475e-05,
      "loss": 0.1601,
      "step": 46050
    },
    {
      "epoch": 6.013566397078007,
      "grad_norm": 0.024507908150553703,
      "learning_rate": 4.6993216801460996e-05,
      "loss": 0.0872,
      "step": 46100
    },
    {
      "epoch": 6.02008870336551,
      "grad_norm": 3.9961490631103516,
      "learning_rate": 4.698995564831725e-05,
      "loss": 0.098,
      "step": 46150
    },
    {
      "epoch": 6.026611009653013,
      "grad_norm": 0.551292896270752,
      "learning_rate": 4.6986694495173495e-05,
      "loss": 0.1075,
      "step": 46200
    },
    {
      "epoch": 6.033133315940517,
      "grad_norm": 5.59677791595459,
      "learning_rate": 4.698343334202974e-05,
      "loss": 0.1441,
      "step": 46250
    },
    {
      "epoch": 6.03965562222802,
      "grad_norm": 9.253799438476562,
      "learning_rate": 4.698017218888599e-05,
      "loss": 0.1283,
      "step": 46300
    },
    {
      "epoch": 6.046177928515523,
      "grad_norm": 0.44993963837623596,
      "learning_rate": 4.697691103574224e-05,
      "loss": 0.106,
      "step": 46350
    },
    {
      "epoch": 6.0527002348030265,
      "grad_norm": 0.8418005704879761,
      "learning_rate": 4.697364988259849e-05,
      "loss": 0.0672,
      "step": 46400
    },
    {
      "epoch": 6.05922254109053,
      "grad_norm": 0.012499460019171238,
      "learning_rate": 4.697038872945474e-05,
      "loss": 0.0761,
      "step": 46450
    },
    {
      "epoch": 6.065744847378033,
      "grad_norm": 0.012196858413517475,
      "learning_rate": 4.6967127576310985e-05,
      "loss": 0.0975,
      "step": 46500
    },
    {
      "epoch": 6.072267153665536,
      "grad_norm": 15.58808708190918,
      "learning_rate": 4.696386642316724e-05,
      "loss": 0.1575,
      "step": 46550
    },
    {
      "epoch": 6.07878945995304,
      "grad_norm": 0.3143700063228607,
      "learning_rate": 4.6960605270023484e-05,
      "loss": 0.1062,
      "step": 46600
    },
    {
      "epoch": 6.085311766240543,
      "grad_norm": 0.062005653977394104,
      "learning_rate": 4.695734411687973e-05,
      "loss": 0.0825,
      "step": 46650
    },
    {
      "epoch": 6.091834072528046,
      "grad_norm": 0.056840844452381134,
      "learning_rate": 4.695408296373598e-05,
      "loss": 0.1162,
      "step": 46700
    },
    {
      "epoch": 6.0983563788155495,
      "grad_norm": 0.18122917413711548,
      "learning_rate": 4.695082181059223e-05,
      "loss": 0.0795,
      "step": 46750
    },
    {
      "epoch": 6.104878685103053,
      "grad_norm": 0.01900828815996647,
      "learning_rate": 4.6947560657448476e-05,
      "loss": 0.1015,
      "step": 46800
    },
    {
      "epoch": 6.111400991390556,
      "grad_norm": 0.008738093078136444,
      "learning_rate": 4.694429950430472e-05,
      "loss": 0.0848,
      "step": 46850
    },
    {
      "epoch": 6.117923297678059,
      "grad_norm": 7.63224983215332,
      "learning_rate": 4.694103835116097e-05,
      "loss": 0.0701,
      "step": 46900
    },
    {
      "epoch": 6.124445603965563,
      "grad_norm": 0.007449398748576641,
      "learning_rate": 4.693777719801722e-05,
      "loss": 0.1145,
      "step": 46950
    },
    {
      "epoch": 6.130967910253066,
      "grad_norm": 0.08058082312345505,
      "learning_rate": 4.6934516044873474e-05,
      "loss": 0.1258,
      "step": 47000
    },
    {
      "epoch": 6.137490216540569,
      "grad_norm": 0.047489915043115616,
      "learning_rate": 4.693125489172972e-05,
      "loss": 0.1107,
      "step": 47050
    },
    {
      "epoch": 6.144012522828072,
      "grad_norm": 0.11122820526361465,
      "learning_rate": 4.692799373858597e-05,
      "loss": 0.1149,
      "step": 47100
    },
    {
      "epoch": 6.150534829115576,
      "grad_norm": 0.7913675308227539,
      "learning_rate": 4.692473258544221e-05,
      "loss": 0.0775,
      "step": 47150
    },
    {
      "epoch": 6.157057135403079,
      "grad_norm": 0.5482044816017151,
      "learning_rate": 4.6921471432298466e-05,
      "loss": 0.0761,
      "step": 47200
    },
    {
      "epoch": 6.163579441690581,
      "grad_norm": 0.51641446352005,
      "learning_rate": 4.691821027915471e-05,
      "loss": 0.0925,
      "step": 47250
    },
    {
      "epoch": 6.170101747978085,
      "grad_norm": 0.19361437857151031,
      "learning_rate": 4.691494912601096e-05,
      "loss": 0.0954,
      "step": 47300
    },
    {
      "epoch": 6.176624054265588,
      "grad_norm": 0.045498818159103394,
      "learning_rate": 4.6911687972867204e-05,
      "loss": 0.0932,
      "step": 47350
    },
    {
      "epoch": 6.183146360553091,
      "grad_norm": 7.418529987335205,
      "learning_rate": 4.690842681972346e-05,
      "loss": 0.0728,
      "step": 47400
    },
    {
      "epoch": 6.1896686668405945,
      "grad_norm": 11.030814170837402,
      "learning_rate": 4.6905165666579703e-05,
      "loss": 0.0807,
      "step": 47450
    },
    {
      "epoch": 6.196190973128098,
      "grad_norm": 0.04090093448758125,
      "learning_rate": 4.690190451343595e-05,
      "loss": 0.0498,
      "step": 47500
    },
    {
      "epoch": 6.202713279415601,
      "grad_norm": 10.709746360778809,
      "learning_rate": 4.68986433602922e-05,
      "loss": 0.1366,
      "step": 47550
    },
    {
      "epoch": 6.209235585703104,
      "grad_norm": 0.2909468710422516,
      "learning_rate": 4.689538220714845e-05,
      "loss": 0.1014,
      "step": 47600
    },
    {
      "epoch": 6.215757891990608,
      "grad_norm": 0.5197641253471375,
      "learning_rate": 4.68921210540047e-05,
      "loss": 0.0997,
      "step": 47650
    },
    {
      "epoch": 6.222280198278111,
      "grad_norm": 0.5895951390266418,
      "learning_rate": 4.688885990086095e-05,
      "loss": 0.0648,
      "step": 47700
    },
    {
      "epoch": 6.228802504565614,
      "grad_norm": 0.06491866707801819,
      "learning_rate": 4.6885598747717194e-05,
      "loss": 0.0969,
      "step": 47750
    },
    {
      "epoch": 6.235324810853117,
      "grad_norm": 0.05534707382321358,
      "learning_rate": 4.688233759457345e-05,
      "loss": 0.1194,
      "step": 47800
    },
    {
      "epoch": 6.241847117140621,
      "grad_norm": 0.06611337512731552,
      "learning_rate": 4.687907644142969e-05,
      "loss": 0.093,
      "step": 47850
    },
    {
      "epoch": 6.248369423428124,
      "grad_norm": 8.308087348937988,
      "learning_rate": 4.687581528828594e-05,
      "loss": 0.11,
      "step": 47900
    },
    {
      "epoch": 6.254891729715627,
      "grad_norm": 11.733442306518555,
      "learning_rate": 4.6872554135142186e-05,
      "loss": 0.1629,
      "step": 47950
    },
    {
      "epoch": 6.2614140360031305,
      "grad_norm": 0.11006154865026474,
      "learning_rate": 4.686929298199844e-05,
      "loss": 0.1272,
      "step": 48000
    },
    {
      "epoch": 6.267936342290634,
      "grad_norm": 0.8815834522247314,
      "learning_rate": 4.6866031828854685e-05,
      "loss": 0.1371,
      "step": 48050
    },
    {
      "epoch": 6.274458648578137,
      "grad_norm": 7.440612316131592,
      "learning_rate": 4.686277067571093e-05,
      "loss": 0.0641,
      "step": 48100
    },
    {
      "epoch": 6.28098095486564,
      "grad_norm": 0.00777317164465785,
      "learning_rate": 4.685950952256718e-05,
      "loss": 0.1227,
      "step": 48150
    },
    {
      "epoch": 6.287503261153144,
      "grad_norm": 15.955753326416016,
      "learning_rate": 4.685624836942343e-05,
      "loss": 0.0794,
      "step": 48200
    },
    {
      "epoch": 6.294025567440647,
      "grad_norm": 1.1922627687454224,
      "learning_rate": 4.685298721627968e-05,
      "loss": 0.1217,
      "step": 48250
    },
    {
      "epoch": 6.30054787372815,
      "grad_norm": 0.11137378215789795,
      "learning_rate": 4.684972606313593e-05,
      "loss": 0.1071,
      "step": 48300
    },
    {
      "epoch": 6.3070701800156534,
      "grad_norm": 0.10499591380357742,
      "learning_rate": 4.6846464909992175e-05,
      "loss": 0.098,
      "step": 48350
    },
    {
      "epoch": 6.313592486303157,
      "grad_norm": 0.01882309280335903,
      "learning_rate": 4.684320375684843e-05,
      "loss": 0.0979,
      "step": 48400
    },
    {
      "epoch": 6.32011479259066,
      "grad_norm": 6.969826698303223,
      "learning_rate": 4.6839942603704675e-05,
      "loss": 0.1784,
      "step": 48450
    },
    {
      "epoch": 6.326637098878163,
      "grad_norm": 0.058929041028022766,
      "learning_rate": 4.683668145056092e-05,
      "loss": 0.0703,
      "step": 48500
    },
    {
      "epoch": 6.3331594051656666,
      "grad_norm": 0.028779281303286552,
      "learning_rate": 4.683342029741717e-05,
      "loss": 0.0727,
      "step": 48550
    },
    {
      "epoch": 6.33968171145317,
      "grad_norm": 0.03875662013888359,
      "learning_rate": 4.683015914427342e-05,
      "loss": 0.0575,
      "step": 48600
    },
    {
      "epoch": 6.346204017740673,
      "grad_norm": 0.18987718224525452,
      "learning_rate": 4.6826897991129666e-05,
      "loss": 0.1252,
      "step": 48650
    },
    {
      "epoch": 6.352726324028176,
      "grad_norm": 0.3542339503765106,
      "learning_rate": 4.682363683798591e-05,
      "loss": 0.0963,
      "step": 48700
    },
    {
      "epoch": 6.35924863031568,
      "grad_norm": 0.008274149149656296,
      "learning_rate": 4.682037568484216e-05,
      "loss": 0.0751,
      "step": 48750
    },
    {
      "epoch": 6.365770936603183,
      "grad_norm": 0.017057400196790695,
      "learning_rate": 4.681711453169841e-05,
      "loss": 0.1062,
      "step": 48800
    },
    {
      "epoch": 6.372293242890686,
      "grad_norm": 0.05252078175544739,
      "learning_rate": 4.6813853378554664e-05,
      "loss": 0.1264,
      "step": 48850
    },
    {
      "epoch": 6.3788155491781895,
      "grad_norm": 0.0689820945262909,
      "learning_rate": 4.681059222541091e-05,
      "loss": 0.0956,
      "step": 48900
    },
    {
      "epoch": 6.385337855465693,
      "grad_norm": 8.560345649719238,
      "learning_rate": 4.680733107226716e-05,
      "loss": 0.1277,
      "step": 48950
    },
    {
      "epoch": 6.391860161753196,
      "grad_norm": 0.14053474366664886,
      "learning_rate": 4.68040699191234e-05,
      "loss": 0.0922,
      "step": 49000
    },
    {
      "epoch": 6.398382468040699,
      "grad_norm": 0.03030645102262497,
      "learning_rate": 4.6800808765979656e-05,
      "loss": 0.0976,
      "step": 49050
    },
    {
      "epoch": 6.404904774328203,
      "grad_norm": 0.681706964969635,
      "learning_rate": 4.67975476128359e-05,
      "loss": 0.1152,
      "step": 49100
    },
    {
      "epoch": 6.411427080615706,
      "grad_norm": 0.6042219996452332,
      "learning_rate": 4.679428645969215e-05,
      "loss": 0.0311,
      "step": 49150
    },
    {
      "epoch": 6.417949386903209,
      "grad_norm": 20.46753692626953,
      "learning_rate": 4.6791025306548394e-05,
      "loss": 0.0884,
      "step": 49200
    },
    {
      "epoch": 6.424471693190712,
      "grad_norm": 0.017023328691720963,
      "learning_rate": 4.678776415340465e-05,
      "loss": 0.0669,
      "step": 49250
    },
    {
      "epoch": 6.430993999478216,
      "grad_norm": 0.07442107051610947,
      "learning_rate": 4.6784503000260894e-05,
      "loss": 0.1171,
      "step": 49300
    },
    {
      "epoch": 6.437516305765719,
      "grad_norm": 0.012471102178096771,
      "learning_rate": 4.678124184711714e-05,
      "loss": 0.0886,
      "step": 49350
    },
    {
      "epoch": 6.444038612053222,
      "grad_norm": 0.20792488753795624,
      "learning_rate": 4.6777980693973386e-05,
      "loss": 0.0901,
      "step": 49400
    },
    {
      "epoch": 6.4505609183407255,
      "grad_norm": 14.909290313720703,
      "learning_rate": 4.6774719540829646e-05,
      "loss": 0.1265,
      "step": 49450
    },
    {
      "epoch": 6.457083224628229,
      "grad_norm": 0.016409656032919884,
      "learning_rate": 4.677145838768589e-05,
      "loss": 0.0641,
      "step": 49500
    },
    {
      "epoch": 6.463605530915732,
      "grad_norm": 15.540639877319336,
      "learning_rate": 4.676819723454214e-05,
      "loss": 0.0917,
      "step": 49550
    },
    {
      "epoch": 6.470127837203235,
      "grad_norm": 0.16426536440849304,
      "learning_rate": 4.6764936081398384e-05,
      "loss": 0.0848,
      "step": 49600
    },
    {
      "epoch": 6.476650143490739,
      "grad_norm": 0.49418509006500244,
      "learning_rate": 4.676167492825464e-05,
      "loss": 0.1263,
      "step": 49650
    },
    {
      "epoch": 6.483172449778242,
      "grad_norm": 0.2094978392124176,
      "learning_rate": 4.675841377511088e-05,
      "loss": 0.1426,
      "step": 49700
    },
    {
      "epoch": 6.489694756065745,
      "grad_norm": 0.029573440551757812,
      "learning_rate": 4.675515262196713e-05,
      "loss": 0.0983,
      "step": 49750
    },
    {
      "epoch": 6.4962170623532485,
      "grad_norm": 6.48691987991333,
      "learning_rate": 4.6751891468823376e-05,
      "loss": 0.1025,
      "step": 49800
    },
    {
      "epoch": 6.502739368640752,
      "grad_norm": 0.03716566413640976,
      "learning_rate": 4.674863031567963e-05,
      "loss": 0.0961,
      "step": 49850
    },
    {
      "epoch": 6.509261674928254,
      "grad_norm": 5.951226234436035,
      "learning_rate": 4.6745369162535875e-05,
      "loss": 0.0837,
      "step": 49900
    },
    {
      "epoch": 6.515783981215758,
      "grad_norm": 0.0753050148487091,
      "learning_rate": 4.674210800939212e-05,
      "loss": 0.0715,
      "step": 49950
    },
    {
      "epoch": 6.522306287503261,
      "grad_norm": 0.13430601358413696,
      "learning_rate": 4.673884685624837e-05,
      "loss": 0.17,
      "step": 50000
    },
    {
      "epoch": 6.528828593790765,
      "grad_norm": 0.08010823279619217,
      "learning_rate": 4.673558570310462e-05,
      "loss": 0.0542,
      "step": 50050
    },
    {
      "epoch": 6.535350900078267,
      "grad_norm": 5.260165214538574,
      "learning_rate": 4.673232454996087e-05,
      "loss": 0.1691,
      "step": 50100
    },
    {
      "epoch": 6.541873206365771,
      "grad_norm": 10.986466407775879,
      "learning_rate": 4.672906339681712e-05,
      "loss": 0.0872,
      "step": 50150
    },
    {
      "epoch": 6.548395512653274,
      "grad_norm": 0.014844969846308231,
      "learning_rate": 4.6725802243673365e-05,
      "loss": 0.126,
      "step": 50200
    },
    {
      "epoch": 6.554917818940777,
      "grad_norm": 0.03900351747870445,
      "learning_rate": 4.672254109052961e-05,
      "loss": 0.0791,
      "step": 50250
    },
    {
      "epoch": 6.56144012522828,
      "grad_norm": 13.235471725463867,
      "learning_rate": 4.6719279937385865e-05,
      "loss": 0.1166,
      "step": 50300
    },
    {
      "epoch": 6.567962431515784,
      "grad_norm": 0.08043201267719269,
      "learning_rate": 4.671601878424211e-05,
      "loss": 0.1566,
      "step": 50350
    },
    {
      "epoch": 6.574484737803287,
      "grad_norm": 5.4930338859558105,
      "learning_rate": 4.671275763109836e-05,
      "loss": 0.0891,
      "step": 50400
    },
    {
      "epoch": 6.58100704409079,
      "grad_norm": 15.650544166564941,
      "learning_rate": 4.67094964779546e-05,
      "loss": 0.0691,
      "step": 50450
    },
    {
      "epoch": 6.5875293503782935,
      "grad_norm": 5.473728179931641,
      "learning_rate": 4.6706235324810856e-05,
      "loss": 0.1147,
      "step": 50500
    },
    {
      "epoch": 6.594051656665797,
      "grad_norm": 0.06136848405003548,
      "learning_rate": 4.67029741716671e-05,
      "loss": 0.1069,
      "step": 50550
    },
    {
      "epoch": 6.6005739629533,
      "grad_norm": 0.04662156477570534,
      "learning_rate": 4.669971301852335e-05,
      "loss": 0.091,
      "step": 50600
    },
    {
      "epoch": 6.607096269240803,
      "grad_norm": 0.03760185092687607,
      "learning_rate": 4.6696451865379595e-05,
      "loss": 0.102,
      "step": 50650
    },
    {
      "epoch": 6.613618575528307,
      "grad_norm": 8.864700317382812,
      "learning_rate": 4.6693190712235854e-05,
      "loss": 0.1191,
      "step": 50700
    },
    {
      "epoch": 6.62014088181581,
      "grad_norm": 19.630224227905273,
      "learning_rate": 4.66899295590921e-05,
      "loss": 0.1499,
      "step": 50750
    },
    {
      "epoch": 6.626663188103313,
      "grad_norm": 0.10604037344455719,
      "learning_rate": 4.668666840594835e-05,
      "loss": 0.0492,
      "step": 50800
    },
    {
      "epoch": 6.633185494390816,
      "grad_norm": 0.05670170485973358,
      "learning_rate": 4.668340725280459e-05,
      "loss": 0.0962,
      "step": 50850
    },
    {
      "epoch": 6.63970780067832,
      "grad_norm": 15.686980247497559,
      "learning_rate": 4.6680146099660846e-05,
      "loss": 0.1266,
      "step": 50900
    },
    {
      "epoch": 6.646230106965823,
      "grad_norm": 0.02336869388818741,
      "learning_rate": 4.667688494651709e-05,
      "loss": 0.0432,
      "step": 50950
    },
    {
      "epoch": 6.652752413253326,
      "grad_norm": 0.31983962655067444,
      "learning_rate": 4.667362379337334e-05,
      "loss": 0.0868,
      "step": 51000
    },
    {
      "epoch": 6.6592747195408295,
      "grad_norm": 0.11730506271123886,
      "learning_rate": 4.6670362640229584e-05,
      "loss": 0.1481,
      "step": 51050
    },
    {
      "epoch": 6.665797025828333,
      "grad_norm": 1.7853283882141113,
      "learning_rate": 4.666710148708584e-05,
      "loss": 0.1314,
      "step": 51100
    },
    {
      "epoch": 6.672319332115836,
      "grad_norm": 8.499898910522461,
      "learning_rate": 4.6663840333942084e-05,
      "loss": 0.0652,
      "step": 51150
    },
    {
      "epoch": 6.678841638403339,
      "grad_norm": 9.674007415771484,
      "learning_rate": 4.666057918079833e-05,
      "loss": 0.1734,
      "step": 51200
    },
    {
      "epoch": 6.685363944690843,
      "grad_norm": 0.18015709519386292,
      "learning_rate": 4.6657318027654576e-05,
      "loss": 0.0564,
      "step": 51250
    },
    {
      "epoch": 6.691886250978346,
      "grad_norm": 0.04168388620018959,
      "learning_rate": 4.665405687451083e-05,
      "loss": 0.1273,
      "step": 51300
    },
    {
      "epoch": 6.698408557265849,
      "grad_norm": 15.041991233825684,
      "learning_rate": 4.665079572136708e-05,
      "loss": 0.1335,
      "step": 51350
    },
    {
      "epoch": 6.704930863553352,
      "grad_norm": 0.09293458610773087,
      "learning_rate": 4.664753456822333e-05,
      "loss": 0.1041,
      "step": 51400
    },
    {
      "epoch": 6.711453169840856,
      "grad_norm": 0.07275348156690598,
      "learning_rate": 4.6644273415079574e-05,
      "loss": 0.1169,
      "step": 51450
    },
    {
      "epoch": 6.717975476128359,
      "grad_norm": 3.89986252784729,
      "learning_rate": 4.664101226193582e-05,
      "loss": 0.0608,
      "step": 51500
    },
    {
      "epoch": 6.724497782415862,
      "grad_norm": 0.011140942573547363,
      "learning_rate": 4.6637751108792073e-05,
      "loss": 0.0918,
      "step": 51550
    },
    {
      "epoch": 6.7310200887033655,
      "grad_norm": 0.08360236138105392,
      "learning_rate": 4.663448995564832e-05,
      "loss": 0.1023,
      "step": 51600
    },
    {
      "epoch": 6.737542394990869,
      "grad_norm": 0.1048186719417572,
      "learning_rate": 4.6631228802504566e-05,
      "loss": 0.0841,
      "step": 51650
    },
    {
      "epoch": 6.744064701278372,
      "grad_norm": 4.233772277832031,
      "learning_rate": 4.662796764936081e-05,
      "loss": 0.0976,
      "step": 51700
    },
    {
      "epoch": 6.750587007565875,
      "grad_norm": 1.4209673404693604,
      "learning_rate": 4.6624706496217065e-05,
      "loss": 0.1005,
      "step": 51750
    },
    {
      "epoch": 6.757109313853379,
      "grad_norm": 18.471233367919922,
      "learning_rate": 4.662144534307331e-05,
      "loss": 0.132,
      "step": 51800
    },
    {
      "epoch": 6.763631620140882,
      "grad_norm": 0.017875757068395615,
      "learning_rate": 4.661818418992956e-05,
      "loss": 0.1251,
      "step": 51850
    },
    {
      "epoch": 6.770153926428385,
      "grad_norm": 9.919731140136719,
      "learning_rate": 4.661492303678581e-05,
      "loss": 0.159,
      "step": 51900
    },
    {
      "epoch": 6.7766762327158885,
      "grad_norm": 8.345900535583496,
      "learning_rate": 4.661166188364206e-05,
      "loss": 0.1062,
      "step": 51950
    },
    {
      "epoch": 6.783198539003392,
      "grad_norm": 0.10546725243330002,
      "learning_rate": 4.660840073049831e-05,
      "loss": 0.105,
      "step": 52000
    },
    {
      "epoch": 6.789720845290895,
      "grad_norm": 0.028914300724864006,
      "learning_rate": 4.6605139577354556e-05,
      "loss": 0.1403,
      "step": 52050
    },
    {
      "epoch": 6.796243151578398,
      "grad_norm": 10.327481269836426,
      "learning_rate": 4.66018784242108e-05,
      "loss": 0.07,
      "step": 52100
    },
    {
      "epoch": 6.802765457865902,
      "grad_norm": 0.18635977804660797,
      "learning_rate": 4.6598617271067055e-05,
      "loss": 0.0645,
      "step": 52150
    },
    {
      "epoch": 6.809287764153405,
      "grad_norm": 0.11875651031732559,
      "learning_rate": 4.65953561179233e-05,
      "loss": 0.141,
      "step": 52200
    },
    {
      "epoch": 6.815810070440908,
      "grad_norm": 5.061888694763184,
      "learning_rate": 4.659209496477955e-05,
      "loss": 0.0875,
      "step": 52250
    },
    {
      "epoch": 6.822332376728411,
      "grad_norm": 0.10839376598596573,
      "learning_rate": 4.658883381163579e-05,
      "loss": 0.0899,
      "step": 52300
    },
    {
      "epoch": 6.828854683015915,
      "grad_norm": 13.763410568237305,
      "learning_rate": 4.6585572658492046e-05,
      "loss": 0.0724,
      "step": 52350
    },
    {
      "epoch": 6.835376989303418,
      "grad_norm": 0.05970977246761322,
      "learning_rate": 4.658231150534829e-05,
      "loss": 0.0688,
      "step": 52400
    },
    {
      "epoch": 6.841899295590921,
      "grad_norm": 7.282690525054932,
      "learning_rate": 4.657905035220454e-05,
      "loss": 0.1095,
      "step": 52450
    },
    {
      "epoch": 6.8484216018784245,
      "grad_norm": 0.12031630426645279,
      "learning_rate": 4.6575789199060785e-05,
      "loss": 0.0861,
      "step": 52500
    },
    {
      "epoch": 6.854943908165928,
      "grad_norm": 15.616933822631836,
      "learning_rate": 4.657252804591704e-05,
      "loss": 0.0475,
      "step": 52550
    },
    {
      "epoch": 6.861466214453431,
      "grad_norm": 0.29768556356430054,
      "learning_rate": 4.656926689277329e-05,
      "loss": 0.084,
      "step": 52600
    },
    {
      "epoch": 6.867988520740934,
      "grad_norm": 0.01978636533021927,
      "learning_rate": 4.656600573962954e-05,
      "loss": 0.0819,
      "step": 52650
    },
    {
      "epoch": 6.874510827028438,
      "grad_norm": 0.021899964660406113,
      "learning_rate": 4.656274458648578e-05,
      "loss": 0.1099,
      "step": 52700
    },
    {
      "epoch": 6.88103313331594,
      "grad_norm": 0.010597329586744308,
      "learning_rate": 4.6559483433342036e-05,
      "loss": 0.0718,
      "step": 52750
    },
    {
      "epoch": 6.887555439603444,
      "grad_norm": 0.017011018469929695,
      "learning_rate": 4.655622228019828e-05,
      "loss": 0.072,
      "step": 52800
    },
    {
      "epoch": 6.894077745890947,
      "grad_norm": 0.012963268905878067,
      "learning_rate": 4.655296112705453e-05,
      "loss": 0.098,
      "step": 52850
    },
    {
      "epoch": 6.900600052178451,
      "grad_norm": 4.490184783935547,
      "learning_rate": 4.6549699973910775e-05,
      "loss": 0.1323,
      "step": 52900
    },
    {
      "epoch": 6.907122358465953,
      "grad_norm": 0.5323693156242371,
      "learning_rate": 4.654643882076703e-05,
      "loss": 0.0467,
      "step": 52950
    },
    {
      "epoch": 6.913644664753457,
      "grad_norm": 0.006846283096820116,
      "learning_rate": 4.6543177667623274e-05,
      "loss": 0.1337,
      "step": 53000
    },
    {
      "epoch": 6.92016697104096,
      "grad_norm": 1.0181282758712769,
      "learning_rate": 4.653991651447952e-05,
      "loss": 0.0612,
      "step": 53050
    },
    {
      "epoch": 6.926689277328463,
      "grad_norm": 1.9263393878936768,
      "learning_rate": 4.6536655361335766e-05,
      "loss": 0.0729,
      "step": 53100
    },
    {
      "epoch": 6.933211583615966,
      "grad_norm": 0.06971938908100128,
      "learning_rate": 4.653339420819202e-05,
      "loss": 0.1287,
      "step": 53150
    },
    {
      "epoch": 6.9397338899034695,
      "grad_norm": 0.6825535893440247,
      "learning_rate": 4.653013305504827e-05,
      "loss": 0.0871,
      "step": 53200
    },
    {
      "epoch": 6.946256196190973,
      "grad_norm": 0.010181931778788567,
      "learning_rate": 4.652687190190452e-05,
      "loss": 0.115,
      "step": 53250
    },
    {
      "epoch": 6.952778502478476,
      "grad_norm": 2.8061749935150146,
      "learning_rate": 4.6523610748760764e-05,
      "loss": 0.0777,
      "step": 53300
    },
    {
      "epoch": 6.959300808765979,
      "grad_norm": 0.08428218960762024,
      "learning_rate": 4.652034959561701e-05,
      "loss": 0.1463,
      "step": 53350
    },
    {
      "epoch": 6.965823115053483,
      "grad_norm": 1.477225422859192,
      "learning_rate": 4.6517088442473263e-05,
      "loss": 0.0705,
      "step": 53400
    },
    {
      "epoch": 6.972345421340986,
      "grad_norm": 10.735957145690918,
      "learning_rate": 4.651382728932951e-05,
      "loss": 0.145,
      "step": 53450
    },
    {
      "epoch": 6.978867727628489,
      "grad_norm": 0.08160672336816788,
      "learning_rate": 4.6510566136185756e-05,
      "loss": 0.0938,
      "step": 53500
    },
    {
      "epoch": 6.9853900339159924,
      "grad_norm": 0.022714901715517044,
      "learning_rate": 4.6507304983042e-05,
      "loss": 0.1183,
      "step": 53550
    },
    {
      "epoch": 6.991912340203496,
      "grad_norm": 0.19196631014347076,
      "learning_rate": 4.6504043829898255e-05,
      "loss": 0.1418,
      "step": 53600
    },
    {
      "epoch": 6.998434646490999,
      "grad_norm": 11.879764556884766,
      "learning_rate": 4.65007826767545e-05,
      "loss": 0.0836,
      "step": 53650
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9667362379337334,
      "eval_f1": 0.966718872357087,
      "eval_loss": 0.1257079839706421,
      "eval_precision": 0.9674764890282131,
      "eval_recall": 0.965962441314554,
      "eval_runtime": 27.0953,
      "eval_samples_per_second": 565.855,
      "eval_steps_per_second": 70.75,
      "step": 53662
    },
    {
      "epoch": 7.004956952778502,
      "grad_norm": 0.2821849584579468,
      "learning_rate": 4.649752152361075e-05,
      "loss": 0.0848,
      "step": 53700
    },
    {
      "epoch": 7.0114792590660056,
      "grad_norm": 19.985361099243164,
      "learning_rate": 4.6494260370467e-05,
      "loss": 0.1022,
      "step": 53750
    },
    {
      "epoch": 7.018001565353509,
      "grad_norm": 0.013097751885652542,
      "learning_rate": 4.649099921732325e-05,
      "loss": 0.1218,
      "step": 53800
    },
    {
      "epoch": 7.024523871641012,
      "grad_norm": 8.817046165466309,
      "learning_rate": 4.64877380641795e-05,
      "loss": 0.1039,
      "step": 53850
    },
    {
      "epoch": 7.031046177928515,
      "grad_norm": 0.05697726085782051,
      "learning_rate": 4.6484476911035746e-05,
      "loss": 0.0697,
      "step": 53900
    },
    {
      "epoch": 7.037568484216019,
      "grad_norm": 1.1480780839920044,
      "learning_rate": 4.648121575789199e-05,
      "loss": 0.0686,
      "step": 53950
    },
    {
      "epoch": 7.044090790503522,
      "grad_norm": 0.03302668035030365,
      "learning_rate": 4.6477954604748245e-05,
      "loss": 0.0369,
      "step": 54000
    },
    {
      "epoch": 7.050613096791025,
      "grad_norm": 0.1041765958070755,
      "learning_rate": 4.647469345160449e-05,
      "loss": 0.0594,
      "step": 54050
    },
    {
      "epoch": 7.0571354030785285,
      "grad_norm": 0.029416877776384354,
      "learning_rate": 4.647143229846074e-05,
      "loss": 0.1166,
      "step": 54100
    },
    {
      "epoch": 7.063657709366032,
      "grad_norm": 6.988106727600098,
      "learning_rate": 4.646817114531698e-05,
      "loss": 0.1228,
      "step": 54150
    },
    {
      "epoch": 7.070180015653535,
      "grad_norm": 0.07540600746870041,
      "learning_rate": 4.6464909992173236e-05,
      "loss": 0.0903,
      "step": 54200
    },
    {
      "epoch": 7.076702321941038,
      "grad_norm": 14.843240737915039,
      "learning_rate": 4.646164883902948e-05,
      "loss": 0.1052,
      "step": 54250
    },
    {
      "epoch": 7.083224628228542,
      "grad_norm": 12.481687545776367,
      "learning_rate": 4.645838768588573e-05,
      "loss": 0.1512,
      "step": 54300
    },
    {
      "epoch": 7.089746934516045,
      "grad_norm": 0.36751416325569153,
      "learning_rate": 4.6455126532741975e-05,
      "loss": 0.1481,
      "step": 54350
    },
    {
      "epoch": 7.096269240803548,
      "grad_norm": 14.657684326171875,
      "learning_rate": 4.645186537959823e-05,
      "loss": 0.1598,
      "step": 54400
    },
    {
      "epoch": 7.102791547091051,
      "grad_norm": 12.356267929077148,
      "learning_rate": 4.644860422645448e-05,
      "loss": 0.1042,
      "step": 54450
    },
    {
      "epoch": 7.109313853378555,
      "grad_norm": 0.042692460119724274,
      "learning_rate": 4.644534307331073e-05,
      "loss": 0.0786,
      "step": 54500
    },
    {
      "epoch": 7.115836159666058,
      "grad_norm": 0.027049075812101364,
      "learning_rate": 4.644208192016697e-05,
      "loss": 0.0404,
      "step": 54550
    },
    {
      "epoch": 7.122358465953561,
      "grad_norm": 0.0900779664516449,
      "learning_rate": 4.643882076702322e-05,
      "loss": 0.1243,
      "step": 54600
    },
    {
      "epoch": 7.1288807722410645,
      "grad_norm": 0.03952726349234581,
      "learning_rate": 4.643555961387947e-05,
      "loss": 0.1073,
      "step": 54650
    },
    {
      "epoch": 7.135403078528568,
      "grad_norm": 0.4863782525062561,
      "learning_rate": 4.643229846073572e-05,
      "loss": 0.0418,
      "step": 54700
    },
    {
      "epoch": 7.141925384816071,
      "grad_norm": 0.2654002010822296,
      "learning_rate": 4.6429037307591965e-05,
      "loss": 0.1098,
      "step": 54750
    },
    {
      "epoch": 7.148447691103574,
      "grad_norm": 0.11563082784414291,
      "learning_rate": 4.642577615444821e-05,
      "loss": 0.076,
      "step": 54800
    },
    {
      "epoch": 7.154969997391078,
      "grad_norm": 0.3404771089553833,
      "learning_rate": 4.6422515001304464e-05,
      "loss": 0.0974,
      "step": 54850
    },
    {
      "epoch": 7.161492303678581,
      "grad_norm": 1.1051990985870361,
      "learning_rate": 4.641925384816071e-05,
      "loss": 0.1026,
      "step": 54900
    },
    {
      "epoch": 7.168014609966084,
      "grad_norm": 0.22584693133831024,
      "learning_rate": 4.6415992695016956e-05,
      "loss": 0.0935,
      "step": 54950
    },
    {
      "epoch": 7.1745369162535875,
      "grad_norm": 4.0388078689575195,
      "learning_rate": 4.641273154187321e-05,
      "loss": 0.0966,
      "step": 55000
    },
    {
      "epoch": 7.181059222541091,
      "grad_norm": 0.07006092369556427,
      "learning_rate": 4.640947038872946e-05,
      "loss": 0.1436,
      "step": 55050
    },
    {
      "epoch": 7.187581528828594,
      "grad_norm": 0.09411487728357315,
      "learning_rate": 4.640620923558571e-05,
      "loss": 0.0506,
      "step": 55100
    },
    {
      "epoch": 7.194103835116097,
      "grad_norm": 8.317424774169922,
      "learning_rate": 4.6402948082441954e-05,
      "loss": 0.084,
      "step": 55150
    },
    {
      "epoch": 7.200626141403601,
      "grad_norm": 0.007033734582364559,
      "learning_rate": 4.63996869292982e-05,
      "loss": 0.0995,
      "step": 55200
    },
    {
      "epoch": 7.207148447691104,
      "grad_norm": 0.06853216141462326,
      "learning_rate": 4.6396425776154454e-05,
      "loss": 0.0596,
      "step": 55250
    },
    {
      "epoch": 7.213670753978607,
      "grad_norm": 1.085797905921936,
      "learning_rate": 4.63931646230107e-05,
      "loss": 0.0633,
      "step": 55300
    },
    {
      "epoch": 7.22019306026611,
      "grad_norm": 0.2183689922094345,
      "learning_rate": 4.6389903469866946e-05,
      "loss": 0.1264,
      "step": 55350
    },
    {
      "epoch": 7.226715366553614,
      "grad_norm": 0.921850860118866,
      "learning_rate": 4.638664231672319e-05,
      "loss": 0.1209,
      "step": 55400
    },
    {
      "epoch": 7.233237672841117,
      "grad_norm": 0.21650096774101257,
      "learning_rate": 4.6383381163579445e-05,
      "loss": 0.0912,
      "step": 55450
    },
    {
      "epoch": 7.23975997912862,
      "grad_norm": 0.07763516157865524,
      "learning_rate": 4.638012001043569e-05,
      "loss": 0.1112,
      "step": 55500
    },
    {
      "epoch": 7.2462822854161235,
      "grad_norm": 0.21535328030586243,
      "learning_rate": 4.637685885729194e-05,
      "loss": 0.1188,
      "step": 55550
    },
    {
      "epoch": 7.252804591703627,
      "grad_norm": 0.027251247316598892,
      "learning_rate": 4.637359770414819e-05,
      "loss": 0.092,
      "step": 55600
    },
    {
      "epoch": 7.25932689799113,
      "grad_norm": 0.03251253440976143,
      "learning_rate": 4.6370336551004437e-05,
      "loss": 0.0981,
      "step": 55650
    },
    {
      "epoch": 7.2658492042786325,
      "grad_norm": 0.1164647713303566,
      "learning_rate": 4.636707539786069e-05,
      "loss": 0.0901,
      "step": 55700
    },
    {
      "epoch": 7.272371510566137,
      "grad_norm": 0.05200563743710518,
      "learning_rate": 4.6363814244716936e-05,
      "loss": 0.1091,
      "step": 55750
    },
    {
      "epoch": 7.278893816853639,
      "grad_norm": 17.23712921142578,
      "learning_rate": 4.636055309157318e-05,
      "loss": 0.1196,
      "step": 55800
    },
    {
      "epoch": 7.285416123141143,
      "grad_norm": 0.062325477600097656,
      "learning_rate": 4.635729193842943e-05,
      "loss": 0.1004,
      "step": 55850
    },
    {
      "epoch": 7.291938429428646,
      "grad_norm": 0.029961861670017242,
      "learning_rate": 4.635403078528568e-05,
      "loss": 0.1361,
      "step": 55900
    },
    {
      "epoch": 7.298460735716149,
      "grad_norm": 0.801131010055542,
      "learning_rate": 4.635076963214193e-05,
      "loss": 0.0914,
      "step": 55950
    },
    {
      "epoch": 7.304983042003652,
      "grad_norm": 0.014241169206798077,
      "learning_rate": 4.6347508478998173e-05,
      "loss": 0.0999,
      "step": 56000
    },
    {
      "epoch": 7.311505348291155,
      "grad_norm": 8.428414344787598,
      "learning_rate": 4.634424732585442e-05,
      "loss": 0.1295,
      "step": 56050
    },
    {
      "epoch": 7.318027654578659,
      "grad_norm": 6.4072771072387695,
      "learning_rate": 4.634098617271067e-05,
      "loss": 0.0812,
      "step": 56100
    },
    {
      "epoch": 7.324549960866162,
      "grad_norm": 0.31906622648239136,
      "learning_rate": 4.633772501956692e-05,
      "loss": 0.1194,
      "step": 56150
    },
    {
      "epoch": 7.331072267153665,
      "grad_norm": 0.014596395194530487,
      "learning_rate": 4.6334463866423165e-05,
      "loss": 0.1323,
      "step": 56200
    },
    {
      "epoch": 7.3375945734411685,
      "grad_norm": 2.810122013092041,
      "learning_rate": 4.633120271327942e-05,
      "loss": 0.1119,
      "step": 56250
    },
    {
      "epoch": 7.344116879728672,
      "grad_norm": 0.008774999529123306,
      "learning_rate": 4.632794156013567e-05,
      "loss": 0.0878,
      "step": 56300
    },
    {
      "epoch": 7.350639186016175,
      "grad_norm": 9.187870979309082,
      "learning_rate": 4.632468040699192e-05,
      "loss": 0.0916,
      "step": 56350
    },
    {
      "epoch": 7.357161492303678,
      "grad_norm": 7.520481586456299,
      "learning_rate": 4.632141925384816e-05,
      "loss": 0.1149,
      "step": 56400
    },
    {
      "epoch": 7.363683798591182,
      "grad_norm": 2.157836437225342,
      "learning_rate": 4.631815810070441e-05,
      "loss": 0.0749,
      "step": 56450
    },
    {
      "epoch": 7.370206104878685,
      "grad_norm": 0.4698219895362854,
      "learning_rate": 4.631489694756066e-05,
      "loss": 0.1222,
      "step": 56500
    },
    {
      "epoch": 7.376728411166188,
      "grad_norm": 0.12714877724647522,
      "learning_rate": 4.631163579441691e-05,
      "loss": 0.0777,
      "step": 56550
    },
    {
      "epoch": 7.383250717453691,
      "grad_norm": 0.14403019845485687,
      "learning_rate": 4.6308374641273155e-05,
      "loss": 0.147,
      "step": 56600
    },
    {
      "epoch": 7.389773023741195,
      "grad_norm": 0.16572505235671997,
      "learning_rate": 4.63051134881294e-05,
      "loss": 0.1402,
      "step": 56650
    },
    {
      "epoch": 7.396295330028698,
      "grad_norm": 0.04590337723493576,
      "learning_rate": 4.6301852334985654e-05,
      "loss": 0.1185,
      "step": 56700
    },
    {
      "epoch": 7.402817636316201,
      "grad_norm": 0.05242964252829552,
      "learning_rate": 4.62985911818419e-05,
      "loss": 0.0612,
      "step": 56750
    },
    {
      "epoch": 7.4093399426037045,
      "grad_norm": 2.7591071128845215,
      "learning_rate": 4.6295330028698146e-05,
      "loss": 0.0628,
      "step": 56800
    },
    {
      "epoch": 7.415862248891208,
      "grad_norm": 3.268801689147949,
      "learning_rate": 4.62920688755544e-05,
      "loss": 0.1747,
      "step": 56850
    },
    {
      "epoch": 7.422384555178711,
      "grad_norm": 0.08575750142335892,
      "learning_rate": 4.6288807722410645e-05,
      "loss": 0.086,
      "step": 56900
    },
    {
      "epoch": 7.428906861466214,
      "grad_norm": 0.7935490012168884,
      "learning_rate": 4.62855465692669e-05,
      "loss": 0.0748,
      "step": 56950
    },
    {
      "epoch": 7.435429167753718,
      "grad_norm": 0.1919599026441574,
      "learning_rate": 4.6282285416123145e-05,
      "loss": 0.1243,
      "step": 57000
    },
    {
      "epoch": 7.441951474041221,
      "grad_norm": 0.10591507703065872,
      "learning_rate": 4.627902426297939e-05,
      "loss": 0.1024,
      "step": 57050
    },
    {
      "epoch": 7.448473780328724,
      "grad_norm": 15.03117847442627,
      "learning_rate": 4.6275763109835644e-05,
      "loss": 0.0924,
      "step": 57100
    },
    {
      "epoch": 7.4549960866162275,
      "grad_norm": 0.010675601661205292,
      "learning_rate": 4.627250195669189e-05,
      "loss": 0.0925,
      "step": 57150
    },
    {
      "epoch": 7.461518392903731,
      "grad_norm": 0.32656481862068176,
      "learning_rate": 4.6269240803548136e-05,
      "loss": 0.1559,
      "step": 57200
    },
    {
      "epoch": 7.468040699191234,
      "grad_norm": 0.06263187527656555,
      "learning_rate": 4.626597965040438e-05,
      "loss": 0.1296,
      "step": 57250
    },
    {
      "epoch": 7.474563005478737,
      "grad_norm": 4.650710582733154,
      "learning_rate": 4.6262718497260635e-05,
      "loss": 0.0671,
      "step": 57300
    },
    {
      "epoch": 7.481085311766241,
      "grad_norm": 0.048458974808454514,
      "learning_rate": 4.625945734411688e-05,
      "loss": 0.1069,
      "step": 57350
    },
    {
      "epoch": 7.487607618053744,
      "grad_norm": 0.01607457548379898,
      "learning_rate": 4.625619619097313e-05,
      "loss": 0.0533,
      "step": 57400
    },
    {
      "epoch": 7.494129924341247,
      "grad_norm": 0.16689567267894745,
      "learning_rate": 4.625293503782938e-05,
      "loss": 0.118,
      "step": 57450
    },
    {
      "epoch": 7.50065223062875,
      "grad_norm": 18.91800880432129,
      "learning_rate": 4.624967388468563e-05,
      "loss": 0.1386,
      "step": 57500
    },
    {
      "epoch": 7.507174536916254,
      "grad_norm": 0.08429348468780518,
      "learning_rate": 4.624641273154188e-05,
      "loss": 0.1112,
      "step": 57550
    },
    {
      "epoch": 7.513696843203757,
      "grad_norm": 0.11589766293764114,
      "learning_rate": 4.6243151578398126e-05,
      "loss": 0.094,
      "step": 57600
    },
    {
      "epoch": 7.52021914949126,
      "grad_norm": 1.207889199256897,
      "learning_rate": 4.623989042525437e-05,
      "loss": 0.0777,
      "step": 57650
    },
    {
      "epoch": 7.5267414557787635,
      "grad_norm": 8.834293365478516,
      "learning_rate": 4.623662927211062e-05,
      "loss": 0.1421,
      "step": 57700
    },
    {
      "epoch": 7.533263762066267,
      "grad_norm": 4.653561592102051,
      "learning_rate": 4.623336811896687e-05,
      "loss": 0.1209,
      "step": 57750
    },
    {
      "epoch": 7.53978606835377,
      "grad_norm": 0.03320083022117615,
      "learning_rate": 4.623010696582312e-05,
      "loss": 0.0945,
      "step": 57800
    },
    {
      "epoch": 7.546308374641273,
      "grad_norm": 0.18136441707611084,
      "learning_rate": 4.6226845812679363e-05,
      "loss": 0.0789,
      "step": 57850
    },
    {
      "epoch": 7.552830680928777,
      "grad_norm": 7.0623979568481445,
      "learning_rate": 4.622358465953561e-05,
      "loss": 0.1427,
      "step": 57900
    },
    {
      "epoch": 7.55935298721628,
      "grad_norm": 0.3629106283187866,
      "learning_rate": 4.622032350639186e-05,
      "loss": 0.108,
      "step": 57950
    },
    {
      "epoch": 7.565875293503783,
      "grad_norm": 0.18153268098831177,
      "learning_rate": 4.621706235324811e-05,
      "loss": 0.0918,
      "step": 58000
    },
    {
      "epoch": 7.5723975997912865,
      "grad_norm": 9.673723220825195,
      "learning_rate": 4.621380120010436e-05,
      "loss": 0.1412,
      "step": 58050
    },
    {
      "epoch": 7.57891990607879,
      "grad_norm": 0.05431882292032242,
      "learning_rate": 4.621054004696061e-05,
      "loss": 0.0435,
      "step": 58100
    },
    {
      "epoch": 7.585442212366293,
      "grad_norm": 0.004647547844797373,
      "learning_rate": 4.620727889381686e-05,
      "loss": 0.1316,
      "step": 58150
    },
    {
      "epoch": 7.591964518653796,
      "grad_norm": 6.691464900970459,
      "learning_rate": 4.620401774067311e-05,
      "loss": 0.143,
      "step": 58200
    },
    {
      "epoch": 7.5984868249413,
      "grad_norm": 6.731837749481201,
      "learning_rate": 4.620075658752935e-05,
      "loss": 0.0645,
      "step": 58250
    },
    {
      "epoch": 7.605009131228803,
      "grad_norm": 0.555999219417572,
      "learning_rate": 4.61974954343856e-05,
      "loss": 0.1282,
      "step": 58300
    },
    {
      "epoch": 7.611531437516306,
      "grad_norm": 0.041393354535102844,
      "learning_rate": 4.619423428124185e-05,
      "loss": 0.076,
      "step": 58350
    },
    {
      "epoch": 7.618053743803809,
      "grad_norm": 0.06178669631481171,
      "learning_rate": 4.61909731280981e-05,
      "loss": 0.1006,
      "step": 58400
    },
    {
      "epoch": 7.624576050091313,
      "grad_norm": 0.01675516553223133,
      "learning_rate": 4.6187711974954345e-05,
      "loss": 0.0552,
      "step": 58450
    },
    {
      "epoch": 7.631098356378816,
      "grad_norm": 0.016584478318691254,
      "learning_rate": 4.618445082181059e-05,
      "loss": 0.1134,
      "step": 58500
    },
    {
      "epoch": 7.637620662666318,
      "grad_norm": 0.021530749276280403,
      "learning_rate": 4.6181189668666844e-05,
      "loss": 0.0832,
      "step": 58550
    },
    {
      "epoch": 7.6441429689538225,
      "grad_norm": 1.278039813041687,
      "learning_rate": 4.617792851552309e-05,
      "loss": 0.1086,
      "step": 58600
    },
    {
      "epoch": 7.650665275241325,
      "grad_norm": 0.16504336893558502,
      "learning_rate": 4.6174667362379336e-05,
      "loss": 0.0681,
      "step": 58650
    },
    {
      "epoch": 7.657187581528829,
      "grad_norm": 7.885997772216797,
      "learning_rate": 4.617140620923559e-05,
      "loss": 0.1373,
      "step": 58700
    },
    {
      "epoch": 7.6637098878163314,
      "grad_norm": 0.05284425616264343,
      "learning_rate": 4.6168145056091835e-05,
      "loss": 0.1148,
      "step": 58750
    },
    {
      "epoch": 7.670232194103836,
      "grad_norm": 0.019146371632814407,
      "learning_rate": 4.616488390294809e-05,
      "loss": 0.0796,
      "step": 58800
    },
    {
      "epoch": 7.676754500391338,
      "grad_norm": 10.336371421813965,
      "learning_rate": 4.6161622749804335e-05,
      "loss": 0.1181,
      "step": 58850
    },
    {
      "epoch": 7.683276806678841,
      "grad_norm": 0.004428307060152292,
      "learning_rate": 4.615836159666058e-05,
      "loss": 0.0948,
      "step": 58900
    },
    {
      "epoch": 7.6897991129663446,
      "grad_norm": 0.5343948006629944,
      "learning_rate": 4.615510044351683e-05,
      "loss": 0.086,
      "step": 58950
    },
    {
      "epoch": 7.696321419253848,
      "grad_norm": 6.680943965911865,
      "learning_rate": 4.615183929037308e-05,
      "loss": 0.077,
      "step": 59000
    },
    {
      "epoch": 7.702843725541351,
      "grad_norm": 9.122003555297852,
      "learning_rate": 4.6148578137229326e-05,
      "loss": 0.0739,
      "step": 59050
    },
    {
      "epoch": 7.709366031828854,
      "grad_norm": 0.10685965418815613,
      "learning_rate": 4.614531698408557e-05,
      "loss": 0.0974,
      "step": 59100
    },
    {
      "epoch": 7.715888338116358,
      "grad_norm": 0.20444297790527344,
      "learning_rate": 4.614205583094182e-05,
      "loss": 0.124,
      "step": 59150
    },
    {
      "epoch": 7.722410644403861,
      "grad_norm": 0.1529502272605896,
      "learning_rate": 4.613879467779807e-05,
      "loss": 0.136,
      "step": 59200
    },
    {
      "epoch": 7.728932950691364,
      "grad_norm": 14.4292631149292,
      "learning_rate": 4.613553352465432e-05,
      "loss": 0.0833,
      "step": 59250
    },
    {
      "epoch": 7.7354552569788675,
      "grad_norm": 4.504741668701172,
      "learning_rate": 4.613227237151057e-05,
      "loss": 0.0836,
      "step": 59300
    },
    {
      "epoch": 7.741977563266371,
      "grad_norm": 5.083582401275635,
      "learning_rate": 4.612901121836682e-05,
      "loss": 0.1263,
      "step": 59350
    },
    {
      "epoch": 7.748499869553874,
      "grad_norm": 0.04291032627224922,
      "learning_rate": 4.612575006522307e-05,
      "loss": 0.0799,
      "step": 59400
    },
    {
      "epoch": 7.755022175841377,
      "grad_norm": 17.4124755859375,
      "learning_rate": 4.6122488912079316e-05,
      "loss": 0.0936,
      "step": 59450
    },
    {
      "epoch": 7.761544482128881,
      "grad_norm": 0.005802613217383623,
      "learning_rate": 4.611922775893556e-05,
      "loss": 0.0716,
      "step": 59500
    },
    {
      "epoch": 7.768066788416384,
      "grad_norm": 0.08654152601957321,
      "learning_rate": 4.611596660579181e-05,
      "loss": 0.0466,
      "step": 59550
    },
    {
      "epoch": 7.774589094703887,
      "grad_norm": 0.0052607087418437,
      "learning_rate": 4.611270545264806e-05,
      "loss": 0.0621,
      "step": 59600
    },
    {
      "epoch": 7.78111140099139,
      "grad_norm": 0.0310360137373209,
      "learning_rate": 4.610944429950431e-05,
      "loss": 0.1532,
      "step": 59650
    },
    {
      "epoch": 7.787633707278894,
      "grad_norm": 4.268022060394287,
      "learning_rate": 4.6106183146360554e-05,
      "loss": 0.1776,
      "step": 59700
    },
    {
      "epoch": 7.794156013566397,
      "grad_norm": 0.2571624219417572,
      "learning_rate": 4.61029219932168e-05,
      "loss": 0.0553,
      "step": 59750
    },
    {
      "epoch": 7.8006783198539,
      "grad_norm": 9.912232398986816,
      "learning_rate": 4.609966084007305e-05,
      "loss": 0.151,
      "step": 59800
    },
    {
      "epoch": 7.8072006261414035,
      "grad_norm": 10.627391815185547,
      "learning_rate": 4.60963996869293e-05,
      "loss": 0.0729,
      "step": 59850
    },
    {
      "epoch": 7.813722932428907,
      "grad_norm": 1.1787629127502441,
      "learning_rate": 4.609313853378555e-05,
      "loss": 0.0949,
      "step": 59900
    },
    {
      "epoch": 7.82024523871641,
      "grad_norm": 0.09894291311502457,
      "learning_rate": 4.60898773806418e-05,
      "loss": 0.1108,
      "step": 59950
    },
    {
      "epoch": 7.826767545003913,
      "grad_norm": 0.05403996631503105,
      "learning_rate": 4.6086616227498044e-05,
      "loss": 0.0685,
      "step": 60000
    },
    {
      "epoch": 7.833289851291417,
      "grad_norm": 0.1086423397064209,
      "learning_rate": 4.60833550743543e-05,
      "loss": 0.1451,
      "step": 60050
    },
    {
      "epoch": 7.83981215757892,
      "grad_norm": 0.34577125310897827,
      "learning_rate": 4.608009392121054e-05,
      "loss": 0.1354,
      "step": 60100
    },
    {
      "epoch": 7.846334463866423,
      "grad_norm": 0.26780030131340027,
      "learning_rate": 4.607683276806679e-05,
      "loss": 0.0647,
      "step": 60150
    },
    {
      "epoch": 7.8528567701539265,
      "grad_norm": 12.4766263961792,
      "learning_rate": 4.6073571614923036e-05,
      "loss": 0.0717,
      "step": 60200
    },
    {
      "epoch": 7.85937907644143,
      "grad_norm": 0.03349870443344116,
      "learning_rate": 4.607031046177929e-05,
      "loss": 0.1032,
      "step": 60250
    },
    {
      "epoch": 7.865901382728933,
      "grad_norm": 0.4786554276943207,
      "learning_rate": 4.6067049308635535e-05,
      "loss": 0.0418,
      "step": 60300
    },
    {
      "epoch": 7.872423689016436,
      "grad_norm": 3.5424699783325195,
      "learning_rate": 4.606378815549178e-05,
      "loss": 0.0635,
      "step": 60350
    },
    {
      "epoch": 7.87894599530394,
      "grad_norm": 0.04280762001872063,
      "learning_rate": 4.6060527002348034e-05,
      "loss": 0.0722,
      "step": 60400
    },
    {
      "epoch": 7.885468301591443,
      "grad_norm": 0.010205070488154888,
      "learning_rate": 4.605726584920428e-05,
      "loss": 0.1017,
      "step": 60450
    },
    {
      "epoch": 7.891990607878946,
      "grad_norm": 2.598621368408203,
      "learning_rate": 4.6054004696060526e-05,
      "loss": 0.0977,
      "step": 60500
    },
    {
      "epoch": 7.898512914166449,
      "grad_norm": 15.338403701782227,
      "learning_rate": 4.605074354291678e-05,
      "loss": 0.0594,
      "step": 60550
    },
    {
      "epoch": 7.905035220453953,
      "grad_norm": 0.1503247320652008,
      "learning_rate": 4.6047482389773026e-05,
      "loss": 0.0778,
      "step": 60600
    },
    {
      "epoch": 7.911557526741456,
      "grad_norm": 0.020990747958421707,
      "learning_rate": 4.604422123662928e-05,
      "loss": 0.044,
      "step": 60650
    },
    {
      "epoch": 7.918079833028959,
      "grad_norm": 0.45261210203170776,
      "learning_rate": 4.6040960083485525e-05,
      "loss": 0.0933,
      "step": 60700
    },
    {
      "epoch": 7.9246021393164625,
      "grad_norm": 5.179474353790283,
      "learning_rate": 4.603769893034177e-05,
      "loss": 0.0714,
      "step": 60750
    },
    {
      "epoch": 7.931124445603966,
      "grad_norm": 0.06055101007223129,
      "learning_rate": 4.603443777719802e-05,
      "loss": 0.1155,
      "step": 60800
    },
    {
      "epoch": 7.937646751891469,
      "grad_norm": 8.09504508972168,
      "learning_rate": 4.603117662405427e-05,
      "loss": 0.0847,
      "step": 60850
    },
    {
      "epoch": 7.944169058178972,
      "grad_norm": 0.021688127890229225,
      "learning_rate": 4.6027915470910516e-05,
      "loss": 0.0881,
      "step": 60900
    },
    {
      "epoch": 7.950691364466476,
      "grad_norm": 0.35201558470726013,
      "learning_rate": 4.602465431776676e-05,
      "loss": 0.1357,
      "step": 60950
    },
    {
      "epoch": 7.957213670753979,
      "grad_norm": 0.06711867451667786,
      "learning_rate": 4.602139316462301e-05,
      "loss": 0.1304,
      "step": 61000
    },
    {
      "epoch": 7.963735977041482,
      "grad_norm": 0.1149306520819664,
      "learning_rate": 4.601813201147926e-05,
      "loss": 0.0351,
      "step": 61050
    },
    {
      "epoch": 7.9702582833289854,
      "grad_norm": 0.02731870301067829,
      "learning_rate": 4.601487085833551e-05,
      "loss": 0.1289,
      "step": 61100
    },
    {
      "epoch": 7.976780589616489,
      "grad_norm": 9.133415222167969,
      "learning_rate": 4.601160970519176e-05,
      "loss": 0.0882,
      "step": 61150
    },
    {
      "epoch": 7.983302895903992,
      "grad_norm": 8.294906616210938,
      "learning_rate": 4.600834855204801e-05,
      "loss": 0.0707,
      "step": 61200
    },
    {
      "epoch": 7.989825202191495,
      "grad_norm": 17.609678268432617,
      "learning_rate": 4.600508739890425e-05,
      "loss": 0.1008,
      "step": 61250
    },
    {
      "epoch": 7.9963475084789986,
      "grad_norm": 0.07073389738798141,
      "learning_rate": 4.6001826245760506e-05,
      "loss": 0.1683,
      "step": 61300
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9681711453169841,
      "eval_f1": 0.9682001824579695,
      "eval_loss": 0.10951113700866699,
      "eval_precision": 0.9675696796040636,
      "eval_recall": 0.9688315075639019,
      "eval_runtime": 27.0824,
      "eval_samples_per_second": 566.124,
      "eval_steps_per_second": 70.784,
      "step": 61328
    }
  ],
  "logging_steps": 50,
  "max_steps": 766600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.260928167588659e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
